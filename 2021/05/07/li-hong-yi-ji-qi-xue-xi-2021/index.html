<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="李宏毅机器学习2021, 博客制作,个人经验分享,Unity,人工智能等">
    <meta name="description" content="本站记录本人各种学习的旅途，用于巩固自我并启发后来人">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>李宏毅机器学习2021 | 微笑紫瞳星</title>
    <link rel="icon" type="image/png" href="/favicon.png">

    <link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.css">
    <link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="/css/matery.css">
    <link rel="stylesheet" type="text/css" href="/css/my.css">

    <script src="/libs/jquery/jquery.min.js"></script>

<meta name="generator" content="Hexo 5.3.0">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
<link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"></head>



   <style>
    body{
       background-image: url(https://cdn.jsdelivr.net/gh/Tokisaki-Galaxy/res/site/medias/background.jpg);
       background-repeat:no-repeat;
       background-size:cover;
       background-attachment:fixed;
    }
</style>



<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">微笑紫瞳星</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>关于</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/contact" class="waves-effect waves-light">
      
      <i class="fas fa-comments" style="zoom: 0.6;"></i>
      
      <span>留言板</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/friends" class="waves-effect waves-light">
      
      <i class="fas fa-address-book" style="zoom: 0.6;"></i>
      
      <span>友情链接</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">微笑紫瞳星</div>
        <div class="logo-desc">
            
            本站记录本人各种学习的旅途，用于巩固自我并启发后来人
            
        </div>
    </div>

    

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			关于
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/contact" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-comments"></i>
			
			留言板
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/friends" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-address-book"></i>
			
			友情链接
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/blinkfox/hexo-theme-matery" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/blinkfox/hexo-theme-matery" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('/medias/featureimages/15.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">李宏毅机器学习2021</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        width: 345px;
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        padding: 35px 0 15px 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content {
        padding-bottom: 30px;
        overflow: auto;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;

        position: absolute;
        right: 23.5vw;
        display: block;
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #floating-toc-btn {
        position: fixed;
        right: 15px;
        bottom: 76px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">
                                <span class="chip bg-color">机器学习</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="post-category">
                                机器学习
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2021-05-07
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2021-07-01
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    7.4k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    26 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        
        <!-- 代码块折行 -->
        <style type="text/css">
            code[class*="language-"], pre[class*="language-"] { white-space: pre-wrap !important; }
        </style>
        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <p>  原课程网址：<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1Wv411h7kN?p=1">https://www.bilibili.com/video/BV1Wv411h7kN?p=1</a></p>
<p>本课程专注于深度学习。</p>
<h2 id="机器学习基本概念"><a href="#机器学习基本概念" class="headerlink" title="机器学习基本概念"></a>机器学习基本概念</h2><p>机器学习的本质是<strong>找到一个对应的函数</strong>。例如声音辨识，输入是声音，输出是文字，这种输入是非常复制的，无法用手写的方法表达，需要借助机器的力量。又如AlphaGo本质也是一个函数，输入是棋盘所有子的位置，输出是下一步落子的位置。</p>
<p>如果一个函数的输出是一个数值，找这个函数的任务叫<strong>回归</strong>（regression）。</p>
<p>如果给几个选项，让函数的输出选择几个选项，那么这种方法叫<strong>分类</strong>（classfication）。</p>
<p>如果机器学习要产生一个有结构的物件，例如画图，学文章，就是让机器学会创造（Structured Learning）</p>
<h3 id="找函数的步骤"><a href="#找函数的步骤" class="headerlink" title="找函数的步骤"></a><strong>找函数的步骤</strong></h3><p>首先需要一个猜测，这个猜测是建立在对其模型有一定程度上的了解的基础上的，然后再去计算其中的参数。然后用这个模型计算的结果和实际值对比，算出差距e，差距越大效果越差。衡量这种差距的函数叫做Loss：<br>$$<br>L = \frac{1}{N}\sum e_n<br>$$<br>其中e可以取$|y-\hat{y}|$，也可以取$(y-\hat{y})^2$。</p>
<p>可以根据不同的参数制作出关于Loss的等高线图来观察哪个参数的效果最好，这种图叫做Error Surface：</p>
<img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/1.png" class>

<p>然后我们要做的第三部是<strong>最优化</strong>的过程，任务是把使得Loss最小的参数找出来。在这门课中唯一用到的方法是梯度递减（Gradient Descent）。</p>
<img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/2.png" class>

<img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/3.png" class>

<p>梯度递减的方法是先让Loss函数对参数求导，这个导数为正时，我们就让这个参数减小一定数值，反之增大，导数越大其变化幅度也就越大，这个变换还要乘上我们自己设定的学习率。这样Loss每一步都会随之减小。但是缺点是只能找到局部最优解（local minima），而不一定找到全局最优解（global minima）。</p>
<p>这三个步骤合起来称为训练，是在已知数据的基础上进行的拟合，目标是用这个拟合的函数去预测不知道的数据。</p>
<h2 id="深度学习基本概念"><a href="#深度学习基本概念" class="headerlink" title="深度学习基本概念"></a>深度学习基本概念</h2><p>通过对模型运行结果的观察，我们对事物规律会越发了解，这时，我们就有必要更换模型来达到更准确的预测值。而上面用到的都是线性模型（Linear Model），都是权重（weight）乘以已知数据相加，然后再加上偏置值（bias）。这种拟合存在一定局限性（Model Bias）。没有办法模拟很多非线性的真实情况。</p>
<p>但是，一些折线都可以用常数项加上若干的线性函数组成。</p>
<img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/4.png" class>

<p>对于曲线也可以用若干的直线去逼近它：</p>
<img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/5.png" class>

<p>这些若干的函数可以用SIgmoid函数代替，通过调整不同的c,b,w的数值，就可以实现各种各样的sigmoid函数：</p>
<img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/6.png" class>

<img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/7.png" class>

<p>改变w可以改变sigmoid函数的倾斜程度，改变b可以使其左右移动，改变c可以改变其最终高度以及倾斜度。一系列这种函数的加和，就可以很好拟合出任意的函数：</p>
<img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/8.png" class>

<p>当系统大于一维的情况同理，只是不能用平面表示而已，这样由原来的线性拟合<br>$$<br>y= b+ \sum_jw_jx_j<br>$$<br>变成了：<br>$$<br>y= b + \sum c_i sigmoid(b_i + \sum_j w_{ij}x_j)<br>$$</p>
<img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/9.png" class>

<p>这个函数比较准确地拟合出多维输入的情况下的各种变换了。这个式子是神经网络的基础：<br>$$<br>y = b + c^T \sigma(b + Wx)<br>$$<br>其中里面所有自己定义的参数拿出来拼成一个很长的向量叫做θ。这样需要设定的参数会比原来的线性拟合多得多，这样我们的目标变成了，找到这么一个θ向量，使得Loss的值最小。</p>
<p>同样最优化的过程和线性拟合的方法一样，采用梯度下降法，不断更新参数，最终得到一个最优解。</p>
<img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/10.png" class>

<p>但是在实际操作时，可以对所有的数据进行分组，每次操作一组数据。每次用一组数据算loss进行参数的更新，称为一个update。当所有的数据都进行过一次更新时，称为一个epoch。此处运用的是随机梯度下降的算法。</p>
<img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/11.png" class>

<hr>
<p>如果我们不用Sigmoid函数，也可以直接使用专注分明的函数，我们称为ReLU（Rectified Linear Unit）。一个sigmoid要替换成两个ReLU才能做到一样的事情。</p>
<img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/12.png" class>

<p>式子变成<br>$$<br>y = b + \sum_{2i} c_i max(0,b_i+ \sum_j w_{ij}x_j)<br>$$<br>这里max和Sigmoid都称为激活函数（Activation Funcion）。接下来的实验都使用了ReLU，后面会解释为什么选择这种。</p>
<hr>
<p>我们可以继续改进模型。当我们把上面得出来的数据再进行同样形式的运算，具体做多少次取决于自己，第二层的参数又是于第一层完全不同的，这就是含有隐藏层的<strong>神经网络</strong>。层数越多，神经网络就越复杂，往往也能实现更多地逻辑，会得模型准确率提高，但是也会有过拟合的问题，注意层数要适当。</p>
<img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/13.png" class>

<p>这一套基于神经网络的技术，我们称为<strong>深度学习</strong>。</p>
<h3 id="反向传播（Backpropagation）"><a href="#反向传播（Backpropagation）" class="headerlink" title="反向传播（Backpropagation）"></a>反向传播（Backpropagation）</h3><p>参考视频：<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=ibJpTrp5mcE&amp;ab_channel=Hung-yiLee">https://www.youtube.com/watch?v=ibJpTrp5mcE&amp;ab_channel=Hung-yiLee</a></p>
<p>可参考另一篇文章《Python神经网络编程》</p>
<p>误差反向传播的方法是使用<strong>梯度下降法</strong>，即需要求总误差对一个权值的导数。当所在权值在输出层之前，那么：<br>$$<br>\frac{dE}{dw_{jk}} = - (t_k - o_k) * sigmoid(\sum_j w_{jk}o_j)(1-sigmoid(\sum_j w_{jk}o_j)) * o_j<br>$$<br>其中$t_k$为该权重对应输出节点的真实值，$o_k$为现在该输出节点预测值，$o_j$是隐藏层的输出值。更新权重为<br>$$<br>\Delta w_{jk} = \alpha * \frac{dE}{dw_{jk}}<br>$$<br>如果是更加前面层级的权重，更新方法为：先通过后面的层级一直往前推算，算出该权重后的一个节点的隐藏层误差，而这个误差的计算可以直接忽略激活函数，直接按照后面的权值的比例进行计算即可。然后再运用上面的公式。当然也可以运用链式法则不断的向前递推来算梯度，计算量会大一些。</p>
<p><strong>随机梯度下降</strong></p>
<p>损失函数不计算全部样本的，而是每次随机找一个样本计算。这个方法在更新的过程中有可能跨过鞍点到达全集最优，因此在神经网络中证明非常有效。但是由于每次只能计算一个样本，因此时间复杂度太高。因此我们在实际运用中取随机梯度下降的算法的时候，我们将两者结合，把样本分成一个个batch，分批进行训练。</p>
<h2 id="Google-Colab"><a href="#Google-Colab" class="headerlink" title="Google Colab"></a>Google Colab</h2><p>请参考我的另一篇文章《Google-Colab及其使用》。</p>
<h2 id="Pytorch教学"><a href="#Pytorch教学" class="headerlink" title="Pytorch教学"></a>Pytorch教学</h2><p><strong>这部分内容请务必参考我的另一篇文章《Pytorch教学及示例》。</strong>这篇文章不仅详细讲解了Pytorch的用法和手把手的实战教学，还浅显易懂的讲解了各种基础的深度学习模型，相信对你有很大帮助。</p>
<h2 id="作业一"><a href="#作业一" class="headerlink" title="作业一"></a>作业一</h2><p>请查看我的另一篇文章《用神经网络预测新冠确诊率》。</p>
<h2 id="训练注意事项"><a href="#训练注意事项" class="headerlink" title="训练注意事项"></a>训练注意事项</h2><p>在训练的时候要记住，务必不要用测试集的结果来调节你的模型，过多地根据测试集来调节模型会因为过拟合的问题，在测试集上表现好了，但是在应用的时候表现很差。因此在训练的时候我们不要让测试集进行参与，一般我们把训练集分成两部分，一部分用来训练，一部分用来验证，这时候我们可以用N折交叉验证的方法（N-fold Cross Validation）。先把训练集三等分，三分之一用来验证，三分之二用来训练，每次用不同的三分之一来验证，取这三种情况结果的平均值作为评价模型的标准，选出最好的模型，然后用最好的模型对全部的数据进行训练，这样就不会过拟合（overfitting）在测试集上。</p>
<img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/14.png" class>

<p>训练的模型还有一种情况使其在测试集上表现糟糕：那就是Mismatch，测试集和训练集的分布不同，也就是出现了反常的情况，以往的经验已经不能作为判断的标准，就算增加再多的训练资料也无济于事。</p>
<h2 id="类神经网络训练不起来怎么办"><a href="#类神经网络训练不起来怎么办" class="headerlink" title="类神经网络训练不起来怎么办"></a>类神经网络训练不起来怎么办</h2><h3 id="局部最小值和鞍点"><a href="#局部最小值和鞍点" class="headerlink" title="局部最小值和鞍点"></a>局部最小值和鞍点</h3><p>当一个神经网络的Loss不再下降时，可能是卡在了局部最小点（local minima），也可能卡在鞍点（saddle point），也有可能是局部最大点（local maxima）。这些点统称Critical Point。 在Critical Point时有导数为0但二阶导不为0， 有：</p>
<img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/15.png" class>

<img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/16.png" class>

<p>我们可以通过公式中二阶导的项的正负来判断具体是什么点，如果对于在CriticalPoint附近的任意θ，都使得这个二阶项大于0，即H是正定矩阵，该点一定是Local Minima。如果H是负定矩阵，那么该点一定是LocalMaxima。如果H非正定也非负定，那么该点是一个SaddlePoint。判定正定负定的标准只需看矩阵的特征值（eigen values）是全正还是全负即可。而这个矩阵叫做Hessian矩阵。H矩阵不仅指出了该点所处的状态，还指出了参数更新的方向。</p>
<img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/17.png" class>

<img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/18.png" class>

<p>结论：在处于鞍点时，只需要参数往负特征值对应的特征向量方向更新，就能找到更小的Loss。这就是当梯度为0的时候参数的更新方法。但通常我们在计算时不会采用这个方法，因为运算量过大。</p>
<p>在一个神经网络模型中，参数动即上百万上千万，我们在平面上遇到的局部最小点往往是高维中的鞍点，维度越高，就有越多的路可以走，因此对于一个参数较多的神经网络，阻碍训练进程的往往是鞍点，而不是局部最小点。</p>
<h3 id="batch"><a href="#batch" class="headerlink" title="batch"></a>batch</h3><p>结论：batch_size较大时，训练速度较快，但是训练结果较差，这是optimization的问题。batch_size较小时，训练速度较慢，但训练结果较好。原因是大batch_size容易卡在鞍点出不来，而小的batch_size因为每个batch的差异性，往往另一个batch就能越过原来batch的鞍点使得训练继续下去。而且采用大的batch_size时容易在测试集上表现较差，这就是overfitting。</p>
<img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/19.png" class>

<p>其中有一篇paper的解释是小的batch_size容易跳出较为狭窄的localMnima而倾向于宽阔的localMinima，而大的batch_size容易陷入狭窄的localMinima，而train出来的function和test或者实际的function是有差距的，而狭窄地带周围梯度较大，一点差距就会导致Loss迅速变大，泛化性变差。这就是为什么小的batch_size训练结果较好的原因。</p>
<h3 id="momentum"><a href="#momentum" class="headerlink" title="momentum"></a>momentum</h3><p>参考《深度学习中的优化算法串讲》。</p>
<h3 id="自动调整学习率"><a href="#自动调整学习率" class="headerlink" title="自动调整学习率"></a>自动调整学习率</h3><img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/20.png" class>

<p>在训练的后期往往会在localMinima的附近来回震动，导致Loss没有办法继续下降，这时就要改进我们的优化算法了。</p>
<p>如果在某一个方向上的梯度较大，那么我们的学习率调小一些也不会妨碍我们的学习进程，如果在某一个方向上的梯度较小，那么训练就难以展开，我们需要大一些的学习率来维持训练进度。</p>
<p>更新学习率有几种方法：</p>
<img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/21.png" class>

<p>一种是初始学习率除以一个以往梯度平方的平均值再开根号，可以满足上述要求。这就是Adagrad的方法。缺点是更新速度较慢，以及在过于平衡的地方呆太久时会出现学习率的暴增，冲出原来的点一段距离，然后再慢慢回到原点，往往隔一段时间就会出现一次学习率暴增的现象。</p>
<img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/22.png" class>

<p>第二个方法是RMSProp，用了指数加权移动平均的概念。我们可以调整α这一项来决定之前的梯度占用的比例。这个方法的学习率变化速度要比Adarad快得多，特别是训练后期。但还是会出现学习率暴增的现象。</p>
<img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/23.png" class>

<p>第三个方法是Adam，这个是最流行的算法，是Momentum和RMSProp的合体，性能比上面的都好得多。</p>
<img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/24.png" class>

<p>解决学习率暴增现象的一个方法是上面的初始学习率也可以动态调整，随着训练的进行慢慢调小（Learning Rate Dacay），可以解决这个问题。还一个方法叫做WarmUp，主张学习率先变大后变小。这是一个黑科技，很多论文都用这个方法，但不解释原因，但用了就是好。一个解释是开始的时候先让数据不要离原点太远，先进行一些探索，然后再决定方向。详细可以查看一篇RAdam的论文，有更多解释。</p>
<img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/25.png" class>

<p>这个RAdam就是现在我们要用的优化算法的最终版本。</p>
<img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/37.png" class>



<h3 id="两种Loss函数的-比较"><a href="#两种Loss函数的-比较" class="headerlink" title="两种Loss函数的 比较"></a>两种Loss函数的 比较</h3><img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/26.png" class>

<p>做分类需要用到的是one-hot向量而不是简单地用数字表示，我们期待输入对应的输出跟one-hot向量一致。</p>
<img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/27.png" class>

<p>这部分的内容可以参考《pytoch教学及示例》的logisitic回归的内容。softmax的作用是可以让y映射到0和1直接并且所有的输出节点的值加起来等于1。</p>
<p>这个时候有两个计算Loss的方法，一个是Mean Square Error（MSE），一个是交叉熵Cross Entropy，和最大化可能性等价（maximizing likelihood）</p>
<img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/28.png" class>

<p>这两个方法比较，交叉熵损失更为优秀，最常用在分类问题中，以至于softmax和Cross Entropy都被绑定成一个函数了。</p>
<img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/29.png" class>

<p>上图是比较当输出预测值y在两种方法相同的情况下，随着y的变化各种Loss的变化。在MSE中Loss较大和Loss较小的地方梯度都是很小的，即这就导致了如果初始点在左上角的话，训练的进展会非常缓慢，甚至会训练失败；而交叉熵损失即使在Loss较大的地方梯度都都仍然有明显的梯度变化，更利于训练。</p>
<h3 id="批次标准化（Batch-Normalization）"><a href="#批次标准化（Batch-Normalization）" class="headerlink" title="批次标准化（Batch Normalization）"></a>批次标准化（Batch Normalization）</h3><img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/30.png" class>

<p>通常梯度的变化跟输入的数据息息相关，即使w变化相同的范围，x的数值大小不同也决定y的变化不同，往往x较大的时候，对应的权重w变化一点点就会造成y巨大的变化，因此x的大小就是造成不同的w梯度变化不一的原因，而如果梯度都是这样大小不一的状态，我们一般的优化算法就很难得到好的结果。如果我们能限制x的范围，使得不同x尽量在一个数量级