<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>多智能体强化学习之MADDPG</title>
      <link href="2021/10/25/duo-zhi-neng-ti-qiang-hua-xue-xi-zhi-maddpg/"/>
      <url>2021/10/25/duo-zhi-neng-ti-qiang-hua-xue-xi-zhi-maddpg/</url>
      
        <content type="html"><![CDATA[<p> 论文原文：<a href="https://arxiv.org/pdf/1706.02275.pdf">Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments</a></p><p>论文翻译：<a href="https://blog.csdn.net/qiusuoxiaozi/article/details/79066612">MADDPG翻译</a></p><p>阅读本文需要强化学习基础，可以参考我前面的文章：<a href="https://blog.csdn.net/tianjuewudi/article/details/120932729">多智能体强化学习入门</a></p><p>关于MADDPG强化学习算法的基础DDPG的可以查看我的文章：<a href="https://tianjuewudi.gitee.io/2021/07/16/qiang-hua-xue-xi-shi-jian-jiao-xue/#toc-heading-30">强化学习实践教学</a></p><p>对于MADDPG推荐的博客有：<a href="https://ask.hellobi.com/blog/wenwen/12283">探秘多智能体强化学习-MADDPG算法原理及简单实现</a>，里面包含代码实现。</p><p>github代码（基于Tensorflow）：<a href="https://github.com/princewen/tensorflow_practice/tree/master/RL/Basic-MADDPG-Demo">https://github.com/princewen/tensorflow_practice/tree/master/RL/Basic-MADDPG-Demo</a></p><p>MADDPG算法是单智能体算法DDPG在多智能体环境下的改进。其中最核心的差别就是，每个Agent的Critic部分都能够获取所有Agent的动作信息，进行中心化训练和非中心化执行。即在训练的时候，引入可以观察全局的critic来指导actor训练，而测试的时候只使用有局部观测的actor采取行动。off-line采用中心化训练，on-line采用非中心化执行，on-line与off-line的共同点就是actor，即只需要利用观测到的局部信息。</p><p>下面以两个智能体的情况为例：<br>$$<br>r_1(s,a_1) = E_{a_2 \in A,s’ \in S}[r_1(s’)p(s’|s,a_1,a_2) \pi_2(a_2| s)]<br>$$</p><p>$$<br>p_1(s’ |s ,a_1) = \sum_{a_2 \in A} p(s’ |s,a_1,a_2) \pi_2 (a_2| s)<br>$$</p><p>根据论文描述，算法在以下约束条件下运行：（1）学习的策略只能在执行时只能使用本地信息（即它们自己的观察结果），（2）与[24]不同，我们无需知道环境的可微分动力学模型（3）我们对智能体之间的通信方法不做任何结构上的假设（即，我们不假设一个可区分的通信渠道）。 一旦满足上述要求，那么将产生一个通用的多智能体学习算法，不仅可以应用于具有明确通信渠道的合作博弈，还可以应用竞争性博弈和只涉及主体之间物理交互的博弈。</p><p>论文中三个改进是：</p><ol><li>集中式训练，分布式执行：训练时采用集中式学习训练critic与actor，使用时actor只用知道局部信息就能运行。critic需要其他智能体的策略信息，本文给了一种估计其他智能体策略的方法，能够只用知道其他智能体的观测与动作。</li><li>改进了经验回放记录的数据。为了能够适用于动态环境，每一条信息由$(x,x’,a_q,…,a_n,r_1,…,r_n)$ 组成，$x = (o_1,…,o_n)$  表示每个智能体的观测。</li><li>利用策略集合效果优化（policy ensemble）：对每个智能体学习多个策略，改进时利用所有策略的整体效果进行优化。以提高算法的稳定性以及鲁棒性。</li></ol><img src="/2021/10/25/duo-zhi-neng-ti-qiang-hua-xue-xi-zhi-maddpg/1.png" class=""><h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">actor_network</span><span class="token punctuation">(</span>name<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">with</span> tf<span class="token punctuation">.</span>variable_scope<span class="token punctuation">(</span>name<span class="token punctuation">)</span> <span class="token keyword">as</span> scope<span class="token punctuation">:</span>        x <span class="token operator">=</span> state_input        x <span class="token operator">=</span> tf<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>dense<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>layer_norm<span class="token punctuation">:</span>            x <span class="token operator">=</span> tc<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>layer_norm<span class="token punctuation">(</span>x<span class="token punctuation">,</span> center<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> scale<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> tf<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>dense<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>layer_norm<span class="token punctuation">:</span>            x <span class="token operator">=</span> tc<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>layer_norm<span class="token punctuation">(</span>x<span class="token punctuation">,</span> center<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> scale<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> tf<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>dense<span class="token punctuation">(</span>x<span class="token punctuation">,</span> self<span class="token punctuation">.</span>nb_actions<span class="token punctuation">,</span>        kernel_initializer<span class="token operator">=</span>tf<span class="token punctuation">.</span>random_uniform_initializer<span class="token punctuation">(</span>minval<span class="token operator">=</span><span class="token operator">-</span><span class="token number">3e</span><span class="token operator">-</span><span class="token number">3</span><span class="token punctuation">,</span> maxval<span class="token operator">=</span><span class="token number">3e</span><span class="token operator">-</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>tanh<span class="token punctuation">(</span>x<span class="token punctuation">)</span>    <span class="token keyword">return</span> x<span class="token keyword">def</span> <span class="token function">critic_network</span><span class="token punctuation">(</span>name<span class="token punctuation">,</span> action_input<span class="token punctuation">,</span> reuse<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">with</span> tf<span class="token punctuation">.</span>variable_scope<span class="token punctuation">(</span>name<span class="token punctuation">)</span> <span class="token keyword">as</span> scope<span class="token punctuation">:</span>        <span class="token keyword">if</span> reuse<span class="token punctuation">:</span>            scope<span class="token punctuation">.</span>reuse_variables<span class="token punctuation">(</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> state_input        x <span class="token operator">=</span> tf<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>dense<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>layer_norm<span class="token punctuation">:</span>            x <span class="token operator">=</span> tc<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>layer_norm<span class="token punctuation">(</span>x<span class="token punctuation">,</span> center<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> scale<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> tf<span class="token punctuation">.</span>concat<span class="token punctuation">(</span><span class="token punctuation">[</span>x<span class="token punctuation">,</span> action_input<span class="token punctuation">]</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> tf<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>dense<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>layer_norm<span class="token punctuation">:</span>            x <span class="token operator">=</span> tc<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>layer_norm<span class="token punctuation">(</span>x<span class="token punctuation">,</span> center<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> scale<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> tf<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>dense<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> kernel_initializer<span class="token operator">=</span>tf<span class="token punctuation">.</span>random_uniform_initializer<span class="token punctuation">(</span>minval<span class="token operator">=</span><span class="token operator">-</span><span class="token number">3e</span><span class="token operator">-</span><span class="token number">3</span><span class="token punctuation">,</span> maxval<span class="token operator">=</span><span class="token number">3e</span><span class="token operator">-</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> x</code></pre><p>上面是模型部分的代码，actor部分相对于DDPG没有变化，Critic部分只需要加入其它智能体的动作作为输入即可。</p><pre class=" language-python"><code class="language-python"> <span class="token comment" spellcheck="true"># 最大化Q值</span>self<span class="token punctuation">.</span>actor_loss <span class="token operator">=</span> <span class="token operator">-</span>tf<span class="token punctuation">.</span>reduce_mean<span class="token punctuation">(</span>critic_network<span class="token punctuation">(</span>name <span class="token operator">+</span> <span class="token string">'_critic'</span><span class="token punctuation">,</span> action_input<span class="token operator">=</span>tf<span class="token punctuation">.</span>concat<span class="token punctuation">(</span><span class="token punctuation">[</span>self<span class="token punctuation">.</span>action_output<span class="token punctuation">,</span> other_action_input<span class="token punctuation">]</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>reuse<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span>self<span class="token punctuation">.</span>actor_train <span class="token operator">=</span> self<span class="token punctuation">.</span>actor_optimizer<span class="token punctuation">.</span>minimize<span class="token punctuation">(</span>self<span class="token punctuation">.</span>actor_loss<span class="token punctuation">)</span>self<span class="token punctuation">.</span>target_Q <span class="token operator">=</span> tf<span class="token punctuation">.</span>placeholder<span class="token punctuation">(</span>shape<span class="token operator">=</span><span class="token punctuation">[</span>None<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>tf<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>self<span class="token punctuation">.</span>critic_loss <span class="token operator">=</span> tf<span class="token punctuation">.</span>reduce_mean<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>square<span class="token punctuation">(</span>self<span class="token punctuation">.</span>target_Q <span class="token operator">-</span> self<span class="token punctuation">.</span>critic_output<span class="token punctuation">)</span><span class="token punctuation">)</span>self<span class="token punctuation">.</span>critic_train <span class="token operator">=</span> self<span class="token punctuation">.</span>critic_optimizer<span class="token punctuation">.</span>minimize<span class="token punctuation">(</span>self<span class="token punctuation">.</span>critic_loss<span class="token punctuation">)</span></code></pre><p>在Loss计算上可以看到依旧遵循DDPG的方法。Critic的估计值尽量靠近预测值，actor尽量使得Critic的估计值越大越好。</p><pre class=" language-python"><code class="language-python">agent1_memory<span class="token punctuation">.</span>add<span class="token punctuation">(</span>np<span class="token punctuation">.</span>vstack<span class="token punctuation">(</span><span class="token punctuation">[</span>o_n<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> o_n<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> o_n<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                  np<span class="token punctuation">.</span>vstack<span class="token punctuation">(</span><span class="token punctuation">[</span>agent1_action<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> agent2_action<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> agent3_action<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                  r_n<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>vstack<span class="token punctuation">(</span><span class="token punctuation">[</span>o_n_next<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> o_n_next<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> o_n_next<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">)</span>agent2_memory<span class="token punctuation">.</span>add<span class="token punctuation">(</span>np<span class="token punctuation">.</span>vstack<span class="token punctuation">(</span><span class="token punctuation">[</span>o_n<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> o_n<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> o_n<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                  np<span class="token punctuation">.</span>vstack<span class="token punctuation">(</span><span class="token punctuation">[</span>agent2_action<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> agent3_action<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> agent1_action<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                  r_n<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>vstack<span class="token punctuation">(</span><span class="token punctuation">[</span>o_n_next<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> o_n_next<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> o_n_next<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">)</span>agent3_memory<span class="token punctuation">.</span>add<span class="token punctuation">(</span>np<span class="token punctuation">.</span>vstack<span class="token punctuation">(</span><span class="token punctuation">[</span>o_n<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> o_n<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> o_n<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                  np<span class="token punctuation">.</span>vstack<span class="token punctuation">(</span><span class="token punctuation">[</span>agent3_action<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> agent1_action<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> agent2_action<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                  r_n<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>vstack<span class="token punctuation">(</span><span class="token punctuation">[</span>o_n_next<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> o_n_next<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> o_n_next<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">)</span></code></pre><p>在经验池储存上，MADDPG不但要储存自身的可观察的状态信息，还要储存的是其它智能体的可观测状态信息。同时储存自身和他人的动作信息。以及每个智能体的下一个状态。</p>]]></content>
      
      
      <categories>
          
          <category> 强化学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 强化学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>FPS游戏制作笔记</title>
      <link href="2021/10/23/fps-you-xi-zhi-zuo-bi-ji/"/>
      <url>2021/10/23/fps-you-xi-zhi-zuo-bi-ji/</url>
      
        <content type="html"><![CDATA[<p> 本文是根据VipSkill的FPS训练营课程整理的笔记。</p><ol><li>第一人称控制器使用的是Unity官方的，不用自己造轮子。</li><li>使用另外一个摄影机单独捕捉武器可以在第一人称视角防止武器穿模问题。</li><li>相机中使用Post-Process Layer组件，单独一个空物体挂上Post-Process Volume组件可以有效提高画面质量。</li><li>武器相对于玩家的位置为（0.386,-0.3,0.32），数值仅供参考。</li><li>本Demo使用有限状态机进行状态转换，因此PlayState属性外面还包一层，用来控制赋值时使用一次的事件。</li><li>在动画状态机中，死亡设成触发器类型，丧尸重新刷新时用再用一个触发器类型回到Idle。</li><li>怪物攻击时在攻击部位绑定一个碰撞体进行判定，碰撞体上由代码控制开关和碰撞事件。</li><li>素材图片往往是一个多张图合成的图片，需要用Sprite Editor进行分割。</li><li>玩家不需要碰撞体，一般用Character Controller来控制，通常第一人称控制器已自带。</li><li>一般来说，枪不需要真的射出子弹，只需要使用射线判断即可，否则会出现很多bug。</li><li>我们不需要在每个怪物死亡的时候都对它们Destroy删除，这会造成许多性能上的损耗，通常是将他们的状态直接设为false，到下次生成的时候设为true，然后移动到想要的位置即可，通常对于需要频繁生成删除的物体尤其需要如此。</li><li>怪物使用Unity自带的Nav Mesh Agent 组件完成寻路，再次之前要把环境设为static，并在Navigation中进行烘焙。</li><li>对于UI，玩家，怪物生成器这种只需要一个的东西，我们都可以使用单例模式，这样就能够很方便地相互调用函数。</li></ol><h2 id="玩家代码："><a href="#玩家代码：" class="headerlink" title="玩家代码："></a>玩家代码：</h2><pre class=" language-c#"><code class="language-c#">using System.Collections;using System.Collections.Generic;using UnityEngine;using UnityEngine.UI;using UnityStandardAssets.Characters.FirstPerson;public enum PlayerState{    Idle,    Shoot,    Reload}public class PlayerController : MonoBehaviour{    public static PlayerController Instance;    [SerializeField]    private PlayerState playerState;    private Animator animator;    private AudioSource audioSource;    public AudioClip[] audioClips;    private FirstPersonController firstPersonController;    public Transform weapon;    public Camera[] cameras;    [SerializeField]    private int hp = 100;    #region 射击    private float shootInterval = 0.1f;    [SerializeField]    private bool canShoot = true;    #endregion    #region 弹匣相关    [SerializeField]    private int curr_BulletNum;    private int curr_MaxBulletNum = 30;    [SerializeField]    private int standby_BulletNum;    private int standby_MaxBulletNum = 300;    #endregion    #region 射击效果    public Transform FirePoint;    public Image CrossImage;    public GameObject[] Prefab_bulletEF;    #endregion    public PlayerState PlayerState    {        get => playerState;        set {            playerState = value;            switch (playerState)            {                case PlayerState.Idle:                    animator.SetBool("Reload", false);                    animator.SetBool("Shoot", false);                    FirePoint.gameObject.SetActive(false);                    break;                case PlayerState.Shoot:                    if(curr_BulletNum > 0)                    {                        Shoot();                    }                    else                    {                        if (standby_BulletNum > 0 && curr_BulletNum < curr_MaxBulletNum )                        {                            PlayerState = PlayerState.Reload;                        }                        else                        {                            PlayerState = PlayerState.Idle;                        }                    }                    break;                case PlayerState.Reload:                                                                    FirePoint.gameObject.SetActive(false);                    Debug.Log(1);                    PlayAudio(1, 0.3f);                    animator.SetBool("Shoot", false);                    animator.SetBool("Reload", true);                    break;            }        }    }    private void Awake()    {        Instance = this;    }    public void Init()    {        hp = 100;        curr_BulletNum = curr_MaxBulletNum;        standby_BulletNum = standby_MaxBulletNum;        PlayerState = PlayerState.Idle;        UI_Panel.Instance.UpdateHP_Text(hp);    }    void Start()    {        Application.targetFrameRate = 60;        animator = GetComponentInChildren<Animator>();        audioSource = GetComponent<AudioSource>();        firstPersonController = GetComponent<FirstPersonController>();        // 初始化子弹        curr_BulletNum = curr_MaxBulletNum;        standby_BulletNum = standby_MaxBulletNum;        UpdateBulletUI();        weapon.transform.localPosition = new Vector3(0.386f, -0.3f, 0.32f);        PlayerState = PlayerState.Idle;    }    void Update()    {        StateForUpdate();        if (Input.GetKeyDown(KeyCode.O))        {            hp -= 10;            UI_Panel.Instance.UpdateHP_Text(hp);        }    }    void StateForUpdate()    {        switch (playerState)        {            case PlayerState.Idle:                if (canShoot && Input.GetMouseButton(0))                {                    PlayerState = PlayerState.Shoot;                    return;                }                if (Input.GetKeyDown(KeyCode.R) && standby_BulletNum>0 && curr_BulletNum < curr_MaxBulletNum)                {                    PlayerState = PlayerState.Reload;                    return;                }                if(Input.GetMouseButtonDown(1))                {                    StartAim();                }                if (Input.GetMouseButtonUp(1))                {                    StopAim();                }                break;            case PlayerState.Shoot:                if (Input.GetKeyDown(KeyCode.R) && standby_BulletNum > 0 && curr_BulletNum < curr_MaxBulletNum)                {                     CancelInvoke("ReShootCD");                    canShoot = true;                    PlayerState = PlayerState.Reload;                    return;                }                if (Input.GetMouseButtonDown(1))                {                    StartAim();                }                if (Input.GetMouseButtonUp(1))                {                    StopAim();                }                break;            case PlayerState.Reload:                if(animator.GetCurrentAnimatorClipInfo(0)[0].clip.name == "Replace"      //判断动画名称                    && animator.GetCurrentAnimatorStateInfo(0).normalizedTime >= 1)     //1是指动画进度播放完一遍                {                    int want = curr_MaxBulletNum - curr_BulletNum;                    if ((standby_BulletNum - want) < 0)                    {                        want = standby_BulletNum;                    }                    standby_BulletNum -= want;                    curr_BulletNum += want;                    UpdateBulletUI();                    PlayerState = PlayerState.Idle;                }                break;        }    }    public Camera ShootCamera;    Vector2 ScreenCenterPoint = new Vector2(Screen.width / 2, Screen.height / 2);    void Shoot()    {        curr_BulletNum -= 1;        UpdateBulletUI();        canShoot = false;        // 射击表现        PlayAudio(0);        animator.SetBool("Shoot", true);        FirePoint.gameObject.SetActive(true);        StartShootRecoil();        // 射线检测        //Ray ray = ShootCamera.ScreenPointToRay(Input.mousePosition);        Ray ray = ShootCamera.ScreenPointToRay(ScreenCenterPoint);        if (Physics.Raycast(ray,out RaycastHit hitInfo, 1500f))        {            if(hitInfo.collider.gameObject.tag == "Zombie")            {                //攻击效果                GameObject go = Instantiate(Prefab_bulletEF[1], hitInfo.point, Quaternion.identity);                go.transform.LookAt(ShootCamera.transform);                go.transform.SetParent(hitInfo.collider.gameObject.transform);                //敌人逻辑                ZombieController zombie = hitInfo.collider.gameObject.GetComponent<ZombieController>();                if(zombie == null)                    zombie = hitInfo.collider.gameObject.GetComponentInParent<ZombieController>();                zombie.Hurt(10);            }            else if (hitInfo.collider.gameObject != this.gameObject)            {                //攻击效果                GameObject go = Instantiate(Prefab_bulletEF[0], hitInfo.point, Quaternion.identity);                go.transform.LookAt(ShootCamera.transform);                go.transform.SetParent(hitInfo.collider.gameObject.transform);            }        }        Invoke("ReShootCD", shootInterval);    }    private void UpdateBulletUI()    {        UI_Panel.Instance.UpdateCurrBullet_Text(curr_BulletNum, curr_MaxBulletNum);        UI_Panel.Instance.UpdateStandByBullet_Text(standby_BulletNum);    }    private void ReShootCD()    {        canShoot = true;        PlayerState = PlayerState.Idle;    }    private void PlayAudio(int index,float intensity = 1.0f)    {        audioSource.PlayOneShot(audioClips[index],intensity);    //playOnShot可以叠加播放    }    private void StartShootRecoil()    {        //瞄准器        StartCoroutine(ShootRecoil_Cross());        //视角        StartCoroutine(ShootRecoil_Camera());    }    // 后坐力，瞄准器    IEnumerator ShootRecoil_Cross()    {        Vector2 scale = CrossImage.transform.localScale;        //放大        while (scale.x < 1.3)        {            yield return null;            scale.x += Time.deltaTime * 3;            scale.y += Time.deltaTime * 3;            CrossImage.transform.localScale = scale;        }        //缩小        while (scale.x > 1)        {            scale.x -= Time.deltaTime * 3;            scale.y -= Time.deltaTime * 3;            CrossImage.transform.localScale = scale;        }        scale = Vector2.one;        CrossImage.transform.localScale = scale;    }    //后坐力    IEnumerator ShootRecoil_Camera()    {        float xOffset = Random.Range(0.5f, 0.7f);        float yOffset = Random.Range(-0.2f, 0.2f);        firstPersonController.xRotOffset = xOffset;        firstPersonController.yRotOffset = yOffset;        //yield return new WaitForSeconds(0.1f);        yield return 6;        firstPersonController.xRotOffset = -xOffset;        firstPersonController.yRotOffset = -yOffset;        // yield return new WaitForSeconds(0.1f);        yield return 6;        firstPersonController.xRotOffset = 0;        firstPersonController.yRotOffset = 0;    }    void StartAim()    {        StopCoroutine("DoStartAim");        StartCoroutine("DoStartAim");    }    void StopAim()    {        StopCoroutine("DoStopAim");        StartCoroutine("DoStopAim");    }    IEnumerator DoStartAim()    {        Vector3 pos = weapon.transform.localPosition;        foreach (Camera camera in cameras)        {            camera.fieldOfView = 60;        }        while (pos.x > 0)        {            pos.x -= Time.deltaTime * 2;            weapon.transform.localPosition = pos;            yield return null;        }        pos.x = 0;        weapon.transform.localPosition = pos;        for (int i = 0; i < 10; i++)        {            yield return null;            foreach (Camera camera in cameras)            {                camera.fieldOfView -= 2;            }        }    }    IEnumerator DoStopAim()    {        Vector3 pos = weapon.transform.localPosition;        foreach (Camera camera in cameras)        {            camera.fieldOfView = 42;        }        while (pos.x < 0.386)        {            pos.x += Time.deltaTime * 2;            weapon.transform.localPosition = pos;            yield return null;        }        pos.x = 0.386f;        weapon.transform.localPosition = pos;        for (int i = 0; i < 10; i++)        {            yield return null;            foreach (Camera camera in cameras)            {                camera.fieldOfView += 2;            }        }    }    public void Hurt(int damge)    {        hp -= damge;        if(hp <= 0)        {            hp = 0;            //TODO:死亡逻辑            Dead();        }        UI_Panel.Instance.UpdateHP_Text(hp);    }    void Dead()    {        ZombieManager.Instance.StopAllZombie();        UI_Panel.Instance.PlayerDead();        firstPersonController.enabled = false;        this.enabled = false;        Cursor.lockState = CursorLockMode.Confined;        Cursor.visible = true;    }    public void Revive()    {        Init();        ZombieManager.Instance.StartAllZombie();        UI_Panel.Instance.PlayerRevive();        firstPersonController.enabled = true;        this.enabled = true;        Cursor.lockState = CursorLockMode.Locked;    }    public void Win()    {        Init();        UI_Panel.Instance.YouWin();        firstPersonController.enabled = false;        this.enabled = false;        Cursor.lockState = CursorLockMode.Confined;        Cursor.visible = true;    }    public void ExitGame()    {        Application.Quit();    }}</code></pre><h2 id="丧尸代码："><a href="#丧尸代码：" class="headerlink" title="丧尸代码："></a>丧尸代码：</h2><pre class=" language-c#"><code class="language-c#">using System.Collections;using System.Collections.Generic;using UnityEngine;using UnityEngine.AI;public enum ZombieState{    Idle,    Walk,    Run,    Attack,    Hurt,    Dead}public class ZombieController : MonoBehaviour{    [SerializeField]    private ZombieState zombieState;    private NavMeshAgent navMeshagent;    private AudioSource audioSource;    private Animator animator;    private CapsuleCollider capsuleCollider;    public ZombieWeapon weapon;    [SerializeField]    public int hp = 50;    public AudioClip[] FootstepAudioClips;    public AudioClip[] IdleAudioClips;    public AudioClip[] HurtAudioClips;    public AudioClip[] AttackAudioClips;    private Vector3 target;    public ZombieState ZombieState    {        get => zombieState;        set        {            if(zombieState == ZombieState.Dead && value != ZombieState.Idle)            {                return;            }            zombieState = value;            //Debug.Log(zombieState);            switch (zombieState)            {                case ZombieState.Idle:                    animator.SetBool("Walk", false);                    animator.SetBool("Run", false);                    navMeshagent.isStopped = true;                    Invoke("GoWalk", Random.Range(1, 3));                    break;                case ZombieState.Walk:                    animator.SetBool("Walk", true);                    animator.SetBool("Run", false);                    navMeshagent.isStopped = false;                    navMeshagent.speed = 0.5f;                    //去一个目标点                    target = GameManager.Instance.GetPoints();                    navMeshagent.SetDestination(target);                    break;                case ZombieState.Run:                    navMeshagent.speed = 3f;                    animator.SetBool("Walk", false);                    animator.SetBool("Run", true);                    navMeshagent.isStopped = false;                    break;                case ZombieState.Attack:                    navMeshagent.isStopped = true;                    animator.SetBool("Walk", false);                    animator.SetBool("Run", false);                    animator.SetTrigger("Attack");                    break;                case ZombieState.Hurt:                    navMeshagent.isStopped = true;                    animator.SetBool("Walk", false);                    animator.SetBool("Run", false);                    animator.SetTrigger("Hurt");                    break;                case ZombieState.Dead:                    navMeshagent.isStopped = true;                    animator.SetTrigger("Dead");                    animator.SetBool("Walk", false);                    animator.SetBool("Run", false);                    capsuleCollider.enabled = false;                    Invoke("Destroy", 5);                    break;            }        }    }    void Start()    {        navMeshagent = GetComponent<NavMeshAgent>();        audioSource = GetComponent<AudioSource>();        animator = GetComponent<Animator>();        capsuleCollider = GetComponent<CapsuleCollider>();        ZombieState = ZombieState.Idle;        weapon.Init(this);    }    //处理脏数据    public void Init()    {        animator.SetTrigger("Init");        capsuleCollider.enabled = true;        hp = 100;        ZombieState = ZombieState.Idle;    }    // Update is called once per frame    void Update()    {        StateForUpdate();    }    void StateForUpdate()    {        float dis = PlayerController.Instance.PlayerState == PlayerState.Shoot ? 30f : 10f;        switch (zombieState)        {            case ZombieState.Idle:                break;            case ZombieState.Walk:                if (Vector3.Distance(transform.position, PlayerController.Instance.transform.position) < dis)                {                    //去追玩家                    ZombieState = ZombieState.Run;                    return;                }                if (Vector3.Distance(target,transform.position) < 1)                {                    ZombieState = ZombieState.Idle;                }                break;            case ZombieState.Run:                navMeshagent.SetDestination(PlayerController.Instance.transform.position);                if (Vector3.Distance(transform.position, PlayerController.Instance.transform.position) < 2f)                {                    ZombieState = ZombieState.Attack;                }                break;            case ZombieState.Attack:                if (animator.GetCurrentAnimatorClipInfo(0)[0].clip.name == "Attack"                          && animator.GetCurrentAnimatorStateInfo(0).normalizedTime >= 1)                {                    ZombieState = ZombieState.Run;                }                    break;            case ZombieState.Hurt:                break;            case ZombieState.Dead:                break;        }    }    void GoWalk()    {        ZombieState = ZombieState.Walk;    }    public void Hurt(int value)    {        hp -= value;        if (hp <= 0)        {            hp = 0;            ZombieState = ZombieState.Dead;        }        else        {            //击退            StartCoroutine(MovePuase());        }    }    void Destroy()    {        ZombieManager.Instance.ZombieDead(this);    }    IEnumerator MovePuase()    {        ZombieState = ZombieState.Hurt;        yield return new WaitForSeconds(0.5f);        if(ZombieState != ZombieState.Run)        {            ZombieState = ZombieState.Run;        }    }    #region 动画事件    void IdelAudio()    {        if (Random.Range(0, 4) == 1)        {            audioSource.PlayOneShot(IdleAudioClips[Random.Range(0, IdleAudioClips.Length)]);        }    }    void FootStep()    {        audioSource.PlayOneShot(FootstepAudioClips[Random.Range(0, FootstepAudioClips.Length)]);    }    private void HurtAudio()    {        audioSource.PlayOneShot(HurtAudioClips[Random.Range(0, HurtAudioClips.Length)]);    }    private void AttackAudio()    {        audioSource.PlayOneShot(AttackAudioClips[Random.Range(0, AttackAudioClips.Length)]);    }    private void StartAttack()    {        weapon.StartAttack();    }    private void EndAttack()    {        weapon.EndAttack();    }    #endregion}</code></pre>]]></content>
      
      
      <categories>
          
          <category> 游戏开发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 游戏开发 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>多智能体深度强化学习基础</title>
      <link href="2021/10/15/duo-zhi-neng-ti-shen-du-qiang-hua-xue-xi-ji-chu/"/>
      <url>2021/10/15/duo-zhi-neng-ti-shen-du-qiang-hua-xue-xi-ji-chu/</url>
      
        <content type="html"><![CDATA[<p> 参考文章：<a href="https://zhuanlan.zhihu.com/p/272735656">万字长文：详解多智能体强化学习的基础和应用</a> 、<a href="https://zhuanlan.zhihu.com/p/53474965">多智能体强化学习入门（一）——基础知识与博弈</a></p><p>推荐文章：<a href="https://zhuanlan.zhihu.com/p/349092158">多智能体强化学习路线图 (MARL Roadmap)</a></p><p>推荐综述论文：<a href="https://arxiv.org/abs/2011.00583">An Overview of Multi-Agent Reinforcement Learning from Game Theoretical Perspective</a></p><p>参考书籍：《深度强化学习学科前沿与实战应用》</p><p> 多智能体强化学习（Multi-agent RL简称MARL），是由RL和多智能体系统结合而成的新领域。多智能体系统起源于分布式人工智能，分布式人工智能的研究目标是创建描述自然和社会系统的精确概念模型，研究内容是分布式问题求解（Distributed Problem Solving,DPS）和多智能体系统，核心是把系统分成若干智能，自治的子系统，它们在物理和地理上可以分散，可以独立执行任务，同时又可以相互通信，相互协调，共同完成任务，因此，和传统的人工智能研究相比，多智能体系统不仅考虑个体的智能程度，更多的是整个系统的自主性，社会性等。多智能体环境下具有代表性的算法是OpenAI研究团队提出的MADDPG，在后面会有专门的讲解。</p><p>目前的工作主要关注以下两方面的研究：</p><ul><li>稳定性，要求系统能收敛到均衡态，因此所有的智能体策略都要收敛到协调平衡的状态，最常用的是Nash均衡。</li><li>适应性。要求当其它智能体改变策略是，系统的表现保持不变或者更加优异，在一般情况下适应性由定义的目标最优、兼容性或者安全性等形式表达。</li></ul><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>MARL是指一组具有自我控制能力、能够相互作用的智能体，在同一环境下通过感知器、执行器操作，进而形成完全合作性、完全竞争性或者混合类型的多智能体系统，每个多智能体的奖励都会受到其他智能体动作的影响。因此，如何学习一种策略使得系统达到均衡稳态是该多智能体系统的目标。</p><h3 id="纳什均衡"><a href="#纳什均衡" class="headerlink" title="纳什均衡"></a>纳什均衡</h3><p>在矩阵博弈中，如果联结策$(\pi_1^*,…,\pi_n^*)$满足<br>$$<br>V_i(\pi_1^*,…,\pi_i^*,\pi_n^*) \geq V_i(\pi_1,…,\pi_i,\pi_n) , \forall \pi_i \in \Pi_i,i = 1,…,n<br>$$<br>则为一个纳什均衡。总体来说，纳什均衡就是一个所有智能体的联结策略。在纳什均衡处，对于所有智能体而言都不能在仅改变自身策略的情况下，来获得更大的奖励。</p><h3 id="完全合作型"><a href="#完全合作型" class="headerlink" title="完全合作型"></a>完全合作型</h3><p>完全合作性的MARL系统中，认为系统的最大奖励需要智能体的相互协调才能获得，但当每个智能体都不清楚其他人选择的动作的情况下，得到的奖励都存在不确定性，会造成整个系统的收敛困难和随机性。相反在已知其他智能体的选择的前提下 ，智能体很容易就能学习到最高的奖励。</p><h3 id="完全竞争型"><a href="#完全竞争型" class="headerlink" title="完全竞争型"></a>完全竞争型</h3><p>完全竞争型的MARL中，一般采用最大最小化原则，即无论对方采取任何行动，智能体本身总是采取使自己受益最大的动作，最优策略就是无论对手如何选择，双方都应选择竞争，这样双方获得的奖励加起来才能实现最大化。</p><h3 id="混合类型"><a href="#混合类型" class="headerlink" title="混合类型"></a>混合类型</h3><p>这种类型的RL一般针对静态任务，直接对每个智能体应用单智能体的RL算法，不需要了解其他智能体的动作，所以各自更新独立的Q函数。如果甲乙需要处理AB两个文件，显然同时处理不同的文件能够节省时间，当甲乙做各自的更新表时，双方同时处理一个文件的奖励为0，但处理在各自的Q值表中，自己处理B文件自己得到的奖励是最高的。</p><img src="/2021/10/15/duo-zhi-neng-ti-shen-du-qiang-hua-xue-xi-ji-chu/1.png" class=""><hr><h3 id="马尔科夫博弈"><a href="#马尔科夫博弈" class="headerlink" title="马尔科夫博弈"></a>马尔科夫博弈</h3><p>在单智能体中RL可以用MDP来描述，而MARL需要马尔科夫博弈来描述，又称随机博弈（stochastic game）。包含两个概念，首先是多智能体系统的状态符合马尔科夫性，即下一个状态只与向前时刻有关，与前面的时刻无关。第二，博弈描述的是多智能体之间的关系。</p><p>马尔科夫博弈描述了多智能体系统，这里定义一个元组：<br>$$<br>(N,S,a_1,a_2,…,a_N,T,\gamma,r_1,…,r_N)<br>$$<br>其中N是智能体个数，S是系统状态，一般是多智能体的联合状态，例如合一是所有智能体的坐标。$a_1,a_2,…,a_N$为智能体的动作集合，T为状态转移函数。$T：S * a_1*… * a_N * S$。</p><p>$r_i(s,a_1,…,a_N,s’)$表示智能体在s状态时执行联合动作后再状态s’得到的奖励$r_i$，<strong>当每个智能体奖励函数一致时，智能体之间是合作关系，奖励函数相反时，智能体之间是竞争关系</strong>。奖励函数介于两者直接是混合关系。</p><hr><h3 id="优势与挑战"><a href="#优势与挑战" class="headerlink" title="优势与挑战"></a>优势与挑战</h3><p>多智能体学习的优势是可以通过不同智能体之间共享经验，从而更快、更好地完成任务。当一个智能体出现故障时，其他智能体可以代替执行任务，提高系统的鲁棒性。当系统需要提高扩展性时，可以随时引入新的智能体。</p><p>同时MARL面临的挑战是随着状态、动作和智能体数目的增加，系统的计算复杂度也指数增长，并且难以定义学习目标，无法做到单独最大化某个智能体的奖励。其次，系统难以收敛到一个最优解。所有的智能体都是在一个不断变化的环节中同时学习，最后的策略会随着其他智能体策略的改变而改变，最后导致探索过程更加复杂。因此探索过程不能只满足获取环境信息，还需要其他智能体的信息，以此相互适应，但有不能过度探索，否则会打破整个系统的平衡，影响其他智能体的策略学习。</p><h2 id="部分可见马尔科夫决策过程（POMDP）"><a href="#部分可见马尔科夫决策过程（POMDP）" class="headerlink" title="部分可见马尔科夫决策过程（POMDP）"></a>部分可见马尔科夫决策过程（POMDP）</h2><p>在马尔科夫决策过程（简称MDP）中，一个重要前提是智能体对环境的观察是完整的，而现实中的智能体往往只能观察到部分信息，比如很多情况下难以获取系统的精确状态，另外就是智能体的传感器只能覆盖整个环境的一小部分。针对上述问题，部分可见马尔科夫决策过程（简称POMDP）这个更接近现实世界的模型被提出，这可以看作MDP的扩展。</p><p>通常，我们采用一个七元组$(S,A,T,R,O,Z,\gamma)$来描述POMDP，其中S、A、T、R、γ和MDP的定义一致。另外有：</p><p>O：一组观察结果集，比如机器人传感器获得的环境信息，在MDP中由于完全了解系统状态，O=S，在POMDP中观察仅在概率上取决于潜在的环境信息，因为在不同的环境状态中可以得到相同的观察，因此确定智能体所处的状态变得困难。</p><p>Z：$S  *  A \rightarrow \Delta (O)$是一个观察函数，表明系统状态和观察值之间的关系，具体是在智能体在执行动作a进入环境状态s’后得到观察者的概率。<br>$$<br>Z(s’,a,o’) = P_r(O^{t+1} = o’|S^{t+1}=s’,A^t = a)<br>$$<br>现在整体一下流程：在时刻t，环境处于状态s，智能体采取动作a，根据状态转移方程$T(s’|s,a)$进入环境状态s’，同时智能体获得观察值o，这取决于概率$Z(o’|s’,a) $，最后智能体得到奖励$r = r(s,a)$，目标是使智能体在每个时间步选择的动作能够最大化未来的折扣奖励。</p><hr><p>在POMDP中，智能体不能确信自己所处的状态，因此决策的基础是当前所处状态的概率。智能体需要得到观测值来更新自己对当前所处状态的可信度，“信息收集”的动作可以让智能体先运动到邻近的位置，这个位置收集的信息可能加大智能体对自己所处状态的可信度。虽然无法得知状态，但是可以通过观察和动作的历史来决策，t时刻的观察和动作的历史定义为：<br>$$<br>h_t = (a_0,o_1,…,o_{t-1},a_{t-1},o_t)<br>$$<br>为了采用较短的历史代替所有的观察和行为，引入了信念状态$b(s)$的概念，表示对当前所处状态的可信度。<br>$$<br>b_t(s) = P_r(s|h_t)<br>$$<br>Sondik证明$b_t(s)$是对历史$h_t$的充分估计，在所有状态上维护一个概率分布与维护一个完整历史提供同样的信息。这样就能转化为基于信念空间状态的马尔科夫链来求解，因此POMDP问题的求解转化为求解信念状态函数和策略问题。</p><ul><li>信念状态函数$B(s) ：O * A * B(s) \rightarrow B(s)$</li><li>策略π：$B(s) \rightarrow A$</li></ul><p>随着信念空间的引入，POMDP问题就可以看成是Belief MDP问题。寻求一种最优策略将当前信念状态隐射到智能体的动作上，根据当前信念状态和行为就可以决定下一周期的信念状态和行为。Belief MDP通常被描述为四元组$&lt;B,A,T^b,r^b&gt;$，具体如下：</p><ul><li>$B：B = \Delta (S)$是一系列连续的状态空间</li><li>A：动作空间，和POMDP的定义一致。</li><li>$T_b：B * A \rightarrow B$，状态转移函数，推导如下：</li></ul><p>$$<br>T_b (b,a,b’) = P_r (b’|b,a) = \sum_{o \in O} P_r (b’|a,b,o) P_r(o|a,b) \<br>= \sum_{o \in O} P_r (b’|a,b,o) \sum_{s’ \in S} Z(s’,a,o) \sum_{s \in S} T(s,a,s’) b(s)<br>$$</p><p>$$<br>P_r (b’|a,b,o)=<br>\begin{cases}<br>1,\quad b_o^a = b’\<br>0, \quad b_o^a \neq b’<br>\end{cases}<br>\tag{1}<br>$$</p><p>信念度的更新可以表示为：<br>$$<br>b_o^a (s’) = \frac{Z(s’,a,o) \sum_{s \in S} T(s,a,s’)b(s)}{P_r(o|a,b)}<br>$$<br>之后POMDP的最优策略的选择和值函数的构建可以类似普通的MDP决策进行，在Belief MDP下，一般定义值函数为<br>$$<br>V_{t+1}(b) = \max_{a \in A} [r^b(b,a) + \gamma \sum_{b’ \in B} T^b(b,a,b’)V_t(b’)]<br>$$<br>根据原始POMDP，有：<br>$$<br>V_{t+1}(b) = \max_{a \in A} [\sum_{s \in S}b(s) r(s,a) + \gamma \sum_{o \in O} P_r(o|a,b)V_t(b_o^a)]<br>$$</p><p>$$<br>P_r(o|a,b) = \sum_{s’ \in S} Z(s’,a,o) \sum_{s \in S} T(s’|s,a)b(s)<br>$$</p><p>$$<br>\pi_{t+1}(b) = argmax_{a \in A} [\sum_{s \in S} b(s) r(s,a) + \gamma \sum_{o \in O} P_r(o|a,b) V_t(b_o^a)]<br>$$</p><hr><p>目前对POMDP算法的研究主要分为<strong>精确算法和近似算法</strong>，两者都使用了基于信念状态的模型，表示系统实际处于每个状态的概率。</p><p>由于POMDP模型可以更加真实反映客观世界的模型，对环境，动作和观察的不确定性有进行良好的建模，POMDP被应用到机器人路径规划、机器人导航、用户兴趣获取、对话系统等领域，这些领域要求尽量避免人体直接接触，需要依靠机器人进行操作，而在放射性废物回收，深海探矿、管道网络的检修和维护也非常符合POMDP模型。</p><p>在智能体面临行动产生结果的不确定性和实际状态的不确定性是，可以使用POMDP，例如最小化机器使用费用，最大化生产能力，道路检测管理，电网出现故障需要快速找到故障并排除，还可以应用到医疗诊断的问题上，通过病人的病症确定治疗方案。在军事领域，应用有移动目标的查找、跟踪、拯救，目标的辨认、武器的使用和分配等。</p><hr><h2 id="基于值函数的多智能体强化学习"><a href="#基于值函数的多智能体强化学习" class="headerlink" title="基于值函数的多智能体强化学习"></a>基于值函数的多智能体强化学习</h2><h3 id="1-基于DQN"><a href="#1-基于DQN" class="headerlink" title="1. 基于DQN"></a>1. 基于DQN</h3><p>在多智能体协作的问题和研究中，相对主流的方法是2016年提出的CommNet和DLAL（RIAL），基于两者发展出的最新方法是2017年提出的BiCNet，它在个体行为上使用了DDPG代替DQN，群体链接中采用了双向循环网络取代单向网络。</p><h3 id="2-增强智能体间学习"><a href="#2-增强智能体间学习" class="headerlink" title="2.增强智能体间学习"></a>2.增强智能体间学习</h3><p>增强智能体间学习（Reinforced Inter-Agent Learning，<strong>RIAL</strong>）首先提出一组需要通信的多智能体，然后为这些智能体指定环境参数和学习算法，最后分析智能体如何学习通信协议。所有智能体有共同目标，虽然没有智能体可以观察底层的马尔科夫状态，但是每个智能体都接收到于该状态相关的观察，因此RIAL所考虑的任务是完全合作的，部分可观察的，顺序的多智能体决策问题，因此必须学习通信协议，学习时带宽不受限制。在执行过程中，智能体只能通过有限带宽的通道进行通信。</p><p>RIAL使用的是DRQN（Deep Recurrent Q-Network）解决部分可观测问题。它不是用前馈网络近似$Q(s,a)$，而是使用一个递归神经网络近似$Q(o,a)$，这样可以保持内部的状态并随时间累积观测值。，可以添加一个额外的输入$h_{t-1}$代表网络的隐藏状态，产生$Q(o_t,h_{t-1},a)$。</p><p>当多个智能体和部分可观察性共存时，智能体就有了交流的动机，在没有预先给出协议的情况下，智能体必须开发并同意这样的协议解决问题，协议是从行为观察历史到消息序列的映射，智能体还需要协调信息的发送和解释，这是非常困难的。</p><p>我们定义在RLAL中，每个智能体的Q网络表示为<br>$$<br>Q^i (o_t^i,v_{t-1}^{i’},h_{t-1}^i,a^i)<br>$$<br>$h_{t-1}^i$和$o_t^i$是每个智能体的个体隐藏状态和换成，i是智能体的索引。</p><p>RIAL将网络分成$Q_a^i$和$Q_m^i$分别是环境动作和通信动作的Q值，动作选择器使用ε-greedy策略分别从动作网络中选择$a_t^i$和$m_t^i$，因此网络有|U|+|M|种输出。</p><p>$Q_a^i$和$Q_m^i$都使用DQN进行训练，但不使用经验复用池，以解释多个智能体并发学习时出现的额非平稳性，应为它会使经验过时并具有误导性。为了考虑部分可观测性，将智能体采取的动作a和m作为下一个时间步的输入。</p><p>如果智能体之间共享参数，变可以拓展RIAL为集中学习的网络，此变体只学习一个网络，所有智能体都使用这个网络。但智能体仍然可以表现不同，因为它们接收不同的观察结果，从而演变出不同的隐藏状态，此外每个智能体都接收自己的索引a作为输入从而进行个体化。参数共享大大减少了需要学习的参数量，从而加快了学习速度，在参数共享下，智能体学习两个Q函数$Q_a(o_t^i,m_{t-1}^{i’},h_{t-1}^{t’},a_{t-1}^i,m_{t-1}^i,i,a_t^i)$和$Q_m(.)$，对应动作a和信息m。$a_{t-1}^i$和$m_{t-1}^i$是上一个动作的输入，$m_{t-1}^{t’}$是其他智能体的信息。</p><img src="/2021/10/15/duo-zhi-neng-ti-shen-du-qiang-hua-xue-xi-ji-chu/2.png" class=""><img src="/2021/10/15/duo-zhi-neng-ti-shen-du-qiang-hua-xue-xi-ji-chu/3.png" class=""><p>在不考虑参数共享的情况下，每个智能体包含一个RNN,RIAL将其为T时间步长张开，包括一个内部状态h、一个用于产生任务输出z的输入网络，以及一个用于Q值的输出网络和信息m。智能体i的输入被定义为$(o_t^i,m_{t-1}^{i’},a_{t-1}^i,i)$的元组，输入i和$a_{t-1}^i$通过表传递，$m_{t-1}^{i’}$通过一个一层MLP，两者都产生大小为128的输出，$o_t^i$通过任务特定网络处理，产生相同大小的附加输出。通过这些元素求和产生状态输出，具体如下：</p><p>$$<br>z_t^i = (TaskMLP(o_t^i) + MLP[|M|,128] (m_{t-1})+ Lookup(a_{t-1}^i) + Lookup(i))<br>$$</p><p>同时一个BN层用于预处理$m_{t-1}$时，网络性能和稳定性可以处理更好。通过具有GRU的2层RNN处理$z_t^i$,$h_{1,t}^i = GRU[128,128] (z_t^i,h_{1,t-1}^i)$，其用于近似智能体的动作观察历史。最后顶部GRU层的输出$h_{2,t}^i$，是通过2层MLP $Q_t^i$，$m_t^i = MLP[128,128,(|U| + |M|)] (h_{2,t}^i)$。</p><pre class=" language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">SeitchCNet</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>opt<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>opt <span class="token operator">=</span> opt        dropout_rate <span class="token operator">=</span> opt<span class="token punctuation">.</span>model_rnn_dropout_rate <span class="token operator">or</span> <span class="token number">0</span>        self<span class="token punctuation">.</span>rnn <span class="token operator">=</span> nn<span class="token punctuation">.</span>GRU<span class="token punctuation">(</span>input_size <span class="token operator">=</span> opt<span class="token punctuation">.</span>model_rnn_size<span class="token punctuation">,</span>                          hidden_size <span class="token operator">=</span> opt<span class="token punctuation">.</span>model_rnn_size<span class="token punctuation">,</span>                          num_layers <span class="token operator">=</span> opt<span class="token punctuation">.</span>model_rnn_layers<span class="token punctuation">,</span>                          dropout <span class="token operator">=</span> dropout_rate<span class="token punctuation">,</span>                         batch_first <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>outputs <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> dropout_rate <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">:</span>            self<span class="token punctuation">.</span>outputs<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">'dropout1'</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>dropout_rate<span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>outputs<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">'linear1'</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>opt<span class="token punctuation">.</span>model_rnn_size<span class="token punctuation">,</span>opt<span class="token punctuation">.</span>model_rnn_size<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> opt<span class="token punctuation">.</span>model_bn<span class="token punctuation">:</span>            self<span class="token punctuation">.</span>outputs<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">'batchnorml'</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>BatchNormld<span class="token punctuation">(</span>opt<span class="token punctuation">.</span>model_rnn_size<span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>outputs<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">'relu1'</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>outputs<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">'linear2'</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>opt<span class="token punctuation">.</span>model_rnn_size<span class="token punctuation">,</span>opt<span class="token punctuation">.</span>game_action_space_total<span class="token punctuation">)</span><span class="token punctuation">)</span>            <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>o_t<span class="token punctuation">,</span>messages<span class="token punctuation">,</span>hidden<span class="token punctuation">,</span>prev_action<span class="token punctuation">,</span>agent_index<span class="token punctuation">)</span><span class="token punctuation">:</span>            opt <span class="token operator">=</span> self<span class="token punctuation">.</span>opt            o_t <span class="token operator">=</span> Variable<span class="token punctuation">(</span>o_t<span class="token punctuation">)</span>            hidden <span class="token operator">=</span> Variable<span class="token punctuation">(</span>o_t<span class="token punctuation">)</span>            prev_message <span class="token operator">=</span> None            <span class="token keyword">if</span> opt<span class="token punctuation">.</span>model_dial<span class="token punctuation">:</span>                <span class="token keyword">if</span> opt<span class="token punctuation">.</span>model_action_aware<span class="token punctuation">:</span>                    prev_action <span class="token operator">=</span> Variable<span class="token punctuation">(</span>prev_action<span class="token punctuation">)</span>            <span class="token keyword">else</span><span class="token punctuation">:</span>                <span class="token keyword">if</span> opt<span class="token punctuation">.</span>model_action_aware<span class="token punctuation">:</span>                    prev_action <span class="token punctuation">,</span> prev_message <span class="token operator">=</span> prev_action                    prev_action <span class="token operator">=</span> Variable<span class="token punctuation">(</span>prev_message<span class="token punctuation">)</span>                    prev_message <span class="token operator">=</span> Variable<span class="token punctuation">(</span>prev_message<span class="token punctuation">)</span>                messages <span class="token operator">=</span> Variable<span class="token punctuation">(</span>messages<span class="token punctuation">)</span>            agent_index <span class="token operator">=</span> Variable<span class="token punctuation">(</span>agent_index<span class="token punctuation">)</span>            z_a<span class="token punctuation">,</span> z_o<span class="token punctuation">,</span> z_u<span class="token punctuation">,</span> z_m <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">*</span> <span class="token number">4</span>            z_a <span class="token operator">=</span> self<span class="token punctuation">.</span>agent_lookup<span class="token punctuation">(</span>agent_index<span class="token punctuation">)</span>            z_o <span class="token operator">=</span> self<span class="token punctuation">.</span>state_lookup<span class="token punctuation">(</span>o_t<span class="token punctuation">)</span>            <span class="token keyword">if</span> opt<span class="token punctuation">.</span>model_action_aware<span class="token punctuation">:</span>                z_u <span class="token operator">=</span> self<span class="token punctuation">.</span>prev_action_lookup<span class="token punctuation">(</span>prev_action<span class="token punctuation">)</span>                <span class="token keyword">if</span> prev_message <span class="token keyword">is</span> <span class="token operator">not</span> None<span class="token punctuation">:</span>                    z_u <span class="token operator">+=</span> self<span class="token punctuation">.</span>prev_message_lookup<span class="token punctuation">(</span>prev_message<span class="token punctuation">)</span>            z_m <span class="token operator">=</span> self<span class="token punctuation">.</span>messages_mlp<span class="token punctuation">(</span>messages<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span>self<span class="token punctuation">.</span>comm_size<span class="token punctuation">)</span><span class="token punctuation">)</span>            z <span class="token operator">=</span> z_a <span class="token operator">+</span> z_o <span class="token operator">+</span> z_u <span class="token operator">+</span> z_m            z <span class="token operator">=</span> z<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>            rnn_out<span class="token punctuation">,</span> h_out <span class="token operator">=</span> self<span class="token punctuation">.</span>rnn<span class="token punctuation">(</span>z<span class="token punctuation">,</span>hidden<span class="token punctuation">)</span>            outputs <span class="token operator">=</span> self<span class="token punctuation">.</span>outputs<span class="token punctuation">(</span>rnn_out<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>            <span class="token keyword">return</span> h_out<span class="token punctuation">,</span> outputs</code></pre><h3 id="3-协同多智能体学习的价值分解网络"><a href="#3-协同多智能体学习的价值分解网络" class="headerlink" title="3.协同多智能体学习的价值分解网络"></a>3.协同多智能体学习的价值分解网络</h3><p>论文：<a href="http://arxiv.org/abs/1706.05296">Value-Decomposition Networks For Cooperative Multi-Agent Learning</a></p><p>协同多智能体学习的价值分解网络（Value-Decomposition Networks,VDN），目的是从团队奖励中学习一个最优的线性价值分解，通过代表单个分量价值函数的深度神经网络对总Q梯度进行反向传播。这种附加价值分解是为了避免独立智能体出现虚假奖励。每个智能体学习的隐式值函数值依赖于局部的观察，因此更容易学习。</p><img src="/2021/10/15/duo-zhi-neng-ti-shen-du-qiang-hua-xue-xi-ji-chu/4.png" class=""><p>在原先的DQN多智能体基础上，VDN添加了增强功能，左图显示了随着时间的推移，本地观察如何进入两个智能体的网络（如图中所示的三个步骤），通过低线性层进循环层，然后产生单独的Q值。右图的网络说明了价值分解的主要贡献，VDN产生单独的“值”，它们相加到用于训练的联合Q函数，而动作则独立于各个输出而产生。</p><p>VDN假设联合价值函数可以分解为智能体的价值函数：<br>$$<br>Q((h^1,h^2,…,h^N),(a^1,a^2,…a^N)) \approx \sum_{i = 1}^N \tilde Q(h^i,a^i)<br>$$<br>其中$\tilde Q$只依赖于每个智能体的本地观察，通过求和从Q-learning规则中使用联合奖励反向传播来学习$\tilde Q$，即它是隐式学习的，而不是特定于智能体i的任何奖励中学习的，并且不强制$\tilde Q$是任何特定奖励的行为价值函数。定义：<br>$$<br>Q^{\pi}(s,a) = E[\sum_{t-1}^{\infty} \gamma^{t-1} r(s_t,a_t) | s_t = s,a_1 = a;\pi] \<br>= E[\sum_{t-1}^{\infty} \gamma^{t-1} r_1(o_t^1,a_t^1) | s_t = s,a_1 = a;\pi] + E[\sum_{t-1}^{\infty} \gamma^{t-1} r_2(o_t^2,a_t^2) | s_t = s,a_1 = a;\pi] \<br>= \bar Q_1^{\pi} (s,a) + \bar Q_1^{\pi} (s,a)<br>$$<br>如果$(o^1,a^1)$不足以完全建模$\bar Q_1^{\pi} (s,a)$，则智能体1可以将来自历史观察的信息储存在LSTM中，或者从通信信道中的智能体2接收信息，VDN可以做出预测：<br>$$<br>Q^{\pi} (s,a) =\bar Q_1^{\pi} (s,a) + \bar Q_2^{\pi} (s,a) = \tilde Q_1^{\pi} (h^1,a^1) + \tilde Q_2^{\pi} (h^2,a^2)<br>$$<br>可能的或VDN结构鼓励将此分解成更简单的功能。</p><p>VDN是将复杂的学习问题自动分解为更容易学习的局部子问题的一个步骤。此方法可以与权重共享和信息通道很好地结合在一起，从而是智能体能够始终最优地解决新的测试挑战，在再来的工作中，VDN有希望继续探讨基于非线性值聚合的价值分解研究。</p><h3 id="4-多智能体强化学习的稳定经验复用池"><a href="#4-多智能体强化学习的稳定经验复用池" class="headerlink" title="4.多智能体强化学习的稳定经验复用池"></a>4.多智能体强化学习的稳定经验复用池</h3><p>论文原文：<a href="https://arxiv.org/pdf/1702.08887.pdf">Stabilising Experience Replay for Deep Multi-Agent Reinforcement Learning</a></p><p>如何协调经验复用池于IQL的关系正在成为将深度MARL扩展到更复杂任务的关键障碍。MARL稳定经验复用池包含两种方法：一是将复用池中的经验定义为非环境数据。通过使用该元组中的联合动作的概率来增强复用池中的每条经验，根据当时使用的策略，稍后元组被采样用于训练时，可以计算采样权重校正。旧数据倾向于较低的重要性权重，因此该方法会自然衰减数据。二是通过让每个智能体学习一种策略来避免IQL的非稳定性。受hyper Q-learning的启发，该策略根据观察其行为推断出的其他智。能体策略的估计。具体是每个智能体值需要满足一个低维指纹的条件，该指纹足以消除复用池中采样经验原则位置的歧义。</p><h3 id="5-单调值函数分解（QMIX）"><a href="#5-单调值函数分解（QMIX）" class="headerlink" title="5. 单调值函数分解（QMIX）"></a>5. 单调值函数分解（QMIX）</h3><p><a href="http://arxiv.org/abs/1803.11485v2">QMIX: Monotonic Value Function Factorisation for Deep Multi-Agent Reinforcement Learning</a></p><p>MARL中如何表示和使用动作价值函数使得系统达到一个均衡稳态是多智能体系统的目标。</p><p>IQL让每个智能体单独定义一个函数$Q_a$。这种方法不能明确表示智能体之间的相互作用，并且可能不会收敛，因为每个智能体的学习都被其他智能体的探索和学习混淆。</p><p>另一种是学习一个完全集中式的动作价值函数，即反事实多智能体（counterfactual Multi-Agent COMA）,用它来指导actor-critic框架中的分布策略的优化，但需要on-policy学习，导致样本效率低下，并且存在多个智能体是，训练完全集中的critic是不切实际的。</p><p>因此这里采用了QMIX，和VDN一样采用集中式分解Q的方法，处于IQL和COMA之间，但可以表示更丰富的动作价值函数。由于VDN的完全因子分解对于获得分散策略并不是必须的。相反，QMIX只需要确保在Q上执行的全局argmax与在每个Q上执行的一组单独的argmax参数产生相同的结果。因此，只需要求对$Q^{\pi}$于每个$Q_a$之间存在单调约束，即：<br>$$<br>\frac{\delta Q^{\pi}}{\delta Q_a} \geq 0<br>$$<br>不同于VDN简单的总和，QMIX有代表每个$Q_a$的智能体网络和将它们组合到$Q^{\pi}$中的混合网络组成，以复杂的非线性方式确保集中式和分散式策略之间的一致性。同时，它通过限制混合网络具有正权重来强制执行上式的约束，因此QMIX可以表示复杂的集中式动作价值函数，可以很好扩展智能体数量，并允许通过线性时间的argmax操作轻松得到分散策略。</p><img src="/2021/10/15/duo-zhi-neng-ti-shen-du-qiang-hua-xue-xi-ji-chu/5.png" class=""><h3 id="6-深度强化学习中的对立智能体建模（DRON）"><a href="#6-深度强化学习中的对立智能体建模（DRON）" class="headerlink" title="6.深度强化学习中的对立智能体建模（DRON）"></a>6.深度强化学习中的对立智能体建模（DRON）</h3><p>论文原文：<a href="https://arxiv.org/pdf/1609.05559.pdf">Opponent Modeling in Deep Reinforcement Learning</a></p><p>在一些协作或竞争的任务环境中工作的智能体，需要预测其他智能体行为并快速做出决策，对立智能体建模（DRON）的目标是在RL环境中建立一个通用的对手建模框架，是智能体能够利用各种对手的特质。</p><p>DRON在对手的策略中模拟不确定性，而不是将其分类为一组固定组合。DRON根据过去的观察来学习对手的隐藏表示，并使用隐藏表示来计算自适应响应。此外DRON还提出两种体系结构，一种使用简单级联来组合这两种模块，另一种使用基于混合专家网络（mixture-of-expert network）的体系结构。虽然DRON隐含地对对手进行建模，但可以通过多任务处理增加额外的监督，例如采取动作或策略。</p><h3 id="7-平均场多智能体强化学习"><a href="#7-平均场多智能体强化学习" class="headerlink" title="7.平均场多智能体强化学习"></a>7.平均场多智能体强化学习</h3><p>均值场理论论文：Phase transitions and critical phenomena</p><p>平均场Q学习论文：<a href="https://arxiv.org/pdf/1802.05438.pdf">Mean Field Multi-Agent Reinforcement Learning</a></p><p>当大量智能体共存时会由于维度的增大和智能体的交互的指数增长，学习变得困难，联合学习也会带来Nash均衡问题。</p><p>现在考虑每个智能体都能于一组其他智能体进行交互，通过一系列直接交互，任何一对智能体对在全局范围内相互联系。可以使用均质场理论（mean field theory）来解决可扩展性，即智能体群中的相互作用近似于使用来自某个整体智能体的平均效应和单个智能体的相互作用。所以，学习是在两个实体之间而不是许多实体直接相互增强：单个智能体的最优策略的学习基于智能体的数目动态，同时根据个体策略更新动态数目，基于这样的想法，提出平均场Q学习（mean field Q-learning）和平均场actor-critic算法。该算法分析了解决方案对Nash均衡的收敛性，并且在资源分配、伊辛模型估计（Ising model estimation）和战斗游戏方面的实验证明了平均场方法的学习效果。</p><hr><h2 id="基于策略的多智能体强化学习"><a href="#基于策略的多智能体强化学习" class="headerlink" title="基于策略的多智能体强化学习"></a>基于策略的多智能体强化学习</h2><h3 id="1-基于自身策略的其他智能体行为预测（SOM）"><a href="#1-基于自身策略的其他智能体行为预测（SOM）" class="headerlink" title="1.基于自身策略的其他智能体行为预测（SOM）"></a>1.基于自身策略的其他智能体行为预测（SOM）</h3><p>论文：<a href="http://arxiv.org/abs/1802.09640">Modeling Others using Oneself in Multi-Agent Reinforcement Learning</a></p><h3 id="2-双重平均方案（PD-DistlAG）"><a href="#2-双重平均方案（PD-DistlAG）" class="headerlink" title="2.双重平均方案（PD-DistlAG）"></a>2.双重平均方案（PD-DistlAG）</h3><p>论文：<a href="https://arxiv.org/abs/1806.00877">Multi-Agent Reinforcement Learning via Double Averaging Primal-Dual Optimization</a></p><h3 id="3-多智能体深度强化学习的统一博弈论方法（PRSO）"><a href="#3-多智能体深度强化学习的统一博弈论方法（PRSO）" class="headerlink" title="3.多智能体深度强化学习的统一博弈论方法（PRSO）"></a>3.多智能体深度强化学习的统一博弈论方法（PRSO）</h3><p>论文： <a href="https://arxiv.org/abs/1711.00832">A Unified Game-Theoretic Approach to Multi-agent Reinforcement Learning</a> </p><h2 id="基于AC框架的多智能体强化学习"><a href="#基于AC框架的多智能体强化学习" class="headerlink" title="基于AC框架的多智能体强化学习"></a>基于AC框架的多智能体强化学习</h2><h3 id="1-多智能体深度确定性策略梯度（MADDPG）"><a href="#1-多智能体深度确定性策略梯度（MADDPG）" class="headerlink" title="1. 多智能体深度确定性策略梯度（MADDPG）"></a>1. 多智能体深度确定性策略梯度（MADDPG）</h3><p>论文：<a href="https://arxiv.org/abs/1706.02275">Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments</a></p><h3 id="2-多智能体集中规划的价值函数策略梯度（Dec-POMDP）"><a href="#2-多智能体集中规划的价值函数策略梯度（Dec-POMDP）" class="headerlink" title="2.多智能体集中规划的价值函数策略梯度（Dec-POMDP）"></a>2.多智能体集中规划的价值函数策略梯度（Dec-POMDP）</h3><p>论文：<a href="https://arxiv.org/abs/1804.02884v1">Policy Gradient With Value Function Approximation For Collective Multiagent Planning</a></p><h3 id="3-多智能体系统的策略表示学习"><a href="#3-多智能体系统的策略表示学习" class="headerlink" title="3.多智能体系统的策略表示学习"></a>3.多智能体系统的策略表示学习</h3><p>论文：<a href="https://arxiv.org/pdf/1806.06464.pdf">Learning Policy Representations in Multiagent Systems</a></p><h3 id="4-部分可观察环境下的多智能体策略优化"><a href="#4-部分可观察环境下的多智能体策略优化" class="headerlink" title="4.部分可观察环境下的多智能体策略优化"></a>4.部分可观察环境下的多智能体策略优化</h3><p>论文：<a href="http://arxiv.org/abs/1810.09026v4">Actor-Critic Policy Optimization in Partially Observable Multiagent Environments</a></p><h3 id="5-基于联网智能体的完全去中心化MARL"><a href="#5-基于联网智能体的完全去中心化MARL" class="headerlink" title="5. 基于联网智能体的完全去中心化MARL"></a>5. 基于联网智能体的完全去中心化MARL</h3><p>论文：<a href="http://arxiv.org/abs/1802.08757">Fully Decentralized Multi-Agent Reinforcement Learning with Networked Agents</a></p>]]></content>
      
      
      <categories>
          
          <category> 强化学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 强化学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>分布式强化学习之IMPALA</title>
      <link href="2021/10/14/fen-bu-shi-qiang-hua-xue-xi-zhi-impala/"/>
      <url>2021/10/14/fen-bu-shi-qiang-hua-xue-xi-zhi-impala/</url>
      
        <content type="html"><![CDATA[<p> 参考内容：<a href="https://zhuanlan.zhihu.com/p/58226117">https://zhuanlan.zhihu.com/p/58226117</a></p><p>参考书籍：《深度强化学习学术前沿与实战应用》</p><p>IMPALA全名Importance Weighted Actor-Learner Architecture，也就是重要性加权Actor-learner架构，可以训练高效复杂的任务序列。</p><h2 id="框架概述"><a href="#框架概述" class="headerlink" title="框架概述"></a>框架概述</h2><p>在实际的问题场景中，我们可以将数百个Actor设置在每一个服务器的每一个线程上，它们可以相互独立，同时处理一个任务，也可以同时训练不同的任务，下面开始运行一个完整的过程。</p><p>从每一段训练过程开始，每个Actor将自己的本地策略和中心Learner的最新策略同步，之后于自身所处的环境交互n个时间步。在n步之后，Actor发送自己经历这一段“状态——动作——奖励”轨迹$“s_1,a_1,r_1,s_2,a_2,r_2,…s_n,a_n,r_n”$，以及自己本地的策略分布（包括LSTM的初始状态，通过相应的队列等数据结构），发送回给Learner，我们的Learner从训练启动开始就在不断地收到来自Actor的这些序列信息和策略，并且在这些序列信息中不断进行自身更新。在各个线程训练actor的过程中，Learner是在不断学习更新策略的，无需等待actor都训练完毕，因此<strong>Learner的策略是在时间上比所有actor超前很多的</strong>，每一个Actor和Learner的时间差距有不同，这样的巨大差异是不利于训练质量的，但为了训练速度我们又不能妥协去把异步改为同步，使得服务器相互等待。</p><h2 id="V-trace"><a href="#V-trace" class="headerlink" title="V-trace"></a>V-trace</h2><p>这里引入了一种off-policy的actor-critic算法——V-trace，它用在像IMPALA这样的分布式任务框架上，改进了原先计算梯度的公式，来适应Actor于Learner在策略上的时间差。</p><p>在A3C这样的on-policy场景，值函数的更新可以表示为：<br>$$<br>V_s = V(x_s) + \sum_{t=s}^{s+n-1} \gamma^{t-s}(r_t + \gamma V(x_{t+1}) - V(x_t))<br>$$<br>这时候我们采用off-policy策略来修正时间差，从比较过时和比较新的策略去估计一个最好的策略，这就需要用到重要性采样（Importance Sampling）。这时候我们可以得到在n步下V-trace算法下的目标价值函数：<br>$$<br>V_s =^{def}  V(x_s) + \sum_{t=s}^{s+n-1} \gamma^{t-s}(\prod_{i=s}^{t-1} c_i )\delta_t V<br>$$</p><p>$$<br>\delta_t V =^{def} p_t(r_t + \gamma V(x_{t+1}) - V(x_t))</p><p>$$</p><p>$$<br>p_t =^{def} min(\bar{\rho},\frac{\pi(a_t|x_t)}{\mu(a_t|x_t)})<br>$$</p><p>$$<br>c_i =^{def}min(\bar{c},\frac{\pi(a_i|x_i)}{\mu(a_i|x_i)})<br>$$</p><p>这是一个经过裁剪的重要性采样。裁剪的原因是π于μ的实际分布差距越大，最后估计的策略的差异就越大。而为了更好的估计相应的策略分布，我们采用一步步累积的方法进行s到t步的逐步估计，这样将致使方差越来越大，所以我们才需要进行裁剪，采用相应策略之比的平均值来稳定方差，使训练效果更加稳定。</p><p>引入额外的重要性参数$\rho_t$的作用是为V-trace中的TD-error定义一个不动点，在取不动点的时候，值函数$V_{\pi_{\bar{p}}}$对应的策略是：<br>$$<br>\pi_{\bar{p}}(a|x) =^{def} \frac{min(\bar{\rho} \mu(a|x),\pi(a|x))}{\sum_{b \in A} \min(\bar{\rho} \mu(b|x),\pi(b|x))}<br>$$<br>这样的策略中，不动点$\bar{\rho}$的作用很大，当$\bar{\rho}$为无穷大的时候，我们可以很容易求出这个结果相当于<br>$$<br>\pi_{\bar{p}}(a|x) =^{def} \frac{\pi(a|x)}{\sum_{b \in A} \pi(b|x)} = \pi(a|x)<br>$$<br>当$\bar{\rho}$不是无穷大的时候，生成的策略是目标策略和执行策略之间的中间策略，完美弥补两个策略之间的差异。</p><p>V-trace算法加入裁剪后的重要性因子，$\bar{c}$影响的是模型收敛到最好结果的速度，而$\bar{\rho}$决定的是最后我们想收敛到的目标价值函数，可以更好解决不同的Actor和learner出现的时间差。</p><p>后面的更新用$V_s$替换掉相应的价值函数后，依然是标准的actor-critic算法。值函数的损失梯度依旧采取L2平方损失。<br>$$<br>(V_s - V_{\theta}(x_s)) \nabla_{\theta} V_{\theta}(x_s)<br>$$<br>在当前训练时间为s时，参数为w的策略网络的梯度表示形式如下：<br>$$<br>\rho_s \nabla_w \log \pi_w(a_s,x_s)(r_s + \gamma v_{s+1} - V_{\theta}(x_s))<br>$$<br>与A3C相同，为了防止过早收敛，算法不能达到最优解，还需要在损失梯度中加上一个熵奖励（entropy bonus）：<br>$$<br>-\nabla_w \sum_a \pi_w(a|x_s) \log \pi_w(a|x_s)<br>$$</p><p>这<strong>三项配合一定的权重后求和得到最终损失梯度</strong>，也就得到了算法的整体更新公式。</p><p>在这种大规模训练中，训练一次耗资巨大，为了避免训练的这一波陷入局部极小值点，采用了 <strong><a href="https://link.zhihu.com/?target=https://deepmind.com/blog/population-based-training-neural-networks/">population based training（PBT）</a></strong> 方法。每次训练若干个智能体，每隔一段时间剔除表现不好的，并且对于表现较好的智能体进行mutation（通常是扰动一下超参数组合）。通过这种方法，保证长达几天的训练结束后能得到好的结果。</p><p>有意思是，通过这种方法，学习率会随着学习进度自然慢慢减小，这和很多算法里面linear scheduled learning rate的trick不谋而合。</p>]]></content>
      
      
      <categories>
          
          <category> 强化学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 强化学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>分布式强化学习之D4PG</title>
      <link href="2021/10/14/fen-bu-shi-qiang-hua-xue-xi-zhi-d4pg/"/>
      <url>2021/10/14/fen-bu-shi-qiang-hua-xue-xi-zhi-d4pg/</url>
      
        <content type="html"><![CDATA[<p> D4PG全称Distributed Distributional Deterministic Policy Gradient，是总所周知的DDPG的分布式版本。因此学习D4PG之前，需要了解DDPG。</p><p>首先DDPG是DQN在连续空间的版本，DQN只能处理离散动作空间的问题，对于连续动作空间是无法处理的，因此我们引入了DDPG。DDPG是actor-critic的结构，并且借鉴了DQN的技巧，也就是目标网络和经验回放。因此DDPG有四个网络，一个actor，一个Target-actor，一个critic，一个Target-critic。对于Critic的更新方法和DQN一样，而Actor的更新就是最大化Critic的输出，也就是得到最高的评价。DDPG和DQN具体细节可以参考我以前的文章：<a href="https://tianjuewudi.gitee.io/2021/07/16/qiang-hua-xue-xi-shi-jian-jiao-xue/#toc-heading-30">强化学习实践教学</a></p><hr><p>D4PG将经验收集的Actor和策略学习的Learner分开，使用多个并行的Actor收集数据，并分享一个大的经验数据缓存区，发送给learner进行学习，经验使用N步奖励的方法进行处理，也可以使用优先级经验复用，给每个经验加上一个初始优先级。</p><p>critic的输出是一个分布，这也就是distributional的概念。</p><img src="/2021/10/14/fen-bu-shi-qiang-hua-xue-xi-zhi-d4pg/1.png" class=""><img src="/2021/10/14/fen-bu-shi-qiang-hua-xue-xi-zhi-d4pg/2.png" class=""><p>D4PG的改进使得我们可以运用上百台甚至更多的机器资源，这样就能够采样更多用于训练的数据，比DPPO更好的地方在于Learner不需要等待Actor计算梯度，真正实现了样本采集和训练过程的分离，所以，D4PG可以用于更复杂的连续动作控制领域。缺点在于Actor和Learner的分离可能导致学习到的策略和正在执行的策略产生差距，因此在一个不是很好的策略下采集到的样本也不好，D4PG没有解决两者的平衡问题。</p>]]></content>
      
      
      <categories>
          
          <category> 强化学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 强化学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>分层强化学习（Hierarchy RL）</title>
      <link href="2021/10/12/fen-ceng-qiang-hua-xue-xi-hierarchy-rl/"/>
      <url>2021/10/12/fen-ceng-qiang-hua-xue-xi-hierarchy-rl/</url>
      
        <content type="html"><![CDATA[<p> 阅读本文需要有深度强化学习基础，可以翻看我以前的文章：<a href="https://blog.csdn.net/tianjuewudi/article/details/120698199">强化学习纲要（周博磊课程）</a>、<a href="https://tianjuewudi.gitee.io/2021/07/16/qiang-hua-xue-xi-shi-jian-jiao-xue/">强化学习实践教学</a></p><p>参考原文：<a href="https://zhuanlan.zhihu.com/p/267524544">分层强化学习survey</a>  ，这篇文章讲的十分全面，重复内容不再赘述。</p><p>分层主要解决的是稀疏reward的问题，实际的强化问题往往reward很稀疏，再加上庞大的状态空间和动作空间组合，导致直接硬训往往训不出来，遇到头铁的agent更是如此。我们人类在解决一个复杂问题时，往往会将其分解为若干个容易解决的子问题，分而治之，分层的思想正是来源于此。个人理解目前分层的解决手段大体分两种，一种是基于目标的(goal-reach)，主要做法是选取一定的goal，使agent向着这些goal训练，可以预见这种方法的难点就是如何选取合适的goal；另一种方式是多级控制(multi-level control)，做法是抽象出不同级别的控制层，上层控制下层，这些抽象层在不同的文章中可能叫法不同，如常见的option、skill、macro action等，这种方式换一种说法也可以叫做时序抽象(temporal abstraction)。</p><h2 id="SMDP"><a href="#SMDP" class="headerlink" title="SMDP"></a>SMDP</h2><p>SMDP指的是半马尔科夫决策过程。和马尔科夫决策过程中一个状态经过一个action就能到达下一个状态不同，它需要一段时间过后或是多个action才能到达下个状态。它可以分为两种：一种是时间连续的，每经过连续的时间状态发生改变。一种是时间离散的，经过几个时间步之后状态发生改变。分层强化学习研究第二种，并按照离散时间进行建模。</p><h2 id="h-DQN"><a href="#h-DQN" class="headerlink" title="h-DQN"></a>h-DQN</h2><p>h-DQN也叫hierarchy DQN。是一个整合分层actor-critic函数的架构，可以在不同的时间尺度上进行运作，具有以目标驱动为内在动机的DRL。该模型在两个结构层次上进行决策：顶级模块（元控制器）接受状态并选择目标，低级模块（控制器）使用状态和选择的目标来进行决策。我们可以使用不同时间尺度的随机梯度下降来训练模型，以优化预期的未来内在动机（对应控制器）和外部奖励（对应元控制）。这种处理延迟问题的优势是：在获得最佳外在奖励之前具有长状态链的离散随机决策过程。</p><img src="/2021/10/12/fen-ceng-qiang-hua-xue-xi-hierarchy-rl/1.png" class=""><p>元控制器接收状态并选择目标g，然后控制器使用状态和目标选择动作，目标在接下来的几个时间步中保持不变，直到达到目标或终止状态。内部的critic负责评估是否达到目标，并向控制器提供适当的奖励$r_t(g)$。在这项工作中，进行二元内部奖励的最小化，达到目标为1，否则为0。控制器的目标最大化累计内在奖励，元控制器的目的是优化累计的外在奖励。</p><p>控制器Q值函数：<br>$$<br>Q_1(s,a;g) = \max_{\pi_{a,g}} E[r_t + \gamma \max_{a_{t+1}}Q_1^*(s_{t+1},a_{t+1};g) | s_t = s,a_t=a,g_t=g,\pi_{a,g}]<br>$$<br>元控制器Q值函数：<br>$$<br>Q_2(s,g) = \max_{\pi_{a,g}} E[\sum_{t’=t}^{t+N}f_{t’}+ \gamma \max_{g’}Q_2^*(s_{t+N},g’) | s_t = s,g_t=g,\pi_{a,g}]<br>$$<br>N表示当前目标下，控制器停止之前的时间步数。</p><img src="/2021/10/12/fen-ceng-qiang-hua-xue-xi-hierarchy-rl/2.png" class=""><p>因此需要拟合两个Q函数，而每一Q函数配有一个储存空间，分别是$D_1$储存$(s_t,a_t,g_t,r_t,s_{t+1})$，$D_2$储存$(s_t,g_t,f_t,s_{t+N})$。</p><p>对目标的选择上本文的做法是选取游戏画面中某些重要物体的图像作为目标，随state一起传入神经网络，这些目标图像都是人工选择好的。这也是本文的局限。</p><h2 id="FuN"><a href="#FuN" class="headerlink" title="FuN"></a>FuN</h2><p><a href="https://zhuanlan.zhihu.com/p/46928498">https://zhuanlan.zhihu.com/p/46928498</a></p><h2 id="HIRO"><a href="#HIRO" class="headerlink" title="HIRO"></a>HIRO</h2><p><a href="https://zhuanlan.zhihu.com/p/46946800">https://zhuanlan.zhihu.com/p/46946800</a></p><h2 id="Option-Critic"><a href="#Option-Critic" class="headerlink" title="Option-Critic"></a>Option-Critic</h2><p><a href="https://zhuanlan.zhihu.com/p/47051292">https://zhuanlan.zhihu.com/p/47051292</a></p>]]></content>
      
      
      <categories>
          
          <category> 强化学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 强化学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>分布式强化学习</title>
      <link href="2021/10/10/fen-bu-shi-qiang-hua-xue-xi/"/>
      <url>2021/10/10/fen-bu-shi-qiang-hua-xue-xi/</url>
      
        <content type="html"><![CDATA[<p> 参考视频：<a href="https://www.bilibili.com/video/BV1bi4y147Rv?spm_id_from=333.999.0.0">周博磊强化学习纲要</a></p><p>阅读本文需要强化学习基础，可以阅读我以前的文章：<a href="https://tianjuewudi.gitee.io/2021/07/21/qiang-hua-xue-xi-gang-yao-zhou-bo-lei-ke-cheng/">强化学习纲要（周博磊课程）</a>、<a href="https://tianjuewudi.gitee.io/2021/07/16/qiang-hua-xue-xi-shi-jian-jiao-xue/">强化学习实践教学</a></p><h2 id="分布式系统"><a href="#分布式系统" class="headerlink" title="分布式系统"></a>分布式系统</h2><p>一般情况下我们做的论文课题都是小规模的，使用的都是一个相对较小的数据库，因此使用单机系统基本可以完成任务。但现实生活中的数据往往是巨量的，我们需要一个完整的分布式系统来处理这种大规模的数据。算法和结果只是冰山一角，只有拥有一个好的系统和框架作为支撑，才能得到好的算法和实验结果。</p><p>分布式系统需要满足：</p><ul><li>一致性：确保多节点的协调运作并且结果和单机运行的结果一致。</li><li>容错性：当分布式环境工作时，其中某一个节点出现错误（机器宕机等），任务能够分配到其他机器，工作也能正常。</li><li>交流：分布式系统需要I\O和分布式文件系统的知识。</li></ul><img src="/2021/10/10/fen-bu-shi-qiang-hua-xue-xi/1.png" class><p>分布式系统中存在分布式学习的模型和数据，因此有两种并行。一种是不同的机器做一个网络不同部分的计算。第二种是一套机器拥有一个单独的模型拷贝，但是分配到的数据是不同的，计算结果汇总。</p><img src="/2021/10/10/fen-bu-shi-qiang-hua-xue-xi/2.png" class><p>一台电脑可以拥有多块显卡，因此每一块显卡都可以负责模型的一部分，每台电脑都可以放置一个模型，然后把数据分配到每台电脑的每一块显卡上，这就是上面两种并行方法的综合运用。</p><hr><p>使用算法和模型的时候需要在机器之间传输信息，怎么实施信息之间的交互是需要解决的问题。一种更新参数的方法是使用<strong>Parameter Server</strong>。我们可以用另外一台机器接收各个机器传回来的模型参数，然后给这些参数取平均得到更新值，然后把更新后的参数返回给各个机器，使得每一台机器都可以保持相同的参数进行分布式计算。这里我们也可以在各个机器中计算梯度后只把梯度传递回主机，主机中乘上一个学习率即可。</p><img src="/2021/10/10/fen-bu-shi-qiang-hua-xue-xi/3.png" class><hr><p>对于<strong>模型的更新</strong>有两种常见的方法：同步更新和异步更新。</p><img src="/2021/10/10/fen-bu-shi-qiang-hua-xue-xi/4.png" class><hr><p>上面的方法需要一个主机Parameter Sever，如果主机出现错误，整个训练就会失败。因此我们可以不用主机，这也叫做分散异步随机梯度下降，机器中间点对点传输梯度来更新参数。</p><img src="/2021/10/10/fen-bu-shi-qiang-hua-xue-xi/5.png" class><hr><p>分布式优化：asych SGD，不加lock，这样会导致一个进程读取的参数被另一个进程抢先更新的情况。但Hogwild给出证明两种算法在一定情况下结果趋紧一致。asych SGD是并行系统中广泛应用的设计。</p><img src="/2021/10/10/fen-bu-shi-qiang-hua-xue-xi/6.png" class><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token punctuation">.</span>multiprocessing <span class="token keyword">as</span> mp<span class="token keyword">from</span> model <span class="token keyword">import</span> MyModel<span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>model<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># Construct data_loader,optimizer,etc.</span>    <span class="token keyword">for</span> data<span class="token punctuation">,</span>labels <span class="token keyword">in</span> data_loader<span class="token punctuation">:</span>        optimizer<span class="token punctuation">.</span>zero_frad<span class="token punctuation">(</span><span class="token punctuation">)</span>        loss_fn<span class="token punctuation">(</span>model<span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">,</span>labels<span class="token punctuation">)</span><span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>        opeimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>      <span class="token comment" spellcheck="true"># update the shared parameters</span> <span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>    num_processes <span class="token operator">=</span> <span class="token number">4</span>    model <span class="token operator">=</span> MyModel<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># NOTE: this is required for the "fork" method to work</span>    model<span class="token punctuation">.</span>share_memory<span class="token punctuation">(</span><span class="token punctuation">)</span>     processes <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token keyword">for</span> rank <span class="token keyword">in</span> range<span class="token punctuation">(</span>num_processes<span class="token punctuation">)</span><span class="token punctuation">:</span>        p <span class="token operator">=</span> mp<span class="token punctuation">.</span>Process<span class="token punctuation">(</span>target<span class="token operator">-</span>train<span class="token punctuation">,</span>args<span class="token operator">=</span><span class="token punctuation">(</span>model<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        p<span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> p <span class="token keyword">in</span> processes<span class="token punctuation">:</span>        p<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><hr><p>MapReduce：分布式学习的开山鼻祖算法</p><img src="/2021/10/10/fen-bu-shi-qiang-hua-xue-xi/7.png" class><hr><p>DisBelief</p><img src="/2021/10/10/fen-bu-shi-qiang-hua-xue-xi/8.png" class><hr><p>AlexNet</p><img src="/2021/10/10/fen-bu-shi-qiang-hua-xue-xi/9.png" class><hr><h2 id="分布式强化学习系统"><a href="#分布式强化学习系统" class="headerlink" title="分布式强化学习系统"></a>分布式强化学习系统</h2><p>现在我们考虑强化学习系统的哪些部分可以实行分布式设计。</p><img src="/2021/10/10/fen-bu-shi-qiang-hua-xue-xi/10.png" class><p>我们可以从以上三点出发：考虑增加更多的环境，让更多的智能体同时工作，并且让多个episode同时执行。</p><p>在分布式强化学习之中，我们需要多个环境，多个智能体进行交互。因此在不同的机器中都可以有一个环境和一个智能体，得到多个轨迹，然后传回给learner，learner对参数进行更新，然后把更新后的参数传回给不同机器中的智能体。</p><h3 id="经典算法"><a href="#经典算法" class="headerlink" title="经典算法"></a>经典算法</h3><p>分布式强化学习系统的进展：</p><img src="/2021/10/10/fen-bu-shi-qiang-hua-xue-xi/11.png" class><p>GORILA系统是在DQN的基础上进行分布式加速：</p><img src="/2021/10/10/fen-bu-shi-qiang-hua-xue-xi/12.png" class><p><strong>A3C</strong></p><p>A3C相对于GORILA取缔了reply memory，每个线程都保留了自己的actor，因此每个线程的轨迹都是具有多样化的，可以直接采样进行学习。</p><img src="/2021/10/10/fen-bu-shi-qiang-hua-xue-xi/13.png" class><p>部分代码：</p><pre class=" language-python"><code class="language-python">processes <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token keyword">for</span> rank <span class="token keyword">in</span> range<span class="token punctuation">(</span>args<span class="token punctuation">.</span>processes<span class="token punctuation">)</span><span class="token punctuation">:</span>    p <span class="token operator">=</span> mp<span class="token punctuation">.</span>Process<span class="token punctuation">(</span>target<span class="token operator">=</span>train<span class="token punctuation">,</span> args<span class="token operator">=</span><span class="token punctuation">(</span>shared_model<span class="token punctuation">,</span> shared_optimizer<span class="token punctuation">,</span> rank<span class="token punctuation">,</span> args<span class="token punctuation">,</span> info<span class="token punctuation">)</span><span class="token punctuation">)</span>    p<span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span>    processes<span class="token punctuation">.</span>append<span class="token punctuation">(</span>p<span class="token punctuation">)</span><span class="token keyword">for</span> p <span class="token keyword">in</span> processes<span class="token punctuation">:</span>    p<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><p><strong>A2C</strong>：基于A3C的改进</p><img src="/2021/10/10/fen-bu-shi-qiang-hua-xue-xi/14.png" class><img src="/2021/10/10/fen-bu-shi-qiang-hua-xue-xi/15.png" class><p><strong>Apex-X</strong></p><img src="/2021/10/10/fen-bu-shi-qiang-hua-xue-xi/16.png" class><p><strong>IMPALA</strong></p><img src="/2021/10/10/fen-bu-shi-qiang-hua-xue-xi/17.png" class><p><strong>RLlib</strong></p><img src="/2021/10/10/fen-bu-shi-qiang-hua-xue-xi/18.png" class><img src="/2021/10/10/fen-bu-shi-qiang-hua-xue-xi/19.png" class><img src="/2021/10/10/fen-bu-shi-qiang-hua-xue-xi/20.png" class><p><strong>Evolution Strategies</strong></p><img src="/2021/10/10/fen-bu-shi-qiang-hua-xue-xi/21.png" class>]]></content>
      
      
      <categories>
          
          <category> 强化学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 强化学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>模仿学习（Imitation Learning）</title>
      <link href="2021/10/10/mo-fang-xue-xi-imitation-learning/"/>
      <url>2021/10/10/mo-fang-xue-xi-imitation-learning/</url>
      
        <content type="html"><![CDATA[<p>在游戏中，我们往往有一个计分板准确定义事情的好坏程度。但现实中，定义Reward有可能是非常困难的，并且人定的reward也有可能存在许多意想不到的缺陷。在没有reward的情况下，让AI跟环境互动的一个方法叫做<strong>Imitation-Learning</strong>。在没有reward的前提下，我们可以找人类进行示范，AI可以凭借这些示范以及跟环境的互动进行学习。这种模仿学习使得智能体自身不必从零学起，不必去尝试探索和收集众多的无用数据，能大大加快训练进程。</p><p>这跟supervised-learning有类似之处，如果采用这种做法，我们叫做Behavior-Cloning，也就是复制人类的行为。</p><p>但是这种监督学习有一个缺点，如果是智能体进入到一个以前从来没有见到过的状态，就会产生较大的误差，这种误差会一直累加，到最后没有办法进行正常的行为。因此我们需要让实际遇到的数据和训练数据的分布尽量保持一致。</p><h2 id="DAgger"><a href="#DAgger" class="headerlink" title="DAgger"></a>DAgger</h2><p>前期先让人类去操作policy，拿到足够多的数据以后做完全意义上的offline训练；如果offline训出来效果不好，把效果不好的场景再让人类操作一遍，对各个状态打上动作标签。然后新数据加旧数据一起再训练，直到效果变好为止，这就是DAgger。</p><img src="/2021/10/10/mo-fang-xue-xi-imitation-learning/1.png" class=""><p>通常第三步人来收集数据也是一个比较麻烦和漫长的过程，我们也可以使用其他算法来代替人类来打标签。</p><h2 id="逆强化学习（Inverse-Reinforcement-Learning）"><a href="#逆强化学习（Inverse-Reinforcement-Learning）" class="headerlink" title="逆强化学习（Inverse Reinforcement Learning）"></a>逆强化学习（Inverse Reinforcement Learning）</h2><p>在强化学习中，我们给定环境（状态转移）和奖励函数，我们需要通过收集的数据来对自身的策略函数和值函数进行优化。在逆强化学习中，提供环境（状态转移），也提供策略函数或是示教数据，我们希望从这些数据中反推奖励函数。即给定状态和动作，建立模型输出对应奖励。在奖励函数建立好后，我们就能新训练一个智能体来模仿给定策略（示教数据）的行为。</p><h3 id="GAIL（Generative-Adversarial-Imitation-Learning）"><a href="#GAIL（Generative-Adversarial-Imitation-Learning）" class="headerlink" title="GAIL（Generative Adversarial Imitation Learning）"></a>GAIL（Generative Adversarial Imitation Learning）</h3><img src="/2021/10/10/mo-fang-xue-xi-imitation-learning/2.png" class=""><p>在IRL领域有名的算法是GAIL，这种算法模仿了生成对抗网络GANs。把Actor当成Generator，把Reward Funciton当成Discriminator。<br>我们要训练一个策略网络去尽量拟合提供的示教数据，那么我们可以让需要训练的reward函数来进行评价，Reward函数通过输出评分来分辨哪个是示教数据的轨迹，哪个是自己生成的虚假轨迹；而策略网络负责生成虚假的轨迹，尽可能骗过Reward函数，让其难辨真假。两者是对抗关系，双方的Loss函数是对立的，两者在相互对抗中一起成长，最后训练出一个较好的reward函数和一个较好的策略网络。</p><h2 id="模仿学习结合强化学习"><a href="#模仿学习结合强化学习" class="headerlink" title="模仿学习结合强化学习"></a>模仿学习结合强化学习</h2><p>模仿学习的特点：</p><ol><li>用人工收集数据往往需要较大成本，而且数据量也不会很大，并且存在数据分布不一致的问题。</li><li>人也有很多办不到的策略，如果是非常复杂的控制（例如高达机器人，六旋翼飞行器），人是没办法胜任的。</li><li>训练稳定简单。</li><li>最多只能做到和示教数据一样好，无法超越。</li></ol><p>强化学习的特点：</p><ol><li>需要奖励函数。</li><li>需要足够的探索。</li><li>有可能存在的不能收敛问题。</li><li>可以做到超越人类的决策。</li></ol><p>因此我们可以把两者结合起来，既有人类的经验，又有自己的探索和学习。我们的做法是进行预训练和微调。AlphaGo正是运用了这种框架。同样星际争霸2的AlphaStar同样也是这种训练框架，得到了超越人类的水平。</p><img src="/2021/10/10/mo-fang-xue-xi-imitation-learning/3.png" class=""><p>但在运用pretrain和finetune这种框架时我们通常会面临一个问题，就是在预训练过后进行强化学习的时候，我们的策略一开始采集到的数据很可能是非常糟糕的，这会直接摧毁策略网络，导致效果越来越差，训练没法进行。因此我们需要在策略中将一开始的示教数据保留下来，我们可以<strong>把示教的数据直接放入reply buffer中</strong>，这样可以让策略网络随时进行学习。</p><hr><p>我们可以通过加入一个损失函数同时对loss进行优化：</p> <img src="/2021/10/10/mo-fang-xue-xi-imitation-learning/4.png" class=""><h2 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h2><img src="/2021/10/10/mo-fang-xue-xi-imitation-learning/5.png" class=""><img src="/2021/10/10/mo-fang-xue-xi-imitation-learning/6.png" class=""><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><img src="/2021/10/10/mo-fang-xue-xi-imitation-learning/7.png" class="">]]></content>
      
      
      <categories>
          
          <category> 强化学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 强化学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>强化学习之SAC</title>
      <link href="2021/10/06/qiang-hua-xue-xi-zhi-sac/"/>
      <url>2021/10/06/qiang-hua-xue-xi-zhi-sac/</url>
      
        <content type="html"><![CDATA[<p> 参考视频：<a href="https://www.bilibili.com/video/BV1EK41157fD/?spm_id_from=333.788.recommend_more_video.-1">周博磊强化学习课程</a> </p><p>价值函数优化学习主线：Q-learning→DQN→DDPG→TD3→SAC</p><p>Q-Learning，DQN和DDPG请可以参考我之前的文章：<a href="https://tianjuewudi.gitee.io/2021/07/16/qiang-hua-xue-xi-shi-jian-jiao-xue/#toc-heading-20">强化学习实践教学</a></p><p>TD3可以参考我之前的博客：<a href="https://blog.csdn.net/tianjuewudi/article/details/120626544">强化学习之TD3(pytorch实现)</a></p><p>SAC可以参考博客：<a href="https://blog.csdn.net/qq_38587510/article/details/104970837">https://blog.csdn.net/qq_38587510/article/details/104970837</a></p><p>参考论文：</p><ol><li><a href="https://arxiv.org/abs/1801.01290">Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor</a>，2018年8月发表。</li><li><a href="https://link.zhihu.com/?target=https://arxiv.org/pdf/1812.05905.pdf">Soft Actor-Critic Algorithms and Applications</a>，2019年1月发表。</li></ol><p>​       SAC全称Soft Actor-Critic，它整合了entropy regularization的思想。论文有以上两篇，第一篇采用模型包括一个actor网络，两个状态价值V网络，两个动作价值Q网络，第二篇的模型包括一个actor网络，四个动作价值Q网络。</p><p>​       model-free深度强化学习算法面临两个主要挑战：<strong>高采样复杂度和脆弱的收敛性，因此严重依赖调参</strong>，这两个挑战限制了强化学习向现实应用的推广。SAC引入了<strong>最大熵（Maximum Entropy）强化学习</strong>，要求actor在同时最大化期望和策略分布的熵，也就是说，在保证任务成果的同时希望策略尽可能的随机。</p><h3 id="信息熵"><a href="#信息熵" class="headerlink" title="信息熵"></a>信息熵</h3><p>这里说明一下信息熵的概念：当一件事情发生的概率越小，这件事情的信息量越大，对于一个分布而言，信息量的计算方式是：<br>$$<br>H(U) = E[-\log p_i] = - \sum_{i=1}^n p_i log p_i<br>$$<br>因此actor输出总概率相加为1的情况下，动作概率的分布越散，越不集中于一个action，这个熵的值越大。对于连续动作领域来说，就是随机噪声的采样值越偏离平均值，越出现在高斯分布边缘，这个值越大。</p><h3 id="Maximum-Entropy"><a href="#Maximum-Entropy" class="headerlink" title="Maximum Entropy"></a>Maximum Entropy</h3><p>​       在标准强化学习中需要最大化累积期望reward：<br>$$<br>\sum_{t} E_{（s_t,a_t）～ p_{\pi}}[\gamma^t r(s_t,a_t)]<br>$$<br>​       在最大熵强化学习中需要优化的目标是：<br>$$<br>argmax_{\pi}\sum_{t} E_{\tau ～ \pi}[\gamma^t (R(s_t,a_r,s_{t+1})+ \alpha H(\pi(.|s_t)))]<br>$$<br>​       最大熵强化学习在标准的最大reward强化目标上增加了一个最大熵项，提高了探索能力和鲁棒性。既降低了采样复杂度，又提高了收敛稳定性。可以学到更多near-optimal的行为，也就是在一些状态下，可能存在多个动作都是最优的，那么使选择它们的概率相同，可以提高学习的速度。</p><p>此时有：<br>$$<br> V^{\pi}(s) =  E_{\tau ～ \pi}[\sum_t \gamma^t (R(s_t,a_r,s_{t+1})+ \alpha H(\pi(.|s_t))) | s_0 = s]<br>$$</p><p>$$<br>Q^{\pi}(s，a) =  E_{s’ ～ P,a’～ \pi }[R(s,a,s’)+ \gamma (Q^{\pi}(s’,a’)  + \alpha H(\pi(.|s_t))) ] \<br>=  E_{s’ ～ P,a’～ \pi }[R(s,a,s’)+ \gamma (Q^{\pi}(s’,a’)  - \alpha \log \pi(a’|s’)) ]<br>$$</p><p>因此，采样更新公式应该是：<br>$$<br>Q^{\pi}(s，a) \approx   r + \gamma (Q^{\pi}(s’,\hat{ a’})  - \alpha \log \pi(\hat {a’}|s’)) ,\hat{a’} ～ \pi(.|s’)<br>$$<br>损失函数为：<br>$$<br>L（\phi_i,D） = E[(Q_{\phi}(s,a) - y(r,s’,d))^2]<br>$$<br>TD3类似，SAC也采用了两个Q网络的更新形式，然后使用较小的Q值进行更新。<br>$$<br>y(r,s’,d) =  r + \gamma (1-d)(\min_{j=1,2}Q_{\phi_{targ,j}}(s’,\hat{a’}) - \alpha \log \pi_{\theta}(\hat{a’}|s’)) ,\hat{a’} ～ \pi(.|s’)<br>$$<br>对于状态价值V有：<br>$$<br>V^{\pi}(s) = E_{a ～ \pi}[Q^{\pi}(s,a)] + \alpha H(\pi(.|s))  \<br> = E_{a ～ \pi}[Q^{\pi}(s,a)] - \alpha \log \pi(a|s))<br>$$</p><h3 id="Reparameterization-Trick"><a href="#Reparameterization-Trick" class="headerlink" title="Reparameterization Trick"></a>Reparameterization Trick</h3><p>同时也在动作输出中加入了噪声。这就是Reparameterization Trick。让a从策略网络中进行采样转变成和其没有什么关系的采样。<br>$$<br>\hat{a_{\theta}}(s,\epsilon) = \tanh(μ<em>{\theta}(s) + \sigma</em>{\theta}(s) \odot \epsilon),\epsilon～N(0,1)<br>$$<br>其中μ和σ都是由神经网络学习得到的，因此在奖励最大化的同时鼓励探索的话，σ会尽可能增大以达到探索的目的，这样一个μ和σ都会变化的动作分布大大增加了动作策略的灵活性。</p><h2 id="actor部分代码："><a href="#actor部分代码：" class="headerlink" title="actor部分代码："></a>actor部分代码：</h2><pre class=" language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">GaussianPolicy</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> num_inputs<span class="token punctuation">,</span> num_actions<span class="token punctuation">,</span> hidden_dim<span class="token punctuation">,</span> action_space<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>GaussianPolicy<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>linear1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>num_inputs<span class="token punctuation">,</span> hidden_dim<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>linear2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_dim<span class="token punctuation">,</span> hidden_dim<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>mean_linear <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_dim<span class="token punctuation">,</span> num_actions<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>log_std_linear <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_dim<span class="token punctuation">,</span> num_actions<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 使用对应函数初始化所有的全连接层参数</span>        self<span class="token punctuation">.</span>apply<span class="token punctuation">(</span>weights_init_<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># action rescaling</span>        <span class="token keyword">if</span> action_space <span class="token keyword">is</span> None<span class="token punctuation">:</span>            self<span class="token punctuation">.</span>action_scale <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">)</span>            self<span class="token punctuation">.</span>action_bias <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">)</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            self<span class="token punctuation">.</span>action_scale <span class="token operator">=</span> torch<span class="token punctuation">.</span>FloatTensor<span class="token punctuation">(</span>                <span class="token punctuation">(</span>action_space<span class="token punctuation">.</span>high <span class="token operator">-</span> action_space<span class="token punctuation">.</span>low<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">)</span>            self<span class="token punctuation">.</span>action_bias <span class="token operator">=</span> torch<span class="token punctuation">.</span>FloatTensor<span class="token punctuation">(</span>                <span class="token punctuation">(</span>action_space<span class="token punctuation">.</span>high <span class="token operator">+</span> action_space<span class="token punctuation">.</span>low<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> state<span class="token punctuation">)</span><span class="token punctuation">:</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>linear1<span class="token punctuation">(</span>state<span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>linear2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>        mean <span class="token operator">=</span> self<span class="token punctuation">.</span>mean_linear<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        log_std <span class="token operator">=</span> self<span class="token punctuation">.</span>log_std_linear<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        log_std <span class="token operator">=</span> torch<span class="token punctuation">.</span>clamp<span class="token punctuation">(</span>log_std<span class="token punctuation">,</span> min<span class="token operator">=</span>LOG_SIG_MIN<span class="token punctuation">,</span> max<span class="token operator">=</span>LOG_SIG_MAX<span class="token punctuation">)</span>        <span class="token keyword">return</span> mean<span class="token punctuation">,</span> log_std    <span class="token keyword">def</span> <span class="token function">sample</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> state<span class="token punctuation">)</span><span class="token punctuation">:</span>        mean<span class="token punctuation">,</span> log_std <span class="token operator">=</span> self<span class="token punctuation">.</span>forward<span class="token punctuation">(</span>state<span class="token punctuation">)</span>        std <span class="token operator">=</span> log_std<span class="token punctuation">.</span>exp<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 创建高斯分布</span>        normal <span class="token operator">=</span> Normal<span class="token punctuation">(</span>mean<span class="token punctuation">,</span> std<span class="token punctuation">)</span>        x_t <span class="token operator">=</span> normal<span class="token punctuation">.</span>rsample<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># for reparameterization trick (mean + std * N(0,1))</span>        y_t <span class="token operator">=</span> torch<span class="token punctuation">.</span>tanh<span class="token punctuation">(</span>x_t<span class="token punctuation">)</span>        action <span class="token operator">=</span> y_t <span class="token operator">*</span> self<span class="token punctuation">.</span>action_scale <span class="token operator">+</span> self<span class="token punctuation">.</span>action_bias        log_prob <span class="token operator">=</span> normal<span class="token punctuation">.</span>log_prob<span class="token punctuation">(</span>x_t<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># Enforcing Action Bound</span>        <span class="token comment" spellcheck="true"># ---重点问题---</span>        log_prob <span class="token operator">-=</span> torch<span class="token punctuation">.</span>log<span class="token punctuation">(</span>self<span class="token punctuation">.</span>action_scale <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> y_t<span class="token punctuation">.</span>pow<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">+</span> epsilon<span class="token punctuation">)</span>        log_prob <span class="token operator">=</span> log_prob<span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> keepdim<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>        mean <span class="token operator">=</span> torch<span class="token punctuation">.</span>tanh<span class="token punctuation">(</span>mean<span class="token punctuation">)</span> <span class="token operator">*</span> self<span class="token punctuation">.</span>action_scale <span class="token operator">+</span> self<span class="token punctuation">.</span>action_bias        <span class="token keyword">return</span> action<span class="token punctuation">,</span> log_prob<span class="token punctuation">,</span> mean    <span class="token keyword">def</span> <span class="token function">to</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> device<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>action_scale <span class="token operator">=</span> self<span class="token punctuation">.</span>action_scale<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>action_bias <span class="token operator">=</span> self<span class="token punctuation">.</span>action_bias<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>        <span class="token keyword">return</span> super<span class="token punctuation">(</span>GaussianPolicy<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span></code></pre>]]></content>
      
      
      <categories>
          
          <category> 强化学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 强化学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>强化学习之TD3</title>
      <link href="2021/10/06/qiang-hua-xue-xi-zhi-td3/"/>
      <url>2021/10/06/qiang-hua-xue-xi-zhi-td3/</url>
      
        <content type="html"><![CDATA[<p> 参考视频：<a href="https://www.bilibili.com/video/BV1EK41157fD/?spm_id_from=333.788.recommend_more_video.-1">https://www.bilibili.com/video/BV1EK41157fD/?spm_id_from=333.788.recommend_more_video.-1</a> </p><p>原论文：<a href="https://arxiv.org/abs/1802.09477">https://arxiv.org/abs/1802.09477</a></p><p>价值函数优化学习主线：Q-learning→DQN→DDPG→TD3→SAC</p><p>Q-Learning，DQN和DDPG请可以参考我之前的文章：<a href="https://tianjuewudi.gitee.io/2021/07/16/qiang-hua-xue-xi-shi-jian-jiao-xue/#toc-heading-20">强化学习实践教学</a></p><p>首先DDPG是对DQN的扩展，使得只能用于离散动作空间的DQN扩展到连续动作空间，在方法上同样运用了经验回放和Target网络，同时是一个Actor-Critic方法，因此存在四个网络。</p><p>TD3也叫做Twin Delayed DDPG，全称Twin Delayed Deep Deterministic Policy Gradient。是基于DDPG的改进。同样DDPG也存在着跟DQN相同的缺陷，就是由于采用的是max最大动作价值的方式进行更新，使得动作价值远比实际要高（overestinmate），使得训练不稳定。因此TD3提出了三种改进。</p><h2 id="Clipped-Double-Q-Learning"><a href="#Clipped-Double-Q-Learning" class="headerlink" title="Clipped Double_Q Learning"></a>Clipped Double_Q Learning</h2><p>TD3使用了两个Q网络进行学习，因此是“twin”。而且采用两个网络中动作价值Q较小的值进行更新。两个网络同时使用一个target网络，因此它们同时都会产生一个预测值，我们只用预测值中较小的来对网络进行更新。</p><h2 id="“Delayed”-Policy-Updates"><a href="#“Delayed”-Policy-Updates" class="headerlink" title="“Delayed” Policy Updates"></a>“Delayed” Policy Updates</h2><p>TD3更新策略网络（及其Target网络）的频率要比价值网络慢，论文中推荐更新两次价值网络才更新一次策略网络。这样可以让两者解耦，关联度降低，从而可以克服overestinmation。</p><h2 id="Target-Policy-Smoothing"><a href="#Target-Policy-Smoothing" class="headerlink" title="Target Policy Smoothing"></a>Target Policy Smoothing</h2><p>TD3在策略网络的target网络中引入了噪声，让其更加积极去探索Q价值网络的错误。<br>$$<br>a_{TD3}(s’) = clip(μ<em>{\theta,targ}(s’) + clip(\epsilon,-c,c) ,a</em>{low},a_{high}),\epsilon ～ N(0,\sigma)<br>$$</p><h2 id="Pytorch实现"><a href="#Pytorch实现" class="headerlink" title="Pytorch实现"></a>Pytorch实现</h2><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> copy<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> torch<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> Fdevice <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">"cuda"</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">"cpu"</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># Implementation of Twin Delayed Deep Deterministic Policy Gradients (TD3)</span><span class="token comment" spellcheck="true"># Paper: https://arxiv.org/abs/1802.09477</span><span class="token keyword">class</span> <span class="token class-name">Actor</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> state_dim<span class="token punctuation">,</span> action_dim<span class="token punctuation">,</span> max_action<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>Actor<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>l1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>state_dim<span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>l2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>l3 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> action_dim<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>max_action <span class="token operator">=</span> max_action    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> state<span class="token punctuation">)</span><span class="token punctuation">:</span>        a <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>l1<span class="token punctuation">(</span>state<span class="token punctuation">)</span><span class="token punctuation">)</span>        a <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>l2<span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>max_action <span class="token operator">*</span> torch<span class="token punctuation">.</span>tanh<span class="token punctuation">(</span>self<span class="token punctuation">.</span>l3<span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">Critic</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> state_dim<span class="token punctuation">,</span> action_dim<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>Critic<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># Q1 architecture</span>        self<span class="token punctuation">.</span>l1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>state_dim <span class="token operator">+</span> action_dim<span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>l2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>l3 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># Q2 architecture</span>        self<span class="token punctuation">.</span>l4 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>state_dim <span class="token operator">+</span> action_dim<span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>l5 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>l6 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> state<span class="token punctuation">,</span> action<span class="token punctuation">)</span><span class="token punctuation">:</span>        sa <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>state<span class="token punctuation">,</span> action<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>        q1 <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>l1<span class="token punctuation">(</span>sa<span class="token punctuation">)</span><span class="token punctuation">)</span>        q1 <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>l2<span class="token punctuation">(</span>q1<span class="token punctuation">)</span><span class="token punctuation">)</span>        q1 <span class="token operator">=</span> self<span class="token punctuation">.</span>l3<span class="token punctuation">(</span>q1<span class="token punctuation">)</span>        q2 <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>l4<span class="token punctuation">(</span>sa<span class="token punctuation">)</span><span class="token punctuation">)</span>        q2 <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>l5<span class="token punctuation">(</span>q2<span class="token punctuation">)</span><span class="token punctuation">)</span>        q2 <span class="token operator">=</span> self<span class="token punctuation">.</span>l6<span class="token punctuation">(</span>q2<span class="token punctuation">)</span>        <span class="token keyword">return</span> q1<span class="token punctuation">,</span> q2    <span class="token keyword">def</span> <span class="token function">Q1</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> state<span class="token punctuation">,</span> action<span class="token punctuation">)</span><span class="token punctuation">:</span>        sa <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>state<span class="token punctuation">,</span> action<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>        q1 <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>l1<span class="token punctuation">(</span>sa<span class="token punctuation">)</span><span class="token punctuation">)</span>        q1 <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>l2<span class="token punctuation">(</span>q1<span class="token punctuation">)</span><span class="token punctuation">)</span>        q1 <span class="token operator">=</span> self<span class="token punctuation">.</span>l3<span class="token punctuation">(</span>q1<span class="token punctuation">)</span>        <span class="token keyword">return</span> q1<span class="token keyword">class</span> <span class="token class-name">TD3</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>        self<span class="token punctuation">,</span>        state_dim<span class="token punctuation">,</span>        action_dim<span class="token punctuation">,</span>        max_action<span class="token punctuation">,</span>        discount<span class="token operator">=</span><span class="token number">0.99</span><span class="token punctuation">,</span>        tau<span class="token operator">=</span><span class="token number">0.005</span><span class="token punctuation">,</span>        policy_noise<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">,</span>        noise_clip<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">,</span>        policy_freq<span class="token operator">=</span><span class="token number">2</span>    <span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>actor <span class="token operator">=</span> Actor<span class="token punctuation">(</span>state_dim<span class="token punctuation">,</span> action_dim<span class="token punctuation">,</span> max_action<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>actor_target <span class="token operator">=</span> copy<span class="token punctuation">.</span>deepcopy<span class="token punctuation">(</span>self<span class="token punctuation">.</span>actor<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>actor_optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>self<span class="token punctuation">.</span>actor<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">3e</span><span class="token operator">-</span><span class="token number">4</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>critic <span class="token operator">=</span> Critic<span class="token punctuation">(</span>state_dim<span class="token punctuation">,</span> action_dim<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>critic_target <span class="token operator">=</span> copy<span class="token punctuation">.</span>deepcopy<span class="token punctuation">(</span>self<span class="token punctuation">.</span>critic<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>critic_optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>self<span class="token punctuation">.</span>critic<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">3e</span><span class="token operator">-</span><span class="token number">4</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>max_action <span class="token operator">=</span> max_action        self<span class="token punctuation">.</span>discount <span class="token operator">=</span> discount        self<span class="token punctuation">.</span>tau <span class="token operator">=</span> tau        self<span class="token punctuation">.</span>policy_noise <span class="token operator">=</span> policy_noise        self<span class="token punctuation">.</span>noise_clip <span class="token operator">=</span> noise_clip        self<span class="token punctuation">.</span>policy_freq <span class="token operator">=</span> policy_freq        self<span class="token punctuation">.</span>total_it <span class="token operator">=</span> <span class="token number">0</span>    <span class="token keyword">def</span> <span class="token function">select_action</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> state<span class="token punctuation">)</span><span class="token punctuation">:</span>        state <span class="token operator">=</span> torch<span class="token punctuation">.</span>FloatTensor<span class="token punctuation">(</span>state<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>actor<span class="token punctuation">(</span>state<span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>data<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>flatten<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> replay_buffer<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>total_it <span class="token operator">+=</span> <span class="token number">1</span>        <span class="token comment" spellcheck="true"># Sample replay buffer </span>        state<span class="token punctuation">,</span> action<span class="token punctuation">,</span> next_state<span class="token punctuation">,</span> reward<span class="token punctuation">,</span> not_done <span class="token operator">=</span> replay_buffer<span class="token punctuation">.</span>sample<span class="token punctuation">(</span>batch_size<span class="token punctuation">)</span>        <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token comment" spellcheck="true"># Select action according to policy and add clipped noise</span>            noise <span class="token operator">=</span> <span class="token punctuation">(</span>                torch<span class="token punctuation">.</span>randn_like<span class="token punctuation">(</span>action<span class="token punctuation">)</span> <span class="token operator">*</span> self<span class="token punctuation">.</span>policy_noise            <span class="token punctuation">)</span><span class="token punctuation">.</span>clamp<span class="token punctuation">(</span><span class="token operator">-</span>self<span class="token punctuation">.</span>noise_clip<span class="token punctuation">,</span> self<span class="token punctuation">.</span>noise_clip<span class="token punctuation">)</span>            next_action <span class="token operator">=</span> <span class="token punctuation">(</span>                self<span class="token punctuation">.</span>actor_target<span class="token punctuation">(</span>next_state<span class="token punctuation">)</span> <span class="token operator">+</span> noise            <span class="token punctuation">)</span><span class="token punctuation">.</span>clamp<span class="token punctuation">(</span><span class="token operator">-</span>self<span class="token punctuation">.</span>max_action<span class="token punctuation">,</span> self<span class="token punctuation">.</span>max_action<span class="token punctuation">)</span>            <span class="token comment" spellcheck="true"># Compute the target Q value</span>            target_Q1<span class="token punctuation">,</span> target_Q2 <span class="token operator">=</span> self<span class="token punctuation">.</span>critic_target<span class="token punctuation">(</span>next_state<span class="token punctuation">,</span> next_action<span class="token punctuation">)</span>            target_Q <span class="token operator">=</span> torch<span class="token punctuation">.</span>min<span class="token punctuation">(</span>target_Q1<span class="token punctuation">,</span> target_Q2<span class="token punctuation">)</span>            target_Q <span class="token operator">=</span> reward <span class="token operator">+</span> not_done <span class="token operator">*</span> self<span class="token punctuation">.</span>discount <span class="token operator">*</span> target_Q        <span class="token comment" spellcheck="true"># Get current Q estimates</span>        current_Q1<span class="token punctuation">,</span> current_Q2 <span class="token operator">=</span> self<span class="token punctuation">.</span>critic<span class="token punctuation">(</span>state<span class="token punctuation">,</span> action<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># Compute critic loss</span>        critic_loss <span class="token operator">=</span> F<span class="token punctuation">.</span>mse_loss<span class="token punctuation">(</span>current_Q1<span class="token punctuation">,</span> target_Q<span class="token punctuation">)</span> <span class="token operator">+</span> F<span class="token punctuation">.</span>mse_loss<span class="token punctuation">(</span>current_Q2<span class="token punctuation">,</span> target_Q<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># Optimize the critic</span>        self<span class="token punctuation">.</span>critic_optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>        critic_loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>critic_optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># Delayed policy updates</span>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>total_it <span class="token operator">%</span> self<span class="token punctuation">.</span>policy_freq <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>            <span class="token comment" spellcheck="true"># Compute actor losse</span>            actor_loss <span class="token operator">=</span> <span class="token operator">-</span>self<span class="token punctuation">.</span>critic<span class="token punctuation">.</span>Q1<span class="token punctuation">(</span>state<span class="token punctuation">,</span> self<span class="token punctuation">.</span>actor<span class="token punctuation">(</span>state<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token comment" spellcheck="true"># Optimize the actor </span>            self<span class="token punctuation">.</span>actor_optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>            actor_loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>            self<span class="token punctuation">.</span>actor_optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token comment" spellcheck="true"># Update the frozen target models</span>            <span class="token keyword">for</span> param<span class="token punctuation">,</span> target_param <span class="token keyword">in</span> zip<span class="token punctuation">(</span>self<span class="token punctuation">.</span>critic<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>critic_target<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                target_param<span class="token punctuation">.</span>data<span class="token punctuation">.</span>copy_<span class="token punctuation">(</span>self<span class="token punctuation">.</span>tau <span class="token operator">*</span> param<span class="token punctuation">.</span>data <span class="token operator">+</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> self<span class="token punctuation">.</span>tau<span class="token punctuation">)</span> <span class="token operator">*</span> target_param<span class="token punctuation">.</span>data<span class="token punctuation">)</span>            <span class="token keyword">for</span> param<span class="token punctuation">,</span> target_param <span class="token keyword">in</span> zip<span class="token punctuation">(</span>self<span class="token punctuation">.</span>actor<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>actor_target<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                target_param<span class="token punctuation">.</span>data<span class="token punctuation">.</span>copy_<span class="token punctuation">(</span>self<span class="token punctuation">.</span>tau <span class="token operator">*</span> param<span class="token punctuation">.</span>data <span class="token operator">+</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> self<span class="token punctuation">.</span>tau<span class="token punctuation">)</span> <span class="token operator">*</span> target_param<span class="token punctuation">.</span>data<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">save</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> filename<span class="token punctuation">)</span><span class="token punctuation">:</span>        torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>self<span class="token punctuation">.</span>critic<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> filename <span class="token operator">+</span> <span class="token string">"_critic"</span><span class="token punctuation">)</span>        torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>self<span class="token punctuation">.</span>critic_optimizer<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> filename <span class="token operator">+</span> <span class="token string">"_critic_optimizer"</span><span class="token punctuation">)</span>        torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>self<span class="token punctuation">.</span>actor<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> filename <span class="token operator">+</span> <span class="token string">"_actor"</span><span class="token punctuation">)</span>        torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>self<span class="token punctuation">.</span>actor_optimizer<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> filename <span class="token operator">+</span> <span class="token string">"_actor_optimizer"</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">load</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> filename<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>critic<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>filename <span class="token operator">+</span> <span class="token string">"_critic"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>critic_optimizer<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>filename <span class="token operator">+</span> <span class="token string">"_critic_optimizer"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>critic_target <span class="token operator">=</span> copy<span class="token punctuation">.</span>deepcopy<span class="token punctuation">(</span>self<span class="token punctuation">.</span>critic<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>actor<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>filename <span class="token operator">+</span> <span class="token string">"_actor"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>actor_optimizer<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>filename <span class="token operator">+</span> <span class="token string">"_actor_optimizer"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>actor_target <span class="token operator">=</span> copy<span class="token punctuation">.</span>deepcopy<span class="token punctuation">(</span>self<span class="token punctuation">.</span>actor<span class="token punctuation">)</span></code></pre>]]></content>
      
      
      <categories>
          
          <category> 强化学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 强化学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基于模型的深度强化学习(Model_based RL)</title>
      <link href="2021/10/05/ji-yu-mo-xing-de-shen-du-qiang-hua-xue-xi-model-based-rl/"/>
      <url>2021/10/05/ji-yu-mo-xing-de-shen-du-qiang-hua-xue-xi-model-based-rl/</url>
      
        <content type="html"><![CDATA[<p> 参考视频：<a href="https://www.bilibili.com/video/BV1hV411d7Sg?spm_id_from=333.999.0.0">周博磊强化学习纲要</a></p><p> 阅读本文前需要对强化学习model-free领域有一定的了解，可以查看我之前的文章：《<a href="https://tianjuewudi.gitee.io/2021/07/16/qiang-hua-xue-xi-shi-jian-jiao-xue/">强化学习实践教学</a>》，《<a href="https://tianjuewudi.gitee.io/2021/07/21/qiang-hua-xue-xi-gang-yao-zhou-bo-lei-ke-cheng/#toc-heading-39">强化学习纲要（周博磊课程）</a>》</p><p> 之前介绍的算法例如DQN，DDPG，PPO都是<strong>model-free（无模型）</strong>的，这也是比较多人的研究领域，这些算法是智能体直接和环境互动获得数据，不需要拟合环境模型，智能体对环境的认知只能通过和环境不断大量的交互来实现。这样做的优点是通过无数次与环境的交互可以保证智能体得到最优解。往往在游戏这样的没有采样成本的环境中都可以用model-free。</p><p>接下来我介绍强化学习的另一个领域<strong>model-based（基于模型）</strong>，在这个领域中，智能体通过与环境进行交互获得数据，根据这些数据对环境进行建模拟合出一个模型，然后智能体根据模型来生成样本并利用RL算法优化自身。一旦模型拟合出来，智能体就可以根据该模型来生成样本，因此智能体和环境直接的交互次数会急剧减少，缺点是拟合的模型往往存在偏差，因此model-based的算法通常不保证能收敛到最优解。但是在现实生活中是需要一定的采样成本的，因此采样效率至关重要，因此model-free是一个提升采样效率的重要方式。</p><img src="/2021/10/05/ji-yu-mo-xing-de-shen-du-qiang-hua-xue-xi-model-based-rl/2.png" class><p> model-based的强化学习算法分为两类，一类是值函数优化（value optimization），一类是策略优化（policy optinmization）。</p><img src="/2021/10/05/ji-yu-mo-xing-de-shen-du-qiang-hua-xue-xi-model-based-rl/1.png" class><p>在model-based RL中不仅仅有原来model-free中的结构，还多了一个model，因此原本在model-free中用来训练价值函数和策略函数的experience有了第二个用处，那就是model learning，拟合出一个适当的环境模型。</p><h2 id="环境模型的构成"><a href="#环境模型的构成" class="headerlink" title="环境模型的构成"></a>环境模型的构成</h2><img src="/2021/10/05/ji-yu-mo-xing-de-shen-du-qiang-hua-xue-xi-model-based-rl/3.png" class><p>环境通常由两部分构成，第一就是状态转移矩阵，也就是说在知道现在的状态和采取的动作的情况下，转移到其他各个状态的概率。第二就是奖励函数，在知道现在的状态和采取的动作的情况下,我们可以得到的奖励是多少。</p><p>例如在围棋中的规则是十分清楚的，因此状态之间的转移也是十分清楚的，因此能够打败人类的围棋AI AlphaGO也是用model-based强化学习算法得到的。还有一种是物理模型，现实中的物理模型往往有固定的计算公式，也可以轻松得到其状态转移。</p><p>通常假定状态转移和奖励函数是相互独立的关系。</p><h2 id="环境模型的训练"><a href="#环境模型的训练" class="headerlink" title="环境模型的训练"></a>环境模型的训练</h2><img src="/2021/10/05/ji-yu-mo-xing-de-shen-du-qiang-hua-xue-xi-model-based-rl/4.png" class><p>那么如何训练一个环境使其符合预期呢？</p><p>这里我们只需要用监督学习的方法，收集真实环境中的数据${S_t,A_t \rightarrow R_{t+1},S_{t+1}}$，通过收集很多组这样的数据就能把这个当成样本，输入到环境的神经网络中进行学习。</p><p>这里列举几个常用的模型：</p><ol><li>Table Lookup Model</li><li>Linear Expectation Model</li><li>Linear Gaussian Model</li><li>Gaussian Process Model</li><li>Deep Belief Network Model</li></ol><p>我们通常要对模型的准确率进行评估，如果准确率低，那么应当采用model-free的方法。</p><h2 id="Dyna"><a href="#Dyna" class="headerlink" title="Dyna"></a>Dyna</h2><p>这是Richard Sutton在1991年提出的算法，在现阶段的强化学习算法中并不足够强，但是是我们理解model-based方法的例子。在通过真实的经验数据学习出来的环境模型中，我们刻意采集大量的虚拟数据，这样就能和填补真实数据采集不到的空白，一起去训练值函数模型和策略网络。</p><img src="/2021/10/05/ji-yu-mo-xing-de-shen-du-qiang-hua-xue-xi-model-based-rl/5.png" class><img src="/2021/10/05/ji-yu-mo-xing-de-shen-du-qiang-hua-xue-xi-model-based-rl/6.png" class><h2 id="Model-based-的策略优化（Policy-Optimization）"><a href="#Model-based-的策略优化（Policy-Optimization）" class="headerlink" title="Model-based 的策略优化（Policy Optimization）"></a>Model-based 的策略优化（Policy Optimization）</h2><p>在model-free的policy gradient中，条件转移概率是不需要的。但是在model-based知道转移概率的情况下，就能改进我们的策略优化。</p><p>基于环境模型的策略优化受控制论的影响是非常深远的。因为控制问题也是优化一个controller，而环境通常叫做system dynamics，可以定义成知道现在状态和采取的控制措施，得到的下一个状态。这也是最优控制（optimal controls）的内容，在满足动态转移条件的情况下去优化控制方法，降低cost函数。这和强化学习有很深远的联系。<br>$$<br>arg min_{a_1,…,a_T} \sum_{t=1}^T c(s_t,a_t)  \  \  \ \ subject \ to \ s_t = f(s_{t-1},a_{t-1})<br>$$<br>在环境模型未知的情况下，我们可以结合模型学习和轨迹优化两种方法。</p><img src="/2021/10/05/ji-yu-mo-xing-de-shen-du-qiang-hua-xue-xi-model-based-rl/7.png" class><p>第一种算法是用监督学习训练出环境模型之后，直接采用控制算法（如LQR）来计算最优路径。</p><img src="/2021/10/05/ji-yu-mo-xing-de-shen-du-qiang-hua-xue-xi-model-based-rl/8.png" class><p>第二种算法是为了防止训练数据采样不充分，在训练出环境模型之后，自己产生新的数据加入训练当中。</p><img src="/2021/10/05/ji-yu-mo-xing-de-shen-du-qiang-hua-xue-xi-model-based-rl/9.png" class><p>第三种算法是一种非常有名的算法<strong>MPC（Model Predictive Control）</strong>,是自动驾驶和控制中的常用算法。我们对整个轨迹进行优化，但是我们实际执行时只执行第一步，然后把这一步的数据加入到训练数据集中，个人理解是第一步的误差都是比较小的，数据都比较可靠。</p><img src="/2021/10/05/ji-yu-mo-xing-de-shen-du-qiang-hua-xue-xi-model-based-rl/10.png" class><hr><p>最后第四种算法是把policy learning、model learning、optimal control结合起来。</p><img src="/2021/10/05/ji-yu-mo-xing-de-shen-du-qiang-hua-xue-xi-model-based-rl/11.png" class><ol><li><p>初始化策略函数产生随机策略对真实环境的数据进行收集。</p></li><li><p>用收集的数据训练自己的环境模型。</p></li><li><p>通过环境模型产生的数据来对策略进行优化。</p></li><li><p>用优化后的策略去环境模型中产生新的轨迹，并将新的轨迹数据加入训练数据当中</p></li><li><p>返回第二条。</p></li></ol><p>下面是两种模型的选择：</p><img src="/2021/10/05/ji-yu-mo-xing-de-shen-du-qiang-hua-xue-xi-model-based-rl/12.png" class><img src="/2021/10/05/ji-yu-mo-xing-de-shen-du-qiang-hua-xue-xi-model-based-rl/13.png" class><h2 id="model-based-RL在机器人的应用"><a href="#model-based-RL在机器人的应用" class="headerlink" title="model-based RL在机器人的应用"></a>model-based RL在机器人的应用</h2><img src="/2021/10/05/ji-yu-mo-xing-de-shen-du-qiang-hua-xue-xi-model-based-rl/14.png" class><p>首先是摄像机捕捉画面得到一个3D坐标，我们需要把3D坐标转换成机械臂各个部位旋转的角度，我们可以把奖励函数设置成和Target坐标的距离来进行训练。这里用了Gaussin Process来做环境模型。像这种低成本的机械臂有很大的误差，需要对不确定性有很好的建模。</p><img src="/2021/10/05/ji-yu-mo-xing-de-shen-du-qiang-hua-xue-xi-model-based-rl/15.png" class><hr><img src="/2021/10/05/ji-yu-mo-xing-de-shen-du-qiang-hua-xue-xi-model-based-rl/16.png" class><img src="/2021/10/05/ji-yu-mo-xing-de-shen-du-qiang-hua-xue-xi-model-based-rl/17.png" class>]]></content>
      
      
      <categories>
          
          <category> 强化学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 强化学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>强化学习之DQN超级进化版Rainbow</title>
      <link href="2021/09/25/qiang-hua-xue-xi-zhi-dqn-chao-ji-jin-hua-ban-rainbow/"/>
      <url>2021/09/25/qiang-hua-xue-xi-zhi-dqn-chao-ji-jin-hua-ban-rainbow/</url>
      
        <content type="html"><![CDATA[<p> 阅读本文前可以先了解我前三篇文章《强化学习之DQN》《强化学习之DDQN》、《强化学习之 Dueling DQN》。</p><p>Rainbow结合了DQN算法的6个扩展改进，将它们集成在同一个智能体上，其中包括DDQN，Dueling DQN，Prioritized Replay、Multi-step Learning、Distributional RL、Noisy Net。加上原版的DQN，凑齐七种因素，召唤Rainbow！</p><p>参考知乎：<a href="https://zhuanlan.zhihu.com/p/261322143">https://zhuanlan.zhihu.com/p/261322143</a></p><h2 id="DDQN"><a href="#DDQN" class="headerlink" title="DDQN"></a>DDQN</h2><p>传统DQN中，每次学习的时候都会使用当前策略认为的价值最高的动作，所以会出现对Q值的过高估计，而这个问题表现在神经网络上就是因为选择下一时刻的动作以及计算下一时刻Q值的时候都使用了目标网络。为了将动作选择和价值估计进行解耦，因此有了DDQN。在计算Q实际值是，动作选择由Q网络得到而不是TargetQ网络。价值估计还是由TargetQ网络得到。</p><hr><h2 id="Dueling-DQN"><a href="#Dueling-DQN" class="headerlink" title="Dueling DQN"></a>Dueling DQN</h2><p>这个方法改变的是神经网络的结构，把Q值函数分解为价值函数V和优势函数A的和，即Q= V+A。其中V代表了这种状态的好坏程度，有时函数表明在这个状态下某一个动作相对于其他动作的好坏程度，而Q表明了这个状态下确定的某个动作的价值。为了限制A和V的值使得其在一个合理的范围内，我们可以用一种方法将A的均值限制为0以达到我们的要求。因此Q的计算公式如下：<br>$$<br>Q(s,a;θ,α) = V(s;θ) + (A(s,a;θ,α) - \frac{1}{|A|}\sum_{a’}A(s,a’;θ,α))<br>$$</p><hr><h2 id="基于优先级的复用池（Prioritized-Reply）"><a href="#基于优先级的复用池（Prioritized-Reply）" class="headerlink" title="基于优先级的复用池（Prioritized Reply）"></a>基于优先级的复用池（Prioritized Reply）</h2><p>在传统DQN中，经验池中的数据采样都是随机的，但其实不同样本的价值是不同的，需要给样本一个优先级，并根据样本的优先级进行采样。</p><p>这里需要用到一个指标——TD误差。设目标网络产生的Q值为Q现实值，TargetQ网络产生的Q值为Q估计值。那么TD误差就是Q现实值-Q估计值。用来衡量优先学习的程度，如果TD误差越大，就代表预测精度还有很多的上升空间，这个样本就越需要被学习，即优先级p越高。</p><p>那么如何有效进行抽样？如果我们每次抽样都对p进行排序选取其中的最大值，会浪费大量的计算资源，从而使得训练时间变长。常用的解决方法是使用SumTree的树形结构来储存数据。这种树状结构本质上也是采用了概率式的选择方式，优先级p的大小跟选中的概率成正比，和线性的结构相比，这种方法不用逐一检查数据，大大提高了运行效率。</p><img src="/2021/09/25/qiang-hua-xue-xi-zhi-dqn-chao-ji-jin-hua-ban-rainbow/1.png" class=""><p>首先我们要对所有的数据建立一个树状结构，叶子节点储存每个样本的优先级p，每个树枝节点只有两个分叉，节点的值是两个分支的和。这样最上面的一层的一个节点是所有优先级p的和。</p><p>在抽样的时候，我们会将p的和分成batch_size个区间，然后再每个区间中随机选择一个数。例如我们在[21,28]的区间中选择了24，就按照42往下搜索，从左往右对比，如果这个数比节点小就继续往下走，比节点大则用这个数减去节点的数字然后继续往右进行对比。这里24比13大，因此往右搜索，数字变成24-13=11，11比16小，因此往下走，11比12小，因此我们最终选取的是优先级为12的这组数据。</p><hr><h2 id="多步学习（multi-step-learning）"><a href="#多步学习（multi-step-learning）" class="headerlink" title="多步学习（multi-step learning）"></a>多步学习（multi-step learning）</h2><p>传统DQN使用当前的即时奖励和下一时刻的价值估计来判断目标的价值，然而这种方法在训练的前期网络参数偏差较大时会导致得到的目标价值也会偏大，进而导致目标价值的估计偏差较大，因此出现了多步学习来解决这个问题。在多步学习中，即时奖励会通过与环境交互确切得到，所以训练前期的目标价值可以得到更准确的估计，从而加快训练的速度。</p><p>原DQN使用的是时序差分的更新策略即TD。loss公式为：<br>$$<br>(r_j + \gamma \max_a \hat{Q}(s_{j+1},a;\theta^-) - Q(s_j,a_j;\theta))^2<br>$$<br>以上是one-step的TD算法。</p><p>在rainbow中我们采用multi-step方法，对于N步的情况，loss公式变为：<br>$$<br>(\sum_{k=0}^{N-1}{\gamma^k r_{t+k}} + \gamma^N \max_a \hat{Q}(s_{t+N},a;\theta^-) - Q(s_t,a_t;\theta))^2<br>$$</p><hr><h2 id="分布式RL（Distributional-DQN）"><a href="#分布式RL（Distributional-DQN）" class="headerlink" title="分布式RL（Distributional DQN）"></a>分布式RL（Distributional DQN）</h2><p>论文原文：<a href="https://www.aminer.cn/pub/599c7b58601a182cd272b540/a-distributional-perspective-on-reinforcement-learning">https://www.aminer.cn/pub/599c7b58601a182cd272b540/a-distributional-perspective-on-reinforcement-learning</a></p><p>这篇文章开创了一个新的方向，将我们的认知从“Q值”拓展到”Q分布”。</p><p>在传统DQN中，网络输出的是动作价值Q的估计，但是其实还是忽略了很多信息。假如两个动作能够获得的价值期望相同都是20，第一个动作有90%的情况是10，10%的情况下是110，第二个动作的50%的情况下是25，50%的情况下是15，那么虽然期望一样，但是要想减少风险，就应该选择后一种动作，<strong>只输出期望值看不到背后隐含的风险</strong>。</p><p>如果采用分布视角（deistributional perspective）来建模DRL的模型，可以的得到更好更稳定的结果。我们可以把价值限定在$[V_{min},V_{max}]$之间，选择N个等距的价值采样点，通过神经网络输出这N个采样点的概率，通过Q和TargetQ网络得到估计的<strong>价值分布</strong>和目标的价值分布，计算两个分布之间的差距。</p><p>现在的问题是如何表示这个分布，首先抛弃高斯分布，因为是单峰的，Distributional DQN的论文作者提出了一个叫做<strong>C51</strong>的算法，用51个等间距的atoms来描述一个分布，类似直方图，选择点的范围和个数取决于你的应用。</p><p>这时候网络的架构需要做一定的调整，原DQN输入的是状态s，输出的是一个包含各个动作价值的向量$(Q(s,a1),Q(s,a2),…,Q(s,a_m))$。在Distributional DQN中，输入不变，输出变成一个矩阵，每一行代表一个动作，而列则代表了直方图中的每一条柱子，这个分布的范围是人为确定的，例如atoms有51个，范围为$(0,50)$，则atoms是${0,1,2,…,49,50}$。而神经网络输出的每一个动作对应每一个atoms的概率，有N个atoms则有N个概率，相加为1，形式是${p_0^a,p_1^a,…,p_{N-1}^a}$，每个概率和对应的atoms的值相乘可以得到动作价值的期望，即原本的Q值。</p><p>确定了分布的形式之后，接下来就是如何衡量两个分布的距离，以此来决定Loss函数。这里作者采用的是<strong>KL散度</strong>。</p><p>KL散度，也称为相对熵，是衡量两个分布差距的计算公式。公式如下：<br>$$<br>D_{KL} (p||q) = \sum_{i=1}^N p(x_i) * (\log p(x_i) - \log q(x_i)) =  \sum_{i=1}^N p(x_i) * \log \frac{p(x_i)}{q(x_i)}<br>$$<br>可以证明这个值大于等于0。当两者分布接近时，这个值会趋近于0，这个值越大，分布差距越大。</p><p>从式子中可以看出，KL散度计算的是数据的原分布与近似分布的概率的对数差的期望值。但要注意，散度不具有交换性，不能单纯理解为距离，更准确的说是一个分布相比另一个分布的信息损失。</p><p>在原DQN中，动作价值的更新目标是</p><p>$$<br>r + \gamma \max_a Q(s_{t+1},a)<br>$$<br>在分布式DQN中：<br>$$<br>Q(s_{t+1},a) = \sum_i z_i p_i(s_{t+1},a)<br>$$<br>其中z就是直方图的横坐标的各个值，p就是对应的各个概率。那么更新目标$Z(s,a)$有p0概率为$r + \gamma z_0$，有p1概率为$r + \gamma z_1$，以此类推。</p><p>当分布更新后，对应直方图的横坐标会发生偏移，因此我们需要调整分布。把$r + \gamma z_i$的分布均摊到$z_i$上，例如$r + \gamma z_0$位于z0和z1之间，我们可以计算它到两个点距离的比值决定均摊概率的比值。</p><img src="/2021/09/25/qiang-hua-xue-xi-zhi-dqn-chao-ji-jin-hua-ban-rainbow/2.png" class=""><h2 id="噪声网络（Nosiy-Net）"><a href="#噪声网络（Nosiy-Net）" class="headerlink" title="噪声网络（Nosiy Net）"></a>噪声网络（Nosiy Net）</h2><p>RL过程中总会想办法增加agent的探索能力，传统的DQN通常采用ε-greedy的策略，即以ε的概率采取随机策略，通过在训练初期采取较大的ε来增加系统的探索性，训练后期减小ε来实现系统的稳定。另外一种办法就是噪声网络，即通过对参数增加噪声来增加模型的探索能力。一般噪声会添加在全连接层，考虑全连接层的前项计算公式：<br>$$<br>y = wx +b<br>$$<br>假如两层神经元的个数分别是p和q，那么w是q*p维的，b是q维的，如果b和w满足均值为μ，方差为σ的正态分布，同时存在一定的随机噪声N。假设噪声满足标准正态分布，那么前项计算公式变为：<br>$$<br>y = (μ^w + \sigma^w \odot N^w)x + μ^b + \sigma^b \odot N^b<br>$$</p><p>产生噪声的方法主要有两种一种是Independent Gaussian noise，一种是Factorised Gaussian noise。对于DQN这种很稠密的算法来说我们往往使用Factorised Gaussian noise。对应A3C这种并行更依赖采样的方法我们可以使用Independent Gaussian noise。</p><p>independent Gaussian Noise是给每一个权重都添加一个独立的随机噪声，那么一共需要$p(q+1)$个随机噪声。</p><p>Factorised Gaussian noise 相对节省计算量，它给每一个神经元一个噪声，图中只需要p + q个随机噪声，</p><img src="/2021/09/25/qiang-hua-xue-xi-zhi-dqn-chao-ji-jin-hua-ban-rainbow/3.png" class=""><p>具体到每一个神经元上，$w_{ij}$的噪声为：<br>$$<br>N_{i,j}^w = f(N_i)f(N_j)<br>$$<br>$b_j$的噪声为:<br>$$<br>N_{j}^b = f(N_j)<br>$$<br>其中：<br>$$<br>f(x) = sgn(x) \sqrt{|x|}<br>$$</p>]]></content>
      
      
      <categories>
          
          <category> 强化学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 强化学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>交易与分析</title>
      <link href="2021/09/19/jiao-yi-yu-fen-xi/"/>
      <url>2021/09/19/jiao-yi-yu-fen-xi/</url>
      
        <content type="html"><![CDATA[<p> <a href="https://www.youtube.com/watch?v=sNZ2y5XamPk&amp;list=PLhhGIAWVvaGxHCN1HxcsR15acdK4dy2-c&amp;index=1&amp;ab_channel=%E6%99%BA%E6%AD%8C%E2%9D%80%E2%9D%80">https://www.youtube.com/watch?v=sNZ2y5XamPk&amp;list=PLhhGIAWVvaGxHCN1HxcsR15acdK4dy2-c&amp;index=1&amp;ab_channel=%E6%99%BA%E6%AD%8C%E2%9D%80%E2%9D%80</a></p><h2 id="仓位管理，心态建设，买卖规则重于预测"><a href="#仓位管理，心态建设，买卖规则重于预测" class="headerlink" title="仓位管理，心态建设，买卖规则重于预测"></a>仓位管理，心态建设，买卖规则重于预测</h2><p> 交易前，我们制定规则如下：</p><ol><li>仓位管理是数字货币投资的前提，管理不好一切努力白费。<strong>要遵守2%仓位管理原则</strong>，不能一把梭。</li><li>要对回撤有正确的认识。</li><li>交易规则重于预测分析。</li><li>保证资金安全，追求最大化收益。</li><li>不要承受自己输不起的风险，不要孤注一掷。</li><li><strong>每周最多交易1-2次，3天交易1次，不要高频率交易</strong>。</li><li>连续亏损3单，休息一周。</li></ol><p>2%仓位原则是指每次只使用1%或2%的资金投入到合约账户。其他的都在现货账户中。坚持三个月到半年之后一定能稳定盈利。每次拿出1%是为了让自己的资金不会一次性亏完，同时保证了自己的生活心态，这是至关重要的，同时这个过程中也有足够的资金把握更好的机会，例如：拿1%的资金开20倍杠杆最多把本金亏没，但是一旦上涨超过5%那么盈亏比将超越1：1，达到2：1甚至3：1。</p><p>这里的讲解主要围绕心态，规则，仓位管理进行。仓位够清，心态才会好，才能进行更好的交易。</p><h2 id="量价时空"><a href="#量价时空" class="headerlink" title="量价时空"></a>量价时空</h2><p>价格：市场规律、斜率（价格趋势，通常表现为均线）、人性变化、自由规律、真实数据。</p><p>成交量：市场多空的分歧，成交量和成交额不一样。</p><p>时间：时间可以超越价位平衡，当时间到达，成交量将增加或降低而推动价位升跌。</p><p>空间：市场不同时间，形成的交易成本的差距。</p><p>量价时空就是人性的规律，双方立场，贪婪恐慌的规律。</p><h2 id="tradingview（最好用的分析网站）"><a href="#tradingview（最好用的分析网站）" class="headerlink" title="tradingview（最好用的分析网站）"></a>tradingview（最好用的分析网站）</h2><p>网址：<a href="https://cn.tradingview.com/">https://cn.tradingview.com/</a></p><p>教学：<a href="https://www.youtube.com/watch?v=QOi5LOqxoM4&amp;list=PLhhGIAWVvaGxHCN1HxcsR15acdK4dy2-c&amp;index=3&amp;ab_channel=%E6%99%BA%E6%AD%8C%E2%9D%80%E2%9D%80">https://www.youtube.com/watch?v=QOi5LOqxoM4&amp;list=PLhhGIAWVvaGxHCN1HxcsR15acdK4dy2-c&amp;index=3&amp;ab_channel=%E6%99%BA%E6%AD%8C%E2%9D%80%E2%9D%80</a></p><h2 id="解读K线图"><a href="#解读K线图" class="headerlink" title="解读K线图"></a>解读K线图</h2><img src="/2021/09/19/jiao-yi-yu-fen-xi/1.png" class=""><p>往往数字货币的行情可以用K线图表示，K线图又由一个个像蜡烛一样的柱子构成。其中主干代表开盘和收盘的价格，绿色代表收盘比开盘高，红色则相反，一根柱子代表的时间根据图表设定而定。而主干上下两根烛针，代表了到达过的最高和最低点。</p><p>当主干部分较大则力度较强，而上下两根针（影线）越短越好，这样趋势才会强。上方的针越短，说明涨幅（跌幅）越没有水分。</p><img src="/2021/09/19/jiao-yi-yu-fen-xi/2.png" class=""><p>上面是四种形态的叫法，锤头利好向上，射击之星利空向下。破脚穿头看涨，穿头破脚看跌。</p><img src="/2021/09/19/jiao-yi-yu-fen-xi/3.png" class=""><img src="/2021/09/19/jiao-yi-yu-fen-xi/4.png" class=""><img src="/2021/09/19/jiao-yi-yu-fen-xi/5.png" class=""><img src="/2021/09/19/jiao-yi-yu-fen-xi/6.png" class=""><h2 id="实战（正确使用射击之星和锤头提高胜率）"><a href="#实战（正确使用射击之星和锤头提高胜率）" class="headerlink" title="实战（正确使用射击之星和锤头提高胜率）"></a>实战（正确使用射击之星和锤头提高胜率）</h2><img src="/2021/09/19/jiao-yi-yu-fen-xi/7.png" class=""><p>其中射击之星在顶部出现看跌，在底部出现叫倒转锤头，看涨；锤头出现在底部看涨，出现在顶部看跌。</p><img src="/2021/09/19/jiao-yi-yu-fen-xi/8.png" class=""><p>首先看第一个图，可以看到最高点面前的一个次高点明显有一个<strong>支撑位</strong>，当最高点下来时就是在测试这个支撑位，如果出现了看涨的<strong>信号</strong>，那么大几率看涨。</p><p>第二个图，在后续上涨过程中，如果在上一个顶部位置出现了回调信号，那么就是<strong>双顶</strong>形态，后续看跌。</p><p>第三个图是看<strong>趋势线</strong>。配合前面的看涨信号同样可以看涨，结合第二个图，如果不能在第二个顶端有所突破，那么可能会有一个比较大的下跌。</p><p>第四个图看<strong>移动平均线</strong>，常用是EMA2均线。线在下面看涨，线在上面看跌。</p><p>第五个图看<strong>底部</strong>，下面有一个非常强的底部支撑的形成后续看涨。</p><hr><p>下面来说一个头肩底的结构，当曲线在两次上涨的过程中都遇到阻力，没有突破而造成下跌，说明这个阻力位很强，如果第三波顺利突破了阻力位大概率看涨，同时下次的回调也会测试这个阻力位，出现了上涨信号大概率看涨。</p><img src="/2021/09/19/jiao-yi-yu-fen-xi/9.png" class=""><p>实战中：</p><img src="/2021/09/19/jiao-yi-yu-fen-xi/13.png" class=""><hr><p>当前面的两个最高点都没能突破阻力位，出现下跌信号时赶紧撤单。下一次如果上调将至这个阻力位时，即使出现了上涨信号，也不要做多，因为利润空间很小。</p><img src="/2021/09/19/jiao-yi-yu-fen-xi/10.png" class=""><p>然而，如果在即将到顶的时候出现了一根大阳柱要突破阻力，那么可以继续做多，并且可以下次回调的时候也有可能被阻力位挡住，但如果没能突破就是看跌。</p><img src="/2021/09/19/jiao-yi-yu-fen-xi/11.png" class=""><hr><p>两根柱子的形成：</p><img src="/2021/09/19/jiao-yi-yu-fen-xi/12.png" class=""><hr><p>在实际操作的时候，一定要去找<strong>压力位</strong>和<strong>支撑位</strong>，支撑位做多，压力位做空，中间位置不去操作，养成这样一个习惯，投资胜率能够高达70%以上。</p><h2 id="正确使用支撑位和压力位"><a href="#正确使用支撑位和压力位" class="headerlink" title="正确使用支撑位和压力位"></a>正确使用支撑位和压力位</h2><p>当曲线向上突破的位置有阻碍叫做压力位，向下突破受到阻碍的位置叫做支撑位。</p><ol><li><p>支撑位和压力位受到检验的次数越多，用它来进行的决策越可靠.</p></li><li><p>曲线对此位置有过强烈反应是标准。</p></li><li><p>同时做过支撑位和压力位最佳。因为支撑位和压力位在被打破的时候是能相互转换的。</p></li><li><p>小型山寨币需要慎重进行参考，容易被操纵的币支撑和压力的参考意义会变小。</p></li><li><p>一般情况下数字货币会在整数（整百整千整万）的关口会有心理层面的支撑和压力。例如比特币没一千会有小支撑和压力，一万有大支撑和压力。</p></li><li><p>趋势线也是一个支撑和压力位。</p><img src="/2021/09/19/jiao-yi-yu-fen-xi/14.png" class=""></li></ol><h2 id="如何正确画趋势线"><a href="#如何正确画趋势线" class="headerlink" title="如何正确画趋势线"></a>如何正确画趋势线</h2><ol><li><p> 三点一线才具备参考价值。</p></li><li><p>需要配合均线，其他指标使用。</p><img src="/2021/09/19/jiao-yi-yu-fen-xi/15.png" class=""></li></ol><h2 id="123法则和2B形态"><a href="#123法则和2B形态" class="headerlink" title="123法则和2B形态"></a>123法则和2B形态</h2><p>注意：这两种规律只适用于单边行情，不适用于振荡行情，振荡行情需要在箱体上方做空，下方做多，以50%为界。</p><h3 id="123法则"><a href="#123法则" class="headerlink" title="123法则"></a>123法则</h3> <img src="/2021/09/19/jiao-yi-yu-fen-xi/23.png" class=""> <img src="/2021/09/19/jiao-yi-yu-fen-xi/24.png" class=""> <img src="/2021/09/19/jiao-yi-yu-fen-xi/25.png" class=""><p>因此，只要<strong>不涨（跌）破左边的高（低）点</strong>，并且涨（跌）<strong>破趋势线</strong>，<strong>到达上一个低（高）点</strong>，满足三个条件，就形成123结构，只不过123位置有所不同。在这种情况下，我们就可以在123中最下方的点上开空。</p><h3 id="2B形态"><a href="#2B形态" class="headerlink" title="2B形态"></a>2B形态</h3><p>2B形态和123法则不同的地方在于破了新高（低），其他没有区别。</p> <img src="/2021/09/19/jiao-yi-yu-fen-xi/26.png" class=""><h2 id="MA、EMA均线的使用"><a href="#MA、EMA均线的使用" class="headerlink" title="MA、EMA均线的使用"></a>MA、EMA均线的使用</h2><p>注意：均线系统用于单边行情，不适用于震荡行情。</p><p>这里，我使用的MA和EMA均线都是20、60、120。</p><p>首先，一轮牛市要想开启，价格要在所有均线上方，在牛市开启之前，价格上涨超过的均线依次为EMA20、MA20、EMA60、MA60、EMA120、MA120，并且多头持续排列，然后一轮新牛市开启。</p><p>如果是短线交易，用20均线足以。</p><h2 id="正确解读MACD"><a href="#正确解读MACD" class="headerlink" title="正确解读MACD"></a>正确解读MACD</h2><p>其中MA代表移动平均线，CD代表聚散关系。</p> <img src="/2021/09/19/jiao-yi-yu-fen-xi/27.png" class=""><p>图中包含两条线，一条快速移动平均线，一条慢速移动平均线。上面在选择了EMA12和EMA26的情况下，蓝色的线代表了EMA12 - EMA26的数值，称为Diff，而下面的一条橙色线是9个周期的Diff得到的平均值，称为DEA。</p><p>因此当EMA12大于EMA26时，Diff在上方，反之亦然。</p><p>而中间的烛的作用是把Diff和DEA的差距显示出来，计算方式是（Diff-DEA）*2。</p><p>其实MACD探讨的是一个利润空间的问题，当Diff和DEA远在上方时，代表涨幅较大，当涨幅缩水时这两个指标也会慢慢趋近于0，代表趋势的转变。</p><h2 id="黄金分割和斐波那契回撤"><a href="#黄金分割和斐波那契回撤" class="headerlink" title="黄金分割和斐波那契回撤"></a>黄金分割和斐波那契回撤</h2><p>首先斐波那契回撤有7条线，用来判断在一轮牛市过后曲线能够回撤到什么程度。其中最底端的线在上涨过程中的最下方，也就是1线，最上面的线在上涨的顶部，也就是0线，中间的五条分别代表了回撤的程度，分别是0.234，0.382，0.5，0.618，0.786。其中中间的三条线最为关键，也就是0.382，0.5，0.618。这是几个经过大量验证的数据，请记住。</p> <img src="/2021/09/19/jiao-yi-yu-fen-xi/16.png" class=""> <img src="/2021/09/19/jiao-yi-yu-fen-xi/17.png" class=""><p>我们通常可以只考虑中间的三条线，当曲线到达0.382时出现看涨的趋势，说明这是一个弱回调，上涨趋势继续。当曲线突破0.5时，可能会出现趋势反转但也很有可能在突破0.5时出现大阳烛，趋势继续。</p> <img src="/2021/09/19/jiao-yi-yu-fen-xi/18.png" class=""><p>当曲线突破0.618进行回调时，都被0.5和0.382挡住那么表示趋势结束，未来一段时间看跌。</p> <img src="/2021/09/19/jiao-yi-yu-fen-xi/19.png" class=""><p>这里我们配合MACD来进行分析，每一轮上涨，利润空间都在不断减小，最后达到最高点后没有利润空间，这就是本轮牛市的终结，就会进行新一轮的下跌。</p><p>然后我们可以配合EMA20 60 120来进行分析。</p> <img src="/2021/09/19/jiao-yi-yu-fen-xi/20.png" class=""><p>当三条曲线并驾齐驱，并且K线都没有有效跌破三根曲线到达下方，预示新一轮的牛市开启。而当新高利润慢慢减少，再加上突破黄金分割，就是一个危险的信号。</p><hr><p>当趋势下跌的时候我们也可以用斐波那回撤进行分析。</p> <img src="/2021/09/19/jiao-yi-yu-fen-xi/21.png" class=""><p>当趋势下跌时我们从下往上划线，同样道理，如果上调碰到38.2出现看跌信号，说明这是一波弱回调。</p><p>又例如下面这个图，每次触碰50烛都被挡下了，最后甚至不能触碰50烛，那么可以预测趋势看跌。</p> <img src="/2021/09/19/jiao-yi-yu-fen-xi/22.png" class=""><h2 id="解读网格、马丁、趋势、头皮、对冲交易"><a href="#解读网格、马丁、趋势、头皮、对冲交易" class="headerlink" title="解读网格、马丁、趋势、头皮、对冲交易"></a>解读网格、马丁、趋势、头皮、对冲交易</h2><p>行情分为单边行情和振荡行情，单边行情想要赚钱只需要趋势做对在回调的时候配合斐波那契回撤出手即可，震荡行情我们要观察箱顶和箱底的位置，在上方做空，下方做多，并配合斐波那契回撤即可，难的是有很多时候是两种混合。</p><p>网格交易法：适合震荡行情，30挂多，70挂空，一层一层来，一定要有仓位管理，但非常危险，不推荐。</p><p>马丁交易法：就是在下跌过程中一层层挂单，前提是能扛得住，不推荐。</p><p>对冲：例如如果判定在高点做空，然后K线下跌，有回调迹象，这时候直接开一个等额多单，这样即使回调了不会失去这部分的利润。不推荐。不推荐。</p><p>头皮交易：搞到一点就跑，止损只设置一点点的距离，这样只会亏一点钱，但可以赚的话可以赚到一大部分。不推荐。</p><h2 id="时间周期，交易心得"><a href="#时间周期，交易心得" class="headerlink" title="时间周期，交易心得"></a>时间周期，交易心得</h2><p>时间：时间可以超越价位平衡，当时间到达，成交量将增加或降低而推动价位升跌。</p><p>我们需要给市场一个时间调整。当一波上涨或是下跌后，市场会进入一个调整期，然后再决定涨还是跌，也就是说，时间周期会推动价格加速上涨下跌。比如下面的图每次都需要大约1天的时间反复震荡进行调整，新手常常犯的错误就是以为价格不是涨就是跌，胡乱出手，频繁交易，导致被割韭菜。</p> <img src="/2021/09/19/jiao-yi-yu-fen-xi/28.png" class=""><p>每当调整周期的时候，我们应该仔细观察其触碰经线的反映，观察压力位和支撑位，综合多方面因素考虑，而不是仓皇出手。</p><hr><p>最后说一个重要的事情：1%最大亏损，锻炼的是自己的原则和规律，<strong>一定要有自己的规则，管住自己</strong>，特别是作为一个新手，应该小资金地进行操作，因为<strong>只有不亏钱，才能赚钱</strong>。<strong>只要仓位轻，万物皆可兵！</strong>脑子清醒，眼睛才看得见；脑子糊涂，眼睛也是瞎的。</p><ul><li><p>交易最精彩的一刻，不是资金买入的一刻，而是资金增值退出的一刻。</p></li><li><p>行情在绝望中诞生，在半信半疑中成长，在憧憬中成熟，在希望中毁灭。</p></li><li><p>亏钱的三个原因：过度交易或频繁交易（一周超过3次），不设置止损（死扛），对市场缺乏认知。</p></li><li><p>缺乏市场知识，是市场买卖中损失的主要原因。</p></li><li><p>交易的核心：心态，规律，盈亏比，低回撤。</p><img src="/2021/09/19/jiao-yi-yu-fen-xi/29.png" class=""></li></ul>]]></content>
      
      
      <categories>
          
          <category> 投资 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 投资 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Unity商业级网络游戏开发</title>
      <link href="2021/09/16/unity-shang-ye-ji-wang-luo-you-xi-kai-fa/"/>
      <url>2021/09/16/unity-shang-ye-ji-wang-luo-you-xi-kai-fa/</url>
      
        <content type="html"><![CDATA[<p> 参考视频：<a href="https://www.bilibili.com/video/BV1C7411i7Rg?p=2">https://www.bilibili.com/video/BV1C7411i7Rg?p=2</a></p><h2 id="开发准备："><a href="#开发准备：" class="headerlink" title="开发准备："></a>开发准备：</h2><h3 id="基本操作"><a href="#基本操作" class="headerlink" title="基本操作"></a>基本操作</h3><ol><li><p>下载git，安装时注意以下选项：</p><img src="/2021/09/16/unity-shang-ye-ji-wang-luo-you-xi-kai-fa/1.png" class=""></li><li><p>下载安装TortoiseGit，可以下载一个语言包切换成中文。</p></li><li><p>下载安装Unity。</p></li><li><p>创建一个Unity项目后，进入项目文件夹。点击右键–<strong>创建</strong>Git仓库，在该文件夹下会多出一个.git文件夹（记得显示隐藏文件）。</p></li><li><p>这时候再点击右键会出现一个提交到Master分支的选项，这时我们点击TortoiseGit–Setting完善信息。填上自己的名字和邮箱。</p></li><li><p>在右键菜单中点击<strong>提交</strong>到Master分支，可以看到里面有很多Library的选项。这种通用文件我们不需要提交，而且容易搞错，我们选择提交时无视它。</p><img src="/2021/09/16/unity-shang-ye-ji-wang-luo-you-xi-kai-fa/2.png" class=""></li><li><p>我们右键点击Library文件夹，在TortoiseGit中点击添加到<strong>忽略</strong>列表，点确定。其他不需要提交的都可以这样操作</p><img src="/2021/09/16/unity-shang-ye-ji-wang-luo-you-xi-kai-fa/3.png" class=""></li><li><p>右键–&gt;TortoiesGit–&gt;Show log（显示<strong>日志</strong>），所有的版本操作都显示在上面，也包括你队友的。</p><img src="/2021/09/16/unity-shang-ye-ji-wang-luo-you-xi-kai-fa/4.png" class=""></li><li><p>提交了文件之后，如果我们对后续的修改不满意（这时文件上有个叹号），可以点击tortoiseGit中的revert（<strong>还原</strong>），直接回退到提交时的状态。也可以用Diff来查看差异。</p></li></ol><h3 id="合作开发"><a href="#合作开发" class="headerlink" title="合作开发"></a>合作开发</h3><p>首先大家找到一个能够共享的目录，比如在自己电脑上共享一个目录让其他队友能访问，这样就是git服务器。</p><p>首先创建一个空文件夹，在这个文件夹中创建Git仓库，把这项勾选。这样就创建了一个纯仓库。</p><img src="/2021/09/16/unity-shang-ye-ji-wang-luo-you-xi-kai-fa/5.png" class=""><p>回到本地的项目文件夹打开Git的Setting，点击远端(remote)。把刚刚创建<strong>Git仓库的路径</strong>复制进URL，应用–&gt;确定。这样就把服务器路径配置完成了。</p><img src="/2021/09/16/unity-shang-ye-ji-wang-luo-you-xi-kai-fa/6.png" class=""><p>下面在原项目文件夹下点击push（<strong>推送</strong>）。直接确定。</p><img src="/2021/09/16/unity-shang-ye-ji-wang-luo-you-xi-kai-fa/7.png" class=""><p>那么怎么把东西<strong>下载</strong>下来呢，我们可以利用右键菜单中的git Clone…（git克隆）来把东西拉到自己的文件夹。路径依然填上我们的服务器路径，第二行是下载路径。</p><img src="/2021/09/16/unity-shang-ye-ji-wang-luo-you-xi-kai-fa/8.png" class=""><p>这样我们就把东西下载到另外一个文件夹了，加上原来的文件夹，相当于有两个员工可以提交东西。提交的时候先commit到本地，然后push到服务器就可以了。下载的时候就可以直接pull到自己的文件夹下。查看日志就可以看到有两个人在提交东西。</p><p>这时候就有一个问题，如果两个人同时修改了一个文件然后提交怎么处理，答案是服务器会接受第一个提交，第二个因为冲突无法提交，必须先把东西pull下来之后在别人的基础上修改才能提交。这时候需要共同商讨修改方案。</p><img src="/2021/09/16/unity-shang-ye-ji-wang-luo-you-xi-kai-fa/9.png" class=""><p>这时候需要我们解决冲突，在本地把代码拉下来时会让你合并代码：</p><img src="/2021/09/16/unity-shang-ye-ji-wang-luo-you-xi-kai-fa/10.png" class=""><p>其中左右两边就是冲突的两个文件，下面的是我们修改后需要提交的文件，我们可以直接在下面的文件中做修改即可。或者选中某部分代码，右键菜单中可以选择使用哪边的代码或者是两边都要只是顺序问题。调整好后直接点击保存。保存好后就可以正常提交到本地在push到服务器了。</p><h2 id="登录界面"><a href="#登录界面" class="headerlink" title="登录界面"></a>登录界面</h2><p>首先先创建canvas，里面放两个inputField和一个button。Canvas参数中UI Scale Mode记得调成Scale With Screen Size，下面的Reference Resolution调成1920*1080，游戏画面调成16:9。然后用一个空物体存放这些内容，拖成预制体。</p><p>通用的内容都建议拖成预制体来管理妥当，减少未来的工作量。</p><hr><p>（后面的内容细节操作太多，不便记录，请查看视频）</p>]]></content>
      
      
      <categories>
          
          <category> 游戏开发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 游戏开发 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>强化学习之DQN代码带讲解</title>
      <link href="2021/09/13/qiang-hua-xue-xi-zhi-dqn-dai-ma-dai-jiang-jie/"/>
      <url>2021/09/13/qiang-hua-xue-xi-zhi-dqn-dai-ma-dai-jiang-jie/</url>
      
        <content type="html"><![CDATA[<p>  本代码取自周博磊强化学习课程<a href="https://space.bilibili.com/511221970/channel/detail?cid=105354&amp;ctype=0">https://space.bilibili.com/511221970/channel/detail?cid=105354&amp;ctype=0</a></p><p>源码：<a href="https://download.csdn.net/download/tianjuewudi/24541126">https://download.csdn.net/download/tianjuewudi/24541126</a></p><p> 此处程序个人感觉过多过乱，应整理出属于自己风格的代码结构，这是编程实现必不可少的环节。</p><h2 id="导入包"><a href="#导入包" class="headerlink" title="导入包"></a>导入包</h2><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> gym<span class="token keyword">from</span> gym <span class="token keyword">import</span> wrappers<span class="token keyword">import</span> torch<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn<span class="token keyword">import</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">as</span> optim<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">from</span> IPython<span class="token punctuation">.</span>display <span class="token keyword">import</span> clear_output<span class="token keyword">from</span> matplotlib <span class="token keyword">import</span> pyplot <span class="token keyword">as</span> plt<span class="token operator">%</span>matplotlib inline<span class="token keyword">import</span> random<span class="token keyword">from</span> timeit <span class="token keyword">import</span> default_timer <span class="token keyword">as</span> timer<span class="token keyword">from</span> datetime <span class="token keyword">import</span> timedelta<span class="token keyword">import</span> math<span class="token keyword">from</span> utils<span class="token punctuation">.</span>wrappers <span class="token keyword">import</span> make_atari<span class="token punctuation">,</span> wrap_deepmind<span class="token punctuation">,</span> wrap_pytorch<span class="token keyword">from</span> utils<span class="token punctuation">.</span>hyperparameters <span class="token keyword">import</span> Config<span class="token keyword">from</span> agents<span class="token punctuation">.</span>BaseAgent <span class="token keyword">import</span> BaseAgent<span class="token comment" spellcheck="true"># 这两行不加会导致Notebook出现内核停止的问题</span><span class="token keyword">import</span> osos<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">"KMP_DUPLICATE_LIB_OK"</span><span class="token punctuation">]</span><span class="token operator">=</span><span class="token string">"TRUE"</span></code></pre><h2 id="超参数"><a href="#超参数" class="headerlink" title="超参数"></a>超参数</h2><p>utils.hypeparameter文件：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">import</span> math<span class="token keyword">class</span> <span class="token class-name">Config</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">"cuda"</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">"cpu"</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">#PPO controls</span>        self<span class="token punctuation">.</span>ppo_epoch <span class="token operator">=</span> <span class="token number">3</span>        self<span class="token punctuation">.</span>num_mini_batch <span class="token operator">=</span> <span class="token number">32</span>        self<span class="token punctuation">.</span>ppo_clip_param <span class="token operator">=</span> <span class="token number">0.1</span>        <span class="token comment" spellcheck="true">#a2c controls</span>        self<span class="token punctuation">.</span>num_agents <span class="token operator">=</span> <span class="token number">8</span>        self<span class="token punctuation">.</span>rollout <span class="token operator">=</span> <span class="token number">16</span>        self<span class="token punctuation">.</span>value_loss_weight <span class="token operator">=</span> <span class="token number">0.5</span>        self<span class="token punctuation">.</span>entropy_loss_weight <span class="token operator">=</span> <span class="token number">0.001</span>        self<span class="token punctuation">.</span>grad_norm_max <span class="token operator">=</span> <span class="token number">0.5</span>        self<span class="token punctuation">.</span>USE_GAE<span class="token operator">=</span><span class="token boolean">True</span>        self<span class="token punctuation">.</span>gae_tau <span class="token operator">=</span> <span class="token number">0.95</span>        <span class="token comment" spellcheck="true">#algorithm control</span>        self<span class="token punctuation">.</span>USE_NOISY_NETS<span class="token operator">=</span><span class="token boolean">False</span>        self<span class="token punctuation">.</span>USE_PRIORITY_REPLAY<span class="token operator">=</span><span class="token boolean">False</span>        <span class="token comment" spellcheck="true">#Multi-step returns</span>        self<span class="token punctuation">.</span>N_STEPS <span class="token operator">=</span> <span class="token number">1</span>        <span class="token comment" spellcheck="true">#epsilon variables</span>        self<span class="token punctuation">.</span>epsilon_start <span class="token operator">=</span> <span class="token number">1.0</span>        self<span class="token punctuation">.</span>epsilon_final <span class="token operator">=</span> <span class="token number">0.01</span>        self<span class="token punctuation">.</span>epsilon_decay <span class="token operator">=</span> <span class="token number">30000</span>        self<span class="token punctuation">.</span>epsilon_by_frame <span class="token operator">=</span> <span class="token keyword">lambda</span> frame_idx<span class="token punctuation">:</span> self<span class="token punctuation">.</span>epsilon_final <span class="token operator">+</span> <span class="token punctuation">(</span>self<span class="token punctuation">.</span>epsilon_start <span class="token operator">-</span> self<span class="token punctuation">.</span>epsilon_final<span class="token punctuation">)</span> <span class="token operator">*</span> math<span class="token punctuation">.</span>exp<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">.</span> <span class="token operator">*</span> frame_idx <span class="token operator">/</span> self<span class="token punctuation">.</span>epsilon_decay<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">#misc agent variables</span>        self<span class="token punctuation">.</span>GAMMA<span class="token operator">=</span><span class="token number">0.99</span>        self<span class="token punctuation">.</span>LR<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">4</span>        <span class="token comment" spellcheck="true">#memory</span>        self<span class="token punctuation">.</span>TARGET_NET_UPDATE_FREQ <span class="token operator">=</span> <span class="token number">1000</span>        self<span class="token punctuation">.</span>EXP_REPLAY_SIZE <span class="token operator">=</span> <span class="token number">100000</span>        self<span class="token punctuation">.</span>BATCH_SIZE <span class="token operator">=</span> <span class="token number">32</span>        self<span class="token punctuation">.</span>PRIORITY_ALPHA<span class="token operator">=</span><span class="token number">0.6</span>        self<span class="token punctuation">.</span>PRIORITY_BETA_START<span class="token operator">=</span><span class="token number">0.4</span>        self<span class="token punctuation">.</span>PRIORITY_BETA_FRAMES <span class="token operator">=</span> <span class="token number">100000</span>        <span class="token comment" spellcheck="true">#Noisy Nets</span>        self<span class="token punctuation">.</span>SIGMA_INIT<span class="token operator">=</span><span class="token number">0.5</span>        <span class="token comment" spellcheck="true">#Learning control variables</span>        self<span class="token punctuation">.</span>LEARN_START <span class="token operator">=</span> <span class="token number">10000</span>        self<span class="token punctuation">.</span>MAX_FRAMES<span class="token operator">=</span><span class="token number">100000</span>        <span class="token comment" spellcheck="true">#Categorical Params</span>        self<span class="token punctuation">.</span>ATOMS <span class="token operator">=</span> <span class="token number">51</span>        self<span class="token punctuation">.</span>V_MAX <span class="token operator">=</span> <span class="token number">10</span>        self<span class="token punctuation">.</span>V_MIN <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">10</span>        <span class="token comment" spellcheck="true">#Quantile Regression Parameters</span>        self<span class="token punctuation">.</span>QUANTILES<span class="token operator">=</span><span class="token number">51</span>        <span class="token comment" spellcheck="true">#DRQN Parameters</span>        self<span class="token punctuation">.</span>SEQUENCE_LENGTH<span class="token operator">=</span><span class="token number">8</span></code></pre><p>主文件代码：</p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 导入预先设定的参数</span>config <span class="token operator">=</span> Config<span class="token punctuation">(</span><span class="token punctuation">)</span>config<span class="token punctuation">.</span>device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">"cuda"</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">"cpu"</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># epsilon为探索因子，越小随机探索的概率越低，我们期望在训练初期能给予模型更多的探索机会，找到相对更优的路径，后期稳定更新。</span>config<span class="token punctuation">.</span>epsilon_start <span class="token operator">=</span> <span class="token number">1.0</span>config<span class="token punctuation">.</span>epsilon_final <span class="token operator">=</span> <span class="token number">0.01</span>config<span class="token punctuation">.</span>epsilon_decay <span class="token operator">=</span> <span class="token number">30000</span>config<span class="token punctuation">.</span>epsilon_by_frame <span class="token operator">=</span> <span class="token keyword">lambda</span> frame_idx<span class="token punctuation">:</span> config<span class="token punctuation">.</span>epsilon_final <span class="token operator">+</span> <span class="token punctuation">(</span>config<span class="token punctuation">.</span>epsilon_start <span class="token operator">-</span> config<span class="token punctuation">.</span>epsilon_final<span class="token punctuation">)</span> <span class="token operator">*</span> math<span class="token punctuation">.</span>exp<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">.</span> <span class="token operator">*</span> frame_idx <span class="token operator">/</span> config<span class="token punctuation">.</span>epsilon_decay<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 折扣因子以及学习率</span>config<span class="token punctuation">.</span>GAMMA<span class="token operator">=</span><span class="token number">0.99</span>config<span class="token punctuation">.</span>LR<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">4</span><span class="token comment" spellcheck="true">#memory</span>config<span class="token punctuation">.</span>TARGET_NET_UPDATE_FREQ <span class="token operator">=</span> <span class="token number">1000</span>config<span class="token punctuation">.</span>EXP_REPLAY_SIZE <span class="token operator">=</span> <span class="token number">100000</span>config<span class="token punctuation">.</span>BATCH_SIZE <span class="token operator">=</span> <span class="token number">32</span><span class="token comment" spellcheck="true">#Learning control variables</span>config<span class="token punctuation">.</span>LEARN_START <span class="token operator">=</span> <span class="token number">10000</span><span class="token comment" spellcheck="true"># 最多跑多少episode</span>config<span class="token punctuation">.</span>MAX_FRAMES<span class="token operator">=</span><span class="token number">1000000</span></code></pre><h2 id="经验回放池"><a href="#经验回放池" class="headerlink" title="经验回放池"></a>经验回放池</h2><pre class=" language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">ExperienceReplayMemory</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> capacity<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>capacity <span class="token operator">=</span> capacity        self<span class="token punctuation">.</span>memory <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token comment" spellcheck="true"># 当数据过多时，删除最早的数据</span>    <span class="token keyword">def</span> <span class="token function">push</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> transition<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>memory<span class="token punctuation">.</span>append<span class="token punctuation">(</span>transition<span class="token punctuation">)</span>        <span class="token keyword">if</span> len<span class="token punctuation">(</span>self<span class="token punctuation">.</span>memory<span class="token punctuation">)</span> <span class="token operator">></span> self<span class="token punctuation">.</span>capacity<span class="token punctuation">:</span>            <span class="token keyword">del</span> self<span class="token punctuation">.</span>memory<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>    <span class="token comment" spellcheck="true"># 在经验池中抽取batch_size个样本</span>    <span class="token keyword">def</span> <span class="token function">sample</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> batch_size<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> random<span class="token punctuation">.</span>sample<span class="token punctuation">(</span>self<span class="token punctuation">.</span>memory<span class="token punctuation">,</span> batch_size<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> len<span class="token punctuation">(</span>self<span class="token punctuation">.</span>memory<span class="token punctuation">)</span></code></pre><h2 id="神经网络"><a href="#神经网络" class="headerlink" title="神经网络"></a>神经网络</h2><pre class=" language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">DQN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input_shape<span class="token punctuation">,</span> num_actions<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>DQN<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>input_shape <span class="token operator">=</span> input_shape        self<span class="token punctuation">.</span>num_actions <span class="token operator">=</span> num_actions        <span class="token comment" spellcheck="true"># 注意输入的是一个画面，如果有RGB三层，input_shape[0]=3</span>        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>self<span class="token punctuation">.</span>input_shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv3 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>fc1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>self<span class="token punctuation">.</span>feature_size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>fc2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_actions<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># 三个卷积层+展开+带ReLU全连接层+不带ReLU全连接层</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv3<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fc1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>fc2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> x    <span class="token keyword">def</span> <span class="token function">feature_size</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>conv3<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">*</span>self<span class="token punctuation">.</span>input_shape<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span></code></pre><h2 id="智能体"><a href="#智能体" class="headerlink" title="智能体"></a>智能体</h2><p>BaseAgent文件：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> pickle<span class="token keyword">import</span> os<span class="token punctuation">.</span>path<span class="token keyword">import</span> torch<span class="token keyword">import</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">as</span> optim<span class="token keyword">class</span> <span class="token class-name">BaseAgent</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>model<span class="token operator">=</span>None        self<span class="token punctuation">.</span>target_model<span class="token operator">=</span>None        self<span class="token punctuation">.</span>optimizer <span class="token operator">=</span> None        self<span class="token punctuation">.</span>losses <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        self<span class="token punctuation">.</span>rewards <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        self<span class="token punctuation">.</span>sigma_parameter_mag<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token keyword">def</span> <span class="token function">huber</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        cond <span class="token operator">=</span> <span class="token punctuation">(</span>x<span class="token punctuation">.</span>abs<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&lt;</span> <span class="token number">1.0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>float<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> <span class="token number">0.5</span> <span class="token operator">*</span> x<span class="token punctuation">.</span>pow<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span> <span class="token operator">*</span> cond <span class="token operator">+</span> <span class="token punctuation">(</span>x<span class="token punctuation">.</span>abs<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">0.5</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token number">1.0</span> <span class="token operator">-</span> cond<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 保存模型和优化器</span>    <span class="token keyword">def</span> <span class="token function">save_w</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'./saved_agents/model.dump'</span><span class="token punctuation">)</span>        torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>self<span class="token punctuation">.</span>optimizer<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'./saved_agents/optim.dump'</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 导入模型和优化器</span>    <span class="token keyword">def</span> <span class="token function">load_w</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        fname_model <span class="token operator">=</span> <span class="token string">"./saved_agents/model.dump"</span>        fname_optim <span class="token operator">=</span> <span class="token string">"./saved_agents/optim.dump"</span>        <span class="token keyword">if</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>isfile<span class="token punctuation">(</span>fname_model<span class="token punctuation">)</span><span class="token punctuation">:</span>            self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>fname_model<span class="token punctuation">)</span><span class="token punctuation">)</span>            self<span class="token punctuation">.</span>target_model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>isfile<span class="token punctuation">(</span>fname_optim<span class="token punctuation">)</span><span class="token punctuation">:</span>            self<span class="token punctuation">.</span>optimizer<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>fname_optim<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 保存经验池</span>    <span class="token keyword">def</span> <span class="token function">save_replay</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        pickle<span class="token punctuation">.</span>dump<span class="token punctuation">(</span>self<span class="token punctuation">.</span>memory<span class="token punctuation">,</span> open<span class="token punctuation">(</span><span class="token string">'./saved_agents/exp_replay_agent.dump'</span><span class="token punctuation">,</span> <span class="token string">'wb'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 导入经验池</span>    <span class="token keyword">def</span> <span class="token function">load_replay</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        fname <span class="token operator">=</span> <span class="token string">'./saved_agents/exp_replay_agent.dump'</span>        <span class="token keyword">if</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>isfile<span class="token punctuation">(</span>fname<span class="token punctuation">)</span><span class="token punctuation">:</span>            self<span class="token punctuation">.</span>memory <span class="token operator">=</span> pickle<span class="token punctuation">.</span>load<span class="token punctuation">(</span>open<span class="token punctuation">(</span>fname<span class="token punctuation">,</span> <span class="token string">'rb'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">save_sigma_param_magnitudes</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        tmp <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        <span class="token keyword">for</span> name<span class="token punctuation">,</span> param <span class="token keyword">in</span> self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>named_parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">if</span> param<span class="token punctuation">.</span>requires_grad<span class="token punctuation">:</span>                <span class="token keyword">if</span> <span class="token string">'sigma'</span> <span class="token keyword">in</span> name<span class="token punctuation">:</span>                    <span class="token comment" spellcheck="true"># 把数据放cpu上，ravel把数组展开成一维，tolist变成列表</span>                    tmp<span class="token operator">+=</span>param<span class="token punctuation">.</span>data<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>ravel<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> tmp<span class="token punctuation">:</span>            计算平均值，然后加入列表中            self<span class="token punctuation">.</span>sigma_parameter_mag<span class="token punctuation">.</span>append<span class="token punctuation">(</span>np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>np<span class="token punctuation">.</span>abs<span class="token punctuation">(</span>npA<span class="token punctuation">.</span>array<span class="token punctuation">(</span>tmp<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">save_loss</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> loss<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>losses<span class="token punctuation">.</span>append<span class="token punctuation">(</span>loss<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">save_reward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> reward<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>rewards<span class="token punctuation">.</span>append<span class="token punctuation">(</span>reward<span class="token punctuation">)</span></code></pre><p>主文件代码agent：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Model</span><span class="token punctuation">(</span>BaseAgent<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> static_policy<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> env<span class="token operator">=</span>None<span class="token punctuation">,</span> config<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>Model<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 设定参数</span>        self<span class="token punctuation">.</span>device <span class="token operator">=</span> config<span class="token punctuation">.</span>device        self<span class="token punctuation">.</span>gamma <span class="token operator">=</span> config<span class="token punctuation">.</span>GAMMA        self<span class="token punctuation">.</span>lr <span class="token operator">=</span> config<span class="token punctuation">.</span>LR        self<span class="token punctuation">.</span>target_net_update_freq <span class="token operator">=</span> config<span class="token punctuation">.</span>TARGET_NET_UPDATE_FREQ        self<span class="token punctuation">.</span>experience_replay_size <span class="token operator">=</span> config<span class="token punctuation">.</span>EXP_REPLAY_SIZE        self<span class="token punctuation">.</span>batch_size <span class="token operator">=</span> config<span class="token punctuation">.</span>BATCH_SIZE        self<span class="token punctuation">.</span>learn_start <span class="token operator">=</span> config<span class="token punctuation">.</span>LEARN_START        self<span class="token punctuation">.</span>static_policy <span class="token operator">=</span> static_policy        self<span class="token punctuation">.</span>num_feats <span class="token operator">=</span> env<span class="token punctuation">.</span>observation_space<span class="token punctuation">.</span>shape        self<span class="token punctuation">.</span>num_actions <span class="token operator">=</span> env<span class="token punctuation">.</span>action_space<span class="token punctuation">.</span>n        self<span class="token punctuation">.</span>env <span class="token operator">=</span> env        <span class="token comment" spellcheck="true"># 定义两个网络</span>        self<span class="token punctuation">.</span>declare_networks<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>target_model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>self<span class="token punctuation">.</span>lr<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 迁移网络到GPU</span>        self<span class="token punctuation">.</span>model <span class="token operator">=</span> self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>to<span class="token punctuation">(</span>self<span class="token punctuation">.</span>device<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>target_model<span class="token punctuation">.</span>to<span class="token punctuation">(</span>self<span class="token punctuation">.</span>device<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 训练还是评估,此处执行的是初始化</span>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>static_policy<span class="token punctuation">:</span>            self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>eval<span class="token punctuation">(</span><span class="token punctuation">)</span>            self<span class="token punctuation">.</span>target_model<span class="token punctuation">.</span>eval<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>            self<span class="token punctuation">.</span>target_model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>update_count <span class="token operator">=</span> <span class="token number">0</span>        <span class="token comment" spellcheck="true"># 定义经验池</span>        self<span class="token punctuation">.</span>declare_memory<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">declare_networks</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>model <span class="token operator">=</span> DQN<span class="token punctuation">(</span>self<span class="token punctuation">.</span>num_feats<span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_actions<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>target_model <span class="token operator">=</span> DQN<span class="token punctuation">(</span>self<span class="token punctuation">.</span>num_feats<span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_actions<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">declare_memory</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>memory <span class="token operator">=</span> ExperienceReplayMemory<span class="token punctuation">(</span>self<span class="token punctuation">.</span>experience_replay_size<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">append_to_replay</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> s<span class="token punctuation">,</span> a<span class="token punctuation">,</span> r<span class="token punctuation">,</span> s_<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>memory<span class="token punctuation">.</span>push<span class="token punctuation">(</span><span class="token punctuation">(</span>s<span class="token punctuation">,</span> a<span class="token punctuation">,</span> r<span class="token punctuation">,</span> s_<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 从经验池中抽样并解压得到对应四组数据，并附带non_final_mask是否存在下一状态的batch向量, empty_next_state_values检查下一状态的异常</span>    <span class="token keyword">def</span> <span class="token function">prep_minibatch</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># 从经验池中抽样</span>        transitions <span class="token operator">=</span> self<span class="token punctuation">.</span>memory<span class="token punctuation">.</span>sample<span class="token punctuation">(</span>self<span class="token punctuation">.</span>batch_size<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 把抽样的内容再分成四种数据</span>        batch_state<span class="token punctuation">,</span> batch_action<span class="token punctuation">,</span> batch_reward<span class="token punctuation">,</span> batch_next_state <span class="token operator">=</span> zip<span class="token punctuation">(</span><span class="token operator">*</span>transitions<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># (-1,1,84,84)</span>        shape <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token operator">+</span>self<span class="token punctuation">.</span>num_feats        batch_state <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>batch_state<span class="token punctuation">,</span> device<span class="token operator">=</span>self<span class="token punctuation">.</span>device<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float<span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span>shape<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># shape:32*1</span>        batch_action <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>batch_action<span class="token punctuation">,</span> device<span class="token operator">=</span>self<span class="token punctuation">.</span>device<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>long<span class="token punctuation">)</span><span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>        batch_reward <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>batch_reward<span class="token punctuation">,</span> device<span class="token operator">=</span>self<span class="token punctuation">.</span>device<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float<span class="token punctuation">)</span><span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 是否存在下一个状态shape:32</span>        non_final_mask <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>tuple<span class="token punctuation">(</span>map<span class="token punctuation">(</span><span class="token keyword">lambda</span> s<span class="token punctuation">:</span> s <span class="token keyword">is</span> <span class="token operator">not</span> None<span class="token punctuation">,</span> batch_next_state<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> device<span class="token operator">=</span>self<span class="token punctuation">.</span>device<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>uint8<span class="token punctuation">)</span>        <span class="token keyword">try</span><span class="token punctuation">:</span> <span class="token comment" spellcheck="true">#sometimes all next states are false</span>            <span class="token comment" spellcheck="true"># 过滤出存在的下一个状态</span>            non_final_next_states <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span>s <span class="token keyword">for</span> s <span class="token keyword">in</span> batch_next_state <span class="token keyword">if</span> s <span class="token keyword">is</span> <span class="token operator">not</span> None<span class="token punctuation">]</span><span class="token punctuation">,</span> device<span class="token operator">=</span>self<span class="token punctuation">.</span>sdevice<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float<span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span>shape<span class="token punctuation">)</span>            empty_next_state_values <span class="token operator">=</span> <span class="token boolean">False</span>        <span class="token keyword">except</span><span class="token punctuation">:</span>            non_final_next_states <span class="token operator">=</span> None            empty_next_state_values <span class="token operator">=</span> <span class="token boolean">True</span>        <span class="token keyword">return</span> batch_state<span class="token punctuation">,</span> batch_action<span class="token punctuation">,</span> batch_reward<span class="token punctuation">,</span> non_final_next_states<span class="token punctuation">,</span> non_final_mask<span class="token punctuation">,</span> empty_next_state_values    <span class="token keyword">def</span> <span class="token function">compute_loss</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> batch_vars<span class="token punctuation">)</span><span class="token punctuation">:</span>        batch_state<span class="token punctuation">,</span> batch_action<span class="token punctuation">,</span> batch_reward<span class="token punctuation">,</span> non_final_next_states<span class="token punctuation">,</span> non_final_mask<span class="token punctuation">,</span> empty_next_state_values <span class="token operator">=</span> batch_vars        <span class="token comment" spellcheck="true">#gather第一个参数是对应维度dim，第二个是索引，返回对应索引的值，此处返回的是batch中对应的动作价值Q。</span>        current_q_values <span class="token operator">=</span> self<span class="token punctuation">.</span>model<span class="token punctuation">(</span>batch_state<span class="token punctuation">)</span><span class="token punctuation">.</span>gather<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> batch_action<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">#target</span>        <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            max_next_q_values <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>self<span class="token punctuation">.</span>batch_size<span class="token punctuation">,</span> device<span class="token operator">=</span>self<span class="token punctuation">.</span>device<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float<span class="token punctuation">)</span><span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>            <span class="token keyword">if</span> <span class="token operator">not</span> empty_next_state_values<span class="token punctuation">:</span>                max_next_action <span class="token operator">=</span> self<span class="token punctuation">.</span>get_max_next_state_action<span class="token punctuation">(</span>non_final_next_states<span class="token punctuation">)</span>                <span class="token comment" spellcheck="true"># 这个操作可以把下一个状态为空的动作价值直接设置为0，其他不变</span>                max_next_q_values<span class="token punctuation">[</span>non_final_mask<span class="token punctuation">]</span> <span class="token operator">=</span> self<span class="token punctuation">.</span>target_model<span class="token punctuation">(</span>non_final_next_states<span class="token punctuation">)</span><span class="token punctuation">.</span>gather<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> max_next_action<span class="token punctuation">)</span>            expected_q_values <span class="token operator">=</span> batch_reward <span class="token operator">+</span> <span class="token punctuation">(</span>self<span class="token punctuation">.</span>gamma<span class="token operator">*</span>max_next_q_values<span class="token punctuation">)</span>        diff <span class="token operator">=</span> <span class="token punctuation">(</span>expected_q_values <span class="token operator">-</span> current_q_values<span class="token punctuation">)</span>        loss <span class="token operator">=</span> self<span class="token punctuation">.</span>huber<span class="token punctuation">(</span>diff<span class="token punctuation">)</span>        loss <span class="token operator">=</span> loss<span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> loss    <span class="token keyword">def</span> <span class="token function">update</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> s<span class="token punctuation">,</span> a<span class="token punctuation">,</span> r<span class="token punctuation">,</span> s_<span class="token punctuation">,</span> frame<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>static_policy<span class="token punctuation">:</span>            <span class="token keyword">return</span> None        self<span class="token punctuation">.</span>append_to_replay<span class="token punctuation">(</span>s<span class="token punctuation">,</span> a<span class="token punctuation">,</span> r<span class="token punctuation">,</span> s_<span class="token punctuation">)</span>        <span class="token keyword">if</span> frame <span class="token operator">&lt;</span> self<span class="token punctuation">.</span>learn_start<span class="token punctuation">:</span>            <span class="token keyword">return</span> None        batch_vars <span class="token operator">=</span> self<span class="token punctuation">.</span>prep_minibatch<span class="token punctuation">(</span><span class="token punctuation">)</span>        loss <span class="token operator">=</span> self<span class="token punctuation">.</span>compute_loss<span class="token punctuation">(</span>batch_vars<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># Optimize the model</span>        self<span class="token punctuation">.</span>optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">for</span> param <span class="token keyword">in</span> self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            param<span class="token punctuation">.</span>grad<span class="token punctuation">.</span>data<span class="token punctuation">.</span>clamp_<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>update_target_model<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>save_loss<span class="token punctuation">(</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>save_sigma_param_magnitudes<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">get_action</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> s<span class="token punctuation">,</span> eps<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">if</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>random<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">>=</span> eps <span class="token operator">or</span> self<span class="token punctuation">.</span>static_policy<span class="token punctuation">:</span>                X <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span>s<span class="token punctuation">]</span><span class="token punctuation">,</span> device<span class="token operator">=</span>self<span class="token punctuation">.</span>device<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float<span class="token punctuation">)</span>                <span class="token comment" spellcheck="true"># max(1)对dim=1求最大值，返回两个数，第一个是值，第二个是索引</span>                a <span class="token operator">=</span> self<span class="token punctuation">.</span>model<span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">.</span>max<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>                <span class="token keyword">return</span> a<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token keyword">else</span><span class="token punctuation">:</span>                <span class="token keyword">return</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_actions<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 软更新</span>    <span class="token keyword">def</span> <span class="token function">update_target_model</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>update_count<span class="token operator">+=</span><span class="token number">1</span>        self<span class="token punctuation">.</span>update_count <span class="token operator">=</span> self<span class="token punctuation">.</span>update_count <span class="token operator">%</span> self<span class="token punctuation">.</span>target_net_update_freq        <span class="token keyword">if</span> self<span class="token punctuation">.</span>update_count <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>            self<span class="token punctuation">.</span>target_model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">get_max_next_state_action</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> next_states<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>target_model<span class="token punctuation">(</span>next_states<span class="token punctuation">)</span><span class="token punctuation">.</span>max<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">huber</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        cond <span class="token operator">=</span> <span class="token punctuation">(</span>x<span class="token punctuation">.</span>abs<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&lt;</span> <span class="token number">1.0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>float<span class="token punctuation">)</span>        <span class="token keyword">return</span> <span class="token number">0.5</span> <span class="token operator">*</span> x<span class="token punctuation">.</span>pow<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span> <span class="token operator">*</span> cond <span class="token operator">+</span> <span class="token punctuation">(</span>x<span class="token punctuation">.</span>abs<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">0.5</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> cond<span class="token punctuation">)</span></code></pre><h2 id="绘图plot"><a href="#绘图plot" class="headerlink" title="绘图plot"></a>绘图plot</h2><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 打印三幅图</span><span class="token keyword">def</span> <span class="token function">plot</span><span class="token punctuation">(</span>frame_idx<span class="token punctuation">,</span> rewards<span class="token punctuation">,</span> losses<span class="token punctuation">,</span> sigma<span class="token punctuation">,</span> elapsed_time<span class="token punctuation">)</span><span class="token punctuation">:</span>    clear_output<span class="token punctuation">(</span><span class="token boolean">True</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">131</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'frame %s. reward: %s. time: %s'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>frame_idx<span class="token punctuation">,</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>rewards<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">10</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> elapsed_time<span class="token punctuation">)</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>rewards<span class="token punctuation">)</span>    <span class="token keyword">if</span> losses<span class="token punctuation">:</span>        plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">132</span><span class="token punctuation">)</span>        plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'loss'</span><span class="token punctuation">)</span>        plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>losses<span class="token punctuation">)</span>    <span class="token keyword">if</span> sigma<span class="token punctuation">:</span>        plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">133</span><span class="token punctuation">)</span>        plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'noisy param magnitude'</span><span class="token punctuation">)</span>        plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>sigma<span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><h2 id="主程序"><a href="#主程序" class="headerlink" title="主程序"></a>主程序</h2><pre class=" language-python"><code class="language-python">start<span class="token operator">=</span>timer<span class="token punctuation">(</span><span class="token punctuation">)</span>env_id <span class="token operator">=</span> <span class="token string">"PongNoFrameskip-v4"</span>env    <span class="token operator">=</span> make_atari<span class="token punctuation">(</span>env_id<span class="token punctuation">)</span>env    <span class="token operator">=</span> wrap_deepmind<span class="token punctuation">(</span>env<span class="token punctuation">,</span> frame_stack<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>env    <span class="token operator">=</span> wrap_pytorch<span class="token punctuation">(</span>env<span class="token punctuation">)</span>model <span class="token operator">=</span> Model<span class="token punctuation">(</span>env<span class="token operator">=</span>env<span class="token punctuation">,</span> config<span class="token operator">=</span>config<span class="token punctuation">)</span>episode_reward <span class="token operator">=</span> <span class="token number">0</span>observation <span class="token operator">=</span> env<span class="token punctuation">.</span>reset<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">for</span> frame_idx <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> config<span class="token punctuation">.</span>MAX_FRAMES <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    epsilon <span class="token operator">=</span> config<span class="token punctuation">.</span>epsilon_by_frame<span class="token punctuation">(</span>frame_idx<span class="token punctuation">)</span>    action <span class="token operator">=</span> model<span class="token punctuation">.</span>get_action<span class="token punctuation">(</span>observation<span class="token punctuation">,</span> epsilon<span class="token punctuation">)</span>    prev_observation<span class="token operator">=</span>observation    observation<span class="token punctuation">,</span> reward<span class="token punctuation">,</span> done<span class="token punctuation">,</span> _ <span class="token operator">=</span> env<span class="token punctuation">.</span>step<span class="token punctuation">(</span>action<span class="token punctuation">)</span>    observation <span class="token operator">=</span> None <span class="token keyword">if</span> done <span class="token keyword">else</span> observation    model<span class="token punctuation">.</span>update<span class="token punctuation">(</span>prev_observation<span class="token punctuation">,</span> action<span class="token punctuation">,</span> reward<span class="token punctuation">,</span> observation<span class="token punctuation">,</span> frame_idx<span class="token punctuation">)</span>    episode_reward <span class="token operator">+=</span> reward    <span class="token keyword">if</span> done<span class="token punctuation">:</span>        observation <span class="token operator">=</span> env<span class="token punctuation">.</span>reset<span class="token punctuation">(</span><span class="token punctuation">)</span>        model<span class="token punctuation">.</span>save_reward<span class="token punctuation">(</span>episode_reward<span class="token punctuation">)</span>        episode_reward <span class="token operator">=</span> <span class="token number">0</span>        <span class="token keyword">if</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>model<span class="token punctuation">.</span>rewards<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">10</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">></span> <span class="token number">19</span><span class="token punctuation">:</span>            plot<span class="token punctuation">(</span>frame_idx<span class="token punctuation">,</span> model<span class="token punctuation">.</span>rewards<span class="token punctuation">,</span> model<span class="token punctuation">.</span>losses<span class="token punctuation">,</span> model<span class="token punctuation">.</span>sigma_parameter_mag<span class="token punctuation">,</span> timedelta<span class="token punctuation">(</span>seconds<span class="token operator">=</span>int<span class="token punctuation">(</span>timer<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">-</span>start<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>            <span class="token keyword">break</span>    <span class="token keyword">if</span> frame_idx <span class="token operator">%</span> <span class="token number">10000</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>        plot<span class="token punctuation">(</span>frame_idx<span class="token punctuation">,</span> model<span class="token punctuation">.</span>rewards<span class="token punctuation">,</span> model<span class="token punctuation">.</span>losses<span class="token punctuation">,</span> model<span class="token punctuation">.</span>sigma_parameter_mag<span class="token punctuation">,</span> timedelta<span class="token punctuation">(</span>seconds<span class="token operator">=</span>int<span class="token punctuation">(</span>timer<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">-</span>start<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>model<span class="token punctuation">.</span>save_w<span class="token punctuation">(</span><span class="token punctuation">)</span>env<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>下面是整体的代码架构（可自己灵活添加功能）：</p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 导入包</span><span class="token comment" spellcheck="true"># 设定超参数</span><span class="token comment" spellcheck="true"># ReplayMemory:经验回放池</span><span class="token keyword">class</span> <span class="token class-name">ReplayMemory</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> capacity<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># 初始化，参数为容器大小，创建列表</span>    <span class="token keyword">def</span> <span class="token function">push</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> transition<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># 在列表后面新增数据，当数据超过容器大小时，删除最早的数据</span>    <span class="token keyword">def</span> <span class="token function">sample</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> batch_size<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># 在经验池中抽取batch_size个样本</span>    <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># 返回列表长度</span><span class="token comment" spellcheck="true"># Model:神经网络模型</span><span class="token keyword">class</span> <span class="token class-name">Model</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input_shape<span class="token punctuation">,</span> num_actions<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># 定义网络结构</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># 构造网络结构，输入状态（游戏画面），最后一层是全连接层</span>        <span class="token comment" spellcheck="true"># 输出节点数为action数量，返回的是action的Tensor</span><span class="token comment" spellcheck="true"># 所有Agent通用基类，定义了通用参数，包括各种保存，导入的函数        </span><span class="token keyword">class</span> <span class="token class-name">BaseAgent</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token keyword">class</span> <span class="token class-name">Agent</span><span class="token punctuation">(</span>BaseAgent<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> static_policy <span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">,</span>env <span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># TODO:这里设置超参数</span>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>static_policy<span class="token punctuation">:</span>            self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>eval<span class="token punctuation">(</span><span class="token punctuation">)</span>            self<span class="token punctuation">.</span>target_model<span class="token punctuation">.</span>eval<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>            self<span class="token punctuation">.</span>target_model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#从经验池中抽样，并把数据分门别类，做成几个Tensor</span>    <span class="token keyword">def</span> <span class="token function">prep_minibatch</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># 输入状态，输出最佳动作</span>    <span class="token keyword">def</span> <span class="token function">Get_Action</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>obs<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># 预测下一个最佳动作的索引</span>    <span class="token keyword">def</span> <span class="token function">get_max_next_state_action</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>next_states<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># 重点，计算Loss</span>    <span class="token keyword">def</span> <span class="token function">Compute_Loss</span><span class="token punctuation">(</span>self，batch_vars<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># 用TargetQ网络根据公式计算目标的Q价值，并用Q网络得出现在Q价值</span>        diff <span class="token operator">=</span> <span class="token punctuation">(</span>expected_q_values <span class="token operator">-</span> current_q_values<span class="token punctuation">)</span> <span class="token operator">**</span><span class="token number">2</span>        loss <span class="token operator">=</span> loss<span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> loss<span class="token comment" spellcheck="true"># 放置绘图函数</span><span class="token keyword">class</span> <span class="token class-name">Plot</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token comment" spellcheck="true"># -----------主运行文件--------------</span><span class="token comment" spellcheck="true"># 负责训练</span><span class="token keyword">def</span> <span class="token function">run_train_eposide</span><span class="token punctuation">(</span>agent<span class="token punctuation">,</span>env<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># 储存经验池</span>    <span class="token comment" spellcheck="true"># 采样</span>    <span class="token comment" spellcheck="true"># 计算Loss，调用反向传播</span>    <span class="token comment" spellcheck="true"># 保存数据</span><span class="token comment" spellcheck="true"># 负责展示效果</span><span class="token keyword">def</span> <span class="token function">run_evaluate_eposide</span><span class="token punctuation">(</span>agent<span class="token punctuation">,</span>env<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token keyword">def</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># 创建环境，实例化各种类，开启训练，记得定期保存</span><span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>    main<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre>]]></content>
      
      
      <categories>
          
          <category> 强化学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 强化学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>强化学习之PPO</title>
      <link href="2021/09/08/qiang-hua-xue-xi-zhi-ppo/"/>
      <url>2021/09/08/qiang-hua-xue-xi-zhi-ppo/</url>
      
        <content type="html"><![CDATA[<ul><li><p> 阅读本文前先了解TRPO算法有助于理解，我对此也写过博客：<a href="https://blog.csdn.net/tianjuewudi/article/details/120191097">https://blog.csdn.net/tianjuewudi/article/details/120191097</a></p></li><li><p>参考李宏毅老师的视频：<a href="https://www.bilibili.com/video/BV1Wv411h7kN?p=80">https://www.bilibili.com/video/BV1Wv411h7kN?p=80</a></p></li><li><p>公式加载不出请查看CSDN：<a href="https://blog.csdn.net/tianjuewudi/article/details/120212234">https://blog.csdn.net/tianjuewudi/article/details/120212234</a></p></li></ul><p>PPO，全名Proximal Policy Optimization，近端策略优化算法。</p><p>PPO算法是一种新型的Policy Gradient算法，Policy Gradient算法对步长十分敏感，但是又难以选择合适的步长，在训练过程中新旧策略的的变化差异如果过大则不利于学习。PPO提出了新的目标函数可以再多个训练步骤实现小批量的更新，解决了Policy Gradient算法中步长难以确定的问题。其实TRPO也是为了解决这个思想但是直接求解TRPO这种带约束的问题是十分复杂的，他与PPO算法的效果差不多，但是PPO将KL散度作为惩罚项，更加容易求解。</p><h2 id="理论基础：KL散度"><a href="#理论基础：KL散度" class="headerlink" title="理论基础：KL散度"></a>理论基础：KL散度</h2><p>KL散度，也称为相对熵，是衡量两个分布差距的计算公式。公式如下：<br>$$<br>D_{KL} (p||q) = \sum_{i=1}^N p(x_i) * (\log p(x_i) - \log q(x_i)) =  \sum_{i=1}^N p(x_i) * \log \frac{p(x_i)}{q(x_i)}<br>$$<br>可以证明这个值大于等于0。当两者分布接近时，这个值会趋近于0，这个值越大，分布差距越大。</p><p>从式子中可以看出，KL散度计算的是数据的原分布与近似分布的概率的对数差的期望值。但要注意，散度不具有交换性，不能单纯理解为距离，更准确的说是一个分布相比另一个分布的信息损失。</p><h2 id="PPO"><a href="#PPO" class="headerlink" title="PPO"></a>PPO</h2><p>PPO也分为Actor的部分和Critic的部分。</p><p>首先定义优势函数：<br>$$<br>\hat{A_t} = \sum_{t’&gt;t} \gamma^{t’-t}r_{t’} - V_{\phi}(s_t)<br>$$<br>更新Actor的部分我们把奖励函数设置成：</p><p>$$<br>J_{PPO}(\theta) = \sum_{t=1}^T \frac{\pi_{\theta}(a_t|s_t)}{\pi_{\theta_{old}}(a_t|s_t)}\hat{A}<em>t - \lambda KL[\pi</em>{\theta_{old}}|\pi_{\theta}]<br>$$</p><ul><li>这里的A其实应该用新策略采样出来计算的Advantage函数，但由于参数改变的不多，我们可以用旧策略的A来近似新策略的A。</li><li>前面一项的设置是因为我们只能充旧策略中采样而不能从新策略中采样所以做了important Sampling。同时这样做可以把我们的策略从on-policy转变为off-policy，旧策略可以收集很多数据之后，就能用这些数据训练很多次的网络，然后再重新采样。</li><li>这样当我们新策略的值远大于旧概率时，更新会快一些，但由于后面一项KL散度的存在，不会让概率分布差距过大的新旧策略更新太快，限制了新策略的更新幅度。</li></ul><p>而对于Critic部分，我们构建一个输出状态价值的网络，训练网络接近预定值：<br>$$<br>L_{BL}(\phi) = -\sum_{t=1}^{T}(\sum_{t’&gt;t} \gamma^{t’-t}r_{t’}-V_{\phi}(s_t))^2<br>$$<br>通过梯度递减来训练这个Loss为0.</p><img src="/2021/09/08/qiang-hua-xue-xi-zhi-ppo/2.png" class=""><h3 id="PPO-with-Adaptive-KL-Penalty"><a href="#PPO-with-Adaptive-KL-Penalty" class="headerlink" title="PPO with Adaptive KL Penalty"></a><strong>PPO with Adaptive KL Penalty</strong></h3><p>我们还发现KL散度还要乘以一个变量，该版本PPO的核心想法就是利用自适应的beta值（adaptive beta）：</p><img src="/2021/09/08/qiang-hua-xue-xi-zhi-ppo/1.png" class=""><p>当KL散度大于我们的设定值时，我们需要加大处罚力度，而小于一个设定值时，减小处罚力度，这样使得新旧策略的差距既不会偏大，也不会过小。</p><h3 id="PPO-with-Clipped-Objective"><a href="#PPO-with-Clipped-Objective" class="headerlink" title="PPO with Clipped Objective"></a><strong>PPO with Clipped Objective</strong></h3><p>这是基于上面PPO的改进，相比于用KL散度来限制策略的更新幅度，我们不如直接限制新旧策略的比例来实现防止其差距过大。这样还减少了KL散度的运算，提升了算法性能。<br>$$<br>L^{CLIP}(\theta) = \hat{E_t}[min(r_t(\theta)\hat{A_t},clip(r_t(\theta),1-\epsilon,1+\epsilon)\hat{A_t})]<br>$$</p><p>$$<br>r_t(\theta) =  \frac{\pi_{\theta}(a_t|s_t)}{\pi_{\theta_{old}}(a_t|s_t)}<br>$$</p><p>这里我们把新旧策略的比例限制在1-ε和1+ε直接，说白了就是在超过这个范围时把新策略直接设定为边界值。</p><img src="/2021/09/08/qiang-hua-xue-xi-zhi-ppo/3.png" class=""><p>在A为正数的情况下，我们倾向于采取这种行为，因此新策略该行为的概率会慢慢增大，但是又不能大于我们的界限。在A为负数的情况下，我们倾向于摒弃这种行为，但是我们也不能让策略变化范围过大，因此就有了一个下限。</p>]]></content>
      
      
      <categories>
          
          <category> 强化学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 强化学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>个人学习方向及研究方向</title>
      <link href="2021/09/05/ge-ren-xue-xi-fang-xiang-ji-yan-jiu-fang-xiang/"/>
      <url>2021/09/05/ge-ren-xue-xi-fang-xiang-ji-yan-jiu-fang-xiang/</url>
      
        <content type="html"><![CDATA[<p> 2021年9月5日更新：</p><h2 id="深度强化学习研究方向概述"><a href="#深度强化学习研究方向概述" class="headerlink" title="深度强化学习研究方向概述"></a>深度强化学习研究方向概述</h2><p>注：本段内容摘自知乎<a href="https://zhuanlan.zhihu.com/p/342919579">https://zhuanlan.zhihu.com/p/342919579</a></p><p><strong>赶时间请直接看加粗的四种算法</strong>，它们占据不同的生态位，请根据实际任务需要去选择他们，在强化学习的子领域（多智能体、分层强化学习、逆向强化学习也会以它们为基础开发新的算法）：</p><ul><li>离散动作空间推荐：<strong>Dueling DoubleQN（D3QN）</strong></li><li>连续动作空间推荐：擅长调参就用<strong>TD3</strong>，不擅长调参就用<strong>PPO或SAC</strong>，如果训练环境 Reward function 都是初学者写的，那就用PPO</li></ul><p>来自另外一个大佬的建议：对于连续控制任务，推荐SAC、TD3和PPO，三种算法都值得试一试并从中择优；对于离散控制任务，推荐SAC-Discrete（即离散版SAC）和PPO。</p><h3 id="1-离散的动作空间-discrete-action-space"><a href="#1-离散的动作空间-discrete-action-space" class="headerlink" title="1.离散的动作空间 discrete action space"></a>1.离散的动作空间 discrete action space</h3><ul><li><p><strong>DQN（Deep Q Network）</strong>可用于入门深度强化学习，使用一个Q Network来估计Q值，从而替换了 Q-table，完成从离散状态空间到连续状态空间的跨越。Q Network 会对每一个离散动作的Q值进行估计，执行的时候选择Q值最高的动作（greedy 策略）。并使用 epslion-greedy 策略进行探索（探索的时候，有很小的概率随机执行动作），来获得各种动作的训练数据。</p></li><li><p><strong>DDQN（Double DQN）</strong>更加稳定，因为最优化操作会传播高估误差，所以她同时训练两个Q network并选择较小的Q值用于计算TD-error，降低高估误差。详见和DDQN一样采用了两个估值网络的TD3 <a href="https://zhuanlan.zhihu.com/p/86297106">曾伊言：强化学习算法TD3论文的翻译与解读</a></p></li><li><p><strong><a href="https://link.zhihu.com/?target=https://arxiv.org/abs/1511.06581">Dueling DQN</a>**，Dueling DQN 使用了优势函数 advantage function（A3C也用了）：它只估计state的Q值，不考虑动作，好的策略能将state 导向一个更有优势的局面。原本DQN对一个state的Q值进行估计时，它需要等到</strong>为每个离散动作收集到数据后<strong>，才能进行准确估值。然而，在某些state下，采取不同的action并不会对Q值造成多大的影响，因此Dueling DQN 结合了 优势函数估计的Q值 与 原本DQN对不同动作估计的Q值。使得在某些state下，Dueling DQN 能在</strong>只收集到一个离散动作的数据后**，直接得到准确的估值。当某些环境中，存在大量不受action影响的state，此时Dueling DQN能学得比DQN更快。</p></li><li><p><strong>D3QN（Dueling Double DQN）。</strong>Dueling DQN 与Double DQN 相互兼容，一起用效果很好。简单，泛用，没有使用禁忌。任何一个刚入门的人都能独立地在前两种算法的基础上改出D3QN。在论文中使用了D3QN应该引用DuelingDQN 与 DoubleDQN的文章。</p></li><li><p><strong>Noisy DQN</strong>，探索能力稍强。Noisy DQN 把噪声添加到网络的输出层之前值。原本Q值较大的动作在添加噪声后Q值变大的概率也比较大。这种探索比epslion-greedy随机选一个动作去执行更好，至少这种针对性的探索既保证了探索动作多样，也提高了探索效率。</p></li></ul><p>====估计Q值的期望↑ ↓估计Q值的分布====</p><ul><li><strong>Distributional RL 值分布RL（C51，Distributional Perspective RL）</strong>。在DQN中，Q Network 拟合了Q值的期望，期望可以用一个数值去描述，比较简单。在值分布DQN中，Q Network 拟合了Q值的分布，Q值分布的描述就要麻烦一些了，但是训练效果更好。为C51的算法使用了这种方法，C表示Categorical，51表示他们将值分布划分51个grid。最终在雅达利游戏 Atari Game 上取得好结果。</li><li><a href="https://link.zhihu.com/?target=https://arxiv.org/pdf/1710.10044.pdf">QR-DQN</a><strong>（分位数回归</strong> <a href="https://zhuanlan.zhihu.com/p/40681570">Quantile Regression</a><strong>）</strong>，使用N个分位数去描述Q值分布（这种方法比C51划分51个grid的方法更妙，我推荐看 <a href="https://zhuanlan.zhihu.com/p/138091493">QR-DQN - Frank Tian</a>）。根据分位数的分布画出核分布曲线，详见 <a href="https://link.zhihu.com/?target=https://aakinshin.net/posts/qrde-hd/">Quantile-respectful density estimation based on the Harrell-Davis quantile estimator</a></li><li><strong>Rainbow DQN</strong>，上面提及的DQN变体很多是相互兼容的，因此 David Sliver 他们整合了这些变体，称为Rainbow。</li><li><strong>Ape-X DQN（Distributed Prioritized Experience Replay）</strong>，也是 David Sliver 他们做的。使用了Distributed training，用多个进程创建了多个actor去与环境交互，然后使用收集到的数据去训练同一个learner，用来加快训练速度。Prioritized Experience Replay（优先经验回放 PER 下面会讲）。Ape-X通过充分利用CPU资源，合理利用GPU，从而加快了训练速度。注意，这不等同于减少训练总步数。NVIDIA 有一个叫 Apex的库，用于加速计算。</li></ul><hr><h3 id="2-连续的动作空间-continuous-action-space"><a href="#2-连续的动作空间-continuous-action-space" class="headerlink" title="2.连续的动作空间 continuous action space"></a>2.连续的动作空间 continuous action space</h3><ul><li><strong>DDPG（Deep DPG ）</strong>，可用于入门连续动作空间的DRL算法。DPG 确定策略梯度算法，直接让策略网络输出action，成功在连续动作空间任务上训练出能用的策略，但是它使用 OU-noise 这种有很多超参数的方法去探索环境，训练慢，且不稳定。</li><li><strong>soft target update（软更新）</strong>，用来稳定训练的方法，非常好用，公式是 <img src="https://www.zhihu.com/equation?tex=%5Ctheta%27+=+%5Ctau+%5Ctheta%27+++(1-%5Ctau)%5Ctheta" alt="[公式]"> ，其中 theta是使用梯度进行更新的网络参数，theta’ 是使用了软更新的目标网络target network参数，tau略小于1。软更新让参数的更新不至于发生剧变，从而稳定了训练。从DDPG开始就广泛使用，并且在深度学习的其他领域也能看到它的身影，如 <a href="https://zhuanlan.zhihu.com/p/159765213">谷歌自监督 BYOL Bootstrap Your Own Latent</a> ，看论文的公式（1），就用了soft target update</li><li><strong>TD3（TDDD，Twin Delay DDPG）</strong>，擅长调参的人才建议用，因为它影响训练的敏感超参数很多。它从Double DQN那里继承了Twin Critic，用来降低高估误差；它用来和随机策略梯度很像的方法：计算用于更新TD-error的Q值时，给action加上了噪声，用于让Critic拟合更平滑的Q值估计函数。TD3建议 延迟更新目标网络，即多更新几次网络后，再使用 soft update 将网络更新到target network上，我认为这没有多大用，后来的其他算法也不用这个技巧。TD3还建议在计算Q值时，为动作添加一个噪声，用于平滑Critic函数，在确定策略中，TD3这么用很像“随机策略”。详见 <a href="https://zhuanlan.zhihu.com/p/86297106">曾伊言：强化学习算法TD3论文的翻译与解读</a></li><li><strong>D4PG（Distributed Distributional DDPG）</strong>，这篇文章做了实验，证明了一些大家都知道好用的trick是好用的。Distributed：它像 Ape-X一样用了 多线程开了actors 加快训练速度，Distributional：Q值分布RL（看前面的C51、QR-DQN）。DDPG探索能力差的特点，它也完好无缺地继承了。</li></ul><blockquote><p>在C51算法论文标题中，Distributional Perspective 指 Q值分布的表示。在Ape-X DQN 标题中， Distributed training 指分布式训练。我曾混淆过它们。</p></blockquote><p>====确定策略梯度↑ ↓ 随机策略梯度====</p><ul><li><strong>Stochastic Policy Gradient 随机策略梯度</strong>，随机策略的探索能力更好。随机策略网络会输出action的分布（通常输出高斯分布 均值 与 方差，少数任务下用其他分布），探索的噪声大小由智能体自己决定，更加灵活。但是这对算法提出了更高的要求。</li><li><strong>A3C（Asynchronous Advantage Actor-Critic）</strong>，Asynchronous 指开启多个actor 在环境中探索，并异步更新。原本DDPG的Critic 是 Q(s, a)，根据state-action pair 估计Q值，优势函数只使用 state 去估计Q值，<strong>这是很好的创新：降低了随机策略梯度算法估计Q值的难度</strong>。<strong>然而优势函数有明显缺陷</strong>：不是任何时刻 action 都会影响 state的转移（详见 Dueling DQN），因此这个算法只适合入门学习「优势函数 advantage function」。如果你看到新论文还在使用A3C，那么你要怀疑其作者RL的水平。此外，A3C算法有离散动作版本，也有连续动作版本。A2C 指的是没有Asynchronous 的版本。</li><li><strong>TRPO（Trust Region Policy Optimization）</strong>，信任域 Trust Region。连续动作空间无法每一个动作都搜索一遍，因此大部分情况下只能靠猜。如果要猜，就只能在信任域内部去猜。TRPO将每一次对策略的更新都限制了信任域内，从而极大地增强了训练的稳定性。可惜信任域的计算量太大了，因此其作者推出了PPO，如果你PPO论文看不懂，那么建议你先看TRPO。如果你看到新论文还在使用TRPO，那么你要怀疑其作者RL的水平。</li><li><strong>PPO（Proximal PO 近端策略搜索）</strong>，训练稳定，调参简单，robust（稳健、耐操）。PPO对TRPO的信任域计算过程进行简化，论文中用的词是 surrogate objective。PPO动作的噪声方差是一个可训练的矢量（与动作矢量相同形状），而不由网络输出，这样做增强了PPO的稳健性 robustness。</li><li><strong>PPO+GAE（</strong><a href="https://link.zhihu.com/?target=https://arxiv.org/pdf/1506.02438">Generalized Advantage Estimation</a><strong>）</strong>，训练最稳定，调参最简单，适合高维状态 High-dimensional state，<strong>但是环境不能有太多随机因数</strong>。GAE会根据经验轨迹 trajectory 生成优势函数估计值，然后让Critic去拟合这个值。在这样的调整下，在随机因素小的环境中，不需要太多 trajectory 即可描述当前的策略。尽管GAE可以用于多种RL算法，但是她与PPO这种On-policy 的相性最好。</li><li><a href="https://link.zhihu.com/?target=https://arxiv.org/abs/2009.04416">PPG</a><strong>（Proximal Policy Gradient）</strong>，A3C、PPO 都是同策略 On-policy，它要求：在环境中探索并产生训练数据的策略 与 被更新的策略网络 一定得是同一个策略。她们需要删掉已旧策略的数据，然后使用新策略在环境中重新收集。为了让PPO也能用 off-policy 的数据来训练，PPG诞生了，思路挺简单的，原本的On-policy PPO部分该干啥干啥，额外引入一个使用off-policy数据进行训练的Critic，让它与PPO的Critic共享参数，也就是Auxiliary Task，参见 <a href="https://zhuanlan.zhihu.com/p/342150033">Flood Sung：深度解读：Policy Gradient，PPO及PPG</a> ，以及<a href="https://link.zhihu.com/?target=https://zhuanlan.zhi%3Cb%3Ehu.com/p/14851%3C/b%3E6171">白辰甲：强化学习中自适应的辅助任务加权(Adaptive Auxiliary Task Weighting)</a>。这种算法并不是在任何情况下都能比PPO好，因为PPG涉及到Auxiliary task，这要求她尽可能收集更多的训练数据，并在大batch size 下面才能表现得更好。</li><li>Interpolated Policy Gradient NIPS.2017，<strong>反面例子</strong>，它试图基于 On-policy TRPO 改出一个 能利用 off-policy 数据的TRPO来（就像PPO→PPG），然而Interpolated Policy Gradient 强行地、错误地使用off-policy 数据对Critic 进行训练。结果在其论文中放出的结果中，它的性能甚至比A3C还差，只是比TRPO、DDPG略好（但是它故意没有和比它好的算法在同一个任务下比较：论文结果很诚实，但是用事实说谎）。</li><li>Soft Q-learning（Deep Energy Based Policy）是SAC的前身，最大熵算法的萌芽，她的作者后来写出了SAC（都叫soft ***），你可以跳过Soft QL，直接看SAC的论文。<a href="https://zhuanlan.zhihu.com/p/76681229">黄伟：Soft Q-Learning论文阅读笔记</a></li><li><strong>SAC（Soft Actor-Critic with maximum entropy 最大熵）</strong>，训练很快，探索能力好，但是很依赖Reward Function，不像PPO那样随便整一个Reward function 也能训练。PPO算法会计算新旧策略的差异（计算两个分布之间的距离），并让这个差异保持在信任域内，且不至于太小。SAC算法不是on-policy算法，不容易计算新旧策略的差异，所以它在优化时最大化策略的熵（动作的方差越大，策略的熵越高）。</li><li><strong>SAC（Automating Entropy Adjustment/ Automating Temperature Parameter</strong> <img src="https://www.zhihu.com/equation?tex=%5Calpha" alt="[公式]"> <strong>自动调整温度系数并维持策略的熵在某个值附近）</strong>一般我们使用的SAC是这个版本的SAC，它能自动调整一个叫温度系数alpha 的超参数（温度越高，熵越大）。SAC的策略网络的优化目标=累计收益+ alpha*策略的熵。一般在训练后期，策略找到合适的action分布均值时，它的action分布方差越小，其收益越高，因而对“累计收益”进行优化，会让策略熵倾向于减小。SAC会自动选择合适的温度系数，让策略的熵保持一种适合训练的动态平衡。SAC会事先确定一个目标熵 target entropy（论文作者的推荐值是 log(action_dim)），如果策略熵大于此值，则将alpha调小，反之亦然。从这个角度看，SAC就不是最大化策略熵了，而是将策略熵限制在某个合适大小内，这点又与PPO的“保持在信任域内，且不至于太小”不谋而合</li></ul><hr><h3 id="3-混合的动作空间-hybrid-action-space"><a href="#3-混合的动作空间-hybrid-action-space" class="headerlink" title="3.混合的动作空间 hybrid action space"></a>3.混合的动作空间 hybrid action space</h3><p>在实际任务中，混合动作的需求经常出现：如王者荣耀游戏既需要离散动作（选择技能），又需要连续动作（移动角色）。只要入门了强化学习，就很容易独立地想出以下这些方法，所以我没有把它们放在前面：</p><ul><li><strong>强行使用DQN类算法，把连续动作分成多个离散动作：</strong>不建议这么做，这破坏了连续动作的优势。一个良性的神经网络会是一个平滑的函数（k-Lipschitz 连续），相近的输入会有相似的输出。在连续的动作空间开区间[-1, +1]中，智能体会在学了-1，+1两个样本后，猜测0的样本可能介于 -1，+1 之间。而强行将拆分为离散动作 -1，0，+1之后（无论拆分多么精细），它都猜不出 0的样本，一定要收集到 0的样本才能学习。此外，精细的拆分会增加离散动作个数，尽管更加逼近连续动作，但会增加训练成本。</li><li><a href="https://link.zhihu.com/?target=https://arxiv.org/abs/1910.07207">SAC for Discrete Action Space</a><strong>，把输出的连续动作当成是离散动作的执行概率：</strong>SAC for Discrete Action Space 这个算法提供了将连续动作算法SAC应用在离散动作的一条技术路线：把这个输出的动作矢量当成每个动作的执行概率。一般可以直接把离散动作部分全部改成连续动作，然后套用连续动作算法，这方法简单，但是不一定最好的。</li><li><a href="https://link.zhihu.com/?target=https://arxiv.org/abs/1810.06394">P-DQN</a> <strong>（Parameterized DQN），把DQN和DDPG合起来</strong>：Q network 会输出每个动作对应的Q值，执行的时候选择Q值高的动作。DDPG与其他策略梯度算法，让Critic预测 state-action的Q值，然后用Critic 提供的梯度去优化Actor，让Actor输出Q值高的动作。现在，对于一个混合动作来说，我们可以让Critic学习Q Network，让Critic也为每个离散动作输出对应的Q值，然后用Critic中 arg max Qi 提供梯度优化Actor。这是很容易独立想出来的方法，相比前两个方案缺陷更小。</li><li><a href="https://link.zhihu.com/?target=https://arxiv.org/abs/1903.01344">H-PPO</a> <strong>（Hybrid PPO），同时让策略网络输出混合动作</strong>。连续动作（策略梯度）算法中：DDPG、TD3、SAC使用 状态-动作值函数 Q(state, action)，A3C、<strong>PPO使用 状态值函数 Q(state)**。离散动作无法像连续动作一样将一个action输入到 Q(state, action) 里，因此 Hybird PPO选择了PPO。于是它的策略网络会像Q Network 一样为离散动作输出不同的Q值，也像PPO 一样输出连续动作。（</strong>警告，2021-03 前它依然没有开源代码，但论文描述的方法无误<strong>）。还有 <a href="https://link.zhihu.com/?target=https://arxiv.org/abs/2001.00449">H-MPO</a>（</strong>Hybrid MPO**），MPO是PPO算法的改进版。</li></ul><p>详见<a href="https://link.zhihu.com/?target=https://arxiv.org/abs/1903.01344">Hybird-PPO 2019-03</a> 这篇文章的 Related Work。知乎上也有 <a href="https://zhuanlan.zhihu.com/p/104581527">黑猫紧张：PN-46: H-PPO for Hybrid Action Space (IJCAI 2019)</a></p><h3 id="4-改进经验回放，以适应稀疏奖励-sparse-reward"><a href="#4-改进经验回放，以适应稀疏奖励-sparse-reward" class="headerlink" title="4.改进经验回放，以适应稀疏奖励 sparse reward"></a>4.改进经验回放，以适应稀疏奖励 sparse reward</h3><p>训练LunarLander安全降落，它的奖励reward 在降落后+200，坠毁-100。当它还在空中时做任何动作都不会得到绝对值这么大的奖励。这样的奖励是稀疏的。一些算法（（其实它的奖励函数会根据飞行器在空中的稳定程度、燃料消耗给出一个很小的reward，在这种）</p><ul><li><strong>Prioritized sweeping 优先清理：</strong>根据紧要程度调整样本的更新顺序，优先使用某些样本进行更新，用于加速训练，PER就是沿着这种思想发展出来的</li><li><a href="https://link.zhihu.com/?target=https://arxiv.org/pdf/1511.05952.pdf">PER</a><strong>（优先经验回放 Prioritized Experience Replay）</strong>使用不同顺序的样本进行对网络进行训练，并将不同顺序对应的Q值差异保存下来，以此为依据调整样本更新顺序，用于加速训练。</li><li><a href="https://link.zhihu.com/?target=https://papers.nips.cc/paper/2017/file/453fadbd8a1a3af50a9df4df899537b5-Paper.pdf">HER</a><strong>（后见经验回放 Hindsight Experience Replay）</strong>构建可以把失败经验也利用起来的经验池，提高稀疏奖励下对各种失败探索经验的利用效率。</li></ul><p>这种操作需要消耗CPU算力去完成。在奖励不稀疏的环境下，用了不会明显提升。在一些环境中，上面这类算法必不可少。例如 <a href="https://link.zhihu.com/?target=https://gym.openai.com/envs/%23robotics">Gym 基于收费MuJoCo 的机械臂环境 Robotics Fetch***</a> ，以及 基于<a href="https://link.zhihu.com/?target=https://github.com/bulletphysics/bullet3/blob/master/examples/pybullet/gym/pybullet_envs/bullet/kuka.py">开源PyBullet的机械臂 KukaBulletEnv-v0</a> 。如果不用这类算法，那么我们需要花费更多精力去设计Reward function。</p><h3 id="5-在RL中使用RNN"><a href="#5-在RL中使用RNN" class="headerlink" title="5.在RL中使用RNN"></a>5.在RL中使用RNN</h3><p>有时候，我们需要观察连续的几个状态才能获得完整的状态。例如赛车游戏，打砖块游戏，我们在只观测单独一帧图片时（部分可观测 Partially Observable state），无法知晓物体的运动速度。因此将相邻几个可观测的状态堆叠起来（stack）可以很好地应对这些难题。</p><p>然而，堆叠相邻状态无法应对所有的 PO-MDPs。于是大家想到了用RNN（<a href="https://zhuanlan.zhihu.com/p/94757947">RNN的入门例子：根据前9年的数据预测后3年的客流</a>）。然而RNN需要使用一整段序列去训练，很不适合TD-errors（贝尔曼公式）的更新方式。如图：普通Actor网络的输入只有state，而使用RNN的Actor网络的输入其实是 Partially Observable state 以及 hidden state。这意味着输入critic网络进行Q值评估的state不完整（不包含RNN内部的hidden state）。为了解决<strong>环境的PO-MDPs难题</strong>，我们直接引入RNN结构。然而引入RNN结构的行为又给RL带来了<strong>RNN内部的PO-MDPs难题</strong>。</p><p><img src="https://pic4.zhimg.com/80/v2-bfb5ca44f103cf1de24aaff13c74c527_720w.jpg" alt="img"></p><p>尽管在on-policy算法中，如果使用完整的轨迹（trajectory）进行更新，那么可以缓解critic观测不到 hidden state给训练到来的影响。（如腾讯绝悟的PPO算法使用了RNN），但是这个问题还是没有很好地得到解决。如果想要了解更多使用了RNN的RL算法，请看 <a href="https://zhuanlan.zhihu.com/p/349041830">羽根：【强化学习TOOLBOX 3】RNN, DRQN, R2D2</a> 。2021年前，我极少复现过效果好的RL+RNN算法，因此我不推荐任何使用了RL+RNN的算法。</p><p>虽说 RL＋RNN 有各种问题，但是 R2D2 NGU.2020 Agent57.2020 这些算法都用了RNN。<strong>我并非认为RNN＋RL 不可行，而是认为 在RL中训练RNN 有太多 trick，复现困难。</strong>其中，Agent57 训练RNN 的方法很值得借鉴，在论文E. implementation details 写得比较具体。如: 在env transition，也保存了recurrent state)。我有空会继续补充以下三种算法，写于2021-6-18：</p><p><a href="https://link.zhihu.com/?target=https://openreview.net/pdf?id=r1lyTjAqYX">R2D2</a>（<strong>Recurrent Replay Distributed DQN.</strong> ICLR.2019）</p><p><a href="https://link.zhihu.com/?target=https://openreview.net/pdf?id=Sye57xStvB">NGU</a>（<strong>Never Give Up</strong>: Learning Directed Exploration Strategies. ICLR. 2020）</p><p><a href="https://link.zhihu.com/?target=https://arxiv.org/abs/2003.13350">Agent57</a>（<strong>Agent57</strong>: Outperforming the Atari Human Benchmark. 2020）</p><p>一种在RL里使用RNN的方法<strong>（Note RL+RNN）：让使用了RNN 的Actor 输出hidden state 作为action，就像人类记笔记一样。</strong>把 part state + hidden state 视为完整的state，把 hidden state + action 视为完整的 action。无论是 state-value function 还是 state-action value function 都能使用这个方法。</p><p><img src="https://pic4.zhimg.com/80/v2-6902e22cfa923c026e01b19f9612e287_720w.jpg" alt="img"></p><h3 id="6-强化学习探索"><a href="#6-强化学习探索" class="headerlink" title="6.强化学习探索"></a>6.强化学习探索</h3><p>收集不同的state、在同一个state下尝试不同的action 的探索过程非常重要。通过探索收集到足够多的数据，是我们用RL训练出接近最优策略的前提。下面这篇系统介绍了各种探索策略：</p><p><a href="https://link.zhihu.com/?target=https://lilianweng.github.io/lil-log/2020/06/07/exploration-strategies-in-deep-reinforcement-learning.html">Exploration Strategies in Deep Reinforcement Learning - LiLianWeng</a> （我也推荐看她的其他文章）</p><blockquote><p>最近的 First return, then explore Nature.2021 是Go-explore. 2018的升级版</p></blockquote><h3 id="7-多智能体算法-MultiAgent-RL"><a href="#7-多智能体算法-MultiAgent-RL" class="headerlink" title="7.多智能体算法 MultiAgent RL"></a>7.多智能体算法 MultiAgent RL</h3><p>多智能体算法的综述：<a href="https://link.zhihu.com/?target=https://arxiv.org/abs/2011.00583">An Overview of Multi-agent Reinforcement Learning from Game Theoretical Perspective</a> - 2020-12。在比对了多份MARL综述后，只推荐这一篇，它的目录与注释如下：</p><pre class=" language-python3"><code class="language-python3">Contents1 Introduction    ...    1.3 2019: A Booming Year for MARL  # 写在2019年前的MARL综述可看性低2 Single-Agent Reinforcement Learning     ...3 Multi-Agent Reinforcement Learning    ...    3.2.5 Partially Observable Settings  # state部分可观测的MDPs    3.3 Problem Formulation: Extensive-Form Game    3.3.1 Normal-Form Representation  # 普通形式    3.3.2 Sequence-Form Representation  # 序列形式    3.4 Solving Extensive-form Games     3.4.1 Solutions to Perfect-Information Games  # 完全信息博弈    3.4.2 Solutions to Imperfect-Information Games  # 非完全信息博弈（有战场迷雾）4 The Grand Challenges 38    4.1 The Combinatorial Complexity  # 动作空间变大，搜索策略变难    4.2 The Multi-Dimensional Learning Objectives  # 状态空间变大，搜索策略变难    4.3 The Non-Stationarity Issue  # MARL中，每个智能体的策略总发生改变，导致外部环境不稳定    4.4 The Scalability Issue when N >> 2  # 智能体数量增大，甚至数量改变5 A Survey of MARL Surveys  # 推荐有单智能体基础的人得先看 MARL算法的分类    ...6 Learning in Identical-Interest Games  # 合作的MARL    6.1 Stochastic Team Games     6.1.1 Solutions via Q-function Factorisation  # 基于Q值    6.1.2 Solutions via Multi-Agent Soft Learning   # 基于随机策略    6.2 Dec-POMDP  #  decentralized PO-MDPs 每个智能体智能看到局部的state 导致的部分可观测    6.3 Networked Multi-Agent MDP  智能体是异构的heterogeneous，而非同源homogeneous    6.4 Stochastic Potential Games7 Learning in Zero-Sum Games  # 竞争的MARL （包含了团体间竞争，团体内合作的情况）    ...    7.3.1 Variations of Fictitious Play  # 虚拟博弈， 类似于 Model-based 做 Planning    7.3.2 Counterfactual Regret Minimisation  # 反事实推理（向左错了，于是考虑向右是否更好）    7.4 Policy Space Response Oracle  # 策略空间太大时，考虑用元博弈(meta-game)    7.5 Online Markov Decision Process    7.6 Turn-Based Stochastic Games  # 智能体之间轮流做决策，而不是同时做8 Learning in General-Sum Games    ...  # 混合了团队博弈合作team games 与 零和博弈竞争zero-sum games 的 General-Sum game9 Learning in Games with N → +∞  # 无终止状态的博弈（需要考虑信任与背叛）    9.1 Non-Cooperative Setting: Mean-Field Games  # 博弈平均场，把其他智能体也视为外部环境    ...END</code></pre><p>部分多智能体算法的代码以及少量介绍：<a href="https://link.zhihu.com/?target=https://github.com/starry-sky6688/StarCraft">starry-sky6688/StarCraft 在星际争霸环境 复现了多种多智能体强化学习算法</a></p><p>若智能体间通信没有受到限制（不限量，无延迟），那么我们完全可以把多智能体当成单智能体来处理。适用于部分可观测的MDPs的算法（<a href="https://link.zhihu.com/?target=https://en.wikipedia.org/wiki/Partially_observable_Markov_decision_process">Partially observable MDPs</a>），在多智能体任务中，每个视角有限的智能体观察到的只是 partially observable state。很多多智能体算法会参与 PO-MDPs 的讨论，由于每个智能体只能观察到局部信息而导致的部分可观测被称为 Dec-POMDP，在上面的MARL综述也有讨论。</p><h4 id="7-1-Tutorial-and-Books"><a href="#7-1-Tutorial-and-Books" class="headerlink" title="7.1 Tutorial and Books"></a>7.1 Tutorial and Books</h4><ul><li><a href="https://ora.ox.ac.uk/objects/uuid:a55621b3-53c0-4e1b-ad1c-92438b57ffa4">Deep Multi-Agent Reinforcement Learning</a> by Jakob N Foerster, 2018. PhD Thesis.</li><li><a href="https://onlinelibrary.wiley.com/doi/book/10.1002/9781118884614">Multi-Agent Machine Learning: A Reinforcement Approach</a> by H. M. Schwartz, 2014.</li><li><a href="http://www.ecmlpkdd2013.org/wp-content/uploads/2013/09/Multiagent-Reinforcement-Learning.pdf">Multiagent Reinforcement Learning</a> by Daan Bloembergen, Daniel Hennes, Michael Kaisers, Peter Vrancx. ECML, 2013.</li><li><a href="http://www.masfoundations.org/download.html">Multiagent systems: Algorithmic, game-theoretic, and logical foundations</a> by Shoham Y, Leyton-Brown K. Cambridge University Press, 2008.</li></ul><h4 id="7-2-Review-Papers"><a href="#7-2-Review-Papers" class="headerlink" title="7.2 Review Papers"></a>7.2 Review Papers</h4><ul><li><a href="https://www.jair.org/index.php/jair/article/view/11396">A Survey on Transfer Learning for Multiagent Reinforcement Learning Systems</a> by Silva, Felipe Leno da; Costa, Anna Helena Reali. JAIR, 2019.</li><li><a href="https://www.ijcai.org/proceedings/2018/774">Autonomously Reusing Knowledge in Multiagent Reinforcement Learning</a> by Silva, Felipe Leno da; Taylor, Matthew E.; Costa, Anna Helena Reali. IJCAI, 2018.</li><li><a href="https://project-archive.inf.ed.ac.uk/msc/20162091/msc_proj.pdf">Deep Reinforcement Learning Variants of Multi-Agent Learning Algorithms</a> by Castaneda A O. 2016.</li><li><a href="https://www.jair.org/index.php/jair/article/view/10952">Evolutionary Dynamics of Multi-Agent Learning: A Survey</a> by Bloembergen, Daan, et al. JAIR, 2015.</li><li><a href="https://www.researchgate.net/publication/269100101_Game_Theory_and_Multi-agent_Reinforcement_Learning">Game theory and multi-agent reinforcement learning</a> by Nowé A, Vrancx P, De Hauwere Y M. Reinforcement Learning. Springer Berlin Heidelberg, 2012.</li><li><a href="http://www.dcsc.tudelft.nl/~bdeschutter/pub/rep/10_003.pdf">Multi-agent reinforcement learning: An overview</a> by Buşoniu L, Babuška R, De Schutter B. Innovations in multi-agent systems and applications-1. Springer Berlin Heidelberg, 2010</li><li><a href="http://www.dcsc.tudelft.nl/~bdeschutter/pub/rep/07_019.pdf">A comprehensive survey of multi-agent reinforcement learning</a> by Busoniu L, Babuska R, De Schutter B. IEEE Transactions on Systems Man and Cybernetics Part C Applications and Reviews, 2008</li><li>[If multi-agent learning is the answer, what is the question?](<a href="http://robotics.stanford.edu/~shoham/www">http://robotics.stanford.edu/~shoham/www</a> papers/LearningInMAS.pdf) by Shoham Y, Powers R, Grenager T. Artificial Intelligence, 2007.</li><li><a href="http://users.isr.ist.utl.pt/~mtjspaan/readingGroup/learningNeto05.pdf">From single-agent to multi-agent reinforcement learning: Foundational concepts and methods</a> by Neto G. Learning theory course, 2005.</li><li><a href="https://pdfs.semanticscholar.org/bb9f/bee22eae2b47bbf304804a6ac07def1aecdb.pdf">Evolutionary game theory and multi-agent reinforcement learning</a> by Tuyls K, Nowé A. The Knowledge Engineering Review, 2005.</li><li><a href="https://www.researchgate.net/publication/221622801_An_Overview_of_Cooperative_and_Competitive_Multiagent_Learning">An Overview of Cooperative and Competitive Multiagent Learning</a> by Pieter Jan ’t HoenKarl TuylsLiviu PanaitSean LukeJ. A. La Poutré. AAMAS’s workshop LAMAS, 2005.</li><li><a href="https://cs.gmu.edu/~eclab/papers/panait05cooperative.pdf">Cooperative multi-agent learning: the state of the art</a> by Liviu Panait and Sean Luke, 2005.</li></ul><h4 id="7-3-Framework-papers"><a href="#7-3-Framework-papers" class="headerlink" title="7.3 Framework papers"></a>7.3 Framework papers</h4><ul><li><a href="https://arxiv.org/pdf/1802.05438.pdf">Mean Field Multi-Agent Reinforcement Learning</a> by Yaodong Yang, Rui Luo, Minne Li, Ming Zhou, Weinan Zhang, and Jun Wang. ICML 2018.</li><li><a href="https://arxiv.org/pdf/1706.02275.pdf">Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments</a> by Lowe R, Wu Y, Tamar A, et al. arXiv, 2017.</li><li><a href="https://arxiv.org/pdf/1703.06182.pdf">Deep Decentralized Multi-task Multi-Agent RL under Partial Observability</a> by Omidshafiei S, Pazis J, Amato C, et al. arXiv, 2017.</li><li><a href="https://arxiv.org/pdf/1703.10069.pdf">Multiagent Bidirectionally-Coordinated Nets for Learning to Play StarCraft Combat Games</a> by Peng P, Yuan Q, Wen Y, et al. arXiv, 2017.</li><li><a href="https://arxiv.org/pdf/1703.02702.pdf">Robust Adversarial Reinforcement Learning</a> by Lerrel Pinto, James Davidson, Rahul Sukthankar, Abhinav Gupta. arXiv, 2017.</li><li><a href="https://arxiv.org/pdf/1702.08887.pdf">Stabilising Experience Replay for Deep Multi-Agent Reinforcement Learning</a> by Foerster J, Nardelli N, Farquhar G, et al. arXiv, 2017.</li><li><a href="https://arxiv.org/pdf/1508.05328.pdf">Multiagent reinforcement learning with sparse interactions by negotiation and knowledge transfer</a> by Zhou L, Yang P, Chen C, et al. IEEE transactions on cybernetics, 2016.</li><li><a href="https://arxiv.org/pdf/1409.4561.pdf">Decentralised multi-agent reinforcement learning for dynamic and uncertain environments</a> by Marinescu A, Dusparic I, Taylor A, et al. arXiv, 2014.</li><li><a href="http://irll.eecs.wsu.edu/wp-content/papercite-data/pdf/2014iat-holmesparker.pdf">CLEANing the reward: counterfactual actions to remove exploratory action noise in multiagent learning</a> by HolmesParker C, Taylor M E, Agogino A, et al. AAMAS, 2014.</li><li><a href="http://www.fransoliehoek.net/docs/Amato13MSDM.pdf">Bayesian reinforcement learning for multiagent systems with state uncertainty</a> by Amato C, Oliehoek F A. MSDM Workshop, 2013.</li><li><a href="http://www.weiss-gerhard.info/publications/AI_MAGAZINE_2012_TuylsWeiss.pdf">Multiagent learning: Basics, challenges, and prospects</a> by Tuyls, Karl, and Gerhard Weiss. AI Magazine, 2012.</li><li><a href="http://icml2010.haifa.il.ibm.com/papers/191.pdf">Classes of multiagent q-learning dynamics with epsilon-greedy exploration</a> by Wunder M, Littman M L, Babes M. ICML, 2010.</li><li><a href="http://www.machinelearning.org/proceedings/icml2007/papers/89.pdf">Conditional random fields for multi-agent reinforcement learning</a> by Zhang X, Aberdeen D, Vishwanathan S V N. ICML, 2007.</li><li><a href="http://ama.imag.fr/~partalas/partalasmarl.pdf">Multi-agent reinforcement learning using strategies and voting</a> by Partalas, Ioannis, Ioannis Feneris, and Ioannis Vlahavas. ICTAI, 2007.</li><li><a href="https://pdfs.semanticscholar.org/57fb/ae00e17c0d798559ebab0e8f4267e032f41d.pdf">A reinforcement learning scheme for a partially-observable multi-agent game</a> by Ishii S, Fujita H, Mitsutake M, et al. Machine Learning, 2005.</li><li><a href="http://lib.tkk.fi/Diss/2004/isbn9512273594/article1.pdf">Asymmetric multiagent reinforcement learning</a> by Könönen V. Web Intelligence and Agent Systems, 2004.</li><li><a href="http://dl.acm.org/citation.cfm?id=860686">Adaptive policy gradient in multiagent learning</a> by Banerjee B, Peng J. AAMAS, 2003.</li><li><a href="https://papers.nips.cc/paper/2171-reinforcement-learning-to-play-an-optimal-nash-equilibrium-in-team-markov-games.pdf">Reinforcement learning to play an optimal Nash equilibrium in team Markov games</a> by Wang X, Sandholm T. NIPS, 2002.</li><li><a href="https://www.sciencedirect.com/science/article/pii/S0004370202001212">Multiagent learning using a variable learning rate</a> by Michael Bowling and Manuela Veloso, 2002.</li><li><a href="http://www.sts.rpi.edu/~rsun/si-mal/article3.pdf">Value-function reinforcement learning in Markov game</a> by Littman M L. Cognitive Systems Research, 2001.</li><li><a href="http://researchers.lille.inria.fr/~ghavamza/my_website/Publications_files/agents01.pdf">Hierarchical multi-agent reinforcement learning</a> by Makar, Rajbala, Sridhar Mahadevan, and Mohammad Ghavamzadeh. The fifth international conference on Autonomous agents, 2001.</li><li><a href="https://www.cs.cmu.edu/~mmv/papers/00TR-mike.pdf">An analysis of stochastic game theory for multiagent reinforcement learning</a> by Michael Bowling and Manuela Veloso, 2000.</li></ul><h4 id="7-4-Joint-action-learning"><a href="#7-4-Joint-action-learning" class="headerlink" title="7.4 Joint action learning"></a>7.4 Joint action learning</h4><ul><li><a href="http://www.cs.cmu.edu/~conitzer/awesomeML06.pdf">AWESOME: A general multiagent learning algorithm that converges in self-play and learns a best response against stationary opponents</a> by Conitzer V, Sandholm T. Machine Learning, 2007.</li><li><a href="https://papers.nips.cc/paper/2503-extending-q-learning-to-general-adaptive-multi-agent-systems.pdf">Extending Q-Learning to General Adaptive Multi-Agent Systems</a> by Tesauro, Gerald. NIPS, 2003.</li><li><a href="http://www.lirmm.fr/~jq/Cours/3cycle/module/HuWellman98icml.pdf">Multiagent reinforcement learning: theoretical framework and an algorithm.</a> by Hu, Junling, and Michael P. Wellman. ICML, 1998.</li><li><a href="http://www.aaai.org/Papers/AAAI/1998/AAAI98-106.pdf">The dynamics of reinforcement learning in cooperative multiagent systems</a> by Claus C, Boutilier C. AAAI, 1998.</li><li><a href="https://www.cs.duke.edu/courses/spring07/cps296.3/littman94markov.pdf">Markov games as a framework for multi-agent reinforcement learning</a> by Littman, Michael L. ICML, 1994.</li></ul><h4 id="7-5-Cooperation-and-competition"><a href="#7-5-Cooperation-and-competition" class="headerlink" title="7.5 Cooperation and competition"></a>7.5 Cooperation and competition</h4><ul><li><a href="https://arxiv.org/pdf/1710.03748.pdf">Emergent complexity through multi-agent competition</a> by Trapit Bansal, Jakub Pachocki, Szymon Sidor, Ilya Sutskever, Igor Mordatch, 2018.</li><li><a href="https://arxiv.org/pdf/1709.04326.pdf">Learning with opponent learning awareness</a> by Jakob Foerster, Richard Y. Chen2, Maruan Al-Shedivat, Shimon Whiteson, Pieter Abbeel, Igor Mordatch, 2018.</li><li><a href="https://arxiv.org/pdf/1702.03037.pdf">Multi-agent Reinforcement Learning in Sequential Social Dilemmas</a> by Leibo J Z, Zambaldi V, Lanctot M, et al. arXiv, 2017. [<a href="https://deepmind.com/blog/understanding-agent-cooperation/">Post</a>]</li><li><a href="http://orca.st.usm.edu/~banerjee/papers/p530-ceren.pdf">Reinforcement Learning in Partially Observable Multiagent Settings: Monte Carlo Exploring Policies with PAC Bounds</a> by Roi Ceren, Prashant Doshi, and Bikramjit Banerjee, pp. 530-538, AAMAS 2016.</li><li><a href="http://www.umiacs.umd.edu/~hal/docs/daume16opponent.pdf">Opponent Modeling in Deep Reinforcement Learning</a> by He H, Boyd-Graber J, Kwok K, et al. ICML, 2016.</li><li><a href="https://arxiv.org/pdf/1511.08779.pdf">Multiagent cooperation and competition with deep reinforcement learning</a> by Tampuu A, Matiisen T, Kodelja D, et al. arXiv, 2015.</li><li><a href="http://www.uow.edu.au/~fren/documents/EMR_2013.pdf">Emotional multiagent reinforcement learning in social dilemmas</a> by Yu C, Zhang M, Ren F. International Conference on Principles and Practice of Multi-Agent Systems, 2013.</li><li><a href="http://www.jmlr.org/papers/volume9/bab08a/bab08a.pdf">Multi-agent reinforcement learning in common interest and fixed sum stochastic games: An experimental study</a> by Bab, Avraham, and Ronen I. Brafman. Journal of Machine Learning Research, 2008.</li><li><a href="https://pdfs.semanticscholar.org/5120/d9f2c738ad223e9f8f14cb3fd5612239a35c.pdf">Combining policy search with planning in multi-agent cooperation</a> by Ma J, Cameron S. Robot Soccer World Cup, 2008.</li><li><a href="http://www.jmlr.org/papers/volume7/kok06a/kok06a.pdf">Collaborative multiagent reinforcement learning by payoff propagation</a> by Kok J R, Vlassis N. JMLR, 2006.</li><li><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.107.335&amp;rep=rep1&amp;type=pdf">Learning to cooperate in multi-agent social dilemmas</a> by de Cote E M, Lazaric A, Restelli M. AAMAS, 2006.</li><li><a href="http://www.machinelearning.org/proceedings/icml2005/papers/021_Learning_CrandallGoodrich.pdf">Learning to compete, compromise, and cooperate in repeated general-sum games</a> by Crandall J W, Goodrich M A. ICML, 2005.</li><li><a href="http://www.machinelearning.org/proceedings/icml2004/papers/267.pdf">Sparse cooperative Q-learning</a> by Kok J R, Vlassis N. ICML, 2004.</li></ul><h4 id="7-6-Coordination"><a href="#7-6-Coordination" class="headerlink" title="7.6 Coordination"></a>7.6 Coordination</h4><ul><li><a href="https://arxiv.org/pdf/1703.03121.pdf">Coordinated Multi-Agent Imitation Learning</a> by Le H M, Yue Y, Carr P. arXiv, 2017.</li><li><a href="http://mipc.inf.ed.ac.uk/2014/papers/mipc2014_hao_etal.pdf">Reinforcement social learning of coordination in networked cooperative multiagent systems</a> by Hao J, Huang D, Cai Y, et al. AAAI Workshop, 2014.</li><li><a href="http://www.aamas-conference.org/Proceedings/aamas2013/docs/p1101.pdf">Coordinating multi-agent reinforcement learning with limited communication</a> by Zhang, Chongjie, and Victor Lesser. AAMAS, 2013.</li><li><a href="http://www.ifaamas.org/Proceedings/aamas2012/papers/1B_1.pdf">Coordination guided reinforcement learning</a> by Lau Q P, Lee M L, Hsu W. AAMAS, 2012.</li><li><a href="https://www.cs.toronto.edu/~cebly/Papers/bayesMARL.pdf">Coordination in multiagent reinforcement learning: a Bayesian approach</a> by Chalkiadakis G, Boutilier C. AAMAS, 2003.</li><li><a href="https://users.cs.duke.edu/~parr/icml02.pdf">Coordinated reinforcement learning</a> by Guestrin C, Lagoudakis M, Parr R. ICML, 2002.</li><li><a href="http://www.aaai.org/Papers/AAAI/2002/AAAI02-050.pdf">Reinforcement learning of coordination in cooperative multi-agent systems</a> by Kapetanakis S, Kudenko D. AAAI/IAAI, 2002.</li></ul><h4 id="7-7-Security"><a href="#7-7-Security" class="headerlink" title="7.7 Security"></a>7.7 Security</h4><ul><li><a href="http://www.fransoliehoek.net/docs/Klima16LICMAS.pdf">Markov Security Games: Learning in Spatial Security Problems</a> by Klima R, Tuyls K, Oliehoek F. The Learning, Inference and Control of Multi-Agent Systems at NIPS, 2016.</li><li><a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7244682">Cooperative Capture by Multi-Agent using Reinforcement Learning, Application for Security Patrol Systems</a> by Yasuyuki S, Hirofumi O, Tadashi M, et al. Control Conference (ASCC), 2015</li><li><a href="http://www4.ncsu.edu/~hdai/infocom-2015-XH.pdf">Improving learning and adaptation in security games by exploiting information asymmetry</a> by He X, Dai H, Ning P. INFOCOM, 2015.</li></ul><h4 id="7-8-Self-Play"><a href="#7-8-Self-Play" class="headerlink" title="7.8 Self-Play"></a>7.8 Self-Play</h4><ul><li><a href="https://arxiv.org/pdf/1711.00832.pdf">A Unified Game-Theoretic Approach to Multiagent Reinforcement Learning</a> by Marc Lanctot, Vinicius Zambaldi, Audrunas Gruslys, Angeliki Lazaridou, Karl Tuyls, Julien Perolat, David Silver, Thore Graepel. NIPS 2017.</li><li><a href="https://arxiv.org/pdf/1603.01121.pdf">Deep reinforcement learning from self-play in imperfect-information games</a> by Heinrich, Johannes, and David Silver. arXiv, 2016.</li><li><a href="http://jmlr.org/proceedings/papers/v37/heinrich15.pdf">Fictitious Self-Play in Extensive-Form Games</a> by Heinrich, Johannes, Marc Lanctot, and David Silver. ICML, 2015.</li></ul><h4 id="7-9-Learning-To-Communicate"><a href="#7-9-Learning-To-Communicate" class="headerlink" title="7.9 Learning To Communicate"></a>7.9 Learning To Communicate</h4><ul><li><a href="https://openreview.net/pdf?id=Hk6WhagRW">Emergent Communication through Negotiation</a> by Kris Cao, Angeliki Lazaridou, Marc Lanctot, Joel Z Leibo, Karl Tuyls, Stephen Clark, 2018.</li><li><a href="https://openreview.net/pdf?id=HJGv1Z-AW">Emergence of Linguistic Communication From Referential Games with Symbolic and Pixel Input</a> by Angeliki Lazaridou, Karl Moritz Hermann, Karl Tuyls, Stephen Clark</li><li><a href="https://openreview.net/pdf?id=SkaxnKEYg">EMERGENCE OF LANGUAGE WITH MULTI-AGENT GAMES: LEARNING TO COMMUNICATE WITH SEQUENCES OF SYMBOLS</a> by Serhii Havrylov, Ivan Titov. ICLR Workshop, 2017.</li><li><a href="https://arxiv.org/pdf/1703.06585.pdf">Learning Cooperative Visual Dialog Agents with Deep Reinforcement Learning</a> by Abhishek Das, Satwik Kottur, et al. arXiv, 2017.</li><li><a href="https://arxiv.org/pdf/1703.04908.pdf">Emergence of Grounded Compositional Language in Multi-Agent Populations</a> by Igor Mordatch, Pieter Abbeel. arXiv, 2017. [<a href="https://openai.com/blog/learning-to-communicate/">Post</a>]</li><li><a href="https://repositories.lib.utexas.edu/handle/2152/45681">Cooperation and communication in multiagent deep reinforcement learning</a> by Hausknecht M J. 2017.</li><li><a href="https://openreview.net/pdf?id=Hk8N3Sclg">Multi-agent cooperation and the emergence of (natural) language</a> by Lazaridou A, Peysakhovich A, Baroni M. arXiv, 2016.</li><li><a href="https://arxiv.org/pdf/1602.02672.pdf">Learning to communicate to solve riddles with deep distributed recurrent q-networks</a> by Foerster J N, Assael Y M, de Freitas N, et al. arXiv, 2016.</li><li><a href="https://arxiv.org/pdf/1605.06676.pdf">Learning to communicate with deep multi-agent reinforcement learning</a> by Foerster J, Assael Y M, de Freitas N, et al. NIPS, 2016.</li><li><a href="http://papers.nips.cc/paper/6398-learning-multiagent-communication-with-backpropagation.pdf">Learning multiagent communication with backpropagation</a> by Sukhbaatar S, Fergus R. NIPS, 2016.</li><li><a href="http://people.csail.mit.edu/lpk/papers/dars08.pdf">Efficient distributed reinforcement learning through agreement</a> by Varshavskaya P, Kaelbling L P, Rus D. Distributed Autonomous Robotic Systems, 2009.</li></ul><h4 id="7-10-Transfer-Learning"><a href="#7-10-Transfer-Learning" class="headerlink" title="7.10 Transfer Learning"></a>7.10 Transfer Learning</h4><ul><li><a href="http://www.ifaamas.org/Proceedings/aamas2017/pdfs/p1100.pdf">Simultaneously Learning and Advising in Multiagent Reinforcement Learning</a> by Silva, Felipe Leno da; Glatt, Ruben; and Costa, Anna Helena Reali. AAMAS, 2017.</li><li><a href="https://www.aaai.org/ocs/index.php/AAAI/AAAI17/paper/download/14217/14005">Accelerating Multiagent Reinforcement Learning through Transfer Learning</a> by Silva, Felipe Leno da; and Costa, Anna Helena Reali. AAAI, 2017.</li><li><a href="https://web.cs.umass.edu/publication/docs/2015/UM-CS-2015-004.pdf">Accelerating multi-agent reinforcement learning with dynamic co-learning</a> by Garant D, da Silva B C, Lesser V, et al. Technical report, 2015</li><li><a href="https://www.scss.tcd.ie/~tayloral/res/papers/Taylor_ParallelTransferLearning_ICML_2013.pdf">Transfer learning in multi-agent systems through parallel transfer</a> by Taylor, Adam, et al. ICML, 2013.</li><li><a href="https://ewrl.files.wordpress.com/2011/08/ewrl2011_submission_19.pdf">Transfer learning in multi-agent reinforcement learning domains</a> by Boutsioukis, Georgios, Ioannis Partalas, and Ioannis Vlahavas. European Workshop on Reinforcement Learning, 2011.</li><li><a href="https://ai.vub.ac.be/~ydehauwe/publications/ICAART2011_2.pdf">Transfer Learning for Multi-agent Coordination</a> by Vrancx, Peter, Yann-Michaël De Hauwere, and Ann Nowé. ICAART, 2011.</li></ul><h4 id="7-11-Imitation-and-Inverse-Reinforcement-Learning"><a href="#7-11-Imitation-and-Inverse-Reinforcement-Learning" class="headerlink" title="7.11 Imitation and Inverse Reinforcement Learning"></a>7.11 Imitation and Inverse Reinforcement Learning</h4><ul><li><a href="https://arxiv.org/abs/1907.13220">Multi-Agent Adversarial Inverse Reinforcement Learning</a> by Lantao Yu, Jiaming Song, Stefano Ermon. ICML 2019.</li><li><a href="https://papers.nips.cc/paper/7975-multi-agent-generative-adversarial-imitation-learning">Multi-Agent Generative Adversarial Imitation Learning</a> by Jiaming Song, Hongyu Ren, Dorsa Sadigh, Stefano Ermon. NeurIPS 2018.</li><li><a href="http://papers.nips.cc/paper/6420-cooperative-inverse-reinforcement-learning.pdf">Cooperative inverse reinforcement learning</a> by Hadfield-Menell D, Russell S J, Abbeel P, et al. NIPS, 2016.</li><li><a href="https://arxiv.org/pdf/1403.6822.pdf">Comparison of Multi-agent and Single-agent Inverse Learning on a Simulated Soccer Example</a> by Lin X, Beling P A, Cogill R. arXiv, 2014.</li><li><a href="https://arxiv.org/pdf/1403.6508.pdf">Multi-agent inverse reinforcement learning for zero-sum games</a> by Lin X, Beling P A, Cogill R. arXiv, 2014.</li><li><a href="http://aamas2014.lip6.fr/proceedings/aamas/p173.pdf">Multi-robot inverse reinforcement learning under occlusion with interactions</a> by Bogert K, Doshi P. AAMAS, 2014.</li><li><a href="http://homes.soic.indiana.edu/natarasr/Papers/mairl.pdf">Multi-agent inverse reinforcement learning</a> by Natarajan S, Kunapuli G, Judah K, et al. ICMLA, 2010.</li></ul><h4 id="7-12-Meta-Learning"><a href="#7-12-Meta-Learning" class="headerlink" title="7.12 Meta Learning"></a>7.12 Meta Learning</h4><ul><li><a href="https://arxiv.org/pdf/1710.03641.pdf">Continuous Adaptation via Meta-Learning in Nonstationary and Competitive Environments</a> by l-Shedivat, M. 2018.</li></ul><h4 id="7-13-Application"><a href="#7-13-Application" class="headerlink" title="7.13 Application"></a>7.13 Application</h4><ul><li><a href="https://arxiv.org/pdf/1712.00600.pdf">MAgent: A Many-Agent Reinforcement Learning Platform for Artificial Collective Intelligence</a> by Zheng L et al. NIPS 2017 &amp; AAAI 2018 Demo. (<a href="https://github.com/geek-ai/MAgent">Github Page</a>)</li><li><a href="https://arxiv.org/pdf/1702.05573.pdf">Collaborative Deep Reinforcement Learning for Joint Object Search</a> by Kong X, Xin B, Wang Y, et al. arXiv, 2017.</li><li><a href="http://www.ibpsa.org/proceedings/BS2017/BS2017_051.pdf">Multi-Agent Stochastic Simulation of Occupants for Building Simulation</a> by Chapman J, Siebers P, Darren R. Building Simulation, 2017.</li><li><a href="http://www.ibpsa.org/proceedings/BS2017/BS2017_056.pdf">Extending No-MASS: Multi-Agent Stochastic Simulation for Demand Response of residential appliances</a> by Sancho-Tomás A, Chapman J, Sumner M, Darren R. Building Simulation, 2017.</li><li><a href="https://arxiv.org/pdf/1610.03295.pdf">Safe, Multi-Agent, Reinforcement Learning for Autonomous Driving</a> by Shalev-Shwartz S, Shammah S, Shashua A. arXiv, 2016.</li><li><a href="https://www.researchgate.net/profile/Karl_Mason/publication/299416955_Applying_Multi-Agent_Reinforcement_Learning_to_Watershed_Management/links/56f545b908ae95e8b6d1d3ff.pdf">Applying multi-agent reinforcement learning to watershed management</a> by Mason, Karl, et al. Proceedings of the Adaptive and Learning Agents workshop at AAMAS, 2016.</li><li><a href="http://www.aaai.org/ocs/index.php/AIIDE/AIIDE10/paper/viewFile/2112/2550">Crowd Simulation Via Multi-Agent Reinforcement Learning</a> by Torrey L. AAAI, 2010.</li><li><a href="https://pdfs.semanticscholar.org/61bc/b98b7ae3df894f4f72aba3d145bd48ca2cd5.pdf">Traffic light control by multiagent reinforcement learning systems</a> by Bakker, Bram, et al. Interactive Collaborative Information Systems, 2010.</li><li><a href="https://staff.science.uva.nl/s.a.whiteson/pubs/kuyerecml08.pdf">Multiagent reinforcement learning for urban traffic control using coordination graphs</a> by Kuyer, Lior, et al. oint European Conference on Machine Learning and Knowledge Discovery in Databases, 2008.</li><li><a href="https://www.researchgate.net/publication/221465347_A_Multi-agent_Q-learning_Framework_for_Optimizing_Stock_Trading_Systems">A multi-agent Q-learning framework for optimizing stock trading systems</a> by Lee J W, Jangmin O. DEXA, 2002.</li><li><a href="http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=422747CB9AF552CF1C4E455220E3F96F?doi=10.1.1.32.9887&amp;rep=rep1&amp;type=pdf">Multi-agent reinforcement learning for traffic light control</a> by Wiering, Marco. ICML. 2000.</li></ul><p>本文作者认为，多智能体强化学习算法在2021年前，<strong>只有QMix（基于Q值分解+DQN）和MAPPO（基于MADDPG提出的CTDE框架+PPO）这两个算法可信</strong>。其他MARL算法我只能当它们不存在。</p><hr><h3 id="8-分层强化学习-Hierarchical-RL"><a href="#8-分层强化学习-Hierarchical-RL" class="headerlink" title="8.分层强化学习 Hierarchical RL"></a>8.分层强化学习 Hierarchical RL</h3><p>神经网络有一个缺陷（特性）：在数据集A上面训练的网络，拿到数据集B上训练后，这个网络会把数据集A学到的东西忘掉（灾难性遗忘 <a href="https://link.zhihu.com/?target=https://www.sciencedirect.com/science/article/pii/S1364661399012942">Catastrophic forgetting 1999</a>）。如果我让智能体学游泳，再让它学跑步，它容易把游泳给忘了（人好像也这样，不够没有它那么严重）。深度学习领域有「迁移学习」、强化学习领域有「分层强化学习」在试图解决这些难题。</p><ul><li><strong>FuNs，分级网络 FeUdal Networks</strong> ，分层强化学习不再用单一策略去解决这些更复杂的问题，而是将策略分为上层策略与多个下层策略 sub-policy 。上层策略会根据不同的状态决定使用哪个下层策略。它使用了同策路on-policy的A3C算法</li><li><strong>HIRO，使用异策略进行校正的分层强化学习 HIerarchical Reinforcement learning with Off-policy correction</strong>，警惕HIRO这个算法：FuN使用同策路on-policy的A3C算法，HIRO使用异策略off-policy的TD3算法，这个让我警惕：我个人认为不能像HIRO那样去使用TD3算法。</li><li><strong>Option-Critic，有控制权的下层策略</strong>，让将上层的策略和下层策略的控制权也当成是可以学习的，让下层的策略学习把“决定使用哪个策略的选择权”交还给上层策略的时机，这是一种隐式的分层强化学习方案，我没有复现过这个算法，我不确定这是否真的有效。</li></ul><p>我不懂分层强化学习，请看别人写的 <a href="https://zhuanlan.zhihu.com/p/46928498">张楚珩：【强化学习算法 18】FuN</a> ，<a href="https://zhuanlan.zhihu.com/p/46946800">张楚珩：【强化学习算法 19】HIRO</a> ，<a href="https://zhuanlan.zhihu.com/p/47051292">张楚珩：【强化学习算法 20】Option-Critic</a></p><h3 id="9-逆向强化学习-Inverse-RL-与-模仿学习-Imitation-Learning"><a href="#9-逆向强化学习-Inverse-RL-与-模仿学习-Imitation-Learning" class="headerlink" title="9.逆向强化学习 Inverse RL 与 模仿学习 Imitation Learning"></a>9.逆向强化学习 Inverse RL 与 模仿学习 Imitation Learning</h3><p>强化学习会在回报函数 Reward function的指导下探索训练环境，并使用未来的期望收益来强化当前动作，试图求出更优的策略。然而，现实中不容易找到需要既懂任务又懂RL的人类去手动设计Reward function。</p><blockquote><p>以 LunarLander为例子：降落+200 坠毁-100，消耗燃料会扣0~100。其实只有这些我们也能用很长的时间训练得到能安全降落的飞行器。但实际上，我们还可以根据飞行器的平稳程度给它每步一位数的奖惩，根据飞行器距离降落点的距离给他额外的奖励。这些很细节的调整可以减少智能体的训练时间。所以我前面建议：如果训练环境 Reward function 都是初学者写的，那就用PPO。等到 Reward function 设计得更合理之后，才适合用SAC。</p></blockquote><ul><li>强化学习：训练环境+DRL算法+Reward Function = 搜索出好的策略</li><li>逆向强化学习：训练环境+IRL算法+好的策略 = 逆向得到Reward Function</li></ul><p>逆向强化学习为了解决这个问题，提出：通过模仿好的策略 去反向得到 Reward function。我不懂逆向强化学习，如果强行写解释也只能翻译其他人的综述：<a href="https://link.zhihu.com/?target=https://arxiv.org/abs/1806.06877">A Survey of Inverse Reinforcement Learning: Challenges, Methods and Progress</a></p><h3 id="10-基于模型的强化学习算法-Model-based-RL（重点介绍MuZero）"><a href="#10-基于模型的强化学习算法-Model-based-RL（重点介绍MuZero）" class="headerlink" title="10.基于模型的强化学习算法 Model-based RL（重点介绍MuZero）"></a>10.基于模型的强化学习算法 Model-based RL（重点介绍MuZero）</h3><p>这里的「模型」指：状态转移模型。离散状态空间下的状态转移模型可以用 状态转移矩阵去描述。基于模型的算法需要将状态转移模型探索出来（或由人类提供），而 无模型算法 model-free RL 不需要探索出模型，它仅依靠智能体在环境中探索 rollout 得到的一条条 trajectory 中记录的 environment transition (s, a, r, next state) 即可对策略进行更新。</p><p>我对无模型算法不够了解，如果强行写解释也只能翻译其他人的综述：<a href="https://link.zhihu.com/?target=https://arxiv.org/abs/2006.16712">Model-based Reinforcement Learning: A Survey</a> 。OpenAI 提供了一些简单的代码： <a href="https://link.zhihu.com/?target=https://spinningup.openai.com/en/latest/spinningup/rl_intro2.html">SpinningUp Model-based RL</a> 。</p><p><strong>近年来受到最多圈外人关注的 model-based RL 是 MuZero</strong>。在下棋、雅达利游戏这种状态转移模型相对容易拟合的离散动作空间任务中，MuZero取得了非常不错的表现。它有三个网络：</p><ul><li><strong>编码器：</strong>输入连续观测到的几个state，将其编码成 latent state。为何非要使用 latent state 而不直接使用 state？ 在当前state 下做出action 后，并不会转移到某个确切的状态，next state 是一个不容易直接描述的分布。因此接下来的生成器不会（也无法）直接预测 next state，只能预测 latent state。</li><li><strong>预测器：</strong>输入当前观测到的state，生成执行每个动作的概率，并预测执行每个动作的value （Q值，我不反对将它粗略地理解为DQN的 Q Network）。</li><li><strong>生成器：</strong>输入当前观测到的state，生成 执行每个离散动作后会转移到的 latent state 以及对应的 Reward（这是单步的Reward，不是累加得到的Q值）。生成器就是MuZero 这个model-based RL算法 学到的状态转移模型。</li></ul><p>如果离散动作的数量很多（如围棋），那么MuZero 会使用MCTS（<a href="https://link.zhihu.com/?target=https://en.wikipedia.org/wiki/Monte_Carlo_tree_search">Monte Carlo tree search</a> 蒙特卡洛树搜索），剪除低概率的分支并估计Q值（论文里用 <img src="https://www.zhihu.com/equation?tex=u" alt="[公式]"> ），具体剪去多少分支要看有多少算力和时间。</p><p><img src="https://pic2.zhimg.com/80/v2-f11ec27c059ff5fa607351655ecfe5dd_720w.jpg" alt="img">图中左上角绿色的柱子是离散动作执行概率，可以看到：虽然围棋有很多位置可下，但实际上只有几个位置能下出好棋。如果对面不是柯洁，那么一些分支可以剪除不去计算它。</p><blockquote><p>剪枝：蒸馏学习的 Weight Pruning 权重剪枝，消除权重中不必要的值。在MCTS中的剪枝是不计算执行概率过低的动作分支。</p></blockquote><p>model-based RL 学到状态转移模型之后，就能在探索环境之前想象出接下来几步的变化，然后基于环境模型做规划，减少与环境的交互次数。（在model-based RL 中经常可以读到 Imagination，planning，dream这些词）。这里顺便解释一下 MuZero 的 Mu 是什么意思？ 解释来自<a href="https://link.zhihu.com/?target=http://www.furidamu.org/blog/2020/12/22/muzero-intuition/">MuZero Intuition - Julian Schrittwieser - What’s in a name?</a></p><ul><li>希腊字母 μ，用来表示强化学习算法学到的策略模型</li><li>夢（梦）。MuZero使用预测器预测智能体在环境中的下一步。</li><li>無（无）。MuZero（AlphaZero）不需要像前身AlphaGo 那依赖人类知识去学习。</li></ul><p>推荐看知乎问题：如何评价DeepMind新提出的MuZero算法？ 下面的 <a href="https://www.zhihu.com/question/356976342/answer/1653420480">什么名字可以吸粉的回答</a>（他的翻译比较好：representation function 编码器，prediction function 预测器，dynamics function 生成器） 与 <a href="https://www.zhihu.com/question/356976342/answer/906149260">Evensgn的回答</a> （Value Prediction Network 值得看一看）。</p><h3 id="11-会议-amp-期刊"><a href="#11-会议-amp-期刊" class="headerlink" title="11.会议&amp;期刊"></a>11.会议&amp;期刊</h3><h4 id="会议"><a href="#会议" class="headerlink" title="会议"></a>会议</h4><p>AAAI、NIPS、ICML、ICLR、IJCAI、AAMAS、IROS等</p><h4 id="期刊"><a href="#期刊" class="headerlink" title="期刊"></a>期刊</h4><p>AI、JMLR、JAIR、Machine Learning、JAAMAS等</p><h4 id="计算机和人工智能会议（期刊）排名"><a href="#计算机和人工智能会议（期刊）排名" class="headerlink" title="计算机和人工智能会议（期刊）排名"></a>计算机和人工智能会议（期刊）排名</h4><p><a href="https://mp.weixin.qq.com/s?__biz=Mzg4MDE3OTA5NA==&amp;mid=2247490957&amp;idx=1&amp;sn=b9aa515f7833ba1503be298ac2360960&amp;source=41#wechat_redirect">清华发布新版计算机学科推荐学术会议和期刊列表，与CCF有何不同？</a><br><a href="https://www.aminer.cn/ranks/conf/artificial-intelligence-and-pattern-recognition">https://www.aminer.cn/ranks/conf/artificial-intelligence-and-pattern-recognition</a></p><h3 id="12-公众号"><a href="#12-公众号" class="headerlink" title="12.公众号"></a>12.公众号</h3><p>深度强化学习实验室、机器之心、AI科技评论、新智元、学术头条</p><h3 id="13-知乎"><a href="#13-知乎" class="headerlink" title="13.知乎"></a>13.知乎</h3><h4 id="大牛"><a href="#大牛" class="headerlink" title="大牛"></a>大牛</h4><p>田渊栋、Flood Sung、许铁-巡洋舰科技（微信公众号同名）、<br>周博磊、俞扬、张楚珩、天津包子馅儿、JQWang2048 及其互关大牛等</p><h4 id="专栏"><a href="#专栏" class="headerlink" title="专栏"></a>专栏</h4><ul><li>David Silver强化学习公开课中文讲解及实践（叶强，比较经典）</li><li>强化学习知识大讲堂（《深入浅出强化学习：原理入门》作者天津包子馅儿）</li><li>智能单元（杜克、Floodsung、wxam，聚焦通用人工智能，Flood Sung：深度学习论文阅读路线图 Deep Learning Papers Reading Roadmap很棒，Flood Sung：最前沿：深度强化学习的强者之路）</li><li>深度强化学习落地方法论（西交 大牛，实操经验丰富）</li><li>深度强化学习（知乎：JQWang2048，GitHub：NeuronDance，CSDN：J. Q. Wang）</li><li>神经网络与强化学习（《Reinforcement Learning: An Introduction》读书笔记）</li><li>强化学习基础David Silver笔记（陈雄辉，南大，DiDi AI Labs）</li></ul><h3 id="14-官网"><a href="#14-官网" class="headerlink" title="14. 官网"></a>14. 官网</h3><h4 id="OpenAI"><a href="#OpenAI" class="headerlink" title="OpenAI"></a><a href="http://deeprl.neurondance.com/d/www.openai.com">OpenAI</a></h4><h4 id="DeepMind"><a href="#DeepMind" class="headerlink" title="DeepMind"></a><a href="http://deeprl.neurondance.com/d/www.deepmind.com">DeepMind</a></h4><h4 id="Berkeley-Artificial-Intelligence-Research"><a href="#Berkeley-Artificial-Intelligence-Research" class="headerlink" title="Berkeley Artificial Intelligence Research"></a><a href="http://deeprl.neurondance.com/d/bair.berkeley.edu">Berkeley Artificial Intelligence Research</a></h4><p>以及Sutton老爷子、Andrew NG、David Silver、Pieter Abbeel、John Schulman、Sergey Levine、Chelsea Finn、Andrej Karpathy等主页</p><h3 id="15-环境及框架"><a href="#15-环境及框架" class="headerlink" title="15.环境及框架"></a>15.环境及框架</h3><ul><li><p><a href="https://gym.openai.com/">OpenAI Gym</a> (<a href="https://github.com/openai/gym">GitHub</a>) (<a href="https://gym.openai.com/docs/">docs</a>)</p></li><li><p>rllab (<a href="https://github.com/rll/rllab">GitHub</a>) (<a href="http://rllab.readthedocs.io/">readthedocs</a>)</p></li><li><p>Ray <a href="https://ray.readthedocs.io/en/latest/index.html">(Doc)</a></p></li><li><p>Dopamine: <a href="https://github.com/google/dopamine">https://github.com/google/dopamine</a> (uses some tensorflow)</p></li><li><p>trfl: <a href="https://github.com/deepmind/trfl">https://github.com/deepmind/trfl</a> (uses tensorflow)</p></li><li><p>ChainerRL (<a href="https://github.com/chainer/chainerrl">GitHub</a>) (API: Python)</p></li><li><p>Surreal <a href="https://github.com/SurrealAI/surreal">GitHub</a> (API: Python) (support: Stanford Vision and Learning Lab).<a href="https://surreal.stanford.edu/img/surreal-corl2018.pdf">Paper</a></p></li><li><p>PyMARL <a href="https://github.com/oxwhirl/pymarl">GitHub</a> (support: <a href="http://whirl.cs.ox.ac.uk/">http://whirl.cs.ox.ac.uk/</a>)</p></li><li><p>TF-Agents: <a href="https://github.com/tensorflow/agents">https://github.com/tensorflow/agents</a> (uses tensorflow)</p></li><li><p>TensorForce (<a href="https://github.com/reinforceio/tensorforce">GitHub</a>) (uses tensorflow)</p></li><li><p><a href="https://sites.google.com/a/rl-community.org/rl-glue/Home/rl-glue">RL-Glue</a> (<a href="https://code.google.com/archive/p/rl-glue-ext/wikis/RLGlueCore.wiki">Google Code Archive</a>) (API: C/C++, Java, Matlab, Python, Lisp) (support: Alberta)</p></li><li><p>MAgent <a href="https://github.com/geek-ai/MAgent">https://github.com/geek-ai/MAgent</a> (uses tensorflow)</p></li><li><p>RLlib <a href="http://ray.readthedocs.io/en/latest/rllib.html">http://ray.readthedocs.io/en/latest/rllib.html</a> (API: Python)</p></li><li><p><a href="http://burlap.cs.brown.edu/">http://burlap.cs.brown.edu/</a> (API: Java)</p></li><li><p><a href="https://bair.berkeley.edu/blog/2019/09/24/rlpyt/">rlpyt: A Research Code Base for Deep Reinforcement Learning in PyTorch</a></p></li><li><p><a href="https://github.com/araffin/robotics-rl-srl">robotics-rl-srl</a> - S-RL Toolbox: Reinforcement Learning (RL) and State Representation Learning (SRL) for Robotics</p></li><li><p><a href="https://github.com/deepmind/pysc2">pysc2: StarCraft II Learning Environment</a></p></li><li><p><a href="https://github.com/mgbellemare/Arcade-Learning-Environment">Arcade-Learning-Environment</a></p></li><li><p><a href="https://github.com/openai/universe">OpenAI universe</a> - A software platform for measuring and training an AI’s general intelligence across the world’s supply of games, websites and other applications</p></li><li><p><a href="https://github.com/deepmind/lab">DeepMind Lab</a> - A customisable 3D platform for agent-based AI research</p></li><li><p><a href="https://github.com/Microsoft/malmo">Project Malmo</a> - A platform for Artificial Intelligence experimentation and research built on top of Minecraft by Microsoft</p></li><li><p><a href="https://github.com/nadavbh12/Retro-Learning-Environment">Retro Learning Environment</a> - An AI platform for reinforcement learning based on video game emulators. Currently supports SNES and Sega Genesis. Compatible with OpenAI gym.</p></li><li><p><a href="https://github.com/twitter/torch-twrl">torch-twrl</a> - A package that enables reinforcement learning in Torch by Twitter</p></li><li><p><a href="https://github.com/facebook/UETorch">UETorch</a> - A Torch plugin for Unreal Engine 4 by Facebook</p></li><li><p><a href="https://github.com/TorchCraft/TorchCraft">TorchCraft</a> - Connecting Torch to StarCraft</p></li><li><p><a href="https://github.com/openai/rllab">rllab</a> - A framework for developing and evaluating reinforcement learning algorithms, fully compatible with OpenAI Gym</p></li><li><p><a href="https://github.com/reinforceio/tensorforce">TensorForce</a> - Practical deep reinforcement learning on TensorFlow with Gitter support and OpenAI Gym/Universe/DeepMind Lab integration.</p></li><li><p><a href="https://github.com/kengz/openai_lab">OpenAI lab</a> - An experimentation system for Reinforcement Learning using OpenAI Gym, Tensorflow, and Keras.</p></li><li><p><a href="https://github.com/matthiasplappert/keras-rl">keras-rl</a> - State-of-the art deep reinforcement learning algorithms in Keras designed for compatibility with OpenAI.</p></li><li><p><a href="http://burlap.cs.brown.edu/">BURLAP</a> - Brown-UMBC Reinforcement Learning and Planning, a library written in Java</p></li><li><p><a href="https://github.com/geek-ai/MAgent">MAgent</a> - A Platform for Many-agent Reinforcement Learning.</p></li><li><p><a href="http://ray.readthedocs.io/en/latest/rllib.html">Ray RLlib</a> - Ray RLlib is a reinforcement learning library that aims to provide both performance and composability.</p></li><li><p><a href="https://github.com/kengz/SLM-Lab">SLM Lab</a> - A research framework for Deep Reinforcement Learning using Unity, OpenAI Gym, PyTorch, Tensorflow.</p></li><li><p><a href="https://github.com/Unity-Technologies/ml-agents">Unity ML Agents</a> - Create reinforcement learning environments using the Unity Editor</p></li><li><p><a href="https://github.com/NervanaSystems/coach">Intel Coach</a> - Coach is a python reinforcement learning research framework containing implementation of many state-of-the-art algorithms.</p></li><li><p><a href="https://github.com/facebookresearch/ELF">ELF</a> - An End-To-End, Lightweight and Flexible Platform for Game Research</p></li><li><p><a href="https://arxiv.org/pdf/1809.02627v1.pdf">Unity ML-Agents Toolkit</a></p></li><li><p><a href="https://github.com/vitchyr/rlkit">rlkit</a></p></li><li><p><a href="https://gym.openai.com/envs/#classic_control">https://gym.openai.com/envs/#classic_control</a></p></li><li><p><a href="https://github.com/erlerobot/gym-gazebo">https://github.com/erlerobot/gym-gazebo</a></p></li><li><p><a href="https://github.com/robotology/gym-ignition">https://github.com/robotology/gym-ignition</a></p></li><li><p><a href="https://github.com/dartsim/gym-dart">https://github.com/dartsim/gym-dart</a></p></li><li><p><a href="https://github.com/Roboy/gym-roboy">https://github.com/Roboy/gym-roboy</a></p></li><li><p><a href="https://github.com/openai/retro">https://github.com/openai/retro</a></p></li><li><p><a href="https://github.com/openai/gym-soccer">https://github.com/openai/gym-soccer</a></p></li><li><p><a href="https://github.com/duckietown/gym-duckietown">https://github.com/duckietown/gym-duckietown</a></p></li><li><p><a href="https://github.com/Unity-Technologies/ml-agents">https://github.com/Unity-Technologies/ml-agents</a> (Unity, multiagent)</p></li><li><p><a href="https://github.com/koulanurag/ma-gym">https://github.com/koulanurag/ma-gym</a> (multiagent)</p></li><li><p><a href="https://github.com/ucuapps/modelicagym">https://github.com/ucuapps/modelicagym</a></p></li><li><p><a href="https://github.com/mwydmuch/ViZDoom">https://github.com/mwydmuch/ViZDoom</a></p></li><li><p><a href="https://github.com/benelot/pybullet-gym">https://github.com/benelot/pybullet-gym</a></p></li><li><p><a href="https://github.com/Healthcare-Robotics/assistive-gym">https://github.com/Healthcare-Robotics/assistive-gym</a></p></li><li><p><a href="https://github.com/Microsoft/malmo">https://github.com/Microsoft/malmo</a></p></li><li><p><a href="https://github.com/nadavbh12/Retro-Learning-Environment">https://github.com/nadavbh12/Retro-Learning-Environment</a></p></li><li><p><a href="https://github.com/twitter/torch-twrl">https://github.com/twitter/torch-twrl</a></p></li><li><p><a href="https://github.com/arex18/rocket-lander">https://github.com/arex18/rocket-lander</a></p></li><li><p><a href="https://github.com/ppaquette/gym-doom">https://github.com/ppaquette/gym-doom</a></p></li><li><p><a href="https://github.com/thedimlebowski/Trading-Gym">https://github.com/thedimlebowski/Trading-Gym</a></p></li><li><p><a href="https://github.com/Phylliade/awesome-openai-gym-environments">https://github.com/Phylliade/awesome-openai-gym-environments</a></p></li><li><p><a href="https://github.com/deepmind/pysc2">https://github.com/deepmind/pysc2</a> (by DeepMind) (Blizzard StarCraft II Learning Environment (SC2LE) component)</p></li></ul><h3 id="好用的强化学习算法"><a href="#好用的强化学习算法" class="headerlink" title="好用的强化学习算法"></a>好用的强化学习算法</h3><ul><li>没有很多需要调整的超参数。D3QN、SAC超参数较少，且SAC可自行调整超参数 <img src="https://www.zhihu.com/equation?tex=%5Calpha" alt="[公式]"></li><li>超参数很容易调整或确定。SAC的 reward scaling 可以在训练前直接推算出来。PPO超参数的细微改变不会极大地影响训练</li><li>训练快，收敛稳、得分高。看下面的学习曲线 learning curve</li></ul><p><img src="https://pic4.zhimg.com/80/v2-9d8ff9652e255dbf6d41e754a9b0d997_720w.jpg" alt="img">弯弯曲曲的学习曲线很正常，图片截取自 Ape-X 与 SAC 论文</p><h4 id="学习曲线怎么看？"><a href="#学习曲线怎么看？" class="headerlink" title="学习曲线怎么看？"></a>学习曲线怎么看？</h4><ul><li>横轴可以是训练所需的步数（智能体与环境交互的次数）、训练轮数（达到固定步数、失败、通关 就终止终止这一轮的训练episode）、训练耗时（这个指标还与设备性能有关）</li><li>纵轴可以是 每轮得分（ 每一轮的每一步的reward 加起来，episode return），对于没有终止状态的任务，可以计算某个时间窗口内reward之和</li><li>有时候还有用 plt.fill_between 之类的上下std画出来的波动范围，用于让崎岖的曲线更好看一点：先选择某一段数据，然后计算它的均值，再把它的标准差画出来，甚至可以画出它的上下偏差（琴形图）。如果同一个策略在环境随机重置后得分相差很大，那么就需要多测几次。</li></ul><h4 id="好的算法的学习曲线应该是？"><a href="#好的算法的学习曲线应该是？" class="headerlink" title="好的算法的学习曲线应该是？"></a>好的算法的学习曲线应该是？</h4><ul><li>训练快，曲线越快达到某个目标分数 target reward （需要多测几次的结果才有说服力）</li><li>收敛稳，曲线后期不抖动（曲线在前期剧烈抖动是可以接受的）</li><li>得分高，曲线的最高点可以达到很高（即便曲线后期下降地很厉害也没关系，因为我们可以保存整个训练期间“平均得分”最高的模型）</li></ul><h2 id="未来的工作方向"><a href="#未来的工作方向" class="headerlink" title="未来的工作方向"></a>未来的工作方向</h2><p>所以当下有两条路建议选择：一是去腾讯AIlab、华为诺亚、网易伏羲或者阿里研究型项目，二是去其他高校有积淀的实验室。这两种方式都蛮不错的，应该会比自己闭门造车的速度快。只不过，这些地方的要求都不会低，想要去做科研要好好准备面试。</p>]]></content>
      
      
      <categories>
          
          <category> 学习方法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 研究方法 </tag>
            
            <tag> 论文写作 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>强化学习之TRPO</title>
      <link href="2021/09/03/qiang-hua-xue-xi-zhi-trpo/"/>
      <url>2021/09/03/qiang-hua-xue-xi-zhi-trpo/</url>
      
        <content type="html"><![CDATA[<p>​       注：TRPO算是我至今遇到过的最难理解的算法了，我查了很多资料，花费好几天时间，也未曾理解，向TRPO的一作致敬。。。本文是我的查资料笔记，由于公式过多，可以先学比较重要的PPO。</p><p>​       TRPO全称为Trust region policy optimization，意思是信赖域策略优化。</p><p>​       TRPO是Policy Gradient的改进算法。Policy Gradient有几个缺陷：当更新步长不合适时，更新的参数所对应的策略是一个更不好的策略，当利用这个更不好的策略进行采样学习时，再次更新的参数会更差，因此很容易导致越学越差，最后崩溃，这是DDPG，A3C等算法都有的问题。所以，合适的步长对于强化学习非常关键。如何找到新的策略使得新的回报函数的值单调增，或单调不减。这是TRPO解决方式就是Trust region，让其在一个安全范围内更新参数。Policy Gradient是一种on-policy的方法，而用off-policy效率会更高，因此TRPO采用了Important Sampling的方法。</p><hr><h2 id="前期学习流程"><a href="#前期学习流程" class="headerlink" title="前期学习流程"></a>前期学习流程</h2><p>​        为了确保我们每次更新都能得到一个更好的策略，一个方法是把策略$\pi_{i+1}$对应的期望回报函数$\eta(\pi_{i+1})$分解成$\eta(\pi_{i})$加上一个不小于0的项，这样就能保证策略朝着更优的方向前进。</p><p>​        在A2C中，核心思想是加入了一个advantage函数，可以用这个函数来判断新的策略是否优于预期：<br>$$<br>A_{\pi}(s_t,a) = E[r(s_t) + \gamma V_{\pi}(s_{t+1}) - V(s_t)]<br>$$<br>下面推导一个旧策略回报$\eta(\pi)$和新策略回报$\eta(\tilde{\pi})$关系重要公式：<br>$$<br>E[\sum_{t=0}^{\infty} \gamma^t A_{\pi}(s_t,a_t)]    \<br>= E[\sum_{t=0}^{\infty} \gamma^t(r(s_t) + \gamma V_{\pi}(s_{t+1}) - V(s_t))]   \<br>=E[-V_{\pi}(s_0) + \sum_{t=0}^{\infty} \gamma^t r(s_t)] \<br>= - \eta(\pi) + \eta(\tilde{\pi})<br>$$<br>因此：<br>$$<br>\eta(\tilde{\pi})  =  \eta(\pi) + E[\sum_{t=0}^{\infty} \gamma^t A_{\pi}(s_t,a_t)]<br>$$</p><p>根据Advantage函数的相关知识，判断新策略是否优于旧策略的标准是：</p><p>$$<br>\bar{A}(s) = \sum_a \tilde{\pi}(a|s)A_{\pi}(s,\tilde a) \geq 0<br>$$<br>继续推导：</p><img src="/2021/09/03/qiang-hua-xue-xi-zhi-trpo/1.png" class><p>这个公式没法应用，这里s是由新分布产生的，对新分布有很强的依赖性。这个公式其实在应用中完全无法达到，因为我们是为了得到新的策略，所以这里的其他项完全无从所知。</p><p>这里实际用转态s的动作优势回报A(s,a)期望$\bar{a}(s)$来代替优势回报$A(s,a)$</p><p>现在得到：<br>$$<br>\eta(\tilde{\pi})  =  \eta(\pi) + E_{\tau|\pi}[\sum_{t=0}^{\infty} \gamma^t \bar A_{}(s_t)]<br>$$<br>现在研究一下$\bar{A}(s_t)$<br>$$<br>\bar A(s) = \sum_{\tilde a} \tilde{\pi}(a|s)A_{\pi}(s,\tilde a)\<br>= E[A_{\pi}(s,\tilde a)]\<br>= E[A_{\pi}(s,\tilde a)  - A_{\pi}(s,a)]\<br>= P(a \neq \tilde a |s) E[A_{\pi}(s,\tilde a)  - A_{\pi}(s,a)]\ +P(a = \tilde a |s) E[A_{\pi}(s,\tilde a)  - A_{\pi}(s,a)]\<br>=P(a \neq \tilde a |s) E[A_{\pi}(s,\tilde a)  - A_{\pi}(s,a)]<br>$$<br>结论：</p><p>假设 当智能体所处状态为s的时候新的策略$ \tilde{\pi} $和旧的策略π以α的概率(P ( a ≠ a ~ ∣ s )选择不同的动作，以1-α的概率(P ( a = a ~ ∣ s ) ) 是选择相同的策略<br>$$<br>π_ {n e w} ( a ∣ s ) = ( 1 − α ) π<em>{ o l d }( a ∣ s ) + α π ′ ( a ∣ s )<br>$$<br>并且：<br>$$<br>|A</em>{\pi}(s,\tilde a)  - A_{\pi}(s,a)| \leq 2\max_{a,s} |A_{\pi}(s,a)|<br>$$<br>因此：<br>$$<br>|\bar A (s)| = P(a \neq \tilde a |s) E[A_{\pi}(s,\tilde a)  - A_{\pi}(s,a)] \leq 2 \alpha max_a |A_{\pi}(s,a)|<br>$$</p><p>定义：对于$n_{t}= 0$表示在在智能体在t时刻之前(t=0,1,2,3,4…t-1)，策略 π ,和策略$\tilde{\pi} $产生的相同状态s，并且采取的每个状态s采取的动作a都相同，此时$P ( n _ { t } = 0 ) = (1-\alpha)^{t}$</p><p>对于$n_{t}&gt;0$表示在在智能体在t时刻之前(t=0,1,2,3,4…t-1)，策略 π ,和策略$\tilde{\pi} $产生的相同状态s，但是不同动作a的次数，此时$P ( n _ { t } &gt; 0 ) = 1- (1-\alpha)^{t}$</p><p>有：<br>$$<br>E_{s_t∼\tilde\pi}[\bar A(s_t)] = P(n_t = 0)E_{s_t ∼ \pi | n_t = 0}[\bar A(s_t)] + P(n_t &gt; 0)E_{s_t ∼ \tilde\pi | n_t &gt; 0}[\bar A(s_t)]<br>$$</p><p>$$<br>E_{s_t∼\pi}[\bar A(s_t)] = P(n_t = 0)E_{s_t ∼ \pi | n_t = 0}[\bar A(s_t)] + P(n_t &gt; 0)E_{s_t ∼ \pi | n_t &gt; 0}[\bar A(s_t)]<br>$$</p><p>相减得：<br>$$<br>E_{s_t∼\tilde\pi}[\bar A(s_t)] -E_{s_t∼\pi}[\bar A(s_t)]\<br>=  P(n_t &gt; 0)(E_{s_t ∼ \tilde\pi | n_t &gt; 0}[\bar A(s_t)] - E_{s_t ∼ \pi | n_t &gt; 0}[\bar A(s_t)])<br>$$</p><p>$$<br>|E_{s_t∼\tilde\pi}[\bar A(s_t)] -E_{s_t∼\pi}[\bar A(s_t)]|\<br>=  P(n_t &gt; 0)(|E_{s_t ∼ \tilde\pi | n_t &gt; 0}[\bar A(s_t)] - E_{s_t ∼ \pi | n_t &gt; 0}[\bar A(s_t)]|)  \<br>\leq P(n_t &gt; 0)(|E_{s_t ∼ \tilde\pi | n_t &gt; 0}[\bar A(s_t)]| + | E_{s_t ∼ \pi | n_t &gt; 0}[\bar A(s_t)]|) \<br>\leq P(n_t &gt; 0)4\alpha \max_{s,a}|A_{\pi}(s,a)| \<br>= 4\alpha (1-(1-\alpha)^t)\max_{s,a}|A_{\pi}(s,a)|<br>$$</p><p>又由前面公式可得：<br>$$<br>\eta(\tilde{\pi})  = \sum_s \rho_{\tilde\pi}(s)\sum_a \tilde\pi(a|s)A^{\pi}(s,a)  =  \eta(\pi) + E_{\tau ∼ \tilde\pi}[\sum_{t=0}^{\infty} \gamma^t A_{\pi}(s_t,a_t)]<br>$$<br>令：<br>$$<br>L(\tilde{\pi})  = \sum_s \rho_{\pi}(s)\sum_a \tilde\pi(a|s)A^{\pi}(s,a)  =  \eta(\pi) + E_{\tau ∼ \pi}[\sum_{t=0}^{\infty} \gamma^t A_{\pi}(s_t,a_t)]<br>$$<br>则：<br>$$<br>|\eta(\tilde{\pi}) -L(\tilde{\pi})| \<br>= \sum_{t=0}^{\infty}|E_{\tau ∼ \tilde\pi}[ \gamma^t A_{\pi}]-E_{\tau ∼ \pi}[ \gamma^t A_{\pi}]| \<br>\leq \sum_{t=0}^{\infty} \gamma^t * 4\epsilon \alpha (1-(1-\alpha)^t)\<br>=  4\epsilon \alpha(\frac{1}{1-\gamma} - \frac{1}{1-\gamma(1-\alpha)}) \<br>= \frac{4\alpha^2 \gamma \epsilon}{(1-\gamma)^2 + \alpha \gamma(1-\gamma)} \<br>\leq \frac{4\alpha^2 \gamma \epsilon}{(1-\gamma)^2 }<br>$$<br>其中：<br>$$<br>\epsilon = \max_{a,s}|A_{\pi} (s,a)|<br>$$<br>上面两者只有采用的$\rho_{\pi}(s)$不同，一个是新策略的状态分布，一个是旧策略的状态分布。</p><p><strong>因此，最后的公式就推导出来了：</strong><br>$$<br>\eta(\pi_{new}) \geq L_{\pi_{old}}(\pi_{new}) - \frac{4\alpha^2 \gamma \epsilon}{(1-\gamma)^2 }<br>$$</p><hr><p>那么，如何进行求解：</p><p>新策略我们并不知道，也无法求解，所以，需要进行进一步的处理，虽然我们不知道新策略怎么求，但是旧的策略我们是知道的可以用重要性采样（weighted sampling)的方法进行采样把新策略采样出来。</p><p>关于重要性采用可参考：<a href="https://zhuanlan.zhihu.com/p/41217212">https://zhuanlan.zhihu.com/p/41217212</a><br>$$<br>L(\tilde{\pi})  =  \eta(\pi)+\sum_s \rho_{\pi}(s)\sum_a \tilde\pi(a|s)A^{\pi}(s,a)  =  \eta(\pi) + E_{\tau ∼ \pi}[\sum_{t=0}^{\infty} \gamma^t A_{\pi}(s_t,a_t)]<br>$$<br>通过重要性采样得：<br>$$<br>L(\tilde{\pi})  =  \eta(\pi)+E_{s～\rho_{\theta},a～\pi_{\theta}} [\frac{\tilde\pi(a|s)}{\pi_{\theta_{}}}A_{\theta}(s,a)]<br>$$</p><img src="/2021/09/03/qiang-hua-xue-xi-zhi-trpo/3.png" class><p>最终的工程实践版本：</p><img src="/2021/09/03/qiang-hua-xue-xi-zhi-trpo/4.png" class><img src="/2021/09/03/qiang-hua-xue-xi-zhi-trpo/5.png" class><hr><p>TRPO中存在四个技巧：</p><ol><li>在原式中计算$\rho_{\pi}(s)时，我们需要新的策略，而新策略目前还未知，因此，我们可以利用旧策略来代替新策略，因为两者相差并不是很大。</li><li>利用重要性采样处理动作分布。</li></ol><p>参考论文：</p><p>1.<a href="https://blog.csdn.net/meizhulei/article/details/85138538?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522163071834316780269895578%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&amp;request_id=163071834316780269895578&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-2-85138538.first_rank_v2_pc_rank_v29&amp;utm_term=%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0TRPO&amp;spm=1018.2226.3001.4187">人工智能Paper解读之强化学习TRPO算法</a></p><p>2.<a href="https://blog.csdn.net/weixin_41679411/article/details/82421121">强化学习–信赖域系方法：TRPO、PPO（附适合初学者阅读的完整PPO代码连接）</a></p><h2 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h2><p>TRPO算法重复着两个步骤：</p><ol><li>近似：我们构建一个$L(\theta|\theta_{old})$函数，在信赖域内近似于价值函数$J(\theta)$。</li><li>最大化：在信赖域内，找到一组新的参数，使得$L(\theta|\theta_{old})$最大化。</li></ol><h3 id="近似："><a href="#近似：" class="headerlink" title="近似："></a>近似：</h3><p>$$<br>V_{\pi}(s) = \sum_a \pi(a|s;\theta) * Q_{\pi}(s,a) \<br> = \sum_a \pi(a|s;\theta_{old})\frac{\pi(a|s;\theta)}{\pi(a|s;\theta_{old})} * Q_{\pi}(s,a) \<br> = E_{A～\pi(a|s;\theta_{old})}[\frac{\pi(a|s;\theta)}{\pi(a|s;\theta_{old})} * Q_{\pi}(s,a)]<br>$$</p><p>$$<br>J(\theta) = E_S[V_{\pi}(S)] \<br>= E_{S,A}[\frac{\pi(A|S;\theta)}{\pi(A|S;\theta_{old})} * Q_{\pi}(S,A)]<br>$$</p><p>这是TRPO的最重要的公式。</p><p>在实际运用中，我们做蒙特卡洛近似，如果对于旧策略，我们收集到的数据如下：<br>$$<br>s_1,a_1,r_1,s_2,a_2,r_2,…,s_n,a_n,r_n<br>$$<br>公式改变如下：<br>$$<br>L(\theta|\theta_{old})<br>= \frac{1}{n}\sum_{i=1}^{n}\frac{\pi(a_i|s_i;\theta)}{\pi(a_i|s_i;\theta_{old})} * Q_{\pi}(s_i,a_i)<br>$$<br>这里L就是对J的近似，但这里还无法对L做最大化，原因在于动作价值函数Q我们并不知道是什么，所以我们也要对它做近似。</p><p>对于Q是动作价值的期望，我们对它做蒙特卡洛近似，根据折扣函数，可得：<br>$$<br>u_i = r_i + \gamma r_{i+1} + \gamma^2r_{i+2}… + \gamma^{n-i} r_n<br>$$<br>我们可以用这种计算方式来代替Q。这里我们也可以把Q换成A，也就是优势函数：<br>$$<br>A = Q- V = \gamma V_{t+1} + R_{t} - V_t<br>$$</p><h3 id="最大化"><a href="#最大化" class="headerlink" title="最大化"></a>最大化</h3><p>有了上面的近似以后，我们对其在信赖域内作最大化：通过调整策略网络参数，使得新的策略网络的奖励期望越大越好。数学公式表达为：<br>$$<br>\theta_{new} \leftarrow argmax_{\theta}L(\theta|\theta_{old})<br>\ s.t. \theta \in N{(\theta_{old})}<br>$$<br>有很多方式表达两组参数的距离，这里介绍两种：</p><ol><li><p>二范数距离，即两者的欧式距离，平方和后开方：<br>$$<br>||\theta - \theta_{old}|| &lt; \Delta<br>$$</p></li><li><p>KL散度：这不是用来衡量两组参数的，而是用来衡量网络输出的概率分布的，概率分布的区别越大，KL散度越大，区别越小越趋近于0，也叫相对熵。</p><p>离散形式<br>$$<br>KL(P||Q) = \sum P(x)log \frac{P(x)}{Q(x)}<br>$$<br>连续形式：<br>$$<br>KL(P||Q) = \int P(x)log \frac{P(x)}{Q(x)}dx<br>$$</p></li></ol><p>那么这里的约束条件就是：<br>$$<br>\frac{1}{n} \sum_{i=1}^{n} KL[\pi(.|s_i;\theta_{old})||\pi(.|s_i;\theta)] &lt; \Delta<br>$$<br>至此，游戏完成了一轮episode，我们进行了一次参数更新，往往更新进行很多次才能得到一个比较好的策略网络。</p><p>TRPO的优点是曲线稳定不会剧烈波动，对学习率设置不会太敏感。而且观察到更少的奖励就能达到跟策略梯度算法相同的表现。</p>]]></content>
      
      
      <categories>
          
          <category> 强化学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 强化学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>强化学习之A2C和A3C</title>
      <link href="2021/09/02/qiang-hua-xue-xi-zhi-a2c-he-a3c/"/>
      <url>2021/09/02/qiang-hua-xue-xi-zhi-a2c-he-a3c/</url>
      
        <content type="html"><![CDATA[<p> 阅读本文可参考我以前的文章《强化学习实践教学》<a href="https://tianjuewudi.gitee.io/2021/07/16/qiang-hua-xue-xi-shi-jian-jiao-xue/#toc-heading-29%EF%BC%8C%E5%85%B6%E4%B8%AD%E7%9A%84%E8%BF%9E%E7%BB%AD%E5%8A%A8%E4%BD%9C%E7%A9%BA%E9%97%B4%E4%B8%8A%E6%B1%82%E8%A7%A3RL%E7%AB%A0%E8%8A%82%E6%98%AF%E6%9C%AC%E6%96%87%E7%9A%84%E5%9F%BA%E7%A1%80%EF%BC%8C%E5%85%B6%E4%B8%AD%E7%9A%84DDPG%E5%92%8CActor-Critic%E9%99%A4%E4%BA%86Target%E7%BD%91%E7%BB%9C%E5%A4%96%E5%85%B6%E4%BD%99%E9%83%BD%E4%B8%80%E8%87%B4%E3%80%82">https://tianjuewudi.gitee.io/2021/07/16/qiang-hua-xue-xi-shi-jian-jiao-xue/#toc-heading-29，其中的连续动作空间上求解RL章节是本文的基础，其中的DDPG和Actor-Critic除了Target网络外其余都一致。</a></p><p>首先，A2C的全称是Advantage Actor Critic，而A3C是Asynchronous Advantage Actor Critic，A2C源自A3C。</p><h2 id="Actor-Critic"><a href="#Actor-Critic" class="headerlink" title="Actor Critic"></a>Actor Critic</h2><p>首先解释一下Actor Critic的概念，Q-learning是一种价值迭代法，而policy gradient是一种策略迭代法，Actor Critic同时使用了这两种方法。</p><p>Actor直接负责输出每个Action的概率，有多少个Action就有多少个输出。Critic输出的是状态的价值V。这是两个神经网络。在Policy Gradient中，一个episode的累计Reward就像是一个Critic，决定了Actor的学习方向，使得Actor倾向于学习Critic累计Reward更高的逻辑。因此策略梯度可写作：<br>$$<br>g = E[\sum_{t=0}^{\infty}\psi_t \nabla_{\theta}log \pi_{\theta}(a_t|s_t)]<br>$$<br>其中这里的π就是actor，ψ就是critic，这是一个广义的框架。</p><p>critic有多种形式：</p><ol><li>一个轨迹中的Reward相加。</li><li>一个轨迹中后面某部分的Reward相加。</li><li>相加后的Reward减去一个baseline。</li><li>采用行为价值函数Q代替。</li><li>采用优势函数A，即Q-V。</li><li>采用TD-error，计算新的状态价值减去原本的状态价值。</li></ol><p>经典的AC方法使用的是4-6。</p><p>权重更新公式为：<br>$$<br>w = w + \beta \psi \nabla_W \hat v(S_t,w)<br>$$</p><hr><p><strong>以下是重点</strong>：</p><p>在两个神经网络中，我们一般用$\pi (a|s;\theta)$表示策略网络actor，θ代表其中的参数，$q(s,a;w)$代表价值网络critic，w代表其中的参数。注意这里actor网络只需要输入状态，而critic网络则需要输入状态和动作，两个网络往往可以共用前一部分。</p><p>actor网络的更新参数的目标是让critic网络的值越大越好。当确定状态s的情况下，如何选取动作action来使得critic的值最大就是actor网络需要优化的目标。而更新Critic的参数是为了让其的打分更精准，训练的依据就是环境给的reward。</p><p>下面讲解如何更新Critic参数，依靠的是常用的TD算法：</p><img src="/2021/09/02/qiang-hua-xue-xi-zhi-a2c-he-a3c/1.png" class><p>下面是更新Actor参数的方法：</p><img src="/2021/09/02/qiang-hua-xue-xi-zhi-a2c-he-a3c/3.png" class><p>下面做一个总结：</p><img src="/2021/09/02/qiang-hua-xue-xi-zhi-a2c-he-a3c/2.png" class><p>由于实际操作中我们不可能得出期望值，因此直接做蒙泰卡罗近似，每个episode拿一次的采样值来更新一点点 ，使得采样到的action得到的动作价值尽可能增大即可，操作比critic要简单得多。</p><h2 id="Advantage-Actor-Critic"><a href="#Advantage-Actor-Critic" class="headerlink" title="Advantage Actor Critic"></a>Advantage Actor Critic</h2><p>​     A2C的出现是为了解决AC的高方差问题。在所有行为的得分为正的情况下不代表所有的行为都是正确的，我们必须有选择地学习更好的行为。因此我们会在原有Reward基础上减去一个常数，这个数的计算方式就是Advantage。这是因为我们对于输入的同一个状况，由于输出要具有一定随机性的存在，那么其实这些所有可能所能获得的Reward的平均值就是VθVθ，这就是Critic的含义。我们用来更新参数的AtAt是用Reward减去这个平均值，也就是<strong>如果对于一个状况的行为的得分比我们critic预测的要高，则采纳，反之舍弃</strong>。</p><p>​    Advantage学习是使用两步以上的奖励来更新Q函数。这个步数需要自己设置合理，以下举例两步：<br>$$<br>Q(s_t,a_t) \rightarrow R(t+1) + \gamma R(t+2) + \gamma^2 max_a Q(s_{t+2},a)<br>$$</p><hr><p>以下是重点：</p><p>A2C于AC的不同之处在于给Q值增加了一个baseline，我们用Q值减去这个baseline来判断当前逻辑的好坏，这个baseline通常由$V_t$来担任。那么原来更新的Q值被替换为：<br>$$<br>Q(s_t,a_t) - V(s_t)<br>$$<br>而Q值我们通常用的是一个回合随机出来的特殊值。我们想要采用期望值，这个期望值的计算方式是$r_t + \gamma V(s_{t+1})$，这是因为执行一个动作的下一回合必定更新到$s_{t+1}$的状态，在加上本回合获得的Reward就是Q的期望值 。这样我们就可以得到最后的价值公式：<br>$$<br>r_t+ \gamma V(s_{t+1}) - V(s_t)<br>$$<br>其中大于0时我们倾向于采用，反之亦然。</p><p>这样的好处是我们现在只用计算V不用计算Q了。</p><h2 id="Asynchronous-Advantage-Actor-Critic"><a href="#Asynchronous-Advantage-Actor-Critic" class="headerlink" title="Asynchronous Advantage Actor Critic"></a>Asynchronous Advantage Actor Critic</h2><p>A3C全称为异步优势动作评价算法（Asynchronous advantage actor-critic）。</p><p>然而经验回放机制存在两个问题：</p><ol><li>agent 与环境的每次实时交互都需要耗费很多的内存和计算力；</li><li>经验回放机制要求 agent 采用离策略（off-policy）方法来进行学习，而off-policy方法只能基于旧策略生成的数据进行更新；</li></ol><p>前文讲到，神经网络训练时，需要的数据是独立同分布的，为了打破数据之间的相关性，DQN和DDPG的方法都采用了经验回放的技巧。然而经验回放需要大量的内存，打破数据的相关性，经验回放并非是唯一的方法。另外一种是<strong>异步的方法，所谓异步的方法是指数据并非同时产生</strong>，A3C的方法便是其中表现非常优异的异步强化学习算法。</p><p>A3C模型如下图所示，每个Worker直接从Global Network中拿参数，自己与环境互动输出行为。利用每个Worker的梯度，对Global Network的参数进行更新。每一个Worker都是一个A2C。A3C主要有两个操作，一个是pull，一个是push：<br> pull：把主网络的参数直接赋予Worker中的网络<br> push：使用各Worker中的梯度，对主网络的参数进行更新</p><img src="/2021/09/02/qiang-hua-xue-xi-zhi-a2c-he-a3c/4.png" class><img src="/2021/09/02/qiang-hua-xue-xi-zhi-a2c-he-a3c/5.png" class><p>这种异步更新的方法在多种算法中都适用。所有的异步agent执行完后再用累计的梯度信息更新网络参数。其中n-step的算法（后两个）需要每个异步agent复制一份子网络，每个anget执行n步后倒退算出每步的总回报和相关梯度，用累计梯度更新主网络参数。</p><hr><p>M Babaeizadeh等人提出了一种<a href="https://openreview.net/forum?id=r1VGvBcxl&amp;noteId=r1VGvBcxl">混合CPU/GPU版的A3C</a>，并提供开源代码<a href="https://github.com/NVlabs/GA3C%E3%80%82">https://github.com/NVlabs/GA3C。</a></p><p>具体地，GA3C主要分为：</p><p>Agent，和A3C功能一样，收集样本，但是不需要各自复制一份模型，只需要在每次选择Action前，将当前的State作为请求加入 Prediction Queue；执行动作n步后倒退算出每步的总回报，得到的n个(st,at,R,st+1)(st,at,R,st+1)加入 Trainning Queue；<br>Predictor，将 Prediction Queue 中的请求样本出队作为minibatch填入GPU的网络模型中，将模型预测的Action返回给各自的Agent，为减少延迟，可以使用多线程并行多个predictiors；<br>Trainer，将 Trainning Queue 的样本出队作为minibatch填入GPU的网络模型中，训练更新模型，同样，为减少延迟，可以使用多线程并行多个trainers；</p><p>参考文献：</p><p>1.<a href="https://blog.csdn.net/u013236946/article/details/73195035?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522163064699216780269875133%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&amp;request_id=163064699216780269875133&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-1-73195035.first_rank_v2_pc_rank_v29&amp;utm_term=%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0+A3C&amp;spm=1018.2226.3001.4187">深度强化学习——A3C</a></p><p>2.<a href="https://blog.csdn.net/bbbeoy/article/details/105603045">强化学习AC、A2C、A3C算法原理与实现</a></p>]]></content>
      
      
      <categories>
          
          <category> 强化学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 强化学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>挖矿教程</title>
      <link href="2021/09/01/wa-kuang-jiao-cheng/"/>
      <url>2021/09/01/wa-kuang-jiao-cheng/</url>
      
        <content type="html"><![CDATA[<p>​       首先，根据我的使用情况，一张2080ti的显卡一天的挖矿收益约为32人民币，需要付出的只有电费而已，这样一来，只需几个月，就可以把买显卡的靠挖矿赚取回来，如此一个高利润，低成本的买卖，自然吸引了不少人入坑，造成高端显卡的供不应求。</p><p>​       要想挖矿，我们需要两个工具，一个是自己的比特币钱包，一个是挖矿的平台，现在靠自己单干能挖到矿的极少，因此都是集体挖矿，收益平分。比特币钱包有很多种类，具体可以自己查询，我自己使用的是electrum，可以到官网下载<a href="https://www.electrum.org/#home">https://www.electrum.org/#home</a></p><p>​      下载安装过后，我们直接创建一个新的钱包，这里要记住自己创建钱包时的秘钥！！这通常由一串单词构成，丢失秘钥几乎等于丢失钱包上的比特币！！！</p><p>​       创建钱包后，我们需要创建一个收款地址，我们需要在过期选项中选never，否则这个收款地址过一段时间就不能用了。这样，当我们要收获比特币时，我们填上这个收款地址，就能接收比特币。</p><img src="/2021/09/01/wa-kuang-jiao-cheng/1.png" class=""><p>​       第二个需要的东西就是挖矿平台啦，这里我用的是nicehash 网址：<a href="https://www.nicehash.com/">https://www.nicehash.com/</a> （建议使用20系和30系的显卡）。先注册一个账号，然后点击挖矿-添加矿机-选择挖矿选项，一般我们用的英伟达显卡只需要选第一项即可，然后就可以去github下载一个开源的挖矿软件了。</p><img src="/2021/09/01/wa-kuang-jiao-cheng/2.png" class=""><p>​      联网安装好后，我们打开软件，从nicehash中复制挖矿地址到软件上即可挖矿啦！注意：我们需要保证自己的驱动在461.33以上，否则挖不了矿，需要到网上去查找一个对应驱动进行安装。</p><img src="/2021/09/01/wa-kuang-jiao-cheng/3.png" class=""><p>可以看到我们的预计收益和矿机的运行状态，然后我们可以在矿机最右边的选择中选择Extreme，就可以让矿机以最大的速率挖矿啦！</p><img src="/2021/09/01/wa-kuang-jiao-cheng/4.png" class=""><p>关于比特币体现，我们可以用刚刚比特币钱包的那个收款地址来把比特币接收到钱包中，然后选择一个交易平台进行体现，大功告成！</p>]]></content>
      
      
      <categories>
          
          <category> 其他 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>强化学习之Dueling DQN</title>
      <link href="2021/08/29/qiang-hua-xue-xi-zhi-dueling-dqn/"/>
      <url>2021/08/29/qiang-hua-xue-xi-zhi-dueling-dqn/</url>
      
        <content type="html"><![CDATA[<p> 注：本文续于《强化学习之DDQN》</p><p>Dueling DQN的思想是把神经网络中Q价值的输出分成两部分，第一部分是状态价值V，这部分价值由状态直接决定和Action无关。第二部分就是动作价值和状态价值的差值A，每一个Action都存在一个差值。这两部分构成了倒数第二层的神经网络，节点数为Action数+1。然后最后一层的Q值就可以直接由V和A相加构成。</p><p>$$<br>Q = V + A<br>$$<br>Dueling DQN和DDQN唯一不同的地方是网络结构，因此修改程序时只需要修改Network类即可。这种计算结构使得学习性能得到提高。优点在于与DQN相比，无论动作a如何，都可以逐步学习与V(s)相关的网络连接参数，因此学习的轮数比DQN更少，随着动作选择的增加，优势更加明显。</p><pre class=" language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Network</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>     <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>n_in<span class="token punctuation">,</span>n_mid<span class="token punctuation">,</span>n_out<span class="token punctuation">)</span><span class="token punctuation">:</span>         super<span class="token punctuation">(</span>Network<span class="token punctuation">,</span>self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>         self<span class="token punctuation">.</span>fc1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>n_in<span class="token punctuation">,</span>n_mid<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>fc2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>n_mid<span class="token punctuation">,</span>n_mid<span class="token punctuation">)</span>         self<span class="token punctuation">.</span>fc3_adv <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>n_mid<span class="token punctuation">,</span>n_out<span class="token punctuation">)</span>         self<span class="token punctuation">.</span>fc3_v <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>n_mid<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>     <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>         h1 <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fc1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>        h2 <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fc2<span class="token punctuation">(</span>h1<span class="token punctuation">)</span><span class="token punctuation">)</span>        adv <span class="token operator">=</span> self<span class="token punctuation">.</span>fc3_adv<span class="token punctuation">(</span>h2<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># expand函数作用是采用复制的方式扩展一个维度的长度，-1指不改变长度，这里把V复制成和A数量一样多</span>        val <span class="token operator">=</span> self<span class="token punctuation">.</span>fc3_v<span class="token punctuation">(</span>h2<span class="token punctuation">)</span><span class="token punctuation">.</span>expand<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span>adv<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># V + A ,然后都减去A的平均值</span>        output <span class="token operator">=</span> val <span class="token operator">+</span> adv <span class="token operator">-</span> adv<span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>keepdim <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">.</span>expand<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1.</span>adv<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> output</code></pre><p>在实际操作中，我们通常需要减去一个平均值：</p><img src="/2021/08/29/qiang-hua-xue-xi-zhi-dueling-dqn/1.png" class=""><p>采用这种方法，虽然使得值函数V和优势函数A不再完美的表示值函数和优势函数(在语义上的表示)，但是这种操作提高了稳定性。而且，并没有改变值函数V和优势函数A的本质表示。如果只是简单相加，由于动作类型的不同，具有不同的偏置量，可能无法得到很好的学习，通过在一个节点内的输出加入另一个节点的信息，可以让神经网络在误差传递的过程中得到更加充分的学习。</p>]]></content>
      
      
      <categories>
          
          <category> 强化学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 强化学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>强化学习之DDQN</title>
      <link href="2021/08/29/qiang-hua-xue-xi-zhi-ddqn/"/>
      <url>2021/08/29/qiang-hua-xue-xi-zhi-ddqn/</url>
      
        <content type="html"><![CDATA[<p> 知识基础DQN参考我的博文：<a href="https://tianjuewudi.gitee.io/2021/07/16/qiang-hua-xue-xi-shi-jian-jiao-xue/#toc-heading-19">https://tianjuewudi.gitee.io/2021/07/16/qiang-hua-xue-xi-shi-jian-jiao-xue/#toc-heading-19</a></p><h2 id="DQN复习"><a href="#DQN复习" class="headerlink" title="DQN复习"></a>DQN复习</h2><p>​       我们利用神经网络来代替表格法，我们可以输入S并输出多个Q，每个Q对应一个A。神经网络只需要储存有限的网络参数，我们的任务就是不断调整这些参数，使得输入输出符合我们的预期，而且状态可以泛化，相似的状态输出也差不多。<br>​        DQN有两大创新点，一个是经验回放，一个是固定Q目标。经验回放是指探索的数据特征形成一组组数据，并且可以随机打乱，使得神经网络可以重复多次地进行学习。这样可以打乱样本的关联性，而且能提高样本利用率。固定Q目标是指我们把Q值固定一段时间来训练参数，我们需要另外一个一样的网络（target Q网络），Q网络的作用是产生一个Q预测值，直接用来决策产生action。而target Q是产生一个Q目标值，我们通过这个目标值的$Q_{t+1}$计算Q网络$Q_{t}$，target Q往往固定一段时间来使Q网络得到充分训练。</p><h2 id="DQN的缺陷"><a href="#DQN的缺陷" class="headerlink" title="DQN的缺陷"></a>DQN的缺陷</h2><p>使用了 max 操作，Q-learning、DQN算法都会过高估计(overestimate)Q值。</p><h2 id="DDQN与DQN的异同"><a href="#DDQN与DQN的异同" class="headerlink" title="DDQN与DQN的异同"></a>DDQN与DQN的异同</h2><p>DDQN和DQN一样，也有一样的两个Q网络结构。下面是DQN的更新公式<br>$$<br>Q_m(S_{t},a_t) = Q_m(S_{t},a_t)+ \eta * (R_{t+1} + γ \max_a Q_t(S_ {t+1}    ,a) - Q_m(s_t,a_t))<br>$$<br>DDQN采用的是一种使更新公式更稳定的方法：<br>$$<br>a_m = arg \max_a Q_m(s_{t+1},a)<br>$$</p><p>$$<br>Q_m(S_{t},a_t) = Q_m(S_{t},a_t)+ \eta * (R_{t+1} + γ  Q_t(S_ {t+1}    ,a_m) - Q_m(s_t,a_t))<br>$$</p><p>也就是说DDQN与DQN的不同之处在于用来更新Q网络的Target Q中$Q(S_{t+1},a)$的选择方式，DQN直接用Target Q网络中t+1时刻可选Q的最大值用来更新，而DDQN用的是根据Q网络t+1时刻的最大Q来选择对应的action，然后用这个action来对应决定Target Q网络中的Q值，这样更新的Q值就会小于等于DQN更新的Q值，改善overestimate的问题。</p>]]></content>
      
      
      <categories>
          
          <category> 强化学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 强化学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>强化学习纲要（周博磊课程）</title>
      <link href="2021/07/21/qiang-hua-xue-xi-gang-yao-zhou-bo-lei-ke-cheng/"/>
      <url>2021/07/21/qiang-hua-xue-xi-gang-yao-zhou-bo-lei-ke-cheng/</url>
      
        <content type="html"><![CDATA[<p> 提示：阅读本文需要一定的深度学习基础。 </p><p>课程链接：<a href="https://www.bilibili.com/video/BV1LE411G7Xj">https://www.bilibili.com/video/BV1LE411G7Xj</a></p><p>我以前的强化学习笔记，相同的内容在下面就不再赘述：</p><p>1、<a href="https://tianjuewudi.gitee.io/2021/07/08/qiang-hua-xue-xi-gai-shu-reinforcement-learning/">强化学习概述</a></p><p>2、<a href="https://tianjuewudi.gitee.io/2021/07/16/qiang-hua-xue-xi-shi-jian-jiao-xue/">强化学习实践教学</a></p><h1 id="Foundation"><a href="#Foundation" class="headerlink" title="Foundation"></a>Foundation</h1><h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><p>这部分内容可以参考我《强化学习概述》的序章。</p><p>强化学习的特征可以概括为以下几点：</p><ol><li>需要通过在环境中探索来获取对环境的理解。</li><li>Agent在环境中获得的奖励是延迟的，在获取奖励的过程中，由于没有反馈，你不知道自己每一步是对是错，优化这个过程是我们需要做的。</li><li>时间关联性，获取的数据都是有时间关联的，会使训练非常不稳定。</li><li>Agent的行为会影响随后的到的数据。</li><li>Agent的任务是让奖励最大化。</li></ol><p>强化学习包含以下几个组成部分：</p><ol><li>行为策略：也就是决定自己行为的函数，通常可以由神经网络来担任。</li><li>价值函数：对自己现在所处的状态进行价值的评估。可以对后面的收益带来多大的影响。</li><li>模型：决定了这个世界的运行方式。通过agent当前的状态的行为决定下一个状态，以及可以得到多大的奖励。</li></ol><p>当有了行为策略，价值函数和世界模型之后，这三个成分就形成了一个马尔科夫决策过程（MDPs）。这个过程可视化了状态转移和我们采取的行为。</p><p>基于agent学习方式不同，我们可以分成两类：</p><ol><li>基于价值（Value-based）：依靠价值函数进行学习和决策。</li><li>基于策略（Policy-based）：无需构建价值函数，输入状态就可以直接得到下一步动作的概率分布。</li><li>Actor-Critic：这是上面两者的结合。既有策略函数（Actor），也有价值函数（Critic）。Actor的任务是对外输出动作并且根据Critic的打分来调整自己的参数来获得更好的输出，使得Critic打分更高。Critic的任务是对Actor的输出做评估（预测），并且通过reward不断调整自己的预测能可能地接近reward。这也就是一个Q网络。</li></ol><p>基于agent有没有学习环境的模型进行分类：</p><ol><li>基于模型（Model-based）：知道环境的模型，通过学习状态转移采取措施。</li><li>无模型（Model-free）：没有环境的模型，通过学习Value Function和Policy Function进行决策。</li></ol><img src="/2021/07/21/qiang-hua-xue-xi-gang-yao-zhou-bo-lei-ke-cheng/1.png" class><p>在model-free领域又有三种分类：</p><img src="/2021/07/21/qiang-hua-xue-xi-gang-yao-zhou-bo-lei-ke-cheng/15.png" class><p><strong>强化学习的Exploration和Exploitation</strong>：</p><p>这是两个很核心的问题，其中Exploration探讨怎么探索环境，尝试不同的行为，期望得到一个最佳的策略。Exploitation探讨不去尝试新的东西，用已知的内容做最好的决策。</p><h2 id="Markov-Decision-Process（MDP）"><a href="#Markov-Decision-Process（MDP）" class="headerlink" title="Markov Decision Process（MDP）"></a>Markov Decision Process（MDP）</h2><img src="/2021/07/21/qiang-hua-xue-xi-gang-yao-zhou-bo-lei-ke-cheng/2.png" class><p>马尔科夫决策过程是强化学习的基本框架。而Agent和Environment的交互过程，是可以用马尔科夫决策过程表示。其中，环境是全部可以观测的，部分观测问题也可以转换为MDP问题。</p><p>一个状态转移符合马尔科夫，意思是<strong>下一个状态取决于当前状态</strong>，和之前的状态没有关系。</p><p>描述状态转移概率，我们可以用状态转移矩阵表示：</p><img src="/2021/07/21/qiang-hua-xue-xi-gang-yao-zhou-bo-lei-ke-cheng/3.png" class><h3 id="马尔科夫链-Markov-Chain-Markov-Process（MP）"><a href="#马尔科夫链-Markov-Chain-Markov-Process（MP）" class="headerlink" title="马尔科夫链 Markov Chain / Markov Process（MP）"></a>马尔科夫链 Markov Chain / Markov Process（MP）</h3><p>马尔科夫链可以表示所有的状态转移概率：</p><img src="/2021/07/21/qiang-hua-xue-xi-gang-yao-zhou-bo-lei-ke-cheng/4.png" class><p>通过对马尔科夫链进行采样，我们可以得到很多从一个起始点开始的一串的轨迹。</p><h3 id="马尔科夫奖励过程-Markov-Reward-Process（MRP）"><a href="#马尔科夫奖励过程-Markov-Reward-Process（MRP）" class="headerlink" title="马尔科夫奖励过程  Markov Reward Process（MRP）"></a>马尔科夫奖励过程  Markov Reward Process（MRP）</h3><p>马尔科夫奖励过程是一个马尔科夫链加上奖励函数。在马尔科夫链中加入奖励函数，奖励函数是一个期望，表示到达某一个状态时可以获得多大的奖励。</p><img src="/2021/07/21/qiang-hua-xue-xi-gang-yao-zhou-bo-lei-ke-cheng/5.png" class><h3 id="Return-and-Value-Funciton"><a href="#Return-and-Value-Funciton" class="headerlink" title="Return and Value Funciton"></a>Return and Value Funciton</h3><h4 id="Horizon"><a href="#Horizon" class="headerlink" title="Horizon"></a>Horizon</h4><p>轨迹的长度是由有限个步数决定的。</p><h4 id="Return"><a href="#Return" class="headerlink" title="Return"></a>Return</h4><p>我们把奖励reward按照一定折扣相加得到。<br>$$<br>G_t = R_{t+1} + \gamma R_{t+2} + \gamma^2 R_{t+2} + \gamma^3 R_{t+3} + … +  \gamma^{T-t-1} R_{T}<br>$$</p><h4 id="State-Value-Function-for-a-MRP"><a href="#State-Value-Function-for-a-MRP" class="headerlink" title="State Value Function for a MRP"></a>State Value Function for a MRP</h4><p>$$<br>V_t(s) = E[G_t|s_t = s] = E[R_{t+1} + \gamma R_{t+2} + \gamma^2 R_{t+2} + \gamma^3 R_{t+3} + \gamma^{T-t-1} R_{T} | s_t = s]<br>$$</p><p>也就是说，一个状态的价值由后面的状态可以得到的reward按一定系数叠加得到，越往后的reward，对当前状态的价值影响越小。</p><p>MRP价值函数满足以下<strong>贝尔曼等式（Bellman equation）</strong>：<br>$$<br>V(s) = R(s) + \gamma \sum_{s’ \in S} P(s’|s) V(s’)<br>$$<br>也就是说现在状态的价值V（s）和现在的奖励以及下一个所有可能到达的状态的价值V（s’）相关。用矩阵表示：</p><img src="/2021/07/21/qiang-hua-xue-xi-gang-yao-zhou-bo-lei-ke-cheng/6.png" class><p>在状态转移矩阵较小的情况下，我们可以通过直接求逆矩阵就可以得出每一个状态的价值。</p><h3 id="MRP价值的解法"><a href="#MRP价值的解法" class="headerlink" title="MRP价值的解法"></a>MRP价值的解法</h3><ol><li>第一种解法是动态规划（Dynamic Programming）</li><li>第二种解法是蒙泰卡罗评估（Monte-Carlo evaluation）</li><li>第三种解法是时序差分（Temporal-Difference Learning）</li></ol><h4 id="Monte-Carlo-Algorithm"><a href="#Monte-Carlo-Algorithm" class="headerlink" title="Monte Carlo Algorithm"></a>Monte Carlo Algorithm</h4><img src="/2021/07/21/qiang-hua-xue-xi-gang-yao-zhou-bo-lei-ke-cheng/7.png" class><p>蒙泰卡罗算法的做法是直接在某状态开始直接收集多条轨迹的数据，得到多个价值，然后把所有的价值平均起来得到该状态的价值$V_t(s)$，可以说随机的数量足够多，那么$V_t(s)$就会接近真实的价值。</p><h4 id="Iterative-Algorithm"><a href="#Iterative-Algorithm" class="headerlink" title="Iterative Algorithm"></a>Iterative Algorithm</h4><img src="/2021/07/21/qiang-hua-xue-xi-gang-yao-zhou-bo-lei-ke-cheng/8.png" class><p>动态规划的办法是一直迭代Bellman Equation。当迭代到价值稳定时（变化小于某一个值），我们就可以直接输出V（s）。但是我们需要知道状态转移概率。这是一个model-based的方法。</p><h4 id="Temporal-Difference-Learning"><a href="#Temporal-Difference-Learning" class="headerlink" title="Temporal-Difference Learning"></a>Temporal-Difference Learning</h4><p>这是前两者的结合。在后面会提到。</p><h3 id="马尔科夫决策过程（Markov-Decision-Process）-MDP"><a href="#马尔科夫决策过程（Markov-Decision-Process）-MDP" class="headerlink" title="马尔科夫决策过程（Markov Decision Process）(MDP)"></a>马尔科夫决策过程（Markov Decision Process）(MDP)</h3><p>马尔科夫决策过程比马尔科夫奖励过程多了一个行为（action）。</p><ol><li><p><strong>未来的状态不仅取决于现在的状态，也取决于你所采取的行动。</strong></p></li><li><p><strong>奖励函数的设置不仅和当前状态有关，和行为也有关。</strong></p></li></ol><h4 id="Policy-in-MDP"><a href="#Policy-in-MDP" class="headerlink" title="Policy in MDP"></a>Policy in MDP</h4><img src="/2021/07/21/qiang-hua-xue-xi-gang-yao-zhou-bo-lei-ke-cheng/9.png" class><p>Policy函数决定了在某一个状态中采取的行为，可以输出一个行为的概率（离散控制），也可以是一个连续值（确定动作的连续控制）。而且假设Policy是静态的，也就是说具有时间独立性，不同时间的策略函数不变。</p><p>当我们知道MDP和policy π的时候，我们可以把MDP转换为MRP。<br>$$<br>P^π(s’|s) = \sum_{a\in A} π(a|s) P(s’|s,a)<br>$$<br>也就是说，一个状态转移到另一个状态的概率的计算方式是：<strong>Policy可控的决策过程的采取该动作概率</strong> 乘上 <strong>不可控的该动作下环境选择下一个状态的概率</strong>，然后把每个行动的可能性都相加。</p><p>奖励函数的计算方式也是分行动的，因为每个行动的reward都不相同：<br>$$<br>R^π(s) = \sum_{a \in A} π(a|s) R(s,a)<br>$$</p><h4 id="Value-Function-for-MDP"><a href="#Value-Function-for-MDP" class="headerlink" title="Value Function for MDP"></a>Value Function for MDP</h4><p>MDP的价值函数分为<strong>状态价值</strong>（state-value）和<strong>行为价值</strong>（action-value）。状态价值由当前的状态决定，而行为价值由当前状态和行动共同决定。有多少行为就有多少行为价值。</p><p>状态价值$v^{π}(s)$和行为价值$q^{π}(s)$的关系是：<br>$$<br>v^{π}(s) = \sum_{a \in A} π(a|s) q^{π}(s,a)<br>$$<br><strong>也就是说状态价值由行为价值按照一定的比例构成。</strong></p><p>因此贝尔曼等式有两条，也称Bellman Expection Equation：<br>$$<br>v^π (s) = E_{π} [R_{t+1} + \gamma v^{π} (s_{t+1}) | s_t = s]<br>$$</p><p>$$<br>q^π (s,a) = E_{π} [R_{t+1} + \gamma q^{π} (s_{t+1},A_{t+1}) | s_t = s ,A_t = a]<br>$$</p><p><strong>这两个公式将是写代码更新参数的重点！！！尤其是行为价值公式！</strong></p><p>容易得出行为价值公式有：<br>$$<br>q^π (s,a) = R_{s}^a + \gamma \sum_{s’ \in S} P(s’|s ,a)v^π(s’)<br>$$<br>联立<br>$$<br>v^{π}(s) = \sum_{a \in A} π(a|s) q^{π}(s,a)<br>$$<br>可以得出：<br>$$<br>v^{π}(s) = \sum_{a \in A} π(a|s) ( R_{s}^a + \gamma \sum_{s’ \in S} P(s’|s ,a)v^π(s’))<br>$$</p><p>$$<br>q^π (s,a) = R_{s}^a + \gamma \sum_{s’ \in S} P(s’|s ,a) \sum_{a \in A} π(a’|s’) q^{π}(s’,a’)<br>$$</p><p>这就是上一个节点与下一个相同属性节点价值之间的关系，使用于知道环境模型的情况下。也就是model-based。</p><h4 id="Policy-Evaluation"><a href="#Policy-Evaluation" class="headerlink" title="Policy Evaluation"></a>Policy Evaluation</h4><p>简单的说是计算$v^π(s)$，也叫做价值预测。用这个预测来指导我们的动作选择。</p><h4 id="Prediction-and-Control"><a href="#Prediction-and-Control" class="headerlink" title="Prediction and Control"></a>Prediction and Control</h4><p>预测和控制是MDP的核心问题。</p><p>预测：给定MDP&lt;S,A,P,R,γ&gt;和policy π，或者给定MRP$&lt;S,P^π,R^π,γ&gt;$，我们可以对状态价值V进行计算。</p><p>控制：给定MDP，寻找最佳的价值函数V和最佳策略π。最佳指的是找π使得V最大。</p><h4 id="Dynamic-Programming"><a href="#Dynamic-Programming" class="headerlink" title="Dynamic Programming"></a>Dynamic Programming</h4><p>这两个问题都可以通过动态规划（Dynamic Programming）解决。只要我们可以把问题分解成一个个最优子结构，把子结构解出来，就可以组成一个最优解。我们可以把问题分解成递归的结构，因为状态相连，子状态得到一个值，未来状态也能推算出来，价值函数也就能储存和重用最优解。</p><img src="/2021/07/21/qiang-hua-xue-xi-gang-yao-zhou-bo-lei-ke-cheng/10.png" class><p>或者用MRP公式也能迭代：<br>$$<br>v_{t+1} (s) = R^{π}(s) + \gamma  P^π (s’|s ,a)v_t(s’)<br>$$</p><h4 id="Find-Optimal-Policy（重中之重，反复查看）"><a href="#Find-Optimal-Policy（重中之重，反复查看）" class="headerlink" title="Find Optimal Policy（重中之重，反复查看）"></a>Find Optimal Policy（重中之重，反复查看）</h4><p>当我们采取的策略π可以使得行为价值q最大化，那么这个策略就是最佳策略。寻找最佳策略的过程也叫MDP Control。</p><p>这里有两种解最佳策略的方法，一种是Policy iteration，一种是value iteration。这两个方法都是model-based的。</p><p><strong>policy iteration:</strong></p><img src="/2021/07/21/qiang-hua-xue-xi-gang-yao-zhou-bo-lei-ke-cheng/11.png" class><ol><li>随机选择一个策略作为初始值。</li><li>Policy Evaluation：通过现有的策略π计算状态价值v。</li><li>Policy Improvement：计算当前最好的Action，更新策略$π(s) = argmax_a \sum_{s’,r}(r+\gamma V(s’))$。</li><li>不断循环第二和第三步。</li></ol><img src="/2021/07/21/qiang-hua-xue-xi-gang-yao-zhou-bo-lei-ke-cheng/13.png" class><p>策略评估会评估从上次策略改进中获得的贪心策略的价值函数 V。另一方面，策略改进通过使每个状态的 V 值最大化的动作来更新策略。更新方程以贝尔曼方程为基础。它不断迭代直到收敛。</p><p>优化过后，<strong>贝尔曼最优等式（Bellman Optimality Equation）</strong>满足：<br>$$<br>v^{π}(s) = \max_{a \in A} q^π (s,a)<br>$$<br>之前的两条公式变为：<br>$$<br>v^*(s) = \max_aR(s,a) + \gamma \sum_{s’ \in S} P(s’|s ,a)v^*(s’)<br>$$</p><p>$$<br>q^* (s,a) = R(s,a) + \gamma \sum_{s’ \in S} P(s’|s ,a) \max_{a’}  q^*(s’,a’)<br>$$</p><p>Q-learning就是基于贝尔曼最优等式实现的。</p><pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">policy_iteration</span><span class="token punctuation">(</span>env<span class="token punctuation">,</span> gamma <span class="token operator">=</span> <span class="token number">1.0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">""" Policy-Iteration algorithm """</span>    policy <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>choice<span class="token punctuation">(</span>env<span class="token punctuation">.</span>env<span class="token punctuation">.</span>nA<span class="token punctuation">,</span> size<span class="token operator">=</span><span class="token punctuation">(</span>env<span class="token punctuation">.</span>env<span class="token punctuation">.</span>nS<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># initialize a random policy</span>    max_iterations <span class="token operator">=</span> <span class="token number">200000</span>    gamma <span class="token operator">=</span> <span class="token number">1.0</span>    <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>max_iterations<span class="token punctuation">)</span><span class="token punctuation">:</span>        old_policy_v <span class="token operator">=</span> compute_policy_v<span class="token punctuation">(</span>env<span class="token punctuation">,</span> policy<span class="token punctuation">,</span> gamma<span class="token punctuation">)</span>        new_policy <span class="token operator">=</span> extract_policy<span class="token punctuation">(</span>old_policy_v<span class="token punctuation">,</span> gamma<span class="token punctuation">)</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span>np<span class="token punctuation">.</span>all<span class="token punctuation">(</span>policy <span class="token operator">==</span> new_policy<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">'Policy-Iteration converged at step %d.'</span> <span class="token operator">%</span><span class="token punctuation">(</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>            <span class="token keyword">break</span>        policy <span class="token operator">=</span> new_policy    <span class="token keyword">return</span> policy</code></pre><p><strong>Value Iteration</strong>:</p><ul><li><p>在Policy Iteration中</p></li><li><ul><li>第一步 Policy Evaluation：一直迭代至收敛，获得准确的V(s)</li><li>第二步 Policy Improvement：根据准确的V(s)，求解最好的Action</li></ul></li><li><p>对比之下，在Value Iteration中</p></li><li><ul><li>第一步 “Policy Eval”：迭代只做一步，获得不太准确的V(s)</li><li>第二步 “Policy Improvement”：根据不太准确的V(s)，求解最好的Action</li></ul></li></ul><img src="/2021/07/21/qiang-hua-xue-xi-gang-yao-zhou-bo-lei-ke-cheng/14.png" class><p>Value Iteration的迭代出optimal value function后只做一次policy update，即：循环（对于当前状态每个可能的action，都做一次value evaluation，然后取最大的value，作为当前状态的价值），直到收敛。最后，按照最优价值的转移方向更新一次策略。</p><p>这里把贝尔曼最优等式拿进来，寻找最佳的Value-Funciton，没有Policy Function在里面。<br>$$<br>v^*(s) \leftarrow \max_{a \in A}(R(s,a) + \gamma \sum_{s’ \in S} P(s’|s ,a)v^*(s’))<br>$$</p><img src="/2021/07/21/qiang-hua-xue-xi-gang-yao-zhou-bo-lei-ke-cheng/12.png" class><pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">value_iteration</span><span class="token punctuation">(</span>env<span class="token punctuation">,</span> gamma <span class="token operator">=</span> <span class="token number">1.0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">""" Value-iteration algorithm """</span>    v <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>env<span class="token punctuation">.</span>env<span class="token punctuation">.</span>nS<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># initialize value-function</span>    max_iterations <span class="token operator">=</span> <span class="token number">100000</span>    eps <span class="token operator">=</span> <span class="token number">1e</span><span class="token operator">-</span><span class="token number">20</span>    <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>max_iterations<span class="token punctuation">)</span><span class="token punctuation">:</span>        prev_v <span class="token operator">=</span> np<span class="token punctuation">.</span>copy<span class="token punctuation">(</span>v<span class="token punctuation">)</span>        <span class="token keyword">for</span> s <span class="token keyword">in</span> range<span class="token punctuation">(</span>env<span class="token punctuation">.</span>env<span class="token punctuation">.</span>nS<span class="token punctuation">)</span><span class="token punctuation">:</span>            q_sa <span class="token operator">=</span> <span class="token punctuation">[</span>sum<span class="token punctuation">(</span><span class="token punctuation">[</span>p<span class="token operator">*</span><span class="token punctuation">(</span>r <span class="token operator">+</span> gamma <span class="token operator">*</span> prev_v<span class="token punctuation">[</span>s_<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token keyword">for</span> p<span class="token punctuation">,</span> s_<span class="token punctuation">,</span> r<span class="token punctuation">,</span> _ <span class="token keyword">in</span> env<span class="token punctuation">.</span>env<span class="token punctuation">.</span>P<span class="token punctuation">[</span>s<span class="token punctuation">]</span><span class="token punctuation">[</span>a<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token keyword">for</span> a <span class="token keyword">in</span> range<span class="token punctuation">(</span>env<span class="token punctuation">.</span>env<span class="token punctuation">.</span>nA<span class="token punctuation">)</span><span class="token punctuation">]</span>             v<span class="token punctuation">[</span>s<span class="token punctuation">]</span> <span class="token operator">=</span> max<span class="token punctuation">(</span>q_sa<span class="token punctuation">)</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span>np<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>np<span class="token punctuation">.</span>fabs<span class="token punctuation">(</span>prev_v <span class="token operator">-</span> v<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">&lt;=</span> eps<span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">'Value-iteration converged at iteration# %d.'</span> <span class="token operator">%</span><span class="token punctuation">(</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>            <span class="token keyword">break</span>    <span class="token keyword">return</span> v</code></pre><h2 id="Model-free-Prediction-and-Control"><a href="#Model-free-Prediction-and-Control" class="headerlink" title="Model-free Prediction and Control"></a>Model-free Prediction and Control</h2><h3 id="Model-free下的价值估计"><a href="#Model-free下的价值估计" class="headerlink" title="Model-free下的价值估计"></a>Model-free下的价值估计</h3><p>Model-free相对于model-based的不同在于是否知道MDP。而现实中大部分MDP都没有现成的模型可以用，所以我们只能采用Model-free的方法。</p><p>MDP已知：奖励函数R和转移矩阵P都可以为agent所知。所有agent才能通过Policy Iteration和Policy Iteration来寻找最佳策略。</p><p>在Model-free RL中，我们并没有直接获取转移状态和奖励函数，我们让agent跟环境进行交互，采集很多轨迹数据，agent需要从这些轨迹中获取信息，改进策略，以获得更多奖励。</p><p>当我们给定策略的时候，在没有给MDP转移模型的情况如何估计一个状态的价值？有两种常见的方法。一种是蒙泰卡罗（Monte Carlo policy evalution），一种是时序差分学习（Temporal Difference）</p><h4 id="Monte-Carlo-Policy-Evaluation"><a href="#Monte-Carlo-Policy-Evaluation" class="headerlink" title="Monte-Carlo Policy Evaluation"></a>Monte-Carlo Policy Evaluation</h4><p>蒙泰卡罗算法的做法是直接在某状态开始直接收集多条轨迹的数据，得到多个价值，然后把所有的价值平均起来得到该状态的价值$V_t(s)$，可以说随机的数量足够多，那么$V_t(s)$就会接近真实的价值。但这个算法的限制是只能用在有终止的马尔科夫决策过程。相对于动态规划（DP）来说，这是一个model-free的算法，而且只更新轨迹上的数据，速度较快。特点是需要跑完一个episode才能更新一次。<br>$$<br>v(S_t) \leftarrow v(S_t) + \alpha(G_{i,t} - v(S_t))<br>$$</p><h4 id="Temporal-Difference（TD）Learning"><a href="#Temporal-Difference（TD）Learning" class="headerlink" title="Temporal-Difference（TD）Learning"></a>Temporal-Difference（TD）Learning</h4><p>这是一个介于MC和DP之间的方法。这既可以用于Model-free，也能在一个episode不完整的情况下实现更新，一个step就能更新一次，每次只更新一点。<br>$$<br>v(S_t) \leftarrow v(S_t) + \alpha(R_{t+1} + \gamma v(S_{t+1}) - v(S_t))<br>$$<br>这个算法可以拓展到2-step TD，3-step TD等等，每两个或三个step或更多step更新一次。当这个步数为无穷时，TD算法就可以转变为MC算法，这就是它们的联系。</p><h4 id="各种算法直接的区别"><a href="#各种算法直接的区别" class="headerlink" title="各种算法直接的区别"></a>各种算法直接的区别</h4><p>对于动态规划，需要考虑到所有支路的情况，取一个期望。</p><img src="/2021/07/21/qiang-hua-xue-xi-gang-yao-zhou-bo-lei-ke-cheng/16.png" class><p>对于MC，我们每次只取一条路径来进行更新，期望通过多条路径的更新达到和期望一样的效果。</p><img src="/2021/07/21/qiang-hua-xue-xi-gang-yao-zhou-bo-lei-ke-cheng/17.png" class><p>对于TD，每次还是走一条路径，一个step就更新一次。</p><img src="/2021/07/21/qiang-hua-xue-xi-gang-yao-zhou-bo-lei-ke-cheng/18.png" class><h3 id="model-free下的策略更新"><a href="#model-free下的策略更新" class="headerlink" title="model-free下的策略更新"></a>model-free下的策略更新</h3><p>通常我们希望每个状态都能得到充分的更新，因此我们需要尽可能采样到比较多的状态。通过MC采样的方法我们需要采样尽可能多的轨迹，然后<strong>更新一个Q表格</strong>。同样我们用TD可以保证每个step进行更新，不用等episode结束。</p><p>我们需要保证算法有足够多的探索，因此我们在刚开始迭代的时候让算法有较大的概率随机采取action，而不是按照greedy也就是动作价值最大的策略，在后面再把这个概率降下来。</p><h4 id="Sarsa"><a href="#Sarsa" class="headerlink" title="Sarsa"></a>Sarsa</h4><p>更新公式<br>$$<br>Q(S_t,A_t) \leftarrow Q(S_t,A_t) + \alpha [R_{t+1} + \gamma Q(S_{t+1},A_{t+1}) - Q(S_{t},A_t)]<br>$$<br>其中α是学习率，我们每一个step需要更新Q表格中的一个值，更新完后使用greedy的策略进行探索，也有一定的概率随机探索，这是基于离散或有限状态的方法，是表格型的方法，没有用到神经网络。</p><pre class=" language-python"><code class="language-python">    <span class="token comment" spellcheck="true"># 学习方法，也就是更新Q-table的方法，采用Sarsa算法来更新Q表格</span>    <span class="token keyword">def</span> <span class="token function">learn</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> obs<span class="token punctuation">,</span> action<span class="token punctuation">,</span> reward<span class="token punctuation">,</span> next_obs<span class="token punctuation">,</span> next_action<span class="token punctuation">,</span> done<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">""" on-policy            obs: 交互前的obs, s_t            action: 本次交互选择的action, a_t            reward: 本次动作获得的奖励r            next_obs: 本次交互后的obs, s_t+1            next_action: 根据当前Q表格, 针对next_obs会选择的动作, a_t+1            done: episode是否结束        """</span>        predict_Q <span class="token operator">=</span> self<span class="token punctuation">.</span>Q<span class="token punctuation">[</span>obs<span class="token punctuation">,</span> action<span class="token punctuation">]</span>        <span class="token keyword">if</span> done<span class="token punctuation">:</span>            target_Q <span class="token operator">=</span> reward  <span class="token comment" spellcheck="true"># 没有下一个状态了</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            target_Q <span class="token operator">=</span> reward <span class="token operator">+</span> self<span class="token punctuation">.</span>gamma <span class="token operator">*</span> self<span class="token punctuation">.</span>Q<span class="token punctuation">[</span>next_obs<span class="token punctuation">,</span>                                                    next_action<span class="token punctuation">]</span>  <span class="token comment" spellcheck="true"># Sarsa</span>        self<span class="token punctuation">.</span>Q<span class="token punctuation">[</span>obs<span class="token punctuation">,</span> action<span class="token punctuation">]</span> <span class="token operator">+=</span> self<span class="token punctuation">.</span>lr <span class="token operator">*</span> <span class="token punctuation">(</span>target_Q <span class="token operator">-</span> predict_Q<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 修正q</span></code></pre><h4 id="on-policy和off-policy"><a href="#on-policy和off-policy" class="headerlink" title="on-policy和off-policy"></a>on-policy和off-policy</h4><p>上面的算法Sarsa是一种on-policy的算法，也就是说探索和决策都采用同一种策略，而off-policy的算法是探索和决策采用不同的策略，这样我们在探索的时候就能使用更为激进的手段收集更多的数据，然后交给策略进行学习，这样也能比较有效利用到之前采集的数据。下面就讲一下off-policy中的Q-learning。</p><h4 id="Q-learning"><a href="#Q-learning" class="headerlink" title="Q-learning"></a>Q-learning</h4><p>更新公式：<br>$$<br>Q(S_t,A_t) \leftarrow Q(S_t,A_t) + \alpha [R_{t+1} + \gamma \max_a Q(S_{t+1},a) - Q(S_{t},A_t)]<br>$$<br>可以看到，和Sarsa不同的地方在于我们没有用到第二个action，也就是说，我们无需知道下一个状态之后agent需要采取的动作。我们只需要从下一个状态采取的所有动作中选取动作价值最大的action的值来进行更新。因此更新用的第二个action和探索用的第二个action无关，这就是off-policy。Q-Learning的另一个特点是一个动作价值不会被隔壁的动作价值所影响，只取决于隔壁最大的动作价值。除了价值更新方法的不同，探索的策略依旧和Sarsa相同，这样Q-learning采取的策略就会比Sarsa激进得多。往往Q-learning会学习到最佳的策略。</p><pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">learn</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> obs<span class="token punctuation">,</span> action<span class="token punctuation">,</span> reward<span class="token punctuation">,</span> next_obs<span class="token punctuation">,</span> done<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">""" off-policy            obs: 交互前的obs, s_t            action: 本次交互选择的action, a_t            reward: 本次动作获得的奖励r            next_obs: 本次交互后的obs, s_t+1            done: episode是否结束        """</span>        predict_Q <span class="token operator">=</span> self<span class="token punctuation">.</span>Q<span class="token punctuation">[</span>obs<span class="token punctuation">,</span> action<span class="token punctuation">]</span>        <span class="token keyword">if</span> done<span class="token punctuation">:</span>            target_Q <span class="token operator">=</span> reward  <span class="token comment" spellcheck="true"># 没有下一个状态了</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            target_Q <span class="token operator">=</span> reward <span class="token operator">+</span> self<span class="token punctuation">.</span>gamma <span class="token operator">*</span> np<span class="token punctuation">.</span>max<span class="token punctuation">(</span>                self<span class="token punctuation">.</span>Q<span class="token punctuation">[</span>next_obs<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># Q-learning</span>        self<span class="token punctuation">.</span>Q<span class="token punctuation">[</span>obs<span class="token punctuation">,</span> action<span class="token punctuation">]</span> <span class="token operator">+=</span> self<span class="token punctuation">.</span>lr <span class="token operator">*</span> <span class="token punctuation">(</span>target_Q <span class="token operator">-</span> predict_Q<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 修正q</span></code></pre><h2 id="Value-Function-Approximation"><a href="#Value-Function-Approximation" class="headerlink" title="Value Function Approximation"></a>Value Function Approximation</h2><p>这部分内容我以前有过记录：<a href="https://tianjuewudi.gitee.io/2021/07/16/qiang-hua-xue-xi-shi-jian-jiao-xue/#toc-heading-19">强化学习实战</a>，请查看<strong>利用神经网络方法求解RL</strong>的章节。其中的DQN算法是一个经典算法。</p><h3 id="Deep-Q-Networks"><a href="#Deep-Q-Networks" class="headerlink" title="Deep Q Networks"></a>Deep Q Networks</h3><p>Code of DQN in PyTorch：<a href="https://github.com/cuhkrlcourse/DeepRL-Tutorials/blob/master/01.DQN.ipynb">https://github.com/cuhkrlcourse/DeepRL-Tutorials/blob/master/01.DQN.ipynb</a></p><p>Code of Flappy Bird：<a href="https://github.com/xmfbit/DQN-FlappyBird">https://github.com/xmfbit/DQN-FlappyBird</a></p><h2 id="Policy-Optimization-State-of-the-Art"><a href="#Policy-Optimization-State-of-the-Art" class="headerlink" title="Policy Optimization:State of the Art"></a>Policy Optimization:State of the Art</h2><p>之前讲解的算法都是基于value-based的算法，利用各种方法来调整动作价值的更新，依靠这个价值来进行决策。下面来讲解policy-based的算法，这种算法无需构建价值函数，输入状态就可以直接由网络输出得到下一步动作的概率分布。此部分内容可以参考<a href="https://tianjuewudi.gitee.io/2021/07/16/qiang-hua-xue-xi-shi-jian-jiao-xue/#toc-heading-19">强化学习实战</a>的<strong>基于策略梯度求解RL</strong>。</p><p>如果客观函数是不可导的，我们没法计算导数，这时候我们可以使用Derivative-free的方法，这里简要介绍两种。</p><h3 id="Cross-Entropy-Method（CEM）"><a href="#Cross-Entropy-Method（CEM）" class="headerlink" title="Cross Entropy Method（CEM）"></a>Cross Entropy Method（CEM）</h3><p>这种算法跟遗传算法类似，不断取前10%最优的参数对分布进行优化。</p><img src="/2021/07/21/qiang-hua-xue-xi-gang-yao-zhou-bo-lei-ke-cheng/19.png" class><h3 id="Finite-Difference"><a href="#Finite-Difference" class="headerlink" title="Finite Difference"></a>Finite Difference</h3><p>我们可以加一个很小的扰动来观察J（θ）的变化来近似获取梯度。</p><img src="/2021/07/21/qiang-hua-xue-xi-gang-yao-zhou-bo-lei-ke-cheng/20.png" class><h3 id="Actor-Critic"><a href="#Actor-Critic" class="headerlink" title="Actor-Critic"></a>Actor-Critic</h3><p>此部分内容可以参考<a href="https://tianjuewudi.gitee.io/2021/07/16/qiang-hua-xue-xi-shi-jian-jiao-xue/#toc-heading-19">强化学习实战</a>的<strong>连续动作空间上求解RL</strong>。这里用了DDPG的算法。</p><p>这里Actor-Critic也可以运用到上面的Policy Gradient中，Policy网络的更新方式中的Reward加权更新改变为 Reward - Critic 加权更新，也就是说当Reward 比Critic预测的程度高，我们趋向于采纳这种行为，反之摒弃这种行为。</p><h3 id="拓展"><a href="#拓展" class="headerlink" title="拓展"></a>拓展</h3><img src="/2021/07/21/qiang-hua-xue-xi-gang-yao-zhou-bo-lei-ke-cheng/21.png" class><img src="/2021/07/21/qiang-hua-xue-xi-gang-yao-zhou-bo-lei-ke-cheng/22.png" class><p>我会根据上面的两条主线讲解相关算法，这些内容我会一个算法开一篇文章进行讲解。目前我已经写了以下文章：</p><p><a href="https://blog.csdn.net/tianjuewudi/article/details/119985803">强化学习之DDQN</a></p><p><a href="https://blog.csdn.net/tianjuewudi/article/details/120051087">强化学习之Dueling DQN</a></p><p><a href="https://blog.csdn.net/tianjuewudi/article/details/120092230">强化学习之AC、A2C和A3C</a></p><p><a href="https://blog.csdn.net/tianjuewudi/article/details/120191097">强化学习之TRPO</a></p><p><a href="https://blog.csdn.net/tianjuewudi/article/details/120212234">强化学习之PPO</a></p><p><a href="https://blog.csdn.net/tianjuewudi/article/details/120580521">强化学习之DQN超级进化版Rainbow</a></p><p><a href="https://blog.csdn.net/tianjuewudi/article/details/120626544">强化学习之TD3（pytorch实现）</a></p><p><a href="https://blog.csdn.net/tianjuewudi/article/details/120662471">强化学习之SAC</a></p><h2 id="Model-based-RL"><a href="#Model-based-RL" class="headerlink" title="Model-based RL"></a>Model-based RL</h2><p>这部分内容我另外发了一篇文章：<a href="https://blog.csdn.net/tianjuewudi/article/details/120681063">model-based强化学习入门</a></p><h2 id="Imitation-Learning"><a href="#Imitation-Learning" class="headerlink" title="Imitation Learning"></a>Imitation Learning</h2><p>这部分内容我另外发了一篇文章：<a href="https://blog.csdn.net/tianjuewudi/article/details/120684729">模仿学习（Imitation Learning）入门</a></p><h2 id="Distributed-RL"><a href="#Distributed-RL" class="headerlink" title="Distributed RL"></a>Distributed RL</h2><p>这部分内容我另外发了一篇文章：<a href="https://blog.csdn.net/tianjuewudi/article/details/120697733">分布式强化学习</a></p>]]></content>
      
      
      <categories>
          
          <category> 强化学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 强化学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>强化学习实践教学</title>
      <link href="2021/07/16/qiang-hua-xue-xi-shi-jian-jiao-xue/"/>
      <url>2021/07/16/qiang-hua-xue-xi-shi-jian-jiao-xue/</url>
      
        <content type="html"><![CDATA[<p> 参考视频：<a href="https://www.bilibili.com/video/BV1yv411i7xd">https://www.bilibili.com/video/BV1yv411i7xd</a> </p><p>代码下载：<a href="https://github.com/PaddlePaddle/PARL">https://github.com/PaddlePaddle/PARL</a></p><p>可以先阅读我的文章《强化学习概述》，重复的内容不再叙述。代码主要参考强化学习算法框架库：PARL</p><h2 id="资料推荐"><a href="#资料推荐" class="headerlink" title="资料推荐"></a>资料推荐</h2><ul><li><p>书籍：《Reinforcement Learning: An Introduction》</p></li><li><p>视频：David Silver经典强化学习公开课、UC Berkeley CS285、斯坦福CS234</p></li><li><p>经典论文：</p><ul><li><p>DQN：<a href="https://arxiv.org/pdf/1312.5602.pdf">https://arxiv.org/pdf/1312.5602.pdf</a></p></li><li><p>A3C: <a href="https://www.jmlr.org/proceedings/papers/v48/mniha16.pdf">https://www.jmlr.org/proceedings/papers/v48/mniha16.pdf</a></p></li><li><p>DDPG: <a href="https://arxiv.org/pdf/1509.02971">https://arxiv.org/pdf/1509.02971</a></p></li><li><p>PPO: <a href="https://arxiv.org/pdf/1707.06347">https://arxiv.org/pdf/1707.06347</a></p></li></ul></li></ul><ul><li>前沿研究方向：Model-base RL、Hierarchical RL、Multi Agent RL、Meta Learning。</li></ul><img src="/2021/07/16/qiang-hua-xue-xi-shi-jian-jiao-xue/1.png" class=""><h2 id="序章"><a href="#序章" class="headerlink" title="序章"></a>序章</h2><h3 id="Agent学习的两种方案"><a href="#Agent学习的两种方案" class="headerlink" title="Agent学习的两种方案"></a>Agent学习的两种方案</h3><p>一种是基于价值（value-based），一种是基于策略（policy-based）</p><img src="/2021/07/16/qiang-hua-xue-xi-shi-jian-jiao-xue/2.png" class=""><p>基于价值：我们给每一个状态都赋予一个“价值”的概念，例如上图C状态的价值大于A状态，也就是往C走离奖励更近。我们的做法是让Agent总是往价值高的地方移动，这样就能找出一个最优的策略。一旦函数优化到最优了，相同的输入永远是同一个输出。</p><p>代表方法：Sarsa、Q-learning、DQN。</p><img src="/2021/07/16/qiang-hua-xue-xi-shi-jian-jiao-xue/3.png" class=""><p>基于策略：我们直接让一条策略走到底，然后用最后的reward来判断策略是好是坏。好的策略能在以后的行为中获得更高的触发几率。由于输出的是几率，因此同样的输入会获得不同的输出，随机性更强。</p><p>代表方法：Policy Gradient。</p><h3 id="RL概览分类"><a href="#RL概览分类" class="headerlink" title="RL概览分类"></a>RL概览分类</h3><img src="/2021/07/16/qiang-hua-xue-xi-shi-jian-jiao-xue/4.png" class=""><p>强化学习分为无模型（model-free）和基于模型（model-based），无模型的研究会更加热门，上面的两种方案都是无模型的分类。</p><p>Model-free: 不需要知道状态之间的转移概率（transition probability）。</p><p>Model-based: 需要知道状态之间的转移概率。</p><p>而在Model-free中又有三种分类：</p><img src="/2021/07/16/qiang-hua-xue-xi-shi-jian-jiao-xue/60.png" class=""><h3 id="算法库"><a href="#算法库" class="headerlink" title="算法库"></a>算法库</h3><img src="/2021/07/16/qiang-hua-xue-xi-shi-jian-jiao-xue/5.png" class=""><p>这里我们使用强化学习算法框架库：PARL。这里涵盖了很多的经典算法，又能复现一些最新的流行算法。看代码的学习方式，也是最快上手的学习方式。直接扫左上角二维码来学习。其中多智能体是一个热门的研究方向，被认为更接近人类社会的交互形式。</p><h3 id="RL编程实践：GYM"><a href="#RL编程实践：GYM" class="headerlink" title="RL编程实践：GYM"></a>RL编程实践：GYM</h3><p>前面的是和算法相关的库。另外一类是和环境相关的库。GYM是学术界比较喜欢的环境库。环境分为离散控制场景和连续控制场景，离散控制是输出只有有限个量，例如控制方向时只有向左向右，一般使用atari环境评估。连续控制是输出是一个连续的量，例如机械臂旋转的角度，一般使用mujoco环境来评估。</p><img src="/2021/07/16/qiang-hua-xue-xi-shi-jian-jiao-xue/6.png" class=""><h3 id="环境安装"><a href="#环境安装" class="headerlink" title="环境安装"></a>环境安装</h3><p>在安装了python环境的前提下，打开cmd，输入以下命令：</p><pre class=" language-cmd"><code class="language-cmd">pip install paddlepaddle==1.6.3 # 网络超时加上-i https://pypi.tuna.tsinghua.edu.cn/simple，安装GPU版本要用paddlepaddle-gpupip install parl==1.3.1     #如果安装不成功，在install后加上--userpip install gym</code></pre><h3 id="程序示例及PARL的优势"><a href="#程序示例及PARL的优势" class="headerlink" title="程序示例及PARL的优势"></a>程序示例及PARL的优势</h3><img src="/2021/07/16/qiang-hua-xue-xi-shi-jian-jiao-xue/7.png" class=""><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> gym<span class="token keyword">from</span> gridworld <span class="token keyword">import</span> CliffWalkingWapper<span class="token keyword">import</span> turtle<span class="token comment" spellcheck="true"># 创建环境</span>env <span class="token operator">=</span> gym<span class="token punctuation">.</span>make<span class="token punctuation">(</span><span class="token string">"CliffWalking-v0"</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 绘制一个图形界面，不写这一行只有文字界面</span>env <span class="token operator">=</span> CliffWalkingWapper<span class="token punctuation">(</span>env<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 重置界面，开始新的一轮</span>env<span class="token punctuation">.</span>reset<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 展示界面</span>env<span class="token punctuation">.</span>render<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 跟环境交互一步，如果有返回值第一个是纵坐标，第二个是reward，第三个是一轮是否结束</span><span class="token comment" spellcheck="true"># step(1)是往右走，step(2)是往下走，step(3)是向左走</span>env<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>env<span class="token punctuation">.</span>render<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 让程序运行结束后界面不立刻关闭</span>turtle<span class="token punctuation">.</span>exitonclick<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><p>PARL对框架库做了很好的抽象，所有的算法几乎都集中于Model，Algorithm，Agent三个类。其中Algoritm已经实现了核心的部分，另外两部分开发者可以很方便实现订制。在上面下载的PARL中，有许多算法的Example。</p><img src="/2021/07/16/qiang-hua-xue-xi-shi-jian-jiao-xue/8.png" class=""><p>从上面随便找一个example，然后<strong>对model和Agent文件做一定修改，就可以移植到新的应用场景中。</strong></p><p>PARL的工业应用能力很强。只需要加两行代码，就可以把单机训练变成多机训练。PARL的并行能力很强，和Python不同，真正做到多线程运行，节省大量时间</p><img src="/2021/07/16/qiang-hua-xue-xi-shi-jian-jiao-xue/9.png" class=""><p>配置好环境后，直接运行QuickStart里面的程序，看看是否成功，此处本人没有运行成功，报错信息如下：</p><pre><code>C:\Python39\lib\site-packages\parl\remote\communication.py:38: FutureWarning: 'pyarrow.default_serialization_context' is deprecated as of 2.0.0 and will be removed in a future version. Use pickle or the pyarrow IPC functionality instead.  context = pyarrow.default_serialization_context()W0718 17:57:30.795331  4240 device_context.cc:404] Please NOTE: device: 0, GPU Compute Capability: 6.1, Driver API Version: 11.1, Runtime API Version: 10.2[07-18 17:57:30 MainThread @train.py:73] obs_dim 4, act_dim 2W0718 17:57:30.798295  4240 dynamic_loader.cc:238] Note: [Recommend] copy cudnn into CUDA installation directory.  For instance, download cudnn-10.0-windows10-x64-v7.6.5.32.zip from NVIDIA's official website, then, unzip it and copy it into C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0You should do this according to your CUDA installation directory and CUDNN version.</code></pre><p>安装CUDNN依旧测试失败，如果有人知道缘由，请私聊。</p><h2 id="基于表格型方法求解RL"><a href="#基于表格型方法求解RL" class="headerlink" title="基于表格型方法求解RL"></a>基于表格型方法求解RL</h2><h3 id="强化学习MDP四元组"><a href="#强化学习MDP四元组" class="headerlink" title="强化学习MDP四元组"></a>强化学习MDP四元组</h3><img src="/2021/07/16/qiang-hua-xue-xi-shi-jian-jiao-xue/10.png" class=""><p>这就是强化学习MDP四元组。我们用状态转移概率表述：在$s_t$状态选择$a_t$的动作转移到$s_{t+1}$而且拿到奖励$r_t$的概率。这样的决策过程是马尔科夫决策过程（MDP）。这是一个序列决策的经典表达方式。</p><h3 id="状态转移和序列决策"><a href="#状态转移和序列决策" class="headerlink" title="状态转移和序列决策"></a>状态转移和序列决策</h3><img src="/2021/07/16/qiang-hua-xue-xi-shi-jian-jiao-xue/11.png" class=""><p>每次我们只能走其中的一条完整通路，这就是一个观察状态和执行决策不断循环的过程。每次我们都用两个函数描述环境。一个是Probability Function（P函数）,反映了环境的随机性。一个状态如果必然转移到下一个特定的状态，那么状态转移概率是100%。如果有多种可能的情况，每个的状态转移概率在0到100%之间。和状态转移概率成对的是Reward Function（R函数），描述了环境的好坏。P函数和R函数已知，则称这个环境已知，也称为<strong>Model-based</strong>。<strong>如果这些条件已知，那么我们就可以用动态规划来寻找最优策略。</strong>但这里我们不讲动态规划。</p><p>这里我们针对的是在环境未知的情况下的解决方法，因为在实际问题中的状态转移概率往往是未知的。对于P函数和R函数未知的状况我们称为<strong>Model-free</strong>。</p><h3 id="Q表格"><a href="#Q表格" class="headerlink" title="Q表格"></a>Q表格</h3><img src="/2021/07/16/qiang-hua-xue-xi-shi-jian-jiao-xue/12.png" class=""><p>Q表格指导每一个Step的动作选择，目标导向是<strong>未来的总收益</strong>。由于收益往往具有延迟，因此未来的总收益才能代表当前动作选择的价值。但是由于前面的动作对越往后的状态影响越小，因此我们需要引入衰减因子。</p><img src="/2021/07/16/qiang-hua-xue-xi-shi-jian-jiao-xue/13.png" class=""><p><strong>强化的概念是我们可以用下一个状态的价值更新现在状态的价值。</strong>因此我们每一个Step都可以更新Q表格，这是一种时序差分的更新方法。</p><h3 id="时序差分（Temporal-Difference）"><a href="#时序差分（Temporal-Difference）" class="headerlink" title="时序差分（Temporal Difference）"></a>时序差分（Temporal Difference）</h3><p>推荐一个有意思的网站：<a href="https://cs.stanford.edu/people/karpathy/reinforcejs/gridworld_td.html">https://cs.stanford.edu/people/karpathy/reinforcejs/gridworld_td.html</a></p><img src="/2021/07/16/qiang-hua-xue-xi-shi-jian-jiao-xue/14.png" class=""><p>只有一个格子的reward为1，有很多格子reward为-1，随着小球的探索，有价值的格子也会把周围格子的分数拉高，形成一个整体的“评分体系”。只需要沿着分数增加的方向走一定能找到reward为1的点。</p><img src="/2021/07/16/qiang-hua-xue-xi-shi-jian-jiao-xue/15.png" class=""><p><strong>这就是一种时序差分的更新方法。</strong></p><img src="/2021/07/16/qiang-hua-xue-xi-shi-jian-jiao-xue/16.png" class=""><p>我们要让$Q(S_t,A_t)$逐步逼近理想的值，因此我们每次只更新一点点，α就是更新的速率。通过不断的更新我们可以让每一个状态的$G_t$都满足：<br>$$<br>G_t  = R_{t+1} + \gamma G_{t+1}<br>$$<br>这就是<strong>Sarsa算法</strong>，命名方式是按照这五个值来进行计算。上面的格子的价值更新就是按照上面的公式来的。</p><h3 id="Sarsa算法代码解析"><a href="#Sarsa算法代码解析" class="headerlink" title="Sarsa算法代码解析"></a>Sarsa算法代码解析</h3><p>Agent最重要的是实现两个功能，一个是根据算法选Action，第二个是学习Q表格。并且每一个step都包含这两步。</p><p>我们要另开一个agent.py文件，声明一个Agent类，Sample函数选择要输出Action，learn函数来更新Q。</p><pre class=" language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">SarsaAgent</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>obs_n<span class="token punctuation">,</span>act_n<span class="token punctuation">,</span>learning_rate<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">,</span>gamma<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">,</span>e_greed<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>act_n <span class="token operator">=</span> act_n  <span class="token comment" spellcheck="true"># 动作维度，有几个动作可选</span>        self<span class="token punctuation">.</span>lr <span class="token operator">=</span> learning_rate  <span class="token comment" spellcheck="true"># 学习率</span>        self<span class="token punctuation">.</span>gamma <span class="token operator">=</span> gamma  <span class="token comment" spellcheck="true"># reward的衰减率</span>        self<span class="token punctuation">.</span>epsilon <span class="token operator">=</span> e_greed  <span class="token comment" spellcheck="true"># 按一定概率随机选动作</span>        self<span class="token punctuation">.</span>Q <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>obs_n<span class="token punctuation">,</span> act_n<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#生成一个矩阵作为Q表格,参数分别是状态的维度和动作维度，有多少格子就有多少状态</span>    <span class="token comment" spellcheck="true"># 根据输入观察值，返回输出的Action对应的索引，带探索</span>    <span class="token keyword">def</span> <span class="token function">sample</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> obs<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>uniform<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">&lt;</span> <span class="token punctuation">(</span><span class="token number">1.0</span> <span class="token operator">-</span> self<span class="token punctuation">.</span>epsilon<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment" spellcheck="true">#根据table的Q值选动作</span>            action <span class="token operator">=</span> self<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>obs<span class="token punctuation">)</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            action <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>choice<span class="token punctuation">(</span>self<span class="token punctuation">.</span>act_n<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true">#有一定概率随机探索选取一个动作</span>        <span class="token keyword">return</span> action    <span class="token comment" spellcheck="true"># 根据输入观察值，输出分数最高的一个动作值</span>    <span class="token keyword">def</span> <span class="token function">predict</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> obs<span class="token punctuation">)</span><span class="token punctuation">:</span>        Q_list <span class="token operator">=</span> self<span class="token punctuation">.</span>Q<span class="token punctuation">[</span>obs<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>        maxQ <span class="token operator">=</span> np<span class="token punctuation">.</span>max<span class="token punctuation">(</span>Q_list<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">#where函数返回一个包含数组和数据类型的元组，取第一个才是数组</span>        action_list <span class="token operator">=</span> np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>Q_list <span class="token operator">==</span> maxQ<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>  <span class="token comment" spellcheck="true"># maxQ可能对应多个action</span>        action <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>choice<span class="token punctuation">(</span>action_list<span class="token punctuation">)</span>        <span class="token keyword">return</span> action    <span class="token comment" spellcheck="true"># 学习方法，也就是更新Q-table的方法，采用Sarsa算法来更新Q表格</span>    <span class="token keyword">def</span> <span class="token function">learn</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> obs<span class="token punctuation">,</span> action<span class="token punctuation">,</span> reward<span class="token punctuation">,</span> next_obs<span class="token punctuation">,</span> next_action<span class="token punctuation">,</span> done<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">""" on-policy            obs: 交互前的obs, s_t            action: 本次交互选择的action, a_t            reward: 本次动作获得的奖励r            next_obs: 本次交互后的obs, s_t+1            next_action: 根据当前Q表格, 针对next_obs会选择的动作, a_t+1            done: episode是否结束        """</span>        predict_Q <span class="token operator">=</span> self<span class="token punctuation">.</span>Q<span class="token punctuation">[</span>obs<span class="token punctuation">,</span> action<span class="token punctuation">]</span>        <span class="token keyword">if</span> done<span class="token punctuation">:</span>            target_Q <span class="token operator">=</span> reward  <span class="token comment" spellcheck="true"># 没有下一个状态了</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            target_Q <span class="token operator">=</span> reward <span class="token operator">+</span> self<span class="token punctuation">.</span>gamma <span class="token operator">*</span> self<span class="token punctuation">.</span>Q<span class="token punctuation">[</span>next_obs<span class="token punctuation">,</span>                                                    next_action<span class="token punctuation">]</span>  <span class="token comment" spellcheck="true"># Sarsa</span>        self<span class="token punctuation">.</span>Q<span class="token punctuation">[</span>obs<span class="token punctuation">,</span> action<span class="token punctuation">]</span> <span class="token operator">+=</span> self<span class="token punctuation">.</span>lr <span class="token operator">*</span> <span class="token punctuation">(</span>target_Q <span class="token operator">-</span> predict_Q<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 修正q</span>    <span class="token comment" spellcheck="true"># 保存Q表格</span>    <span class="token keyword">def</span> <span class="token function">save</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        npy_file <span class="token operator">=</span> <span class="token string">'./q_table.npy'</span>        np<span class="token punctuation">.</span>save<span class="token punctuation">(</span>npy_file<span class="token punctuation">,</span> self<span class="token punctuation">.</span>Q<span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span>npy_file <span class="token operator">+</span> <span class="token string">' saved.'</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 读取Q表格</span>    <span class="token keyword">def</span> <span class="token function">restore</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> npy_file<span class="token operator">=</span><span class="token string">'./q_table.npy'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>Q <span class="token operator">=</span> np<span class="token punctuation">.</span>load<span class="token punctuation">(</span>npy_file<span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span>npy_file <span class="token operator">+</span> <span class="token string">' loaded.'</span><span class="token punctuation">)</span></code></pre><p>然后再开一个文件写我们的main函数：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> gym<span class="token keyword">from</span> gridworld <span class="token keyword">import</span> CliffWalkingWapper<span class="token punctuation">,</span> FrozenLakeWapper<span class="token keyword">from</span> agent <span class="token keyword">import</span> SarsaAgent<span class="token keyword">import</span> time<span class="token keyword">def</span> <span class="token function">run_episode</span><span class="token punctuation">(</span>env<span class="token punctuation">,</span> agent<span class="token punctuation">,</span> render<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    total_steps <span class="token operator">=</span> <span class="token number">0</span>  <span class="token comment" spellcheck="true"># 记录每个episode走了多少step</span>    total_reward <span class="token operator">=</span> <span class="token number">0</span>    obs <span class="token operator">=</span> env<span class="token punctuation">.</span>reset<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 重置环境, 重新开一局（即开始新的一个episode）</span>    action <span class="token operator">=</span> agent<span class="token punctuation">.</span>sample<span class="token punctuation">(</span>obs<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 根据算法选择一个动作</span>    <span class="token keyword">while</span> <span class="token boolean">True</span><span class="token punctuation">:</span>        next_obs<span class="token punctuation">,</span> reward<span class="token punctuation">,</span> done<span class="token punctuation">,</span> _ <span class="token operator">=</span> env<span class="token punctuation">.</span>step<span class="token punctuation">(</span>action<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 执行动作,action在0~3代表不同方向，并返回下一个状态</span>        next_action <span class="token operator">=</span> agent<span class="token punctuation">.</span>sample<span class="token punctuation">(</span>next_obs<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 根据算法选择下一个动作</span>        <span class="token comment" spellcheck="true"># 训练 Sarsa 算法，更新Q表格</span>        agent<span class="token punctuation">.</span>learn<span class="token punctuation">(</span>obs<span class="token punctuation">,</span> action<span class="token punctuation">,</span> reward<span class="token punctuation">,</span> next_obs<span class="token punctuation">,</span> next_action<span class="token punctuation">,</span> done<span class="token punctuation">)</span>        action <span class="token operator">=</span> next_action <span class="token comment" spellcheck="true"># 把下一个动作更新为现在的动作</span>        obs <span class="token operator">=</span> next_obs  <span class="token comment" spellcheck="true"># 把下一个状态更新为现在的状态</span>        total_reward <span class="token operator">+=</span> reward        total_steps <span class="token operator">+=</span> <span class="token number">1</span>  <span class="token comment" spellcheck="true"># 计算step数</span>        <span class="token keyword">if</span> render<span class="token punctuation">:</span>            env<span class="token punctuation">.</span>render<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true">#渲染新的一帧图形</span>        <span class="token keyword">if</span> done<span class="token punctuation">:</span>            <span class="token keyword">break</span>    <span class="token keyword">return</span> total_reward<span class="token punctuation">,</span> total_steps<span class="token comment" spellcheck="true"># 测试函数</span><span class="token keyword">def</span> <span class="token function">test_episode</span><span class="token punctuation">(</span>env<span class="token punctuation">,</span> agent<span class="token punctuation">)</span><span class="token punctuation">:</span>    total_reward <span class="token operator">=</span> <span class="token number">0</span>    obs <span class="token operator">=</span> env<span class="token punctuation">.</span>reset<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">while</span> <span class="token boolean">True</span><span class="token punctuation">:</span>        action <span class="token operator">=</span> agent<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>obs<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># greedy</span>        next_obs<span class="token punctuation">,</span> reward<span class="token punctuation">,</span> done<span class="token punctuation">,</span> _ <span class="token operator">=</span> env<span class="token punctuation">.</span>step<span class="token punctuation">(</span>action<span class="token punctuation">)</span>        total_reward <span class="token operator">+=</span> reward        obs <span class="token operator">=</span> next_obs        time<span class="token punctuation">.</span>sleep<span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">)</span>        env<span class="token punctuation">.</span>render<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> done<span class="token punctuation">:</span>            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'test reward = %.1f'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>total_reward<span class="token punctuation">)</span><span class="token punctuation">)</span>            <span class="token keyword">break</span><span class="token keyword">def</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># env = gym.make("FrozenLake-v0", is_slippery=False)  # 0 left, 1 down, 2 right, 3 up</span>    <span class="token comment" spellcheck="true"># env = FrozenLakeWapper(env)</span>    env <span class="token operator">=</span> gym<span class="token punctuation">.</span>make<span class="token punctuation">(</span><span class="token string">"CliffWalking-v0"</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 0 up, 1 right, 2 down, 3 left</span>    <span class="token comment" spellcheck="true"># 创建一个图形界面</span>    env <span class="token operator">=</span> CliffWalkingWapper<span class="token punctuation">(</span>env<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 实例化agent</span>    agent <span class="token operator">=</span> SarsaAgent<span class="token punctuation">(</span>        obs_n<span class="token operator">=</span>env<span class="token punctuation">.</span>observation_space<span class="token punctuation">.</span>n<span class="token punctuation">,</span>        act_n<span class="token operator">=</span>env<span class="token punctuation">.</span>action_space<span class="token punctuation">.</span>n<span class="token punctuation">,</span>        learning_rate<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">,</span>        gamma<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">,</span>        e_greed<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span>    is_render <span class="token operator">=</span> <span class="token boolean">False</span>    <span class="token keyword">for</span> episode <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">500</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        ep_reward<span class="token punctuation">,</span> ep_steps <span class="token operator">=</span> run_episode<span class="token punctuation">(</span>env<span class="token punctuation">,</span> agent<span class="token punctuation">,</span> is_render<span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Episode %s: steps = %s , reward = %.1f'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>episode<span class="token punctuation">,</span> ep_steps<span class="token punctuation">,</span>                                                          ep_reward<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 每隔20个episode渲染一下看看效果</span>        <span class="token keyword">if</span> episode <span class="token operator">%</span> <span class="token number">20</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>            is_render <span class="token operator">=</span> <span class="token boolean">True</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            is_render <span class="token operator">=</span> <span class="token boolean">False</span>    <span class="token comment" spellcheck="true"># 训练结束，查看算法效果</span>    test_episode<span class="token punctuation">(</span>env<span class="token punctuation">,</span> agent<span class="token punctuation">)</span><span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>    main<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><p>生成图形环境的文件gridworld.py的代码如下：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> gym<span class="token keyword">import</span> turtle<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token comment" spellcheck="true"># turtle tutorial : https://docs.python.org/3.3/library/turtle.html</span><span class="token keyword">def</span> <span class="token function">GridWorld</span><span class="token punctuation">(</span>gridmap<span class="token operator">=</span>None<span class="token punctuation">,</span> is_slippery<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">if</span> gridmap <span class="token keyword">is</span> None<span class="token punctuation">:</span>        gridmap <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'SFFF'</span><span class="token punctuation">,</span> <span class="token string">'FHFH'</span><span class="token punctuation">,</span> <span class="token string">'FFFH'</span><span class="token punctuation">,</span> <span class="token string">'HFFG'</span><span class="token punctuation">]</span>    env <span class="token operator">=</span> gym<span class="token punctuation">.</span>make<span class="token punctuation">(</span><span class="token string">"FrozenLake-v0"</span><span class="token punctuation">,</span> desc<span class="token operator">=</span>gridmap<span class="token punctuation">,</span> is_slippery<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>    env <span class="token operator">=</span> FrozenLakeWapper<span class="token punctuation">(</span>env<span class="token punctuation">)</span>    <span class="token keyword">return</span> env<span class="token keyword">class</span> <span class="token class-name">FrozenLakeWapper</span><span class="token punctuation">(</span>gym<span class="token punctuation">.</span>Wrapper<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> env<span class="token punctuation">)</span><span class="token punctuation">:</span>        gym<span class="token punctuation">.</span>Wrapper<span class="token punctuation">.</span>__init__<span class="token punctuation">(</span>self<span class="token punctuation">,</span> env<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>max_y <span class="token operator">=</span> env<span class="token punctuation">.</span>desc<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>        self<span class="token punctuation">.</span>max_x <span class="token operator">=</span> env<span class="token punctuation">.</span>desc<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>        self<span class="token punctuation">.</span>t <span class="token operator">=</span> None        self<span class="token punctuation">.</span>unit <span class="token operator">=</span> <span class="token number">50</span>    <span class="token keyword">def</span> <span class="token function">draw_box</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> fillcolor<span class="token operator">=</span><span class="token string">''</span><span class="token punctuation">,</span> line_color<span class="token operator">=</span><span class="token string">'gray'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>t<span class="token punctuation">.</span>up<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>t<span class="token punctuation">.</span>goto<span class="token punctuation">(</span>x <span class="token operator">*</span> self<span class="token punctuation">.</span>unit<span class="token punctuation">,</span> y <span class="token operator">*</span> self<span class="token punctuation">.</span>unit<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>t<span class="token punctuation">.</span>color<span class="token punctuation">(</span>line_color<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>t<span class="token punctuation">.</span>fillcolor<span class="token punctuation">(</span>fillcolor<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>t<span class="token punctuation">.</span>setheading<span class="token punctuation">(</span><span class="token number">90</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>t<span class="token punctuation">.</span>down<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>t<span class="token punctuation">.</span>begin_fill<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">for</span> _ <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            self<span class="token punctuation">.</span>t<span class="token punctuation">.</span>forward<span class="token punctuation">(</span>self<span class="token punctuation">.</span>unit<span class="token punctuation">)</span>            self<span class="token punctuation">.</span>t<span class="token punctuation">.</span>right<span class="token punctuation">(</span><span class="token number">90</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>t<span class="token punctuation">.</span>end_fill<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">move_player</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>t<span class="token punctuation">.</span>up<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>t<span class="token punctuation">.</span>setheading<span class="token punctuation">(</span><span class="token number">90</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>t<span class="token punctuation">.</span>fillcolor<span class="token punctuation">(</span><span class="token string">'red'</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>t<span class="token punctuation">.</span>goto<span class="token punctuation">(</span><span class="token punctuation">(</span>x <span class="token operator">+</span> <span class="token number">0.5</span><span class="token punctuation">)</span> <span class="token operator">*</span> self<span class="token punctuation">.</span>unit<span class="token punctuation">,</span> <span class="token punctuation">(</span>y <span class="token operator">+</span> <span class="token number">0.5</span><span class="token punctuation">)</span> <span class="token operator">*</span> self<span class="token punctuation">.</span>unit<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">render</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>t <span class="token operator">==</span> None<span class="token punctuation">:</span>            self<span class="token punctuation">.</span>t <span class="token operator">=</span> turtle<span class="token punctuation">.</span>Turtle<span class="token punctuation">(</span><span class="token punctuation">)</span>            self<span class="token punctuation">.</span>wn <span class="token operator">=</span> turtle<span class="token punctuation">.</span>Screen<span class="token punctuation">(</span><span class="token punctuation">)</span>            self<span class="token punctuation">.</span>wn<span class="token punctuation">.</span>setup<span class="token punctuation">(</span>self<span class="token punctuation">.</span>unit <span class="token operator">*</span> self<span class="token punctuation">.</span>max_x <span class="token operator">+</span> <span class="token number">100</span><span class="token punctuation">,</span>                          self<span class="token punctuation">.</span>unit <span class="token operator">*</span> self<span class="token punctuation">.</span>max_y <span class="token operator">+</span> <span class="token number">100</span><span class="token punctuation">)</span>            self<span class="token punctuation">.</span>wn<span class="token punctuation">.</span>setworldcoordinates<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>unit <span class="token operator">*</span> self<span class="token punctuation">.</span>max_x<span class="token punctuation">,</span>                                        self<span class="token punctuation">.</span>unit <span class="token operator">*</span> self<span class="token punctuation">.</span>max_y<span class="token punctuation">)</span>            self<span class="token punctuation">.</span>t<span class="token punctuation">.</span>shape<span class="token punctuation">(</span><span class="token string">'circle'</span><span class="token punctuation">)</span>            self<span class="token punctuation">.</span>t<span class="token punctuation">.</span>width<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>            self<span class="token punctuation">.</span>t<span class="token punctuation">.</span>speed<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>            self<span class="token punctuation">.</span>t<span class="token punctuation">.</span>color<span class="token punctuation">(</span><span class="token string">'gray'</span><span class="token punctuation">)</span>            <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>self<span class="token punctuation">.</span>desc<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                <span class="token keyword">for</span> j <span class="token keyword">in</span> range<span class="token punctuation">(</span>self<span class="token punctuation">.</span>desc<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                    x <span class="token operator">=</span> j                    y <span class="token operator">=</span> self<span class="token punctuation">.</span>max_y <span class="token operator">-</span> <span class="token number">1</span> <span class="token operator">-</span> i                    <span class="token keyword">if</span> self<span class="token punctuation">.</span>desc<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token operator">==</span> b<span class="token string">'S'</span><span class="token punctuation">:</span>  <span class="token comment" spellcheck="true"># Start</span>                        self<span class="token punctuation">.</span>draw_box<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> <span class="token string">'white'</span><span class="token punctuation">)</span>                    <span class="token keyword">elif</span> self<span class="token punctuation">.</span>desc<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token operator">==</span> b<span class="token string">'F'</span><span class="token punctuation">:</span>  <span class="token comment" spellcheck="true"># Frozen ice</span>                        self<span class="token punctuation">.</span>draw_box<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> <span class="token string">'white'</span><span class="token punctuation">)</span>                    <span class="token keyword">elif</span> self<span class="token punctuation">.</span>desc<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token operator">==</span> b<span class="token string">'G'</span><span class="token punctuation">:</span>  <span class="token comment" spellcheck="true"># Goal</span>                        self<span class="token punctuation">.</span>draw_box<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> <span class="token string">'yellow'</span><span class="token punctuation">)</span>                    <span class="token keyword">elif</span> self<span class="token punctuation">.</span>desc<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token operator">==</span> b<span class="token string">'H'</span><span class="token punctuation">:</span>  <span class="token comment" spellcheck="true"># Hole</span>                        self<span class="token punctuation">.</span>draw_box<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> <span class="token string">'black'</span><span class="token punctuation">)</span>                    <span class="token keyword">else</span><span class="token punctuation">:</span>                        self<span class="token punctuation">.</span>draw_box<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> <span class="token string">'white'</span><span class="token punctuation">)</span>            self<span class="token punctuation">.</span>t<span class="token punctuation">.</span>shape<span class="token punctuation">(</span><span class="token string">'turtle'</span><span class="token punctuation">)</span>        x_pos <span class="token operator">=</span> self<span class="token punctuation">.</span>s <span class="token operator">%</span> self<span class="token punctuation">.</span>max_x        y_pos <span class="token operator">=</span> self<span class="token punctuation">.</span>max_y <span class="token operator">-</span> <span class="token number">1</span> <span class="token operator">-</span> int<span class="token punctuation">(</span>self<span class="token punctuation">.</span>s <span class="token operator">/</span> self<span class="token punctuation">.</span>max_x<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>move_player<span class="token punctuation">(</span>x_pos<span class="token punctuation">,</span> y_pos<span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">CliffWalkingWapper</span><span class="token punctuation">(</span>gym<span class="token punctuation">.</span>Wrapper<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> env<span class="token punctuation">)</span><span class="token punctuation">:</span>        gym<span class="token punctuation">.</span>Wrapper<span class="token punctuation">.</span>__init__<span class="token punctuation">(</span>self<span class="token punctuation">,</span> env<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>t <span class="token operator">=</span> None        self<span class="token punctuation">.</span>unit <span class="token operator">=</span> <span class="token number">50</span>        self<span class="token punctuation">.</span>max_x <span class="token operator">=</span> <span class="token number">12</span>        self<span class="token punctuation">.</span>max_y <span class="token operator">=</span> <span class="token number">4</span>    <span class="token keyword">def</span> <span class="token function">draw_x_line</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> y<span class="token punctuation">,</span> x0<span class="token punctuation">,</span> x1<span class="token punctuation">,</span> color<span class="token operator">=</span><span class="token string">'gray'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">assert</span> x1 <span class="token operator">&gt;</span> x0        self<span class="token punctuation">.</span>t<span class="token punctuation">.</span>color<span class="token punctuation">(</span>color<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>t<span class="token punctuation">.</span>setheading<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>t<span class="token punctuation">.</span>up<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>t<span class="token punctuation">.</span>goto<span class="token punctuation">(</span>x0<span class="token punctuation">,</span> y<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>t<span class="token punctuation">.</span>down<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>t<span class="token punctuation">.</span>forward<span class="token punctuation">(</span>x1 <span class="token operator">-</span> x0<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">draw_y_line</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> y0<span class="token punctuation">,</span> y1<span class="token punctuation">,</span> color<span class="token operator">=</span><span class="token string">'gray'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">assert</span> y1 <span class="token operator">&gt;</span> y0        self<span class="token punctuation">.</span>t<span class="token punctuation">.</span>color<span class="token punctuation">(</span>color<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>t<span class="token punctuation">.</span>setheading<span class="token punctuation">(</span><span class="token number">90</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>t<span class="token punctuation">.</span>up<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>t<span class="token punctuation">.</span>goto<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y0<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>t<span class="token punctuation">.</span>down<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>t<span class="token punctuation">.</span>forward<span class="token punctuation">(</span>y1 <span class="token operator">-</span> y0<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">draw_box</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> fillcolor<span class="token operator">=</span><span class="token string">''</span><span class="token punctuation">,</span> line_color<span class="token operator">=</span><span class="token string">'gray'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>t<span class="token punctuation">.</span>up<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>t<span class="token punctuation">.</span>goto<span class="token punctuation">(</span>x <span class="token operator">*</span> self<span class="token punctuation">.</span>unit<span class="token punctuation">,</span> y <span class="token operator">*</span> self<span class="token punctuation">.</span>unit<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>t<span class="token punctuation">.</span>color<span class="token punctuation">(</span>line_color<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>t<span class="token punctuation">.</span>fillcolor<span class="token punctuation">(</span>fillcolor<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>t<span class="token punctuation">.</span>setheading<span class="token punctuation">(</span><span class="token number">90</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>t<span class="token punctuation">.</span>down<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>t<span class="token punctuation">.</span>begin_fill<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            self<span class="token punctuation">.</span>t<span class="token punctuation">.</span>forward<span class="token punctuation">(</span>self<span class="token punctuation">.</span>unit<span class="token punctuation">)</span>            self<span class="token punctuation">.</span>t<span class="token punctuation">.</span>right<span class="token punctuation">(</span><span class="token number">90</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>t<span class="token punctuation">.</span>end_fill<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">move_player</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>t<span class="token punctuation">.</span>up<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>t<span class="token punctuation">.</span>setheading<span class="token punctuation">(</span><span class="token number">90</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>t<span class="token punctuation">.</span>fillcolor<span class="token punctuation">(</span><span class="token string">'red'</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>t<span class="token punctuation">.</span>goto<span class="token punctuation">(</span><span class="token punctuation">(</span>x <span class="token operator">+</span> <span class="token number">0.5</span><span class="token punctuation">)</span> <span class="token operator">*</span> self<span class="token punctuation">.</span>unit<span class="token punctuation">,</span> <span class="token punctuation">(</span>y <span class="token operator">+</span> <span class="token number">0.5</span><span class="token punctuation">)</span> <span class="token operator">*</span> self<span class="token punctuation">.</span>unit<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">render</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>t <span class="token operator">==</span> None<span class="token punctuation">:</span>            self<span class="token punctuation">.</span>t <span class="token operator">=</span> turtle<span class="token punctuation">.</span>Turtle<span class="token punctuation">(</span><span class="token punctuation">)</span>            self<span class="token punctuation">.</span>wn <span class="token operator">=</span> turtle<span class="token punctuation">.</span>Screen<span class="token punctuation">(</span><span class="token punctuation">)</span>            self<span class="token punctuation">.</span>wn<span class="token punctuation">.</span>setup<span class="token punctuation">(</span>self<span class="token punctuation">.</span>unit <span class="token operator">*</span> self<span class="token punctuation">.</span>max_x <span class="token operator">+</span> <span class="token number">100</span><span class="token punctuation">,</span>                          self<span class="token punctuation">.</span>unit <span class="token operator">*</span> self<span class="token punctuation">.</span>max_y <span class="token operator">+</span> <span class="token number">100</span><span class="token punctuation">)</span>            self<span class="token punctuation">.</span>wn<span class="token punctuation">.</span>setworldcoordinates<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>unit <span class="token operator">*</span> self<span class="token punctuation">.</span>max_x<span class="token punctuation">,</span>                                        self<span class="token punctuation">.</span>unit <span class="token operator">*</span> self<span class="token punctuation">.</span>max_y<span class="token punctuation">)</span>            self<span class="token punctuation">.</span>t<span class="token punctuation">.</span>shape<span class="token punctuation">(</span><span class="token string">'circle'</span><span class="token punctuation">)</span>            self<span class="token punctuation">.</span>t<span class="token punctuation">.</span>width<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>            self<span class="token punctuation">.</span>t<span class="token punctuation">.</span>speed<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>            self<span class="token punctuation">.</span>t<span class="token punctuation">.</span>color<span class="token punctuation">(</span><span class="token string">'gray'</span><span class="token punctuation">)</span>            <span class="token keyword">for</span> _ <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                self<span class="token punctuation">.</span>t<span class="token punctuation">.</span>forward<span class="token punctuation">(</span>self<span class="token punctuation">.</span>max_x <span class="token operator">*</span> self<span class="token punctuation">.</span>unit<span class="token punctuation">)</span>                self<span class="token punctuation">.</span>t<span class="token punctuation">.</span>left<span class="token punctuation">(</span><span class="token number">90</span><span class="token punctuation">)</span>                self<span class="token punctuation">.</span>t<span class="token punctuation">.</span>forward<span class="token punctuation">(</span>self<span class="token punctuation">.</span>max_y <span class="token operator">*</span> self<span class="token punctuation">.</span>unit<span class="token punctuation">)</span>                self<span class="token punctuation">.</span>t<span class="token punctuation">.</span>left<span class="token punctuation">(</span><span class="token number">90</span><span class="token punctuation">)</span>            <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>max_y<span class="token punctuation">)</span><span class="token punctuation">:</span>                self<span class="token punctuation">.</span>draw_x_line<span class="token punctuation">(</span>                    y<span class="token operator">=</span>i <span class="token operator">*</span> self<span class="token punctuation">.</span>unit<span class="token punctuation">,</span> x0<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> x1<span class="token operator">=</span>self<span class="token punctuation">.</span>max_x <span class="token operator">*</span> self<span class="token punctuation">.</span>unit<span class="token punctuation">)</span>            <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>max_x<span class="token punctuation">)</span><span class="token punctuation">:</span>                self<span class="token punctuation">.</span>draw_y_line<span class="token punctuation">(</span>                    x<span class="token operator">=</span>i <span class="token operator">*</span> self<span class="token punctuation">.</span>unit<span class="token punctuation">,</span> y0<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> y1<span class="token operator">=</span>self<span class="token punctuation">.</span>max_y <span class="token operator">*</span> self<span class="token punctuation">.</span>unit<span class="token punctuation">)</span>            <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>max_x <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                self<span class="token punctuation">.</span>draw_box<span class="token punctuation">(</span>i<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token string">'black'</span><span class="token punctuation">)</span>            self<span class="token punctuation">.</span>draw_box<span class="token punctuation">(</span>self<span class="token punctuation">.</span>max_x <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token string">'yellow'</span><span class="token punctuation">)</span>            self<span class="token punctuation">.</span>t<span class="token punctuation">.</span>shape<span class="token punctuation">(</span><span class="token string">'turtle'</span><span class="token punctuation">)</span>        x_pos <span class="token operator">=</span> self<span class="token punctuation">.</span>s <span class="token operator">%</span> self<span class="token punctuation">.</span>max_x        y_pos <span class="token operator">=</span> self<span class="token punctuation">.</span>max_y <span class="token operator">-</span> <span class="token number">1</span> <span class="token operator">-</span> int<span class="token punctuation">(</span>self<span class="token punctuation">.</span>s <span class="token operator">/</span> self<span class="token punctuation">.</span>max_x<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>move_player<span class="token punctuation">(</span>x_pos<span class="token punctuation">,</span> y_pos<span class="token punctuation">)</span></code></pre><h3 id="On-policy和Off-policy"><a href="#On-policy和Off-policy" class="headerlink" title="On-policy和Off-policy"></a>On-policy和Off-policy</h3><p>On-policy: 探索环境使用的策略和要更新的策略是一个策略（SARSA）</p><p>Off-policy: 探索环境使用的策略和要更新的策略不是同一个策略（Q-learning）</p><p>上面我们学的SARSA是on-policy，优化的是实际执行的策略，因此只存在一种策略。off-policy在学习的过程中保留了两种不同的策略，一种是Target policy，使我们想要的最佳的目标策略。另一个是Behavior policy，是探索环境的策略，需要大胆探索所有可能的环境，然后交给目标策略去学习。而且交给目标策略的数据不需要$A_{t+1}$（也就是Sarsa最后一个a）。</p><img src="/2021/07/16/qiang-hua-xue-xi-shi-jian-jiao-xue/17.png" class=""><p>对比：</p><img src="/2021/07/16/qiang-hua-xue-xi-shi-jian-jiao-xue/18.png" class=""><h3 id="Q-learning"><a href="#Q-learning" class="headerlink" title="Q-learning"></a>Q-learning</h3><img src="/2021/07/16/qiang-hua-xue-xi-shi-jian-jiao-xue/19.png" class=""><p>可以看到代码实现方面Q-learning和Sarsa类似，只是把初始action的选择也放到了循环当中，并且learn函数已经不用传入$A_{t+1}$了。</p><p>而在Agent类中，只有learn函数中的一行和Sarsa有区别，也就是Q表格的更新公式。</p><pre class=" language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">QLearningAgent</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token operator">-</span><span class="token operator">-</span>snip<span class="token operator">-</span><span class="token operator">-</span>    <span class="token comment" spellcheck="true"># 学习方法，也就是更新Q-table的方法</span>    <span class="token keyword">def</span> <span class="token function">learn</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> obs<span class="token punctuation">,</span> action<span class="token punctuation">,</span> reward<span class="token punctuation">,</span> next_obs<span class="token punctuation">,</span> done<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">""" off-policy            obs: 交互前的obs, s_t            action: 本次交互选择的action, a_t            reward: 本次动作获得的奖励r            next_obs: 本次交互后的obs, s_t+1            done: episode是否结束        """</span>        predict_Q <span class="token operator">=</span> self<span class="token punctuation">.</span>Q<span class="token punctuation">[</span>obs<span class="token punctuation">,</span> action<span class="token punctuation">]</span>        <span class="token keyword">if</span> done<span class="token punctuation">:</span>            target_Q <span class="token operator">=</span> reward  <span class="token comment" spellcheck="true"># 没有下一个状态了</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            target_Q <span class="token operator">=</span> reward <span class="token operator">+</span> self<span class="token punctuation">.</span>gamma <span class="token operator">*</span> np<span class="token punctuation">.</span>max<span class="token punctuation">(</span>                self<span class="token punctuation">.</span>Q<span class="token punctuation">[</span>next_obs<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># Q-learning</span>        self<span class="token punctuation">.</span>Q<span class="token punctuation">[</span>obs<span class="token punctuation">,</span> action<span class="token punctuation">]</span> <span class="token operator">+=</span> self<span class="token punctuation">.</span>lr <span class="token operator">*</span> <span class="token punctuation">(</span>target_Q <span class="token operator">-</span> predict_Q<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 修正q</span>    <span class="token operator">-</span><span class="token operator">-</span>snip<span class="token operator">-</span><span class="token operator">-</span></code></pre><p>也就是说，探索的策略没变，都是往高价值的格子方向探索并带有10%的探索几率。但是更新格子价值的时候，我们并不是根据探索的下一步来调整格子的价值，而是挑选周围全部可以达到的格子价值的最大值。因此，<strong>在Q-learning中，价值低的格子并不能影响周围格子的价值，只有价值高的格子才能影响周围格子的价值。</strong></p><p>这和Sarsa不同，Sarsa下一步格子的价值都会影响到上一步格子，因此在reward为负数的格子周围那些格子的价值也为负数，因此agent会绕的远远地。而Q-learning，没有这个顾虑，因此agent直接就是最短路径拿到reward，因此total-reward会比Sarsa高。</p><img src="/2021/07/16/qiang-hua-xue-xi-shi-jian-jiao-xue/20.png" class=""><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>Sarsa的策略偏向于保守，既会趋利也会避害，即使探索不太完全也会里reward底的地方较远（防止随机走的时候掉进去），而Q-learning更具探索性，能找到一条最优的路径，但是探索的时候Behavior policy容易随机reward低点，但这不妨碍Target policy学习到更好的策略。</p><p><strong>其中每走一步reward减1的设定是探索的关键点。</strong>由于没有探索到的格子价值为0，而探索到的无reward格子的价值往往为负数，agent会更趋向于探索没有探索过的格子。</p><p>那么Sarsa和Q-learning这两个<strong>经典的表格型算法</strong>和编程实现到此讲解完毕。</p><h3 id="拓展"><a href="#拓展" class="headerlink" title="拓展"></a>拓展</h3><img src="/2021/07/16/qiang-hua-xue-xi-shi-jian-jiao-xue/21.png" class=""><p>讲到这里，你应该已经了解两个算法的具体实现了，到多个环境中去跑算法观察现象吧！我们可以自定义格子世界，看看我们的算法是如何找到最优路径的。</p><p>同时，我也发现这两个算法都有一定的缺陷，就是没有办法跑黑块较多且较大的地图，这是由于战线过长中途又没有反馈，因此agent很难知道自己走的路线是对是错，我个人的想法是，往往这时候我们需要人为加入额外的reward来引导。</p><img src="/2021/07/16/qiang-hua-xue-xi-shi-jian-jiao-xue/22.png" class=""><h2 id="基于神经网络方法求解RL"><a href="#基于神经网络方法求解RL" class="headerlink" title="基于神经网络方法求解RL"></a>基于神经网络方法求解RL</h2><p>关于神经网络的内容可以自行查看深度学习内容，或查看我的文章《李宏毅机器学习2021》<a href="https://tianjuewudi.gitee.io/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/%E3%80%82%E4%BB%A5%E5%8F%8A%E3%80%8APytorch%E5%AE%9E%E6%88%98%E6%95%99%E5%AD%A6%E3%80%8B%E3%80%82">https://tianjuewudi.gitee.io/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/。以及《Pytorch实战教学》。</a></p><p> 当我们的强化学习（RL）碰到了深度学习（DL），我们就来到了深度强化学习（DRL）的领域。</p><p>表格法有很大的缺陷：</p><ol><li>表格占用的内存空间巨大。</li><li>当表格极大时，查表效率低下。</li><li>只能表示有限个离散状态和动作。</li></ol><p>现在我们需要更换工具了，我们可以用神经网络来代替表格法，我们可以用S和A作为神经网络的输入，由此输出价值Q。也可以输入S并输出多个Q，每个Q对应一个A。神经网络只需要储存有限的网络参数，我们的任务就是不断调整这些参数，使得输入输出符合我们的预期，而且状态可以泛化，相似的状态输出也差不多，不用像表格法一样需要重新训练。</p><img src="/2021/07/16/qiang-hua-xue-xi-shi-jian-jiao-xue/23.png" class=""><p>其中利用神经网络求解RL的经典算法是<strong>DQN</strong>。这是2015年发表在Nature上的论文。神经网络的输入是像素级别的图像，使用神经网络近似代替Q表格，49个游戏中有30个超越人类水平。</p><h3 id="DQN"><a href="#DQN" class="headerlink" title="DQN"></a>DQN</h3><img src="/2021/07/16/qiang-hua-xue-xi-shi-jian-jiao-xue/24.png" class=""><p>DQN的做法类似于Q-learning和神经网络的组合。首先神经网络的训练方法是监督学习，其中训练的样本就是输入状态变量，输出动作Action，我们通过Q-learning不断更新这些样本，然后送到神经网络中进行训练，期望拟合出一个和原来Q表格差不多的神经网络。</p><p>DQN提出了两个创新点使得其更有效率也更稳定。</p><img src="/2021/07/16/qiang-hua-xue-xi-shi-jian-jiao-xue/25.png" class=""><p>第一个是<strong>经验回放</strong>。经验回放可以充分利用off-policy的优势，可以利用Behavior Policy探索的数据特征形成一组组数据，并且可以随机打乱，使得神经网络可以重复多次地进行学习。这样可以打乱样本的关联性，而且能提高样本利用率。</p><img src="/2021/07/16/qiang-hua-xue-xi-shi-jian-jiao-xue/26.png" class=""><p>第二个是<strong>固定Q目标</strong>。增加了算法的平稳性。由于在探索过程中的Q也是时时刻刻都在变化的，因此我们训练的神经网络很难去逼近它的值，因此我们需要把Q值固定一段时间来训练参数，这是Q网络。我们需要另外一个一样的网络（target Q网络），Q网络的作用是产生一个Q预测值，直接用来决策产生action。而target Q是产生一个Q目标值，我们需要训练网络让这两个值越接近越好，这个Loss就是网络需要优化的目标，利用这个Loss我们就可以更新Q网络的参数。刚开始我们的网络的输出是随机的，但是受到reward的影响，各个状态的价值随着更新都会逐渐区分开来。</p><img src="/2021/07/16/qiang-hua-xue-xi-shi-jian-jiao-xue/27.png" class=""><img src="/2021/07/16/qiang-hua-xue-xi-shi-jian-jiao-xue/28.png" class=""><p>这也是PARL这个框架的特点，它把算法框架拆分为model，algorithm，agent三个部分</p><img src="/2021/07/16/qiang-hua-xue-xi-shi-jian-jiao-xue/29.png" class=""><img src="/2021/07/16/qiang-hua-xue-xi-shi-jian-jiao-xue/30.png" class=""><h3 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h3><p>reply_memory.py：用来把一个batch的资料分类整理。</p><pre class=" language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">ReplayMemory</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> max_size<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># deque是高性能的数据结构之一，是一个队列</span>        self<span class="token punctuation">.</span>buffer <span class="token operator">=</span> collections<span class="token punctuation">.</span>deque<span class="token punctuation">(</span>maxlen<span class="token operator">=</span>max_size<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 往队列中添加一条数据</span>    <span class="token keyword">def</span> <span class="token function">append</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> exp<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>buffer<span class="token punctuation">.</span>append<span class="token punctuation">(</span>exp<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">sample</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> batch_size<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># 随机取出batch_size条数据</span>        mini_batch <span class="token operator">=</span> random<span class="token punctuation">.</span>sample<span class="token punctuation">(</span>self<span class="token punctuation">.</span>buffer<span class="token punctuation">,</span> batch_size<span class="token punctuation">)</span>        obs_batch<span class="token punctuation">,</span> action_batch<span class="token punctuation">,</span> reward_batch<span class="token punctuation">,</span> next_obs_batch<span class="token punctuation">,</span> done_batch <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        <span class="token comment" spellcheck="true"># 数据分类存放到列表中</span>        <span class="token keyword">for</span> experience <span class="token keyword">in</span> mini_batch<span class="token punctuation">:</span>            s<span class="token punctuation">,</span> a<span class="token punctuation">,</span> r<span class="token punctuation">,</span> s_p<span class="token punctuation">,</span> done <span class="token operator">=</span> experience            obs_batch<span class="token punctuation">.</span>append<span class="token punctuation">(</span>s<span class="token punctuation">)</span>            action_batch<span class="token punctuation">.</span>append<span class="token punctuation">(</span>a<span class="token punctuation">)</span>            reward_batch<span class="token punctuation">.</span>append<span class="token punctuation">(</span>r<span class="token punctuation">)</span>            next_obs_batch<span class="token punctuation">.</span>append<span class="token punctuation">(</span>s_p<span class="token punctuation">)</span>            done_batch<span class="token punctuation">.</span>append<span class="token punctuation">(</span>done<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 返回分类存放一个batch数据的numpy数组</span>        <span class="token keyword">return</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>obs_batch<span class="token punctuation">)</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token string">'float32'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> \            np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>action_batch<span class="token punctuation">)</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token string">'float32'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>reward_batch<span class="token punctuation">)</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token string">'float32'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>\            np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>next_obs_batch<span class="token punctuation">)</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token string">'float32'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>done_batch<span class="token punctuation">)</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token string">'float32'</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> len<span class="token punctuation">(</span>self<span class="token punctuation">.</span>buffer<span class="token punctuation">)</span></code></pre><p>首先是模型model.py：</p><p>定义了3层的全连接网络，输入维数为1，输入为act_dim维。中间层分别是128和128个节点的全连接层。</p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> parl<span class="token keyword">from</span> parl<span class="token punctuation">.</span>core<span class="token punctuation">.</span>fluid <span class="token keyword">import</span> layers  <span class="token comment" spellcheck="true"># 封装了 paddle.fluid.layers 的API</span><span class="token keyword">class</span> <span class="token class-name">Model</span><span class="token punctuation">(</span>parl<span class="token punctuation">.</span>Model<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># 定义了网络的结构</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> act_dim<span class="token punctuation">)</span><span class="token punctuation">:</span>        hid1_size <span class="token operator">=</span> <span class="token number">128</span>        hid2_size <span class="token operator">=</span> <span class="token number">128</span>        <span class="token comment" spellcheck="true"># 3层全连接网络</span>        self<span class="token punctuation">.</span>fc1 <span class="token operator">=</span> layers<span class="token punctuation">.</span>fc<span class="token punctuation">(</span>size<span class="token operator">=</span>hid1_size<span class="token punctuation">,</span> act<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>fc2 <span class="token operator">=</span> layers<span class="token punctuation">.</span>fc<span class="token punctuation">(</span>size<span class="token operator">=</span>hid2_size<span class="token punctuation">,</span> act<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>fc3 <span class="token operator">=</span> layers<span class="token punctuation">.</span>fc<span class="token punctuation">(</span>size<span class="token operator">=</span>act_dim<span class="token punctuation">,</span> act<span class="token operator">=</span>None<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 决定了网络的输出</span>    <span class="token keyword">def</span> <span class="token function">value</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> obs<span class="token punctuation">)</span><span class="token punctuation">:</span>        h1 <span class="token operator">=</span> self<span class="token punctuation">.</span>fc1<span class="token punctuation">(</span>obs<span class="token punctuation">)</span>        h2 <span class="token operator">=</span> self<span class="token punctuation">.</span>fc2<span class="token punctuation">(</span>h1<span class="token punctuation">)</span>        Q <span class="token operator">=</span> self<span class="token punctuation">.</span>fc3<span class="token punctuation">(</span>h2<span class="token punctuation">)</span>        <span class="token keyword">return</span> Q</code></pre><p>algorithm.py，DQN算法的精髓：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> copy<span class="token keyword">import</span> paddle<span class="token punctuation">.</span>fluid <span class="token keyword">as</span> fluid<span class="token keyword">import</span> parl<span class="token keyword">from</span> parl<span class="token punctuation">.</span>core<span class="token punctuation">.</span>fluid <span class="token keyword">import</span> layers<span class="token keyword">class</span> <span class="token class-name">DQN</span><span class="token punctuation">(</span>parl<span class="token punctuation">.</span>Algorithm<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> model<span class="token punctuation">,</span> act_dim<span class="token operator">=</span>None<span class="token punctuation">,</span> gamma<span class="token operator">=</span>None<span class="token punctuation">,</span> lr<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">""" DQN algorithm            Args:            model (parl.Model): 定义Q函数的前向网络结构            act_dim (int): action空间的维度，即有几个action            gamma (float): reward的衰减因子            lr (float): learning_rate，学习率.        """</span>        self<span class="token punctuation">.</span>model <span class="token operator">=</span> model        <span class="token comment" spellcheck="true"># 复制一个一模一样的网络</span>        self<span class="token punctuation">.</span>target_model <span class="token operator">=</span> copy<span class="token punctuation">.</span>deepcopy<span class="token punctuation">(</span>model<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># assert插入调试断点到程序，这里用isinstance判断数据类型是否正确，否则抛出异常</span>        <span class="token keyword">assert</span> isinstance<span class="token punctuation">(</span>act_dim<span class="token punctuation">,</span> int<span class="token punctuation">)</span>        <span class="token keyword">assert</span> isinstance<span class="token punctuation">(</span>gamma<span class="token punctuation">,</span> float<span class="token punctuation">)</span>        <span class="token keyword">assert</span> isinstance<span class="token punctuation">(</span>lr<span class="token punctuation">,</span> float<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>act_dim <span class="token operator">=</span> act_dim        self<span class="token punctuation">.</span>gamma <span class="token operator">=</span> gamma        self<span class="token punctuation">.</span>lr <span class="token operator">=</span> lr    <span class="token comment" spellcheck="true"># 使用self.model的value网络来获取 [Q(s,a1),Q(s,a2),...]    </span>    <span class="token keyword">def</span> <span class="token function">predict</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> obs<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>value<span class="token punctuation">(</span>obs<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 使用DQN算法更新self.model的value网络,传进的参数是一个个数组，是一个batch中的数据，返回Loss</span>    <span class="token keyword">def</span> <span class="token function">learn</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> obs<span class="token punctuation">,</span> action<span class="token punctuation">,</span> reward<span class="token punctuation">,</span> next_obs<span class="token punctuation">,</span> terminal<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># 从target_model中获取 max Q' 的值，用于计算target_Q</span>        next_pred_value <span class="token operator">=</span> self<span class="token punctuation">.</span>target_model<span class="token punctuation">.</span>value<span class="token punctuation">(</span>next_obs<span class="token punctuation">)</span>        best_v <span class="token operator">=</span> layers<span class="token punctuation">.</span>reduce_max<span class="token punctuation">(</span>next_pred_value<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>        best_v<span class="token punctuation">.</span>stop_gradient <span class="token operator">=</span> <span class="token boolean">True</span>  <span class="token comment" spellcheck="true"># 阻止梯度传递，Target Model不需要训练</span>        terminal <span class="token operator">=</span> layers<span class="token punctuation">.</span>cast<span class="token punctuation">(</span>terminal<span class="token punctuation">,</span> dtype<span class="token operator">=</span><span class="token string">'float32'</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># bool变量转换成浮点数</span>        target <span class="token operator">=</span> reward <span class="token operator">+</span> <span class="token punctuation">(</span><span class="token number">1.0</span> <span class="token operator">-</span> terminal<span class="token punctuation">)</span> <span class="token operator">*</span> self<span class="token punctuation">.</span>gamma <span class="token operator">*</span> best_v  <span class="token comment" spellcheck="true"># 这样就可以把公式统一</span>        pred_value <span class="token operator">=</span> self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>value<span class="token punctuation">(</span>obs<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 获取Q预测值</span>        <span class="token comment" spellcheck="true"># 将action转onehot向量，比如：3 =&gt; [0,0,0,1,0]</span>        action_onehot <span class="token operator">=</span> layers<span class="token punctuation">.</span>one_hot<span class="token punctuation">(</span>action<span class="token punctuation">,</span> self<span class="token punctuation">.</span>act_dim<span class="token punctuation">)</span>        action_onehot <span class="token operator">=</span> layers<span class="token punctuation">.</span>cast<span class="token punctuation">(</span>action_onehot<span class="token punctuation">,</span> dtype<span class="token operator">=</span><span class="token string">'float32'</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 下面一行是逐元素相乘，拿到action对应的 Q(s,a)</span>        <span class="token comment" spellcheck="true"># 比如：pred_value = [[2.3, 5.7, 1.2, 3.9, 1.4]], action_onehot = [[0,0,0,1,0]]</span>        <span class="token comment" spellcheck="true">#  ==&gt; pred_action_value = [[3.9]]</span>        pred_action_value <span class="token operator">=</span> layers<span class="token punctuation">.</span>reduce_sum<span class="token punctuation">(</span>            layers<span class="token punctuation">.</span>elementwise_mul<span class="token punctuation">(</span>action_onehot<span class="token punctuation">,</span> pred_value<span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 计算 Q(s,a) 与 target_Q的均方差，得到loss</span>        cost <span class="token operator">=</span> layers<span class="token punctuation">.</span>square_error_cost<span class="token punctuation">(</span>pred_action_value<span class="token punctuation">,</span> target<span class="token punctuation">)</span>        cost <span class="token operator">=</span> layers<span class="token punctuation">.</span>reduce_mean<span class="token punctuation">(</span>cost<span class="token punctuation">)</span>        optimizer <span class="token operator">=</span> fluid<span class="token punctuation">.</span>optimizer<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>learning_rate<span class="token operator">=</span>self<span class="token punctuation">.</span>lr<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 使用Adam优化器</span>        optimizer<span class="token punctuation">.</span>minimize<span class="token punctuation">(</span>cost<span class="token punctuation">)</span>                                 <span class="token comment" spellcheck="true"># 训练</span>        <span class="token keyword">return</span> cost    <span class="token comment" spellcheck="true"># 把 self.model 的模型参数值同步到 self.target_model</span>    <span class="token keyword">def</span> <span class="token function">sync_target</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>sync_weights_to<span class="token punctuation">(</span>self<span class="token punctuation">.</span>target_model<span class="token punctuation">)</span></code></pre><p>我们看看程序是如何更新神经网络的，我们知道神经网络是代替存储Q表格的地方，首先，我们存在两个神经网络，一个输出预测值，一个输出目标值。首先我们需要通过Target Q网络计算输出的目标值，由于网络没有充分训练，这个值是不准确的。然后我们获取了Q网络的预测值，由于它也没有经过充分训练，这个预测值也是不准确的。虽然不准确，但是我们还是需要<strong>训练Q网络让预测值靠近依靠Target Q网络计算的目标值</strong>。这就是Learn函数做的事情。</p><p>agent.py：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> paddle<span class="token punctuation">.</span>fluid <span class="token keyword">as</span> fluid<span class="token keyword">import</span> parl<span class="token keyword">from</span> parl<span class="token punctuation">.</span>core<span class="token punctuation">.</span>fluid <span class="token keyword">import</span> layers<span class="token keyword">class</span> <span class="token class-name">Agent</span><span class="token punctuation">(</span>parl<span class="token punctuation">.</span>Agent<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>algorithm<span class="token punctuation">,</span>obs_dim<span class="token punctuation">,</span>act_dim<span class="token punctuation">,</span>e_greed<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">,</span>e_greed_decrement<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">assert</span> isinstance<span class="token punctuation">(</span>obs_dim<span class="token punctuation">,</span> int<span class="token punctuation">)</span>        <span class="token keyword">assert</span> isinstance<span class="token punctuation">(</span>act_dim<span class="token punctuation">,</span> int<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>obs_dim <span class="token operator">=</span> obs_dim        self<span class="token punctuation">.</span>act_dim <span class="token operator">=</span> act_dim        super<span class="token punctuation">(</span>Agent<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span>algorithm<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>global_step <span class="token operator">=</span> <span class="token number">0</span>        self<span class="token punctuation">.</span>update_target_steps <span class="token operator">=</span> <span class="token number">200</span>  <span class="token comment" spellcheck="true"># 每隔200个training steps再把model的参数复制到target_model中</span>        self<span class="token punctuation">.</span>e_greed <span class="token operator">=</span> e_greed  <span class="token comment" spellcheck="true"># 有一定概率随机选取动作，探索</span>        self<span class="token punctuation">.</span>e_greed_decrement <span class="token operator">=</span> e_greed_decrement  <span class="token comment" spellcheck="true"># 随着训练逐步收敛，探索的程度慢慢降低</span>    <span class="token keyword">def</span> <span class="token function">build_program</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>pred_program <span class="token operator">=</span> fluid<span class="token punctuation">.</span>Program<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>learn_program <span class="token operator">=</span> fluid<span class="token punctuation">.</span>Program<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">with</span> fluid<span class="token punctuation">.</span>program_guard<span class="token punctuation">(</span>self<span class="token punctuation">.</span>pred_program<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment" spellcheck="true"># 搭建计算图用于 预测动作，定义输入输出变量</span>            obs <span class="token operator">=</span> layers<span class="token punctuation">.</span>data<span class="token punctuation">(</span>                name<span class="token operator">=</span><span class="token string">'obs'</span><span class="token punctuation">,</span> shape<span class="token operator">=</span><span class="token punctuation">[</span>self<span class="token punctuation">.</span>obs_dim<span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span><span class="token string">'float32'</span><span class="token punctuation">)</span>            self<span class="token punctuation">.</span>value <span class="token operator">=</span> self<span class="token punctuation">.</span>alg<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>obs<span class="token punctuation">)</span>        <span class="token keyword">with</span> fluid<span class="token punctuation">.</span>program_guard<span class="token punctuation">(</span>self<span class="token punctuation">.</span>learn_program<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment" spellcheck="true"># 搭建计算图用于 更新Q网络，定义输入输出变量</span>            obs <span class="token operator">=</span> layers<span class="token punctuation">.</span>data<span class="token punctuation">(</span>                name<span class="token operator">=</span><span class="token string">'obs'</span><span class="token punctuation">,</span> shape<span class="token operator">=</span><span class="token punctuation">[</span>self<span class="token punctuation">.</span>obs_dim<span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span><span class="token string">'float32'</span><span class="token punctuation">)</span>            action <span class="token operator">=</span> layers<span class="token punctuation">.</span>data<span class="token punctuation">(</span>name<span class="token operator">=</span><span class="token string">'act'</span><span class="token punctuation">,</span> shape<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span><span class="token string">'int32'</span><span class="token punctuation">)</span>            reward <span class="token operator">=</span> layers<span class="token punctuation">.</span>data<span class="token punctuation">(</span>name<span class="token operator">=</span><span class="token string">'reward'</span><span class="token punctuation">,</span> shape<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span><span class="token string">'float32'</span><span class="token punctuation">)</span>            next_obs <span class="token operator">=</span> layers<span class="token punctuation">.</span>data<span class="token punctuation">(</span>                name<span class="token operator">=</span><span class="token string">'next_obs'</span><span class="token punctuation">,</span> shape<span class="token operator">=</span><span class="token punctuation">[</span>self<span class="token punctuation">.</span>obs_dim<span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span><span class="token string">'float32'</span><span class="token punctuation">)</span>            terminal <span class="token operator">=</span> layers<span class="token punctuation">.</span>data<span class="token punctuation">(</span>name<span class="token operator">=</span><span class="token string">'terminal'</span><span class="token punctuation">,</span> shape<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span><span class="token string">'bool'</span><span class="token punctuation">)</span>            self<span class="token punctuation">.</span>cost <span class="token operator">=</span> self<span class="token punctuation">.</span>alg<span class="token punctuation">.</span>learn<span class="token punctuation">(</span>obs<span class="token punctuation">,</span> action<span class="token punctuation">,</span> reward<span class="token punctuation">,</span> next_obs<span class="token punctuation">,</span> terminal<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">sample</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> obs<span class="token punctuation">)</span><span class="token punctuation">:</span>        sample <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 产生0~1之间的小数</span>        <span class="token keyword">if</span> sample <span class="token operator">&lt;</span> self<span class="token punctuation">.</span>e_greed<span class="token punctuation">:</span>            act <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span>self<span class="token punctuation">.</span>act_dim<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 探索：每个动作都有概率被选择</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            act <span class="token operator">=</span> self<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>obs<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 选择最优动作</span>        self<span class="token punctuation">.</span>e_greed <span class="token operator">=</span> max<span class="token punctuation">(</span>            <span class="token number">0.01</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>e_greed <span class="token operator">-</span> self<span class="token punctuation">.</span>e_greed_decrement<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 随着训练逐步收敛，探索的程度慢慢降低</span>        <span class="token keyword">return</span> act    <span class="token keyword">def</span> <span class="token function">predict</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> obs<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment" spellcheck="true"># 选择最优动作</span>        obs <span class="token operator">=</span> np<span class="token punctuation">.</span>expand_dims<span class="token punctuation">(</span>obs<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>        pred_Q <span class="token operator">=</span> self<span class="token punctuation">.</span>fluid_executor<span class="token punctuation">.</span>run<span class="token punctuation">(</span>            self<span class="token punctuation">.</span>pred_program<span class="token punctuation">,</span>            feed<span class="token operator">=</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;'obs': obs.astype('float32')&amp;#125;,</span>            fetch_list<span class="token operator">=</span><span class="token punctuation">[</span>self<span class="token punctuation">.</span>value<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>        pred_Q <span class="token operator">=</span> np<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span>pred_Q<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>        act <span class="token operator">=</span> np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>pred_Q<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 选择Q最大的下标，即对应的动作</span>        <span class="token keyword">return</span> act    <span class="token keyword">def</span> <span class="token function">learn</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> obs<span class="token punctuation">,</span> act<span class="token punctuation">,</span> reward<span class="token punctuation">,</span> next_obs<span class="token punctuation">,</span> terminal<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># 每隔200个training steps同步一次model和target_model的参数</span>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>global_step <span class="token operator">%</span> self<span class="token punctuation">.</span>update_target_steps <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>            self<span class="token punctuation">.</span>alg<span class="token punctuation">.</span>sync_target<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>global_step <span class="token operator">+=</span> <span class="token number">1</span>        act <span class="token operator">=</span> np<span class="token punctuation">.</span>expand_dims<span class="token punctuation">(</span>act<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        feed <span class="token operator">=</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>            <span class="token string">'obs'</span><span class="token punctuation">:</span> obs<span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token string">'float32'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token string">'act'</span><span class="token punctuation">:</span> act<span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token string">'int32'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token string">'reward'</span><span class="token punctuation">:</span> reward<span class="token punctuation">,</span>            <span class="token string">'next_obs'</span><span class="token punctuation">:</span> next_obs<span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token string">'float32'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token string">'terminal'</span><span class="token punctuation">:</span> terminal        <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;</span>        cost <span class="token operator">=</span> self<span class="token punctuation">.</span>fluid_executor<span class="token punctuation">.</span>run<span class="token punctuation">(</span>            self<span class="token punctuation">.</span>learn_program<span class="token punctuation">,</span> feed<span class="token operator">=</span>feed<span class="token punctuation">,</span> fetch_list<span class="token operator">=</span><span class="token punctuation">[</span>self<span class="token punctuation">.</span>cost<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>  <span class="token comment" spellcheck="true"># 训练一次网络</span>        <span class="token keyword">return</span> cost</code></pre><p>train.py:执行代码所在</p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> os<span class="token keyword">import</span> gym<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> parl<span class="token keyword">from</span> parl<span class="token punctuation">.</span>utils <span class="token keyword">import</span> logger  <span class="token comment" spellcheck="true"># 日志打印工具</span><span class="token keyword">from</span> model <span class="token keyword">import</span> Model<span class="token keyword">from</span> algorithm <span class="token keyword">import</span> DQN<span class="token comment" spellcheck="true">#from parl.algorithms import DQN</span><span class="token keyword">from</span> agent <span class="token keyword">import</span> Agent<span class="token keyword">from</span> replay_memory <span class="token keyword">import</span> ReplayMemoryLEARN_FREQ <span class="token operator">=</span> <span class="token number">5</span>  <span class="token comment" spellcheck="true"># 训练频率，不需要每一个step都learn，攒一些新增经验后再learn，提高效率</span>MEMORY_SIZE <span class="token operator">=</span> <span class="token number">20000</span>  <span class="token comment" spellcheck="true"># replay memory的大小，越大越占用内存</span>MEMORY_WARMUP_SIZE <span class="token operator">=</span> <span class="token number">200</span>  <span class="token comment" spellcheck="true"># replay_memory 里需要预存一些经验数据，再从里面sample一个batch的经验让agent去learn</span>BATCH_SIZE <span class="token operator">=</span> <span class="token number">32</span>  <span class="token comment" spellcheck="true"># 每次给agent learn的数据数量，从replay memory随机里sample一批数据出来</span>LEARNING_RATE <span class="token operator">=</span> <span class="token number">0.001</span>  <span class="token comment" spellcheck="true"># 学习率</span>GAMMA <span class="token operator">=</span> <span class="token number">0.99</span>  <span class="token comment" spellcheck="true"># reward 的衰减因子，一般取 0.9 到 0.999 不等</span><span class="token comment" spellcheck="true"># 训练一个episode</span><span class="token keyword">def</span> <span class="token function">run_episode</span><span class="token punctuation">(</span>env<span class="token punctuation">,</span> agent<span class="token punctuation">,</span> rpm<span class="token punctuation">)</span><span class="token punctuation">:</span>    total_reward <span class="token operator">=</span> <span class="token number">0</span>    obs <span class="token operator">=</span> env<span class="token punctuation">.</span>reset<span class="token punctuation">(</span><span class="token punctuation">)</span>    step <span class="token operator">=</span> <span class="token number">0</span>    <span class="token keyword">while</span> <span class="token boolean">True</span><span class="token punctuation">:</span>        step <span class="token operator">+=</span> <span class="token number">1</span>        action <span class="token operator">=</span> agent<span class="token punctuation">.</span>sample<span class="token punctuation">(</span>obs<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 采样动作，所有动作都有概率被尝试到</span>        next_obs<span class="token punctuation">,</span> reward<span class="token punctuation">,</span> done<span class="token punctuation">,</span> _ <span class="token operator">=</span> env<span class="token punctuation">.</span>step<span class="token punctuation">(</span>action<span class="token punctuation">)</span>        rpm<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">(</span>obs<span class="token punctuation">,</span> action<span class="token punctuation">,</span> reward<span class="token punctuation">,</span> next_obs<span class="token punctuation">,</span> done<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># train model</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span>len<span class="token punctuation">(</span>rpm<span class="token punctuation">)</span> <span class="token operator">&gt;</span> MEMORY_WARMUP_SIZE<span class="token punctuation">)</span> <span class="token operator">and</span> <span class="token punctuation">(</span>step <span class="token operator">%</span> LEARN_FREQ <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token punctuation">(</span>batch_obs<span class="token punctuation">,</span> batch_action<span class="token punctuation">,</span> batch_reward<span class="token punctuation">,</span> batch_next_obs<span class="token punctuation">,</span>             batch_done<span class="token punctuation">)</span> <span class="token operator">=</span> rpm<span class="token punctuation">.</span>sample<span class="token punctuation">(</span>BATCH_SIZE<span class="token punctuation">)</span>            train_loss <span class="token operator">=</span> agent<span class="token punctuation">.</span>learn<span class="token punctuation">(</span>batch_obs<span class="token punctuation">,</span> batch_action<span class="token punctuation">,</span> batch_reward<span class="token punctuation">,</span>                                     batch_next_obs<span class="token punctuation">,</span>                                     batch_done<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># s,a,r,s',done</span>        total_reward <span class="token operator">+=</span> reward        obs <span class="token operator">=</span> next_obs        <span class="token keyword">if</span> done<span class="token punctuation">:</span>            <span class="token keyword">break</span>    <span class="token keyword">return</span> total_reward<span class="token comment" spellcheck="true"># 评估 agent, 跑 5 个episode，总reward求平均</span><span class="token keyword">def</span> <span class="token function">evaluate</span><span class="token punctuation">(</span>env<span class="token punctuation">,</span> agent<span class="token punctuation">,</span> render<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    eval_reward <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        obs <span class="token operator">=</span> env<span class="token punctuation">.</span>reset<span class="token punctuation">(</span><span class="token punctuation">)</span>        episode_reward <span class="token operator">=</span> <span class="token number">0</span>        <span class="token keyword">while</span> <span class="token boolean">True</span><span class="token punctuation">:</span>            action <span class="token operator">=</span> agent<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>obs<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 预测动作，只选最优动作</span>            obs<span class="token punctuation">,</span> reward<span class="token punctuation">,</span> done<span class="token punctuation">,</span> _ <span class="token operator">=</span> env<span class="token punctuation">.</span>step<span class="token punctuation">(</span>action<span class="token punctuation">)</span>            episode_reward <span class="token operator">+=</span> reward            <span class="token keyword">if</span> render<span class="token punctuation">:</span>                env<span class="token punctuation">.</span>render<span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token keyword">if</span> done<span class="token punctuation">:</span>                <span class="token keyword">break</span>        eval_reward<span class="token punctuation">.</span>append<span class="token punctuation">(</span>episode_reward<span class="token punctuation">)</span>    <span class="token keyword">return</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>eval_reward<span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    env <span class="token operator">=</span> gym<span class="token punctuation">.</span>make<span class="token punctuation">(</span>        <span class="token string">'CartPole-v0'</span>    <span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># CartPole-v0: expected reward &gt; 180                MountainCar-v0 : expected reward &gt; -120</span>    action_dim <span class="token operator">=</span> env<span class="token punctuation">.</span>action_space<span class="token punctuation">.</span>n  <span class="token comment" spellcheck="true"># CartPole-v0: 2</span>    obs_shape <span class="token operator">=</span> env<span class="token punctuation">.</span>observation_space<span class="token punctuation">.</span>shape  <span class="token comment" spellcheck="true"># CartPole-v0: (4,)</span>    rpm <span class="token operator">=</span> ReplayMemory<span class="token punctuation">(</span>MEMORY_SIZE<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># DQN的经验回放池</span>    <span class="token comment" spellcheck="true"># 根据parl框架构建agent</span>    model <span class="token operator">=</span> Model<span class="token punctuation">(</span>act_dim<span class="token operator">=</span>action_dim<span class="token punctuation">)</span>    algorithm <span class="token operator">=</span> DQN<span class="token punctuation">(</span>model<span class="token punctuation">,</span> act_dim<span class="token operator">=</span>action_dim<span class="token punctuation">,</span> gamma<span class="token operator">=</span>GAMMA<span class="token punctuation">,</span> lr<span class="token operator">=</span>LEARNING_RATE<span class="token punctuation">)</span>    agent <span class="token operator">=</span> Agent<span class="token punctuation">(</span>        algorithm<span class="token punctuation">,</span>        obs_dim<span class="token operator">=</span>obs_shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        act_dim<span class="token operator">=</span>action_dim<span class="token punctuation">,</span>        e_greed<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">,</span>  <span class="token comment" spellcheck="true"># 有一定概率随机选取动作，探索</span>        e_greed_decrement<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">6</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 随着训练逐步收敛，探索的程度慢慢降低</span>    <span class="token comment" spellcheck="true"># 加载模型</span>    <span class="token comment" spellcheck="true"># save_path = './dqn_model.ckpt'</span>    <span class="token comment" spellcheck="true"># agent.restore(save_path)</span>    <span class="token comment" spellcheck="true"># 先往经验池里存一些数据，避免最开始训练的时候样本丰富度不够</span>    <span class="token keyword">while</span> len<span class="token punctuation">(</span>rpm<span class="token punctuation">)</span> <span class="token operator">&lt;</span> MEMORY_WARMUP_SIZE<span class="token punctuation">:</span>        run_episode<span class="token punctuation">(</span>env<span class="token punctuation">,</span> agent<span class="token punctuation">,</span> rpm<span class="token punctuation">)</span>    max_episode <span class="token operator">=</span> <span class="token number">2000</span>    <span class="token comment" spellcheck="true"># start train</span>    episode <span class="token operator">=</span> <span class="token number">0</span>    <span class="token keyword">while</span> episode <span class="token operator">&lt;</span> max_episode<span class="token punctuation">:</span>  <span class="token comment" spellcheck="true"># 训练max_episode个回合，test部分不计算入episode数量</span>        <span class="token comment" spellcheck="true"># train part</span>        <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">50</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            total_reward <span class="token operator">=</span> run_episode<span class="token punctuation">(</span>env<span class="token punctuation">,</span> agent<span class="token punctuation">,</span> rpm<span class="token punctuation">)</span>            episode <span class="token operator">+=</span> <span class="token number">1</span>        <span class="token comment" spellcheck="true"># test part</span>        eval_reward <span class="token operator">=</span> evaluate<span class="token punctuation">(</span>env<span class="token punctuation">,</span> agent<span class="token punctuation">,</span> render<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># render=True 查看显示效果</span>        logger<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token string">'episode:&amp;#123;&amp;#125;    e_greed:&amp;#123;&amp;#125;   Test reward:&amp;#123;&amp;#125;'</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>            episode<span class="token punctuation">,</span> agent<span class="token punctuation">.</span>e_greed<span class="token punctuation">,</span> eval_reward<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 训练结束，保存模型</span>    save_path <span class="token operator">=</span> <span class="token string">'./dqn_model.ckpt'</span>    agent<span class="token punctuation">.</span>save<span class="token punctuation">(</span>save_path<span class="token punctuation">)</span><span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>    main<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><p><strong>由于库的版本问题，我这里是运行失败的，原因是parl没有layers这个类。。。所以这里我只知道一些实现思路，如果知道新版的代码写法，可以联系我。</strong></p><h2 id="CartPole"><a href="#CartPole" class="headerlink" title="CartPole"></a>CartPole</h2><p>CartPole的环境相当于强化学习中的“Hello World”，是最基础的环境，任何强化学习算法都可以在上面运行并测试是否收敛。</p><img src="/2021/07/16/qiang-hua-xue-xi-shi-jian-jiao-xue/31.png" class=""><h3 id="PARL常用API"><a href="#PARL常用API" class="headerlink" title="PARL常用API"></a>PARL常用API</h3><img src="/2021/07/16/qiang-hua-xue-xi-shi-jian-jiao-xue/32.png" class=""><img src="/2021/07/16/qiang-hua-xue-xi-shi-jian-jiao-xue/33.png" class=""><h3 id=""><a href="#" class="headerlink" title=""></a></h3><h2 id="基于策略梯度求解RL"><a href="#基于策略梯度求解RL" class="headerlink" title="基于策略梯度求解RL"></a>基于策略梯度求解RL</h2><p>  上面我们所学的是value-based，通过探索将Q价值更新到最优，然后根据Q价值来选择最优的动作。下面我们讲policy-based，动作选择不再依赖价值函数，而是根据一个策略走到底，看最后的总收益决定算法好坏，好Action将在以后有更大的概率被随机到。</p><img src="/2021/07/16/qiang-hua-xue-xi-shi-jian-jiao-xue/34.png" class=""><img src="/2021/07/16/qiang-hua-xue-xi-shi-jian-jiao-xue/35.png" class=""><img src="/2021/07/16/qiang-hua-xue-xi-shi-jian-jiao-xue/36.png" class=""><img src="/2021/07/16/qiang-hua-xue-xi-shi-jian-jiao-xue/37.png" class=""><p>可以看到，智能体通过直接输出一个动作选择的概率来选择下一步的action，这个策略是可以优化的，但是执行一个action之后有多种状态的可能性，这也就是环境的随机性。不断输出动作到新的状态到游戏结束称为完成一个episode，这一串的交互称为一个episode的轨迹（Trajectory）。</p><img src="/2021/07/16/qiang-hua-xue-xi-shi-jian-jiao-xue/38.png" class=""><p><strong>期望回报</strong>是穷举所有在该策略下的轨迹能拿到的回报（Reward）的平均值，在实际运用中我们无法穷举，也不能得出状态转移概率，但是我们可以通过运行多个episode然后将得到的reward取平均近似认为是期望回报。</p><p>由于我们没有label对我们的网络进行更新，这时候就需要利用我们的期望回报了，我们通过梯度上升法使得我们的reward变大，那么就能使得策略变好，经过推导可以得出我们更新的梯度公式如下：</p><img src="/2021/07/16/qiang-hua-xue-xi-shi-jian-jiao-xue/39.png" class=""><h3 id="蒙特卡洛（MC）和时序差分（TD）"><a href="#蒙特卡洛（MC）和时序差分（TD）" class="headerlink" title="蒙特卡洛（MC）和时序差分（TD）"></a>蒙特卡洛（MC）和时序差分（TD）</h3><img src="/2021/07/16/qiang-hua-xue-xi-shi-jian-jiao-xue/40.png" class=""><p>蒙特卡洛是完成一个episode之后，再做一次更新，其中$G_t$指的是在一个step之后能拿到的总收益之和。而时序差分指的是每一个step都更新数据。用的是Q function来近似表示总收益。</p><img src="/2021/07/16/qiang-hua-xue-xi-shi-jian-jiao-xue/41.png" class=""><img src="/2021/07/16/qiang-hua-xue-xi-shi-jian-jiao-xue/45.png" class=""><img src="/2021/07/16/qiang-hua-xue-xi-shi-jian-jiao-xue/42.png" class=""><h3 id="Policy-Gradient"><a href="#Policy-Gradient" class="headerlink" title="Policy Gradient"></a>Policy Gradient</h3><p>重点来了！！！我们使用的更新方式是Policy Gradient，也就是策略梯度，我们的loss依旧通过交叉熵方式获得，但还需要乘以一个$G_t$作为权重，也就是我们<strong>计算出来的总收益</strong>！总收益越高的说明我们的决策越好，$G_t$越大，我网络会用较大的梯度来进行更新，反之$G_t$较小则用小梯度更新。这样进行多次更新之后，我们网络算出来的决策就会越来越趋近于好的决策。</p><p>对于离散的动作，我们直接采用价值计算的原始公式，然后用梯度上升法即可，具体操作可以用蒙泰卡罗采样的方法代替：</p><img src="/2021/07/16/qiang-hua-xue-xi-shi-jian-jiao-xue/61.png" class=""><p>对于连续动作（对于离散动作同样适用），例如代码中的例子：</p><img src="/2021/07/16/qiang-hua-xue-xi-shi-jian-jiao-xue/62.png" class=""><p>总结：</p><img src="/2021/07/16/qiang-hua-xue-xi-shi-jian-jiao-xue/63.png" class=""><p>其中对于每个动作价值Q的计算都是在完成一个episode之后，利用带折扣的Reward从后往前进行计算的。还有一种就是利用神经网络来近似价值函数的方法，称为Actor-Critic。</p><h3 id="-1"><a href="#-1" class="headerlink" title=""></a></h3><p>对应代码：</p><pre class=" language-python"><code class="language-python">    <span class="token keyword">def</span> <span class="token function">learn</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> obs<span class="token punctuation">,</span> action<span class="token punctuation">,</span> reward<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">""" 用policy gradient 算法更新policy model        """</span>        act_prob <span class="token operator">=</span> self<span class="token punctuation">.</span>model<span class="token punctuation">(</span>obs<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 获取输出动作概率</span>        <span class="token comment" spellcheck="true"># log_prob = layers.cross_entropy(act_prob, action) # 交叉熵</span>        log_prob <span class="token operator">=</span> layers<span class="token punctuation">.</span>reduce_sum<span class="token punctuation">(</span>            <span class="token operator">-</span><span class="token number">1.0</span> <span class="token operator">*</span> layers<span class="token punctuation">.</span>log<span class="token punctuation">(</span>act_prob<span class="token punctuation">)</span> <span class="token operator">*</span> layers<span class="token punctuation">.</span>one_hot<span class="token punctuation">(</span>                action<span class="token punctuation">,</span> act_prob<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>        cost <span class="token operator">=</span> log_prob <span class="token operator">*</span> reward        cost <span class="token operator">=</span> layers<span class="token punctuation">.</span>reduce_mean<span class="token punctuation">(</span>cost<span class="token punctuation">)</span>        optimizer <span class="token operator">=</span> fluid<span class="token punctuation">.</span>optimizer<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>self<span class="token punctuation">.</span>lr<span class="token punctuation">)</span>        optimizer<span class="token punctuation">.</span>minimize<span class="token punctuation">(</span>cost<span class="token punctuation">)</span>        <span class="token keyword">return</span> cost</code></pre><h3 id="流程及代码："><a href="#流程及代码：" class="headerlink" title="流程及代码："></a>流程及代码：</h3><img src="/2021/07/16/qiang-hua-xue-xi-shi-jian-jiao-xue/43.png" class=""><img src="/2021/07/16/qiang-hua-xue-xi-shi-jian-jiao-xue/44.png" class=""><p>model.py：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> parl<span class="token keyword">from</span> parl <span class="token keyword">import</span> layers<span class="token keyword">class</span> <span class="token class-name">Model</span><span class="token punctuation">(</span>parl<span class="token punctuation">.</span>Model<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> act_dim<span class="token punctuation">)</span><span class="token punctuation">:</span>        act_dim <span class="token operator">=</span> act_dim        hid1_size <span class="token operator">=</span> act_dim <span class="token operator">*</span> <span class="token number">10</span>        self<span class="token punctuation">.</span>fc1 <span class="token operator">=</span> layers<span class="token punctuation">.</span>fc<span class="token punctuation">(</span>size<span class="token operator">=</span>hid1_size<span class="token punctuation">,</span> act<span class="token operator">=</span><span class="token string">'tanh'</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>fc2 <span class="token operator">=</span> layers<span class="token punctuation">.</span>fc<span class="token punctuation">(</span>size<span class="token operator">=</span>act_dim<span class="token punctuation">,</span> act<span class="token operator">=</span><span class="token string">'softmax'</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> obs<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment" spellcheck="true"># 可直接用 model = Model(5); model(obs)调用</span>        out <span class="token operator">=</span> self<span class="token punctuation">.</span>fc1<span class="token punctuation">(</span>obs<span class="token punctuation">)</span>        out <span class="token operator">=</span> self<span class="token punctuation">.</span>fc2<span class="token punctuation">(</span>out<span class="token punctuation">)</span>        <span class="token keyword">return</span> out</code></pre><p>algorithm.py：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> paddle<span class="token punctuation">.</span>fluid <span class="token keyword">as</span> fluid<span class="token keyword">import</span> parl<span class="token keyword">from</span> parl <span class="token keyword">import</span> layers<span class="token keyword">class</span> <span class="token class-name">PolicyGradient</span><span class="token punctuation">(</span>parl<span class="token punctuation">.</span>Algorithm<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> model<span class="token punctuation">,</span> lr<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>model <span class="token operator">=</span> model        <span class="token keyword">assert</span> isinstance<span class="token punctuation">(</span>lr<span class="token punctuation">,</span> float<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>lr <span class="token operator">=</span> lr    <span class="token keyword">def</span> <span class="token function">predict</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> obs<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">""" 使用policy model预测输出的动作概率        """</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>model<span class="token punctuation">(</span>obs<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">learn</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> obs<span class="token punctuation">,</span> action<span class="token punctuation">,</span> reward<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">""" 用policy gradient 算法更新policy model        """</span>        act_prob <span class="token operator">=</span> self<span class="token punctuation">.</span>model<span class="token punctuation">(</span>obs<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 获取输出动作概率</span>        <span class="token comment" spellcheck="true"># log_prob = layers.cross_entropy(act_prob, action) # 交叉熵</span>        log_prob <span class="token operator">=</span> layers<span class="token punctuation">.</span>reduce_sum<span class="token punctuation">(</span>            <span class="token operator">-</span><span class="token number">1.0</span> <span class="token operator">*</span> layers<span class="token punctuation">.</span>log<span class="token punctuation">(</span>act_prob<span class="token punctuation">)</span> <span class="token operator">*</span> layers<span class="token punctuation">.</span>one_hot<span class="token punctuation">(</span>                action<span class="token punctuation">,</span> act_prob<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>        cost <span class="token operator">=</span> log_prob <span class="token operator">*</span> reward        cost <span class="token operator">=</span> layers<span class="token punctuation">.</span>reduce_mean<span class="token punctuation">(</span>cost<span class="token punctuation">)</span>        optimizer <span class="token operator">=</span> fluid<span class="token punctuation">.</span>optimizer<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>self<span class="token punctuation">.</span>lr<span class="token punctuation">)</span>        optimizer<span class="token punctuation">.</span>minimize<span class="token punctuation">(</span>cost<span class="token punctuation">)</span>        <span class="token keyword">return</span> cost</code></pre><p>agent.py：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> paddle<span class="token punctuation">.</span>fluid <span class="token keyword">as</span> fluid<span class="token keyword">import</span> parl<span class="token keyword">from</span> parl <span class="token keyword">import</span> layers<span class="token keyword">class</span> <span class="token class-name">Agent</span><span class="token punctuation">(</span>parl<span class="token punctuation">.</span>Agent<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> algorithm<span class="token punctuation">,</span> obs_dim<span class="token punctuation">,</span> act_dim<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>obs_dim <span class="token operator">=</span> obs_dim        self<span class="token punctuation">.</span>act_dim <span class="token operator">=</span> act_dim        super<span class="token punctuation">(</span>Agent<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span>algorithm<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">build_program</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>pred_program <span class="token operator">=</span> fluid<span class="token punctuation">.</span>Program<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>learn_program <span class="token operator">=</span> fluid<span class="token punctuation">.</span>Program<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">with</span> fluid<span class="token punctuation">.</span>program_guard<span class="token punctuation">(</span>self<span class="token punctuation">.</span>pred_program<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment" spellcheck="true"># 搭建计算图用于 预测动作，定义输入输出变量</span>            obs <span class="token operator">=</span> layers<span class="token punctuation">.</span>data<span class="token punctuation">(</span>                name<span class="token operator">=</span><span class="token string">'obs'</span><span class="token punctuation">,</span> shape<span class="token operator">=</span><span class="token punctuation">[</span>self<span class="token punctuation">.</span>obs_dim<span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span><span class="token string">'float32'</span><span class="token punctuation">)</span>            self<span class="token punctuation">.</span>act_prob <span class="token operator">=</span> self<span class="token punctuation">.</span>alg<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>obs<span class="token punctuation">)</span>        <span class="token keyword">with</span> fluid<span class="token punctuation">.</span>program_guard<span class="token punctuation">(</span>                self<span class="token punctuation">.</span>learn_program<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment" spellcheck="true"># 搭建计算图用于 更新policy网络，定义输入输出变量</span>            obs <span class="token operator">=</span> layers<span class="token punctuation">.</span>data<span class="token punctuation">(</span>                name<span class="token operator">=</span><span class="token string">'obs'</span><span class="token punctuation">,</span> shape<span class="token operator">=</span><span class="token punctuation">[</span>self<span class="token punctuation">.</span>obs_dim<span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span><span class="token string">'float32'</span><span class="token punctuation">)</span>            act <span class="token operator">=</span> layers<span class="token punctuation">.</span>data<span class="token punctuation">(</span>name<span class="token operator">=</span><span class="token string">'act'</span><span class="token punctuation">,</span> shape<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span><span class="token string">'int64'</span><span class="token punctuation">)</span>            reward <span class="token operator">=</span> layers<span class="token punctuation">.</span>data<span class="token punctuation">(</span>name<span class="token operator">=</span><span class="token string">'reward'</span><span class="token punctuation">,</span> shape<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span><span class="token string">'float32'</span><span class="token punctuation">)</span>            self<span class="token punctuation">.</span>cost <span class="token operator">=</span> self<span class="token punctuation">.</span>alg<span class="token punctuation">.</span>learn<span class="token punctuation">(</span>obs<span class="token punctuation">,</span> act<span class="token punctuation">,</span> reward<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">sample</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> obs<span class="token punctuation">)</span><span class="token punctuation">:</span>        obs <span class="token operator">=</span> np<span class="token punctuation">.</span>expand_dims<span class="token punctuation">(</span>obs<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 增加一维维度</span>        act_prob <span class="token operator">=</span> self<span class="token punctuation">.</span>fluid_executor<span class="token punctuation">.</span>run<span class="token punctuation">(</span>            self<span class="token punctuation">.</span>pred_program<span class="token punctuation">,</span>            feed<span class="token operator">=</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;'obs': obs.astype('float32')&amp;#125;,</span>            fetch_list<span class="token operator">=</span><span class="token punctuation">[</span>self<span class="token punctuation">.</span>act_prob<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>        act_prob <span class="token operator">=</span> np<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span>act_prob<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 减少一维维度</span>        act <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>choice<span class="token punctuation">(</span>range<span class="token punctuation">(</span>self<span class="token punctuation">.</span>act_dim<span class="token punctuation">)</span><span class="token punctuation">,</span> p<span class="token operator">=</span>act_prob<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 根据动作概率选取动作</span>        <span class="token keyword">return</span> act    <span class="token keyword">def</span> <span class="token function">predict</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> obs<span class="token punctuation">)</span><span class="token punctuation">:</span>        obs <span class="token operator">=</span> np<span class="token punctuation">.</span>expand_dims<span class="token punctuation">(</span>obs<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>        act_prob <span class="token operator">=</span> self<span class="token punctuation">.</span>fluid_executor<span class="token punctuation">.</span>run<span class="token punctuation">(</span>            self<span class="token punctuation">.</span>pred_program<span class="token punctuation">,</span>            feed<span class="token operator">=</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;'obs': obs.astype('float32')&amp;#125;,</span>            fetch_list<span class="token operator">=</span><span class="token punctuation">[</span>self<span class="token punctuation">.</span>act_prob<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>        act_prob <span class="token operator">=</span> np<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span>act_prob<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>        act <span class="token operator">=</span> np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>act_prob<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 根据动作概率选择概率最高的动作</span>        <span class="token keyword">return</span> act    <span class="token keyword">def</span> <span class="token function">learn</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> obs<span class="token punctuation">,</span> act<span class="token punctuation">,</span> reward<span class="token punctuation">)</span><span class="token punctuation">:</span>        act <span class="token operator">=</span> np<span class="token punctuation">.</span>expand_dims<span class="token punctuation">(</span>act<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        feed <span class="token operator">=</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>            <span class="token string">'obs'</span><span class="token punctuation">:</span> obs<span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token string">'float32'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token string">'act'</span><span class="token punctuation">:</span> act<span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token string">'int64'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token string">'reward'</span><span class="token punctuation">:</span> reward<span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token string">'float32'</span><span class="token punctuation">)</span>        <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;</span>        cost <span class="token operator">=</span> self<span class="token punctuation">.</span>fluid_executor<span class="token punctuation">.</span>run<span class="token punctuation">(</span>            self<span class="token punctuation">.</span>learn_program<span class="token punctuation">,</span> feed<span class="token operator">=</span>feed<span class="token punctuation">,</span> fetch_list<span class="token operator">=</span><span class="token punctuation">[</span>self<span class="token punctuation">.</span>cost<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>        <span class="token keyword">return</span> cost</code></pre><p>train.py：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> gym<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> parl<span class="token keyword">from</span> agent <span class="token keyword">import</span> Agent<span class="token keyword">from</span> model <span class="token keyword">import</span> Model<span class="token keyword">from</span> algorithm <span class="token keyword">import</span> PolicyGradient  <span class="token comment" spellcheck="true"># from parl.algorithms import PolicyGradient</span><span class="token keyword">from</span> parl<span class="token punctuation">.</span>utils <span class="token keyword">import</span> loggerLEARNING_RATE <span class="token operator">=</span> <span class="token number">1e</span><span class="token operator">-</span><span class="token number">3</span><span class="token comment" spellcheck="true"># 训练一个episode</span><span class="token keyword">def</span> <span class="token function">run_episode</span><span class="token punctuation">(</span>env<span class="token punctuation">,</span> agent<span class="token punctuation">)</span><span class="token punctuation">:</span>    obs_list<span class="token punctuation">,</span> action_list<span class="token punctuation">,</span> reward_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    obs <span class="token operator">=</span> env<span class="token punctuation">.</span>reset<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">while</span> <span class="token boolean">True</span><span class="token punctuation">:</span>        obs_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>obs<span class="token punctuation">)</span>        action <span class="token operator">=</span> agent<span class="token punctuation">.</span>sample<span class="token punctuation">(</span>obs<span class="token punctuation">)</span>        action_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>action<span class="token punctuation">)</span>        obs<span class="token punctuation">,</span> reward<span class="token punctuation">,</span> done<span class="token punctuation">,</span> info <span class="token operator">=</span> env<span class="token punctuation">.</span>step<span class="token punctuation">(</span>action<span class="token punctuation">)</span>        reward_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>reward<span class="token punctuation">)</span>        <span class="token keyword">if</span> done<span class="token punctuation">:</span>            <span class="token keyword">break</span>    <span class="token keyword">return</span> obs_list<span class="token punctuation">,</span> action_list<span class="token punctuation">,</span> reward_list<span class="token comment" spellcheck="true"># 评估 agent, 跑 5 个episode，总reward求平均</span><span class="token keyword">def</span> <span class="token function">evaluate</span><span class="token punctuation">(</span>env<span class="token punctuation">,</span> agent<span class="token punctuation">,</span> render<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    eval_reward <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        obs <span class="token operator">=</span> env<span class="token punctuation">.</span>reset<span class="token punctuation">(</span><span class="token punctuation">)</span>        episode_reward <span class="token operator">=</span> <span class="token number">0</span>        <span class="token keyword">while</span> <span class="token boolean">True</span><span class="token punctuation">:</span>            action <span class="token operator">=</span> agent<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>obs<span class="token punctuation">)</span>            obs<span class="token punctuation">,</span> reward<span class="token punctuation">,</span> isOver<span class="token punctuation">,</span> _ <span class="token operator">=</span> env<span class="token punctuation">.</span>step<span class="token punctuation">(</span>action<span class="token punctuation">)</span>            episode_reward <span class="token operator">+=</span> reward            <span class="token keyword">if</span> render<span class="token punctuation">:</span>                env<span class="token punctuation">.</span>render<span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token keyword">if</span> isOver<span class="token punctuation">:</span>                <span class="token keyword">break</span>        eval_reward<span class="token punctuation">.</span>append<span class="token punctuation">(</span>episode_reward<span class="token punctuation">)</span>    <span class="token keyword">return</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>eval_reward<span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">calc_reward_to_go</span><span class="token punctuation">(</span>reward_list<span class="token punctuation">,</span> gamma<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>len<span class="token punctuation">(</span>reward_list<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># G_i = r_i + γ·G_i+1</span>        reward_list<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">+=</span> gamma <span class="token operator">*</span> reward_list<span class="token punctuation">[</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span>  <span class="token comment" spellcheck="true"># Gt</span>    <span class="token keyword">return</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>reward_list<span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    env <span class="token operator">=</span> gym<span class="token punctuation">.</span>make<span class="token punctuation">(</span><span class="token string">'CartPole-v0'</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># env = env.unwrapped # Cancel the minimum score limit</span>    obs_dim <span class="token operator">=</span> env<span class="token punctuation">.</span>observation_space<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>    act_dim <span class="token operator">=</span> env<span class="token punctuation">.</span>action_space<span class="token punctuation">.</span>n    logger<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token string">'obs_dim &amp;#123;&amp;#125;, act_dim &amp;#123;&amp;#125;'</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>obs_dim<span class="token punctuation">,</span> act_dim<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 根据parl框架构建agent</span>    model <span class="token operator">=</span> Model<span class="token punctuation">(</span>act_dim<span class="token operator">=</span>act_dim<span class="token punctuation">)</span>    alg <span class="token operator">=</span> PolicyGradient<span class="token punctuation">(</span>model<span class="token punctuation">,</span> lr<span class="token operator">=</span>LEARNING_RATE<span class="token punctuation">)</span>    agent <span class="token operator">=</span> Agent<span class="token punctuation">(</span>alg<span class="token punctuation">,</span> obs_dim<span class="token operator">=</span>obs_dim<span class="token punctuation">,</span> act_dim<span class="token operator">=</span>act_dim<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 加载模型</span>    <span class="token comment" spellcheck="true"># if os.path.exists('./model.ckpt'):</span>    <span class="token comment" spellcheck="true">#     agent.restore('./model.ckpt')</span>    <span class="token comment" spellcheck="true">#     run_episode(env, agent, train_or_test='test', render=True)</span>    <span class="token comment" spellcheck="true">#     exit()</span>    <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        obs_list<span class="token punctuation">,</span> action_list<span class="token punctuation">,</span> reward_list <span class="token operator">=</span> run_episode<span class="token punctuation">(</span>env<span class="token punctuation">,</span> agent<span class="token punctuation">)</span>        <span class="token keyword">if</span> i <span class="token operator">%</span> <span class="token number">10</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>            logger<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token string">"Episode &amp;#123;&amp;#125;, Reward Sum &amp;#123;&amp;#125;."</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>                i<span class="token punctuation">,</span> sum<span class="token punctuation">(</span>reward_list<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        batch_obs <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>obs_list<span class="token punctuation">)</span>        batch_action <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>action_list<span class="token punctuation">)</span>        batch_reward <span class="token operator">=</span> calc_reward_to_go<span class="token punctuation">(</span>reward_list<span class="token punctuation">)</span>        agent<span class="token punctuation">.</span>learn<span class="token punctuation">(</span>batch_obs<span class="token punctuation">,</span> batch_action<span class="token punctuation">,</span> batch_reward<span class="token punctuation">)</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">%</span> <span class="token number">100</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>            total_reward <span class="token operator">=</span> evaluate<span class="token punctuation">(</span>env<span class="token punctuation">,</span> agent<span class="token punctuation">,</span> render<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>            logger<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token string">'Test reward: &amp;#123;&amp;#125;'</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>total_reward<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># save the parameters to ./model.ckpt</span>    agent<span class="token punctuation">.</span>save<span class="token punctuation">(</span><span class="token string">'./model.ckpt'</span><span class="token punctuation">)</span><span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>    main<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><p>由于库的版本问题，这里依旧没有运行成功。</p><h2 id="连续动作空间上求解RL"><a href="#连续动作空间上求解RL" class="headerlink" title="连续动作空间上求解RL"></a>连续动作空间上求解RL</h2><h3 id="离散动作和连续动作"><a href="#离散动作和连续动作" class="headerlink" title="离散动作和连续动作"></a>离散动作和连续动作</h3><img src="/2021/07/16/qiang-hua-xue-xi-shi-jian-jiao-xue/46.png" class=""><p>在连续动作空间的求解中，前面讲的Sarsa，DQN，Q-learning，Reinforce都是没有办法处理的。这时候我们就需要用神经网络的输出代表一个动作的“幅度”，而不是单纯决定做某个动作。例如我们可以用一个-1到1的输出来控制小车的速度，正数是前进，负数是后退，绝对值越大速度越快。</p><img src="/2021/07/16/qiang-hua-xue-xi-shi-jian-jiao-xue/47.png" class=""><h3 id="DDPG（Deep-Deterministic-Policy-Gradient）"><a href="#DDPG（Deep-Deterministic-Policy-Gradient）" class="headerlink" title="DDPG（Deep Deterministic Policy Gradient）"></a>DDPG（Deep Deterministic Policy Gradient）</h3><p>DDPG借鉴了DQN的技巧，也就是目标网络和经验回放。并且可以输出确定的动作（即动作的幅度），并且是一个单步更新的Policy网络。</p><h4 id="Actor-Critic"><a href="#Actor-Critic" class="headerlink" title="Actor-Critic"></a>Actor-Critic</h4><img src="/2021/07/16/qiang-hua-xue-xi-shi-jian-jiao-xue/48.png" class=""><p>我们有两个神经网络，一个Actor，一个Critic。Actor的任务是对外输出动作并且根据Critic的打分来调整自己的参数来获得更好的输出，使得Critic打分更高。</p><p>Critic的任务是对Actor的输出做评估（预测），并且通过reward不断调整自己的预测能可能地接近reward。这也就是一个Q网络。</p><img src="/2021/07/16/qiang-hua-xue-xi-shi-jian-jiao-xue/49.png" class=""><img src="/2021/07/16/qiang-hua-xue-xi-shi-jian-jiao-xue/50.png" class=""><p>实际上，为了更新的稳定，我们又分别给Actor和Critic都附加一个Target网络，和DQN一样，也就是说DDPG存在四个网络。</p><h3 id="代码实现-1"><a href="#代码实现-1" class="headerlink" title="代码实现"></a>代码实现</h3><img src="/2021/07/16/qiang-hua-xue-xi-shi-jian-jiao-xue/51.png" class=""><p>分类数据的reply_memory.py：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> random<span class="token keyword">import</span> collections<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">class</span> <span class="token class-name">ReplayMemory</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> max_size<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>buffer <span class="token operator">=</span> collections<span class="token punctuation">.</span>deque<span class="token punctuation">(</span>maxlen<span class="token operator">=</span>max_size<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">append</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> exp<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>buffer<span class="token punctuation">.</span>append<span class="token punctuation">(</span>exp<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">sample</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> batch_size<span class="token punctuation">)</span><span class="token punctuation">:</span>        mini_batch <span class="token operator">=</span> random<span class="token punctuation">.</span>sample<span class="token punctuation">(</span>self<span class="token punctuation">.</span>buffer<span class="token punctuation">,</span> batch_size<span class="token punctuation">)</span>        obs_batch<span class="token punctuation">,</span> action_batch<span class="token punctuation">,</span> reward_batch<span class="token punctuation">,</span> next_obs_batch<span class="token punctuation">,</span> done_batch <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        <span class="token keyword">for</span> experience <span class="token keyword">in</span> mini_batch<span class="token punctuation">:</span>            s<span class="token punctuation">,</span> a<span class="token punctuation">,</span> r<span class="token punctuation">,</span> s_p<span class="token punctuation">,</span> done <span class="token operator">=</span> experience            obs_batch<span class="token punctuation">.</span>append<span class="token punctuation">(</span>s<span class="token punctuation">)</span>            action_batch<span class="token punctuation">.</span>append<span class="token punctuation">(</span>a<span class="token punctuation">)</span>            reward_batch<span class="token punctuation">.</span>append<span class="token punctuation">(</span>r<span class="token punctuation">)</span>            next_obs_batch<span class="token punctuation">.</span>append<span class="token punctuation">(</span>s_p<span class="token punctuation">)</span>            done_batch<span class="token punctuation">.</span>append<span class="token punctuation">(</span>done<span class="token punctuation">)</span>        <span class="token keyword">return</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>obs_batch<span class="token punctuation">)</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token string">'float32'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> \            np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>action_batch<span class="token punctuation">)</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token string">'float32'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>reward_batch<span class="token punctuation">)</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token string">'float32'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>\            np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>next_obs_batch<span class="token punctuation">)</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token string">'float32'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>done_batch<span class="token punctuation">)</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token string">'float32'</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> len<span class="token punctuation">(</span>self<span class="token punctuation">.</span>buffer<span class="token punctuation">)</span></code></pre><p>model.py：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> parl<span class="token keyword">from</span> parl <span class="token keyword">import</span> layers<span class="token comment" spellcheck="true"># 用一个类把两个模型封装起来</span><span class="token keyword">class</span> <span class="token class-name">Model</span><span class="token punctuation">(</span>parl<span class="token punctuation">.</span>Model<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> act_dim<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>actor_model <span class="token operator">=</span> ActorModel<span class="token punctuation">(</span>act_dim<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>critic_model <span class="token operator">=</span> CriticModel<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">policy</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> obs<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>actor_model<span class="token punctuation">.</span>policy<span class="token punctuation">(</span>obs<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">value</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> obs<span class="token punctuation">,</span> act<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>critic_model<span class="token punctuation">.</span>value<span class="token punctuation">(</span>obs<span class="token punctuation">,</span> act<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 获取actor网络的parameters的名称，返回包含模型所有参数名称的list</span>    <span class="token keyword">def</span> <span class="token function">get_actor_params</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>actor_model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># Actor网络</span><span class="token keyword">class</span> <span class="token class-name">ActorModel</span><span class="token punctuation">(</span>parl<span class="token punctuation">.</span>Model<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> act_dim<span class="token punctuation">)</span><span class="token punctuation">:</span>        hid_size <span class="token operator">=</span> <span class="token number">100</span>        self<span class="token punctuation">.</span>fc1 <span class="token operator">=</span> layers<span class="token punctuation">.</span>fc<span class="token punctuation">(</span>size<span class="token operator">=</span>hid_size<span class="token punctuation">,</span> act<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>fc2 <span class="token operator">=</span> layers<span class="token punctuation">.</span>fc<span class="token punctuation">(</span>size<span class="token operator">=</span>act_dim<span class="token punctuation">,</span> act<span class="token operator">=</span><span class="token string">'tanh'</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">policy</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> obs<span class="token punctuation">)</span><span class="token punctuation">:</span>        hid <span class="token operator">=</span> self<span class="token punctuation">.</span>fc1<span class="token punctuation">(</span>obs<span class="token punctuation">)</span>        means <span class="token operator">=</span> self<span class="token punctuation">.</span>fc2<span class="token punctuation">(</span>hid<span class="token punctuation">)</span>        <span class="token keyword">return</span> means<span class="token comment" spellcheck="true"># Critic网络</span><span class="token keyword">class</span> <span class="token class-name">CriticModel</span><span class="token punctuation">(</span>parl<span class="token punctuation">.</span>Model<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        hid_size <span class="token operator">=</span> <span class="token number">100</span>        self<span class="token punctuation">.</span>fc1 <span class="token operator">=</span> layers<span class="token punctuation">.</span>fc<span class="token punctuation">(</span>size<span class="token operator">=</span>hid_size<span class="token punctuation">,</span> act<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>fc2 <span class="token operator">=</span> layers<span class="token punctuation">.</span>fc<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> act<span class="token operator">=</span>None<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">value</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> obs<span class="token punctuation">,</span> act<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># 拼接两个数组</span>        concat <span class="token operator">=</span> layers<span class="token punctuation">.</span>concat<span class="token punctuation">(</span><span class="token punctuation">[</span>obs<span class="token punctuation">,</span> act<span class="token punctuation">]</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>        hid <span class="token operator">=</span> self<span class="token punctuation">.</span>fc1<span class="token punctuation">(</span>concat<span class="token punctuation">)</span>        Q <span class="token operator">=</span> self<span class="token punctuation">.</span>fc2<span class="token punctuation">(</span>hid<span class="token punctuation">)</span>        Q <span class="token operator">=</span> layers<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span>Q<span class="token punctuation">,</span> axes<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> Q</code></pre><p>最关键的algorithm.py：</p><p>其实两个Target model都是给Critic更新参数用的，而Actor更新参数只需要看Critic的输出。</p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> parl<span class="token keyword">from</span> parl <span class="token keyword">import</span> layers<span class="token keyword">from</span> copy <span class="token keyword">import</span> deepcopy<span class="token keyword">from</span> paddle <span class="token keyword">import</span> fluid<span class="token keyword">class</span> <span class="token class-name">DDPG</span><span class="token punctuation">(</span>parl<span class="token punctuation">.</span>Algorithm<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>model<span class="token punctuation">,</span>gamma<span class="token operator">=</span>None<span class="token punctuation">,</span>tau<span class="token operator">=</span>None<span class="token punctuation">,</span>actor_lr<span class="token operator">=</span>None<span class="token punctuation">,</span>critic_lr<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""  DDPG algorithm              Args:            model (parl.Model): actor and critic 的前向网络.                                model 必须实现 get_actor_params() 方法.            gamma (float): reward的衰减因子.            tau (float): self.target_model 跟 self.model 同步参数 的 软更新参数            actor_lr (float): actor 的学习率            critic_lr (float): critic 的学习率        """</span>        <span class="token keyword">assert</span> isinstance<span class="token punctuation">(</span>gamma<span class="token punctuation">,</span> float<span class="token punctuation">)</span>        <span class="token keyword">assert</span> isinstance<span class="token punctuation">(</span>tau<span class="token punctuation">,</span> float<span class="token punctuation">)</span>        <span class="token keyword">assert</span> isinstance<span class="token punctuation">(</span>actor_lr<span class="token punctuation">,</span> float<span class="token punctuation">)</span>        <span class="token keyword">assert</span> isinstance<span class="token punctuation">(</span>critic_lr<span class="token punctuation">,</span> float<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>gamma <span class="token operator">=</span> gamma        self<span class="token punctuation">.</span>tau <span class="token operator">=</span> tau        self<span class="token punctuation">.</span>actor_lr <span class="token operator">=</span> actor_lr        self<span class="token punctuation">.</span>critic_lr <span class="token operator">=</span> critic_lr        self<span class="token punctuation">.</span>model <span class="token operator">=</span> model        self<span class="token punctuation">.</span>target_model <span class="token operator">=</span> deepcopy<span class="token punctuation">(</span>model<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">predict</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> obs<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">""" 使用 self.model 的 actor model 来预测动作        """</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>policy<span class="token punctuation">(</span>obs<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">learn</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> obs<span class="token punctuation">,</span> action<span class="token punctuation">,</span> reward<span class="token punctuation">,</span> next_obs<span class="token punctuation">,</span> terminal<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">""" 用DDPG算法更新 actor 和 critic        """</span>        actor_cost <span class="token operator">=</span> self<span class="token punctuation">.</span>_actor_learn<span class="token punctuation">(</span>obs<span class="token punctuation">)</span>        critic_cost <span class="token operator">=</span> self<span class="token punctuation">.</span>_critic_learn<span class="token punctuation">(</span>obs<span class="token punctuation">,</span> action<span class="token punctuation">,</span> reward<span class="token punctuation">,</span> next_obs<span class="token punctuation">,</span>                                         terminal<span class="token punctuation">)</span>        <span class="token keyword">return</span> actor_cost<span class="token punctuation">,</span> critic_cost    <span class="token keyword">def</span> <span class="token function">_actor_learn</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> obs<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># 计算Critic中的Q，然后使这个Q越大越好</span>        action <span class="token operator">=</span> self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>policy<span class="token punctuation">(</span>obs<span class="token punctuation">)</span>        Q <span class="token operator">=</span> self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>value<span class="token punctuation">(</span>obs<span class="token punctuation">,</span> action<span class="token punctuation">)</span>        cost <span class="token operator">=</span> layers<span class="token punctuation">.</span>reduce_mean<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1.0</span> <span class="token operator">*</span> Q<span class="token punctuation">)</span>        optimizer <span class="token operator">=</span> fluid<span class="token punctuation">.</span>optimizer<span class="token punctuation">.</span>AdamOptimizer<span class="token punctuation">(</span>self<span class="token punctuation">.</span>actor_lr<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 只更新Actor的参数，因此要给minimize指定目标，否则也会调整到Critic的参数</span>        optimizer<span class="token punctuation">.</span>minimize<span class="token punctuation">(</span>cost<span class="token punctuation">,</span> parameter_list<span class="token operator">=</span>self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>get_actor_params<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> cost    <span class="token keyword">def</span> <span class="token function">_critic_learn</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> obs<span class="token punctuation">,</span> action<span class="token punctuation">,</span> reward<span class="token punctuation">,</span> next_obs<span class="token punctuation">,</span> terminal<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># 计算Target Q，也就是目标价值</span>        next_action <span class="token operator">=</span> self<span class="token punctuation">.</span>target_model<span class="token punctuation">.</span>policy<span class="token punctuation">(</span>next_obs<span class="token punctuation">)</span>        next_Q <span class="token operator">=</span> self<span class="token punctuation">.</span>target_model<span class="token punctuation">.</span>value<span class="token punctuation">(</span>next_obs<span class="token punctuation">,</span> next_action<span class="token punctuation">)</span>        terminal <span class="token operator">=</span> layers<span class="token punctuation">.</span>cast<span class="token punctuation">(</span>terminal<span class="token punctuation">,</span> dtype<span class="token operator">=</span><span class="token string">'float32'</span><span class="token punctuation">)</span>        target_Q <span class="token operator">=</span> reward <span class="token operator">+</span> <span class="token punctuation">(</span><span class="token number">1.0</span> <span class="token operator">-</span> terminal<span class="token punctuation">)</span> <span class="token operator">*</span> self<span class="token punctuation">.</span>gamma <span class="token operator">*</span> next_Q        target_Q<span class="token punctuation">.</span>stop_gradient <span class="token operator">=</span> <span class="token boolean">True</span>        <span class="token comment" spellcheck="true"># 根据网络得出现在的Q，然后算出均方差，用来训练网络使得Q趋近于Target Q</span>        Q <span class="token operator">=</span> self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>value<span class="token punctuation">(</span>obs<span class="token punctuation">,</span> action<span class="token punctuation">)</span>        cost <span class="token operator">=</span> layers<span class="token punctuation">.</span>square_error_cost<span class="token punctuation">(</span>Q<span class="token punctuation">,</span> target_Q<span class="token punctuation">)</span>        cost <span class="token operator">=</span> layers<span class="token punctuation">.</span>reduce_mean<span class="token punctuation">(</span>cost<span class="token punctuation">)</span>        optimizer <span class="token operator">=</span> fluid<span class="token punctuation">.</span>optimizer<span class="token punctuation">.</span>AdamOptimizer<span class="token punctuation">(</span>self<span class="token punctuation">.</span>critic_lr<span class="token punctuation">)</span>        optimizer<span class="token punctuation">.</span>minimize<span class="token punctuation">(</span>cost<span class="token punctuation">)</span>        <span class="token keyword">return</span> cost    <span class="token keyword">def</span> <span class="token function">sync_target</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> decay<span class="token operator">=</span>None<span class="token punctuation">,</span> share_vars_parallel_executor<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">""" self.target_model从self.model复制参数过来，若decay不为None,则是软更新        """</span>        <span class="token keyword">if</span> decay <span class="token keyword">is</span> None<span class="token punctuation">:</span>            decay <span class="token operator">=</span> <span class="token number">1.0</span> <span class="token operator">-</span> self<span class="token punctuation">.</span>tau        self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>sync_weights_to<span class="token punctuation">(</span>            self<span class="token punctuation">.</span>target_model<span class="token punctuation">,</span>            decay<span class="token operator">=</span>decay<span class="token punctuation">,</span>            share_vars_parallel_executor<span class="token operator">=</span>share_vars_parallel_executor<span class="token punctuation">)</span></code></pre><p>train.py：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> gym<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> parl<span class="token keyword">from</span> parl<span class="token punctuation">.</span>utils <span class="token keyword">import</span> logger<span class="token keyword">from</span> agent <span class="token keyword">import</span> Agent<span class="token keyword">from</span> model <span class="token keyword">import</span> Model<span class="token keyword">from</span> algorithm <span class="token keyword">import</span> DDPG  <span class="token comment" spellcheck="true"># from parl.algorithms import DDPG</span><span class="token keyword">from</span> env <span class="token keyword">import</span> ContinuousCartPoleEnv<span class="token keyword">from</span> replay_memory <span class="token keyword">import</span> ReplayMemoryACTOR_LR <span class="token operator">=</span> <span class="token number">1e</span><span class="token operator">-</span><span class="token number">3</span>  <span class="token comment" spellcheck="true"># Actor网络的 learning rate</span>CRITIC_LR <span class="token operator">=</span> <span class="token number">1e</span><span class="token operator">-</span><span class="token number">3</span>  <span class="token comment" spellcheck="true"># Critic网络的 learning rate</span>GAMMA <span class="token operator">=</span> <span class="token number">0.99</span>  <span class="token comment" spellcheck="true"># reward 的衰减因子</span>TAU <span class="token operator">=</span> <span class="token number">0.001</span>  <span class="token comment" spellcheck="true"># 软更新的系数</span>MEMORY_SIZE <span class="token operator">=</span> int<span class="token punctuation">(</span><span class="token number">1e6</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 经验池大小</span>MEMORY_WARMUP_SIZE <span class="token operator">=</span> MEMORY_SIZE <span class="token operator">//</span> <span class="token number">20</span>  <span class="token comment" spellcheck="true"># 预存一部分经验之后再开始训练</span>BATCH_SIZE <span class="token operator">=</span> <span class="token number">128</span>REWARD_SCALE <span class="token operator">=</span> <span class="token number">0.1</span>  <span class="token comment" spellcheck="true"># reward 缩放系数</span>NOISE <span class="token operator">=</span> <span class="token number">0.05</span>  <span class="token comment" spellcheck="true"># 动作噪声方差</span>TRAIN_EPISODE <span class="token operator">=</span> <span class="token number">6e3</span>  <span class="token comment" spellcheck="true"># 训练的总episode数</span><span class="token comment" spellcheck="true"># 训练一个episode</span><span class="token keyword">def</span> <span class="token function">run_episode</span><span class="token punctuation">(</span>agent<span class="token punctuation">,</span> env<span class="token punctuation">,</span> rpm<span class="token punctuation">)</span><span class="token punctuation">:</span>    obs <span class="token operator">=</span> env<span class="token punctuation">.</span>reset<span class="token punctuation">(</span><span class="token punctuation">)</span>    total_reward <span class="token operator">=</span> <span class="token number">0</span>    steps <span class="token operator">=</span> <span class="token number">0</span>    <span class="token keyword">while</span> <span class="token boolean">True</span><span class="token punctuation">:</span>        steps <span class="token operator">+=</span> <span class="token number">1</span>        batch_obs <span class="token operator">=</span> np<span class="token punctuation">.</span>expand_dims<span class="token punctuation">(</span>obs<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>        action <span class="token operator">=</span> agent<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>batch_obs<span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token string">'float32'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 增加探索扰动, 输出限制在 [-1.0, 1.0] 范围内</span>        action <span class="token operator">=</span> np<span class="token punctuation">.</span>clip<span class="token punctuation">(</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span>action<span class="token punctuation">,</span> NOISE<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.0</span><span class="token punctuation">,</span> <span class="token number">1.0</span><span class="token punctuation">)</span>        next_obs<span class="token punctuation">,</span> reward<span class="token punctuation">,</span> done<span class="token punctuation">,</span> info <span class="token operator">=</span> env<span class="token punctuation">.</span>step<span class="token punctuation">(</span>action<span class="token punctuation">)</span>        action <span class="token operator">=</span> <span class="token punctuation">[</span>action<span class="token punctuation">]</span>  <span class="token comment" spellcheck="true"># 方便存入replaymemory</span>        rpm<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">(</span>obs<span class="token punctuation">,</span> action<span class="token punctuation">,</span> REWARD_SCALE <span class="token operator">*</span> reward<span class="token punctuation">,</span> next_obs<span class="token punctuation">,</span> done<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 预存多个经验以及每五个step提取一次</span>        <span class="token keyword">if</span> len<span class="token punctuation">(</span>rpm<span class="token punctuation">)</span> <span class="token operator">&gt;</span> MEMORY_WARMUP_SIZE <span class="token operator">and</span> <span class="token punctuation">(</span>steps <span class="token operator">%</span> <span class="token number">5</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>            <span class="token punctuation">(</span>batch_obs<span class="token punctuation">,</span> batch_action<span class="token punctuation">,</span> batch_reward<span class="token punctuation">,</span> batch_next_obs<span class="token punctuation">,</span>             batch_done<span class="token punctuation">)</span> <span class="token operator">=</span> rpm<span class="token punctuation">.</span>sample<span class="token punctuation">(</span>BATCH_SIZE<span class="token punctuation">)</span>            agent<span class="token punctuation">.</span>learn<span class="token punctuation">(</span>batch_obs<span class="token punctuation">,</span> batch_action<span class="token punctuation">,</span> batch_reward<span class="token punctuation">,</span> batch_next_obs<span class="token punctuation">,</span>                        batch_done<span class="token punctuation">)</span>        obs <span class="token operator">=</span> next_obs        total_reward <span class="token operator">+=</span> reward        <span class="token keyword">if</span> done <span class="token operator">or</span> steps <span class="token operator">&gt;=</span> <span class="token number">200</span><span class="token punctuation">:</span>            <span class="token keyword">break</span>    <span class="token keyword">return</span> total_reward<span class="token comment" spellcheck="true"># 评估 agent, 跑 5 个episode，总reward求平均</span><span class="token keyword">def</span> <span class="token function">evaluate</span><span class="token punctuation">(</span>env<span class="token punctuation">,</span> agent<span class="token punctuation">,</span> render<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    eval_reward <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        obs <span class="token operator">=</span> env<span class="token punctuation">.</span>reset<span class="token punctuation">(</span><span class="token punctuation">)</span>        total_reward <span class="token operator">=</span> <span class="token number">0</span>        steps <span class="token operator">=</span> <span class="token number">0</span>        <span class="token keyword">while</span> <span class="token boolean">True</span><span class="token punctuation">:</span>            batch_obs <span class="token operator">=</span> np<span class="token punctuation">.</span>expand_dims<span class="token punctuation">(</span>obs<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>            action <span class="token operator">=</span> agent<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>batch_obs<span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token string">'float32'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>            action <span class="token operator">=</span> np<span class="token punctuation">.</span>clip<span class="token punctuation">(</span>action<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.0</span><span class="token punctuation">,</span> <span class="token number">1.0</span><span class="token punctuation">)</span>            steps <span class="token operator">+=</span> <span class="token number">1</span>            next_obs<span class="token punctuation">,</span> reward<span class="token punctuation">,</span> done<span class="token punctuation">,</span> info <span class="token operator">=</span> env<span class="token punctuation">.</span>step<span class="token punctuation">(</span>action<span class="token punctuation">)</span>            obs <span class="token operator">=</span> next_obs            total_reward <span class="token operator">+=</span> reward            <span class="token keyword">if</span> render<span class="token punctuation">:</span>                env<span class="token punctuation">.</span>render<span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token keyword">if</span> done <span class="token operator">or</span> steps <span class="token operator">&gt;=</span> <span class="token number">200</span><span class="token punctuation">:</span>                <span class="token keyword">break</span>        eval_reward<span class="token punctuation">.</span>append<span class="token punctuation">(</span>total_reward<span class="token punctuation">)</span>    <span class="token keyword">return</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>eval_reward<span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    env <span class="token operator">=</span> ContinuousCartPoleEnv<span class="token punctuation">(</span><span class="token punctuation">)</span>    obs_dim <span class="token operator">=</span> env<span class="token punctuation">.</span>observation_space<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>    act_dim <span class="token operator">=</span> env<span class="token punctuation">.</span>action_space<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>    <span class="token comment" spellcheck="true"># 使用PARL框架创建agent</span>    model <span class="token operator">=</span> Model<span class="token punctuation">(</span>act_dim<span class="token punctuation">)</span>    algorithm <span class="token operator">=</span> DDPG<span class="token punctuation">(</span>        model<span class="token punctuation">,</span> gamma<span class="token operator">=</span>GAMMA<span class="token punctuation">,</span> tau<span class="token operator">=</span>TAU<span class="token punctuation">,</span> actor_lr<span class="token operator">=</span>ACTOR_LR<span class="token punctuation">,</span> critic_lr<span class="token operator">=</span>CRITIC_LR<span class="token punctuation">)</span>    agent <span class="token operator">=</span> Agent<span class="token punctuation">(</span>algorithm<span class="token punctuation">,</span> obs_dim<span class="token punctuation">,</span> act_dim<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 创建经验池</span>    rpm <span class="token operator">=</span> ReplayMemory<span class="token punctuation">(</span>MEMORY_SIZE<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 往经验池中预存数据</span>    <span class="token keyword">while</span> len<span class="token punctuation">(</span>rpm<span class="token punctuation">)</span> <span class="token operator">&lt;</span> MEMORY_WARMUP_SIZE<span class="token punctuation">:</span>        run_episode<span class="token punctuation">(</span>agent<span class="token punctuation">,</span> env<span class="token punctuation">,</span> rpm<span class="token punctuation">)</span>    episode <span class="token operator">=</span> <span class="token number">0</span>    <span class="token keyword">while</span> episode <span class="token operator">&lt;</span> TRAIN_EPISODE<span class="token punctuation">:</span>        <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">50</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            total_reward <span class="token operator">=</span> run_episode<span class="token punctuation">(</span>agent<span class="token punctuation">,</span> env<span class="token punctuation">,</span> rpm<span class="token punctuation">)</span>            episode <span class="token operator">+=</span> <span class="token number">1</span>        <span class="token comment" spellcheck="true"># 每50个episode评估一次</span>        eval_reward <span class="token operator">=</span> evaluate<span class="token punctuation">(</span>env<span class="token punctuation">,</span> agent<span class="token punctuation">,</span> render<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>        logger<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token string">'episode:&amp;#123;&amp;#125;    Test reward:&amp;#123;&amp;#125;'</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>            episode<span class="token punctuation">,</span> eval_reward<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>    main<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><p>另外附上环境的代码env.py：</p><pre class=" language-python"><code class="language-python"><span class="token triple-quoted-string string">"""Classic cart-pole system implemented by Rich Sutton et al.Copied from http://incompleteideas.net/sutton/book/code/pole.cpermalink: https://perma.cc/C9ZM-652RContinuous version by Ian Danforth"""</span><span class="token keyword">import</span> math<span class="token keyword">import</span> gym<span class="token keyword">from</span> gym <span class="token keyword">import</span> spaces<span class="token punctuation">,</span> logger<span class="token keyword">from</span> gym<span class="token punctuation">.</span>utils <span class="token keyword">import</span> seeding<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">class</span> <span class="token class-name">ContinuousCartPoleEnv</span><span class="token punctuation">(</span>gym<span class="token punctuation">.</span>Env<span class="token punctuation">)</span><span class="token punctuation">:</span>    metadata <span class="token operator">=</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>        <span class="token string">'render.modes'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'human'</span><span class="token punctuation">,</span> <span class="token string">'rgb_array'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token string">'video.frames_per_second'</span><span class="token punctuation">:</span> <span class="token number">50</span>    <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>gravity <span class="token operator">=</span> <span class="token number">9.8</span>        self<span class="token punctuation">.</span>masscart <span class="token operator">=</span> <span class="token number">1.0</span>        self<span class="token punctuation">.</span>masspole <span class="token operator">=</span> <span class="token number">0.1</span>        self<span class="token punctuation">.</span>total_mass <span class="token operator">=</span> <span class="token punctuation">(</span>self<span class="token punctuation">.</span>masspole <span class="token operator">+</span> self<span class="token punctuation">.</span>masscart<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>length <span class="token operator">=</span> <span class="token number">0.5</span>  <span class="token comment" spellcheck="true"># actually half the pole's length</span>        self<span class="token punctuation">.</span>polemass_length <span class="token operator">=</span> <span class="token punctuation">(</span>self<span class="token punctuation">.</span>masspole <span class="token operator">*</span> self<span class="token punctuation">.</span>length<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>force_mag <span class="token operator">=</span> <span class="token number">30.0</span>        self<span class="token punctuation">.</span>tau <span class="token operator">=</span> <span class="token number">0.02</span>  <span class="token comment" spellcheck="true"># seconds between state updates</span>        self<span class="token punctuation">.</span>min_action <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">1.0</span>        self<span class="token punctuation">.</span>max_action <span class="token operator">=</span> <span class="token number">1.0</span>        <span class="token comment" spellcheck="true"># Angle at which to fail the episode</span>        self<span class="token punctuation">.</span>theta_threshold_radians <span class="token operator">=</span> <span class="token number">12</span> <span class="token operator">*</span> <span class="token number">2</span> <span class="token operator">*</span> math<span class="token punctuation">.</span>pi <span class="token operator">/</span> <span class="token number">360</span>        self<span class="token punctuation">.</span>x_threshold <span class="token operator">=</span> <span class="token number">2.4</span>        <span class="token comment" spellcheck="true"># Angle limit set to 2 * theta_threshold_radians so failing observation</span>        <span class="token comment" spellcheck="true"># is still within bounds</span>        high <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span>            self<span class="token punctuation">.</span>x_threshold <span class="token operator">*</span> <span class="token number">2</span><span class="token punctuation">,</span>            np<span class="token punctuation">.</span>finfo<span class="token punctuation">(</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token punctuation">.</span>max<span class="token punctuation">,</span> self<span class="token punctuation">.</span>theta_threshold_radians <span class="token operator">*</span> <span class="token number">2</span><span class="token punctuation">,</span>            np<span class="token punctuation">.</span>finfo<span class="token punctuation">(</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token punctuation">.</span>max        <span class="token punctuation">]</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>action_space <span class="token operator">=</span> spaces<span class="token punctuation">.</span>Box<span class="token punctuation">(</span>            low<span class="token operator">=</span>self<span class="token punctuation">.</span>min_action<span class="token punctuation">,</span> high<span class="token operator">=</span>self<span class="token punctuation">.</span>max_action<span class="token punctuation">,</span> shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>observation_space <span class="token operator">=</span> spaces<span class="token punctuation">.</span>Box<span class="token punctuation">(</span><span class="token operator">-</span>high<span class="token punctuation">,</span> high<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>viewer <span class="token operator">=</span> None        self<span class="token punctuation">.</span>state <span class="token operator">=</span> None        self<span class="token punctuation">.</span>steps_beyond_done <span class="token operator">=</span> None    <span class="token keyword">def</span> <span class="token function">seed</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> seed<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>np_random<span class="token punctuation">,</span> seed <span class="token operator">=</span> seeding<span class="token punctuation">.</span>np_random<span class="token punctuation">(</span>seed<span class="token punctuation">)</span>        <span class="token keyword">return</span> <span class="token punctuation">[</span>seed<span class="token punctuation">]</span>    <span class="token keyword">def</span> <span class="token function">stepPhysics</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> force<span class="token punctuation">)</span><span class="token punctuation">:</span>        x<span class="token punctuation">,</span> x_dot<span class="token punctuation">,</span> theta<span class="token punctuation">,</span> theta_dot <span class="token operator">=</span> self<span class="token punctuation">.</span>state        costheta <span class="token operator">=</span> math<span class="token punctuation">.</span>cos<span class="token punctuation">(</span>theta<span class="token punctuation">)</span>        sintheta <span class="token operator">=</span> math<span class="token punctuation">.</span>sin<span class="token punctuation">(</span>theta<span class="token punctuation">)</span>        temp <span class="token operator">=</span> <span class="token punctuation">(</span>force <span class="token operator">+</span> self<span class="token punctuation">.</span>polemass_length <span class="token operator">*</span> theta_dot <span class="token operator">*</span> theta_dot <span class="token operator">*</span> sintheta                <span class="token punctuation">)</span> <span class="token operator">/</span> self<span class="token punctuation">.</span>total_mass        thetaacc <span class="token operator">=</span> <span class="token punctuation">(</span>self<span class="token punctuation">.</span>gravity <span class="token operator">*</span> sintheta <span class="token operator">-</span> costheta <span class="token operator">*</span> temp<span class="token punctuation">)</span> <span class="token operator">/</span> \            <span class="token punctuation">(</span>self<span class="token punctuation">.</span>length <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token number">4.0</span><span class="token operator">/</span><span class="token number">3.0</span> <span class="token operator">-</span> self<span class="token punctuation">.</span>masspole <span class="token operator">*</span> costheta <span class="token operator">*</span> costheta <span class="token operator">/</span> self<span class="token punctuation">.</span>total_mass<span class="token punctuation">)</span><span class="token punctuation">)</span>        xacc <span class="token operator">=</span> temp <span class="token operator">-</span> self<span class="token punctuation">.</span>polemass_length <span class="token operator">*</span> thetaacc <span class="token operator">*</span> costheta <span class="token operator">/</span> self<span class="token punctuation">.</span>total_mass        x <span class="token operator">=</span> x <span class="token operator">+</span> self<span class="token punctuation">.</span>tau <span class="token operator">*</span> x_dot        x_dot <span class="token operator">=</span> x_dot <span class="token operator">+</span> self<span class="token punctuation">.</span>tau <span class="token operator">*</span> xacc        theta <span class="token operator">=</span> theta <span class="token operator">+</span> self<span class="token punctuation">.</span>tau <span class="token operator">*</span> theta_dot        theta_dot <span class="token operator">=</span> theta_dot <span class="token operator">+</span> self<span class="token punctuation">.</span>tau <span class="token operator">*</span> thetaacc        <span class="token keyword">return</span> <span class="token punctuation">(</span>x<span class="token punctuation">,</span> x_dot<span class="token punctuation">,</span> theta<span class="token punctuation">,</span> theta_dot<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">step</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> action<span class="token punctuation">)</span><span class="token punctuation">:</span>        action <span class="token operator">=</span> np<span class="token punctuation">.</span>expand_dims<span class="token punctuation">(</span>action<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>        <span class="token keyword">assert</span> self<span class="token punctuation">.</span>action_space<span class="token punctuation">.</span>contains<span class="token punctuation">(</span>action<span class="token punctuation">)</span><span class="token punctuation">,</span> \            <span class="token string">"%r (%s) invalid"</span> <span class="token operator">%</span> <span class="token punctuation">(</span>action<span class="token punctuation">,</span> type<span class="token punctuation">(</span>action<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># Cast action to float to strip np trappings</span>        force <span class="token operator">=</span> self<span class="token punctuation">.</span>force_mag <span class="token operator">*</span> float<span class="token punctuation">(</span>action<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>state <span class="token operator">=</span> self<span class="token punctuation">.</span>stepPhysics<span class="token punctuation">(</span>force<span class="token punctuation">)</span>        x<span class="token punctuation">,</span> x_dot<span class="token punctuation">,</span> theta<span class="token punctuation">,</span> theta_dot <span class="token operator">=</span> self<span class="token punctuation">.</span>state        done <span class="token operator">=</span> x <span class="token operator">&lt;</span> <span class="token operator">-</span>self<span class="token punctuation">.</span>x_threshold \            <span class="token operator">or</span> x <span class="token operator">&gt;</span> self<span class="token punctuation">.</span>x_threshold \            <span class="token operator">or</span> theta <span class="token operator">&lt;</span> <span class="token operator">-</span>self<span class="token punctuation">.</span>theta_threshold_radians \            <span class="token operator">or</span> theta <span class="token operator">&gt;</span> self<span class="token punctuation">.</span>theta_threshold_radians        done <span class="token operator">=</span> bool<span class="token punctuation">(</span>done<span class="token punctuation">)</span>        <span class="token keyword">if</span> <span class="token operator">not</span> done<span class="token punctuation">:</span>            reward <span class="token operator">=</span> <span class="token number">1.0</span>        <span class="token keyword">elif</span> self<span class="token punctuation">.</span>steps_beyond_done <span class="token keyword">is</span> None<span class="token punctuation">:</span>            <span class="token comment" spellcheck="true"># Pole just fell!</span>            self<span class="token punctuation">.</span>steps_beyond_done <span class="token operator">=</span> <span class="token number">0</span>            reward <span class="token operator">=</span> <span class="token number">1.0</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            <span class="token keyword">if</span> self<span class="token punctuation">.</span>steps_beyond_done <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>                logger<span class="token punctuation">.</span>warn<span class="token punctuation">(</span><span class="token triple-quoted-string string">"""You are calling 'step()' even though this environment has already returneddone = True. You should always call 'reset()' once you receive 'done = True'Any further steps are undefined behavior.                """</span><span class="token punctuation">)</span>            self<span class="token punctuation">.</span>steps_beyond_done <span class="token operator">+=</span> <span class="token number">1</span>            reward <span class="token operator">=</span> <span class="token number">0.0</span>        <span class="token keyword">return</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>self<span class="token punctuation">.</span>state<span class="token punctuation">)</span><span class="token punctuation">,</span> reward<span class="token punctuation">,</span> done<span class="token punctuation">,</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;&amp;#125;</span>    <span class="token keyword">def</span> <span class="token function">reset</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>state <span class="token operator">=</span> self<span class="token punctuation">.</span>np_random<span class="token punctuation">.</span>uniform<span class="token punctuation">(</span>low<span class="token operator">=</span><span class="token operator">-</span><span class="token number">0.05</span><span class="token punctuation">,</span> high<span class="token operator">=</span><span class="token number">0.05</span><span class="token punctuation">,</span> size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>steps_beyond_done <span class="token operator">=</span> None        <span class="token keyword">return</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>self<span class="token punctuation">.</span>state<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">render</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">'human'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        screen_width <span class="token operator">=</span> <span class="token number">600</span>        screen_height <span class="token operator">=</span> <span class="token number">400</span>        world_width <span class="token operator">=</span> self<span class="token punctuation">.</span>x_threshold <span class="token operator">*</span> <span class="token number">2</span>        scale <span class="token operator">=</span> screen_width <span class="token operator">/</span> world_width        carty <span class="token operator">=</span> <span class="token number">100</span>  <span class="token comment" spellcheck="true"># TOP OF CART</span>        polewidth <span class="token operator">=</span> <span class="token number">10.0</span>        polelen <span class="token operator">=</span> scale <span class="token operator">*</span> <span class="token number">1.0</span>        cartwidth <span class="token operator">=</span> <span class="token number">50.0</span>        cartheight <span class="token operator">=</span> <span class="token number">30.0</span>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>viewer <span class="token keyword">is</span> None<span class="token punctuation">:</span>            <span class="token keyword">from</span> gym<span class="token punctuation">.</span>envs<span class="token punctuation">.</span>classic_control <span class="token keyword">import</span> rendering            self<span class="token punctuation">.</span>viewer <span class="token operator">=</span> rendering<span class="token punctuation">.</span>Viewer<span class="token punctuation">(</span>screen_width<span class="token punctuation">,</span> screen_height<span class="token punctuation">)</span>            l<span class="token punctuation">,</span> r<span class="token punctuation">,</span> t<span class="token punctuation">,</span> b <span class="token operator">=</span> <span class="token operator">-</span>cartwidth <span class="token operator">/</span> <span class="token number">2</span><span class="token punctuation">,</span> cartwidth <span class="token operator">/</span> <span class="token number">2</span><span class="token punctuation">,</span> cartheight <span class="token operator">/</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token operator">-</span>cartheight <span class="token operator">/</span> <span class="token number">2</span>            axleoffset <span class="token operator">=</span> cartheight <span class="token operator">/</span> <span class="token number">4.0</span>            cart <span class="token operator">=</span> rendering<span class="token punctuation">.</span>FilledPolygon<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">(</span>l<span class="token punctuation">,</span> b<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>l<span class="token punctuation">,</span> t<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>r<span class="token punctuation">,</span> t<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>r<span class="token punctuation">,</span> b<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>            self<span class="token punctuation">.</span>carttrans <span class="token operator">=</span> rendering<span class="token punctuation">.</span>Transform<span class="token punctuation">(</span><span class="token punctuation">)</span>            cart<span class="token punctuation">.</span>add_attr<span class="token punctuation">(</span>self<span class="token punctuation">.</span>carttrans<span class="token punctuation">)</span>            self<span class="token punctuation">.</span>viewer<span class="token punctuation">.</span>add_geom<span class="token punctuation">(</span>cart<span class="token punctuation">)</span>            l<span class="token punctuation">,</span> r<span class="token punctuation">,</span> t<span class="token punctuation">,</span> b <span class="token operator">=</span> <span class="token operator">-</span>polewidth <span class="token operator">/</span> <span class="token number">2</span><span class="token punctuation">,</span> polewidth <span class="token operator">/</span> <span class="token number">2</span><span class="token punctuation">,</span> polelen <span class="token operator">-</span> polewidth <span class="token operator">/</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token operator">-</span>polewidth <span class="token operator">/</span> <span class="token number">2</span>            pole <span class="token operator">=</span> rendering<span class="token punctuation">.</span>FilledPolygon<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">(</span>l<span class="token punctuation">,</span> b<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>l<span class="token punctuation">,</span> t<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>r<span class="token punctuation">,</span> t<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>r<span class="token punctuation">,</span> b<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>            pole<span class="token punctuation">.</span>set_color<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token number">8</span><span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token number">4</span><span class="token punctuation">)</span>            self<span class="token punctuation">.</span>poletrans <span class="token operator">=</span> rendering<span class="token punctuation">.</span>Transform<span class="token punctuation">(</span>translation<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> axleoffset<span class="token punctuation">)</span><span class="token punctuation">)</span>            pole<span class="token punctuation">.</span>add_attr<span class="token punctuation">(</span>self<span class="token punctuation">.</span>poletrans<span class="token punctuation">)</span>            pole<span class="token punctuation">.</span>add_attr<span class="token punctuation">(</span>self<span class="token punctuation">.</span>carttrans<span class="token punctuation">)</span>            self<span class="token punctuation">.</span>viewer<span class="token punctuation">.</span>add_geom<span class="token punctuation">(</span>pole<span class="token punctuation">)</span>            self<span class="token punctuation">.</span>axle <span class="token operator">=</span> rendering<span class="token punctuation">.</span>make_circle<span class="token punctuation">(</span>polewidth <span class="token operator">/</span> <span class="token number">2</span><span class="token punctuation">)</span>            self<span class="token punctuation">.</span>axle<span class="token punctuation">.</span>add_attr<span class="token punctuation">(</span>self<span class="token punctuation">.</span>poletrans<span class="token punctuation">)</span>            self<span class="token punctuation">.</span>axle<span class="token punctuation">.</span>add_attr<span class="token punctuation">(</span>self<span class="token punctuation">.</span>carttrans<span class="token punctuation">)</span>            self<span class="token punctuation">.</span>axle<span class="token punctuation">.</span>set_color<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token number">8</span><span class="token punctuation">)</span>            self<span class="token punctuation">.</span>viewer<span class="token punctuation">.</span>add_geom<span class="token punctuation">(</span>self<span class="token punctuation">.</span>axle<span class="token punctuation">)</span>            self<span class="token punctuation">.</span>track <span class="token operator">=</span> rendering<span class="token punctuation">.</span>Line<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> carty<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>screen_width<span class="token punctuation">,</span> carty<span class="token punctuation">)</span><span class="token punctuation">)</span>            self<span class="token punctuation">.</span>track<span class="token punctuation">.</span>set_color<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>            self<span class="token punctuation">.</span>viewer<span class="token punctuation">.</span>add_geom<span class="token punctuation">(</span>self<span class="token punctuation">.</span>track<span class="token punctuation">)</span>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>state <span class="token keyword">is</span> None<span class="token punctuation">:</span>            <span class="token keyword">return</span> None        x <span class="token operator">=</span> self<span class="token punctuation">.</span>state        cartx <span class="token operator">=</span> x<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">*</span> scale <span class="token operator">+</span> screen_width <span class="token operator">/</span> <span class="token number">2.0</span>  <span class="token comment" spellcheck="true"># MIDDLE OF CART</span>        self<span class="token punctuation">.</span>carttrans<span class="token punctuation">.</span>set_translation<span class="token punctuation">(</span>cartx<span class="token punctuation">,</span> carty<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>poletrans<span class="token punctuation">.</span>set_rotation<span class="token punctuation">(</span><span class="token operator">-</span>x<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>viewer<span class="token punctuation">.</span>render<span class="token punctuation">(</span>return_rgb_array<span class="token operator">=</span><span class="token punctuation">(</span>mode <span class="token operator">==</span> <span class="token string">'rgb_array'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">close</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>viewer<span class="token punctuation">:</span>            self<span class="token punctuation">.</span>viewer<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><h2 id="拓展-1"><a href="#拓展-1" class="headerlink" title="拓展"></a>拓展</h2><h3 id="RLSchool：一个强化学习模拟环境合集"><a href="#RLSchool：一个强化学习模拟环境合集" class="headerlink" title="RLSchool：一个强化学习模拟环境合集"></a>RLSchool：一个强化学习模拟环境合集</h3><img src="/2021/07/16/qiang-hua-xue-xi-shi-jian-jiao-xue/52.png" class=""><h3 id="无人机悬浮控制任务"><a href="#无人机悬浮控制任务" class="headerlink" title="无人机悬浮控制任务"></a>无人机悬浮控制任务</h3><img src="/2021/07/16/qiang-hua-xue-xi-shi-jian-jiao-xue/53.png" class=""><img src="/2021/07/16/qiang-hua-xue-xi-shi-jian-jiao-xue/54.png" class=""><h3 id="更多环境"><a href="#更多环境" class="headerlink" title="更多环境"></a>更多环境</h3><img src="/2021/07/16/qiang-hua-xue-xi-shi-jian-jiao-xue/55.png" class=""><img src="/2021/07/16/qiang-hua-xue-xi-shi-jian-jiao-xue/56.png" class=""><img src="/2021/07/16/qiang-hua-xue-xi-shi-jian-jiao-xue/57.png" class=""><img src="/2021/07/16/qiang-hua-xue-xi-shi-jian-jiao-xue/58.png" class=""><img src="/2021/07/16/qiang-hua-xue-xi-shi-jian-jiao-xue/59.png" class=""><p>1星环境：简单的弹跳和接球游戏：<a href="https://github.com/shivaverma/Orbit">https://github.com/shivaverma/Orbit</a><br>2星环境：GYM环境  Box2D (需要安装 box2d-py)：<a href="https://gym.openai.com/envs/#box2d">https://gym.openai.com/envs/#box2d</a><br>PyGame游戏环境（含Flappy Bird）：<a href="https://github.com/ntasfi/PyGame-Learning-Environment">https://github.com/ntasfi/PyGame-Learning-Environment</a><br>3星环境：GYM环境  Robotics (需要安装 mujoco_py和试用许可证书)：<a href="https://gym.openai.com/envs/#robotics">https://gym.openai.com/envs/#robotics</a><br>股票预测环境：<a href="https://github.com/kh-kim/stock_market_reinforcement_learning">https://github.com/kh-kim/stock_market_reinforcement_learning</a><br>RLSchool四轴飞行器的 速度控制任务 “velocity_control”：<a href="https://github.com/PaddlePaddle/RLSchool/tree/master/rlschool/quadrotor">https://github.com/PaddlePaddle/RLSchool/tree/master/rlschool/quadrotor</a><br>4星环境：RLBench任务环境（使用机械臂完成某一项任务）：<a href="https://github.com/stepjam/RLBench">https://github.com/stepjam/RLBench</a><br>5星环境：交通信号灯控制：<a href="https://github.com/Ujwal2910/Smart-Traffic-Signals-in-India-using-Deep-Reinforcement-Learning-and-Advanced-Computer-Vision">https://github.com/Ujwal2910/Smart-Traffic-Signals-in-India-using-Deep-Reinforcement-Learning-and-Advanced-Computer-Vision</a></p>]]></content>
      
      
      <categories>
          
          <category> 强化学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 强化学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>元学习（Meta Learning）</title>
      <link href="2021/07/15/yuan-xue-xi-meta-learning/"/>
      <url>2021/07/15/yuan-xue-xi-meta-learning/</url>
      
        <content type="html"><![CDATA[<p> 名词解释：Meta Learning = Learn to learn ，也就是学习如何学习。和机器学习不同，这个是另外一个层次的东西了。</p><p>在我们深度学习领域，其实大多数时候都是在调超参数（hyperparameters），在工业届的做法是一次性使用上万张显卡使用多个hyperparameters同时训练多个模型，然后挑选训练得好的。但是在学术界并没有这么多设备，往往依靠个人的经验来调整hyperparameters。那么这种超参数能不能让机器自己学习呢？</p><img src="/2021/07/15/yuan-xue-xi-meta-learning/1.png" class=""><h2 id="流程"><a href="#流程" class="headerlink" title="流程"></a>流程</h2><p>和机器学习类似，元学习也是通过训练资料来进行训练，但是训练目标是找出一个学习算法。我们期待诸如学习率这样的超参数是可以被学习出来的。不同的元学习的方法就是用来学习不同的超参数的。</p><img src="/2021/07/15/yuan-xue-xi-meta-learning/2.png" class=""><p>下面我们需要定义一个Loss函数来评价学习算法的优越程度。在深度学习中，我们使用收集到的资料来计算Loss。而在元学习中，我们使用收集到的任务，每个任务都有训练资料和测试资料。</p><img src="/2021/07/15/yuan-xue-xi-meta-learning/3.png" class=""><img src="/2021/07/15/yuan-xue-xi-meta-learning/4.png" class=""><p>首先我们把训练集导入模型中进行训练，训练的效果就可以直接反应超参数的好坏。训练完成后，使用测试集进行测试。把模型的输出和实际的输出做Cross-entropy，这个值直接当做Loss，这个值越大，说明模型训练得越差，说明使用超参数是一个比较不好的超参数。越小说明训练得越好，超参数越棒。实际上我们不会只用一个任务来测试，往往会使用多个任务，然后把Loss相加，取平均值。</p><p>注意这里元学习和深度学习不同之处在于，Loss的计算元学习是使用了测试集的资料的。因为这里我们训练的单位是任务，所以可以使用<strong>训练任务</strong>中的测试集。</p><img src="/2021/07/15/yuan-xue-xi-meta-learning/5.png" class=""><p>接下来的任务就是解这个最优化问题，找一个最优的超参数。而很多时候我们的超参数是不能用梯度下降法求解的，这时候可以尝试使用RL硬做。</p><hr><p>总之，现在你通过学习算法找出来一个超参数。这时候可以进行测试了，这时候我们用到的数据集叫做<strong>测试任务</strong>，里面同样有训练集和测试集，我们可以直接把测试任务中的训练集倒进模型进行训练，然后用测试任务中的测试集进行测试，确定模型的优越性，同时也反应了超参数的优越性。</p><p>其实Meta Learning也需要调节超参数，等于是为了得到一个不用调超参数的模型，我们要训练另一个需要调超参数模型。</p><img src="/2021/07/15/yuan-xue-xi-meta-learning/6.png" class=""><hr><h2 id="ML和Meta-Learning的区别"><a href="#ML和Meta-Learning的区别" class="headerlink" title="ML和Meta Learning的区别"></a>ML和Meta Learning的区别</h2><p>下面是比较ML和meta Learning的区别。ML的目标是找一个函数，而Meta Learning更像是找一个能找函数的函数。而且使用数据集的形式也有所不同。Meta Learning是一种跨任务的学习。</p><img src="/2021/07/15/yuan-xue-xi-meta-learning/7.png" class=""><img src="/2021/07/15/yuan-xue-xi-meta-learning/8.png" class=""><img src="/2021/07/15/yuan-xue-xi-meta-learning/9.png" class=""><img src="/2021/07/15/yuan-xue-xi-meta-learning/10.png" class=""><img src="/2021/07/15/yuan-xue-xi-meta-learning/11.png" class=""><hr><h2 id="万物皆可Meta"><a href="#万物皆可Meta" class="headerlink" title="万物皆可Meta"></a>万物皆可Meta</h2><h3 id="训练初始化参数"><a href="#训练初始化参数" class="headerlink" title="训练初始化参数"></a>训练初始化参数</h3><p>当我们训练一个模型时，初始的参数往往非常重要，初始的参数好不好往往造成的训练效果天差地别，在Meta-Learning中就有这种选择较好的初始化参数的方法，具体内容可以自行查看论文：</p><img src="/2021/07/15/yuan-xue-xi-meta-learning/12.png" class=""><img src="/2021/07/15/yuan-xue-xi-meta-learning/13.png" class=""><img src="/2021/07/15/yuan-xue-xi-meta-learning/14.png" class=""><h3 id="训练优化器（Optimizer）"><a href="#训练优化器（Optimizer）" class="headerlink" title="训练优化器（Optimizer）"></a>训练优化器（Optimizer）</h3><img src="/2021/07/15/yuan-xue-xi-meta-learning/15.png" class=""><h3 id="训练Network架构"><a href="#训练Network架构" class="headerlink" title="训练Network架构"></a>训练Network架构</h3><p>直接使用RL:</p><img src="/2021/07/15/yuan-xue-xi-meta-learning/16.png" class=""><img src="/2021/07/15/yuan-xue-xi-meta-learning/17.png" class=""><p>使用遗传算法：</p><img src="/2021/07/15/yuan-xue-xi-meta-learning/18.png" class=""><p>把架构变得可以微分：</p><img src="/2021/07/15/yuan-xue-xi-meta-learning/19.png" class=""><h3 id="训练数据处理方式"><a href="#训练数据处理方式" class="headerlink" title="训练数据处理方式"></a>训练数据处理方式</h3><img src="/2021/07/15/yuan-xue-xi-meta-learning/20.png" class=""><h3 id="训练Sample-Reweighting"><a href="#训练Sample-Reweighting" class="headerlink" title="训练Sample Reweighting"></a>训练Sample Reweighting</h3><img src="/2021/07/15/yuan-xue-xi-meta-learning/21.png" class=""><h3 id="舍弃Gradient-Descent"><a href="#舍弃Gradient-Descent" class="headerlink" title="舍弃Gradient Descent"></a>舍弃Gradient Descent</h3><img src="/2021/07/15/yuan-xue-xi-meta-learning/22.png" class=""><h3 id="Learning-to-compare"><a href="#Learning-to-compare" class="headerlink" title="Learning to compare"></a>Learning to compare</h3><p>我们可以使用一个Network同时读进训练资料和测试资料，输出测试资料的结果。</p><img src="/2021/07/15/yuan-xue-xi-meta-learning/23.png" class=""><hr><h2 id="实际应用"><a href="#实际应用" class="headerlink" title="实际应用"></a>实际应用</h2><p>通常我们可以把Meta-Learning用在few-shot learning上，我们只有很少的资料。</p><img src="/2021/07/15/yuan-xue-xi-meta-learning/24.png" class=""><img src="/2021/07/15/yuan-xue-xi-meta-learning/25.png" class=""><img src="/2021/07/15/yuan-xue-xi-meta-learning/26.png" class=""><img src="/2021/07/15/yuan-xue-xi-meta-learning/27.png" class="">]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>神经网络压缩</title>
      <link href="2021/07/14/shen-jing-wang-luo-ya-suo/"/>
      <url>2021/07/14/shen-jing-wang-luo-ya-suo/</url>
      
        <content type="html"><![CDATA[<p> 本文的内容主要讲解如何压缩一个较为庞大的神经网络，使其在较少参数的情况下，拥有和原来差不多的效能。这是因为在一些场景中，例如智能手表，它的内存是有限的，如果模型太过庞大，会导致无法运行在这样的小型智能物件上。下面来介绍五个常用做法：</p><h2 id="Network-Pruning"><a href="#Network-Pruning" class="headerlink" title="Network Pruning"></a>Network Pruning</h2><p>顾名思义，我们可以对神经网络进行修剪，树大必有枯枝。因此我们可以把没有用的参数找出来扔掉。</p><img src="/2021/07/14/shen-jing-wang-luo-ya-suo/1.png" class=""><p>确定参数重要性的方法有多种，我们可以把绝对值大的参数视为重要的参数，也可以把life-long-learning中的方法用进来，例如用这个参数在Loss中的梯度，梯度大则重要。另外，我们也可以判断一个节点的重要性决定是否删除它，通过计算它输出不为0的次数可以判断一个节点的重要性。在删除了部分参数之后，必然对模型的识别正确率产生影响，我们必须重新对其进行评估，然后对这个修改后的模型参数进行微调（fine-tuning）。然后再对参数重要性进行评估，如此经过多次的修剪，我们期望能得到一个性能差不多的小型网络。注意：不要一次性对网络进行大量的修剪，否则性能损失过大，无法通过微调调整回来。</p><p>但往往在实际操作时我们更倾向于删除节点，因为在进行矩阵运算的编程中，删除某个参数后的网络形状是不规则的，无法调用矩阵运算的库，唯一方法是把删掉的参数都设为零，但这其实并没有把网络变小。如果你自己来实现这个功能，往往也会因为缺乏显卡矩阵运算加速的功能反而拖慢运算速度。</p><p><strong>为什么不直接训练一个小的Network呢？</strong>那是因为大的Network比较好训练，<strong>往往训练小的Network没有办法达到跟大的Network一样的正确率</strong>，但先训练一个大的Network，然后把它变小，正确率也不会掉太多。关于大模型为什么容易训练有一个大乐透假说（Lottery Ticket Hypothesis）：大模型可以看作是很多小模型合起来的结果，训练大的模型等于同时训练很多小模型，每一个小模型都不一定能通过Gradient Descent找到一个好的Solution。但是只要有一个小模型成功，就能使大模型成功。相当于买彩票买的越多，中奖概率越高。</p><img src="/2021/07/14/shen-jing-wang-luo-ya-suo/2.png" class=""><p>因此<strong>我们更倾向于训练一个大的模型然后缩小，而不是直接训练一个小的模型</strong>。这是由于我们在小的模型中很难随机到一组好的可优化参数。而在大模型中我们可以利用它的“抽奖”特性，使其得到众多参数，然后我们选出好的参数来作为小模型的初始化参数。这样往往能得到较好的结果。</p><p>这里还有一篇有趣的论文，尝试了不同的修剪策略。得出结论：</p><p>1、一个参数训练前和训练后绝对值的差距越大，那么修剪掉的效果越好。</p><p>2、一组好的初始化参数，只要不改变其正负号，任意改变它的值，训练效果也不会有太大改变。<strong>正负号是初始化参数能不能训练起来的关键。</strong></p><p>3、其实一个大的模型，经过训练后，只有进行适当的修剪，得到的小模型可以直接使用。可以得到和supervised-learning相当的正确率。</p><img src="/2021/07/14/shen-jing-wang-luo-ya-suo/3.png" class=""><p>这里还有一篇打脸“大乐透假说”的文章，实验结论是，小模型其实训练更多地epoch效果就优于Prunning的结果了。“大乐透假说”只有在学习率设定较小，以weight为单位修剪的时候才能观察到。<strong>因此这个假说还尚待研究。</strong></p><img src="/2021/07/14/shen-jing-wang-luo-ya-suo/4.png" class=""><h2 id="Knowledge-Distillation"><a href="#Knowledge-Distillation" class="headerlink" title="Knowledge Distillation"></a>Knowledge Distillation</h2><img src="/2021/07/14/shen-jing-wang-luo-ya-suo/5.png" class="">      <p>这个是神经网络压缩的第二个做法。首先也是训练一个大的模型，称为Teacher Net。拥有较高的正确率，然后我们的目标是再训练一个小模型Student Net，Student Net并不是根据资料给的label进行学习，而是<strong>根据teacher Net的输出进行学习</strong>。也就是说，无论是正确还是错误，Student Net的输出都要跟随Teacher Net的输出。</p><p>这样做的理由和Network Pruning一样，直接训练一个小的Network，没有小Network根据大Network学习效果好。因为让一个Student Net直接根据label来进行学习可能会太难了，1跟7比较像，1跟9也有点像，直接让小模型学习1的概率是1，其他概率是0可能学不起来。但Teacher Net会详细告诉它，大网络也不能把图片完全区分，其实图片是1的概率是0.7，7的概率是0.2，9的概率是0.1，这样反而会学得比较好。</p><p>而且就算训练资料中缺少某个数字，但Teacher Net之前看过这个数字，Student Net没见过。但凭借Teacher Net告诉Student Net概率分布，Student Net都有可能准确识别这个数字。</p><p><strong>Teacher Net也可以是多个Network的Ensemble</strong>。也就是训练多个Network，分类的最终结果由这些Network投票进行决定。这也是机器学习比赛中的常用技巧。但在实际运用中这样的计算量未免太大，因此我们可以用Knowledge Distillation的技术把这些Network综合起来变成一个。具体做法是把Teacher Net中所有Network的输出取平均值，然后再让Student Net去学这个平均值。这样就可以让Student Net逼近一堆Network综合起来的正确率。</p><img src="/2021/07/14/shen-jing-wang-luo-ya-suo/6.png" class=""><p>下面是Knowledge Distillation的一个小技巧，<strong>我们需要对Teacher Net的Softmax函数进行修改</strong>。就是对输入进行除以T的处理，T是一个大于1的数，这样的处理使得输出更为平滑，Student Net更容易学习，因此T是我们需要自己调的参数。同时我们也可以让Student Net里面的其他层向Teacher Net学习，而不只是输出层，这样做比较多的限制往往的到更好的结果。</p><img src="/2021/07/14/shen-jing-wang-luo-ya-suo/7.png" class=""><h2 id="Parameter-Qrantization"><a href="#Parameter-Qrantization" class="headerlink" title="Parameter Qrantization"></a>Parameter Qrantization</h2><p>这是一个压缩参数大小的技巧。</p><img src="/2021/07/14/shen-jing-wang-luo-ya-suo/8.png" class=""><p>1、我们可以使用更少的储存空间来储存一个参数，这样能大大减小模型的大小。例如本来16bit一个数据变成8bit。</p><p>2、更进一步压缩的方法是Weight Clustering。我们按照数值的大小事先设定好分群数量进行分群，然后每一群只拿一个数值表示，这个数字可以是平均数。这样我们就只用记录每个参数属于哪一群和那一群的平均数就行了。</p><p>3、还有一个叫做Huffman encoding，比较常见的用比较多的bit描述，罕见的用较少的bit进行描述。</p><p>4、最极限的程度是每个参数只用一个bit就能存下来，也就是参数只有1和-1两种可能。而这种做法的效果居然是比正常的做法好的，原因是给了Network比较大的限制后，比较不容易Overfitting。</p><img src="/2021/07/14/shen-jing-wang-luo-ya-suo/9.png" class=""><img src="/2021/07/14/shen-jing-wang-luo-ya-suo/10.png" class=""><h2 id="Architecture-Design"><a href="#Architecture-Design" class="headerlink" title="Architecture Design"></a>Architecture Design</h2><p>这个方法主要通过Network架构的设计来达到减少参数量的目的。这个方法是在CV领域减少参数量的利器。</p><img src="/2021/07/14/shen-jing-wang-luo-ya-suo/11.png" class=""><p>我们回顾CNN的结构，我们知道卷积层所需要的参数是远小于一般的全连接层的，这部分可以回顾我的《Pytoch实战教学》中卷积神经网络章节。</p><h3 id="Depthwise-Separable-Convolution"><a href="#Depthwise-Separable-Convolution" class="headerlink" title="Depthwise Separable Convolution"></a>Depthwise Separable Convolution</h3><p>这个做法和卷积层有共同之处，但不是一个东西，因为它使用的filter数和输入的通道数是一样的，而每一个filter只负责输入的一个通道。因此输入是几个通道，输出就是几个通道。但是这种只检查一个通道的方式，对于一些跨通道的特征是检查不出来的。</p><img src="/2021/07/14/shen-jing-wang-luo-ya-suo/12.png" class=""><p>因此这里还有一个Pointwise Convolution，和一般的卷积层是一样的，但我们使用的卷积核大小都是1 * 1的。这是由于我们上面已经检查了一个通道内部的关系，这里只用检查通道之间的关系。</p><img src="/2021/07/14/shen-jing-wang-luo-ya-suo/13.png" class=""><p>可以看到，采取Depthwise + pointwise的方法比采用一般的卷积层的参数量更少。</p><img src="/2021/07/14/shen-jing-wang-luo-ya-suo/14.png" class=""><p>对于线性层我们减少参数的一个简单做法是在中间插入一层节点较少的线性层。</p><img src="/2021/07/14/shen-jing-wang-luo-ya-suo/15.png" class=""><p>我们Depthwise + Pointwise的方法也是一样，其实我们只是把卷积层拆分成两层，第一层的Depthwise复制把9个像素整合为一个，第二层Pointwise复制将双通道变成四通道。</p><img src="/2021/07/14/shen-jing-wang-luo-ya-suo/16.png" class=""><p>更多网络结构的设计请参考论文：</p><img src="/2021/07/14/shen-jing-wang-luo-ya-suo/17.png" class=""><h2 id="Dynamic-Computation"><a href="#Dynamic-Computation" class="headerlink" title="Dynamic Computation"></a>Dynamic Computation</h2><p>核心想法：我们希望Network可以自由调整它需要的运算量。因为同一个模型通常是需要跑在不同的设备上的，因此我们期待当模型转移到一个新设备时，我们不需要重新训练，而让这个模型自由调整所需的运算资源。就算在同一个设备我们也需要动态调整运算资源，例如手机没电的时候我们希望运算资源用少一些。</p><img src="/2021/07/14/shen-jing-wang-luo-ya-suo/18.png" class=""><p>Dynamic Depth:一个做法是我们让模型可以动态调整神经网络的层数，当运算资源不充足时采用较少的层数进行运算，这样的网络训练方法是在中间引出一个点接到额外的layer进行输出，训练的时候只需要让这个额外的输出也接近label的输出就好（在Loss函数中加入计算额外输出的Loss）。但这个不是现在最好的方法，如果想深入学习，请查看上图的链接。</p><img src="/2021/07/14/shen-jing-wang-luo-ya-suo/19.png" class=""><p>Dynamic Width:另一个做法是动态改变网络的宽度，方法和改变深度一样，但直接这么做也存在问题，详情可以查看上图链接。</p><p>对于自由决定网络的宽度和深度有相当的好处，我们可以在处理简单图片时使用较少的网络，处理复杂图片时使用更多的网络，具体内容请查看论文。</p><img src="/2021/07/14/shen-jing-wang-luo-ya-suo/20.png" class=""><hr><h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><p>前面的四个技术都可以让Network变小，在实际运用的时候我们往往使用多个技术。我们可以既用Architecture Design，也用Knowledge Distillation，然后再用Network Pruning，最后再做Parameter Qrantization。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>机器终身学习与灾难性遗忘</title>
      <link href="2021/07/14/ji-qi-zhong-shen-xue-xi-yu-zai-nan-xing-yi-wang/"/>
      <url>2021/07/14/ji-qi-zhong-shen-xue-xi-yu-zai-nan-xing-yi-wang/</url>
      
        <content type="html"><![CDATA[<img src="/2021/07/14/ji-qi-zhong-shen-xue-xi-yu-zai-nan-xing-yi-wang/1.png" class=""><p>按照我们以往的观点，当neural network的模型上线之后，我们可以源源不断地从网上获得反馈，获得新的资料，从而更好地更新我们的模型，达到life-long-learning的效果，使得模型越来越强大。但真的是这样吗？</p><p>这里举一个例子，这里有两个Domain的任务，但非常类似，都是识别手写数字，区别是一个噪声较多，一个没有噪声，当模型学完任务一然后去做任务二的识别，已经可以达到96%的正确率了。但是，如果把拿这个模型继续去学习任务二的资料，我们发现，虽然任务二的正确率有所提升，但是，我们回过头来去做任务一的识别发现，任务一的正确率已经大大下降了。也就是说，<strong>模型发生了遗忘的现象</strong>。在较为类似的Domain上尚且如此，在不那么相似的Domain结果更惨。</p><p>Tips:其实先学任务二，再学任务一，结果会比较好，可见任务的顺序也对正确率有至关重要的影响，研究任务顺序的课题叫做Curriculum Learning。</p> <img src="/2021/07/14/ji-qi-zhong-shen-xue-xi-yu-zai-nan-xing-yi-wang/2.png" class=""><p>但是如果我们把两种资料混合在一起学习的话，正确率是较为不错的。但<strong>如果模型对资料的学习顺序有先后，那么模型往往会遗忘前面学过的内容</strong>。这件事情叫做Catastrophic Forgetting。</p> <img src="/2021/07/14/ji-qi-zhong-shen-xue-xi-yu-zai-nan-xing-yi-wang/3.png" class=""><p>比较简单好用的做法就是把所有资料倒在一起进行学习，这个做法的缺陷是你有可能没有办法储存如此多的资料，训练周期也较为漫长。好处是在所有任务上都能兼顾到较高的正确率，通常life-long-learning没有办法超越这个正确率，被视为life-long-learning的天花板。</p><p>以下是一个模型life-long-learning的好坏评估标准：</p> <img src="/2021/07/14/ji-qi-zhong-shen-xue-xi-yu-zai-nan-xing-yi-wang/4.png" class=""><h2 id="Selective-Synaptic-Plasticity（可选择的突触可塑性）"><a href="#Selective-Synaptic-Plasticity（可选择的突触可塑性）" class="headerlink" title="Selective Synaptic Plasticity（可选择的突触可塑性）"></a>Selective Synaptic Plasticity（可选择的突触可塑性）</h2><p>这是life-long-learning其中一个解法，意思是训练完一个任务后，模型中的一部分链接参数不能够再动了，以后的训练只能选择修改另外一部分参数。这部分研究是发展的最为完整的，因此我们也主要学习这种做法。</p> <img src="/2021/07/14/ji-qi-zhong-shen-xue-xi-yu-zai-nan-xing-yi-wang/5.png" class=""><p>因此，我们希望在对任务分类中比较重要的参数，我们的改动尽可能小一些，对不重要的参数我们希望可以把改动做大一些。这种做法是我们给每个参数都设置一个保镖（guard），这也是一个参数。这个参数代表了我们希望该参数可以改动的幅度，然后重新定义我们的Loss。<br>$$<br>L’(\theta) = L(\theta) + \lambda \sum_i b_i (\theta_i - \theta_i^b)<br>$$<br>$L’(\theta)$就是我们改动后的Loss函数，它于原来Loss函数的不同只在于加上了一项。要使后面一项的值为零，一个条件是使所有更新后的参数不改变它的值。但是前面乘以了一个guard $b_i$的值，当$b_i = 0$时，无论新的参数怎么变化，Loss都是0，说明这个参数对原来的任务不重要，可以任意变化，guard全部为0会造成Catastrophic Forgetting。相反， 当$b_i = + \infty$时，只要参数稍有变化，Loss就是无穷，说明这个参数及其重要，不允许改变，guard全部为正无穷则造成intransigence，由于不肯妥协而学不到任何新东西。因此我们可以通过调整$b_i$来实现用这个新的Loss训练出只改变某些特定参数的网络。</p><p>$b_i$一般只能人为设定。我们可以求Loss对某一个参数的导数，即梯度，来确定这个参数的重要性，梯度较大则$b_i$设大一些，反之设小一些。</p><p>现在看这个算法的实验结果：</p> <img src="/2021/07/14/ji-qi-zhong-shen-xue-xi-yu-zai-nan-xing-yi-wang/6.png" class=""><p>可以看到SGD是所有$b_i = 0$的情况，即不限制参数的改变，可以看到发生了Catastrophic Forgetting，前面任务的正确率下降幅度很大。L2是所有$b_i = 1$的情况，对所有参数做一样的限制，可以看到旧任务的遗忘度比原来的低，但是在学新任务的时候反而造成了新任务正确率低学不起来的情况。EWC是根据梯度设置$b_i$的做法，可以看到不仅躲到了低遗忘率，在新任务上的表现也比较不错。</p><p>对于$b_i$的具体算法有多种，可以查看论文原文：</p> <img src="/2021/07/14/ji-qi-zhong-shen-xue-xi-yu-zai-nan-xing-yi-wang/7.png" class=""><p>这是有关Regularization-based的做法。关于这个还有一个早年的做法是<strong>Gradient Episodec Memory（GEM）</strong>。这个方法劣势是还需要一定量的过去资料。</p> <img src="/2021/07/14/ji-qi-zhong-shen-xue-xi-yu-zai-nan-xing-yi-wang/8.png" class=""><h2 id="Additional-Nerual-Resource-Allocation（额外的神经资源分配）"><a href="#Additional-Nerual-Resource-Allocation（额外的神经资源分配）" class="headerlink" title="Additional Nerual Resource Allocation（额外的神经资源分配）"></a>Additional Nerual Resource Allocation（额外的神经资源分配）</h2><p>这是life-long-learning的第二种做法。</p><h3 id="Progressive-Neural-Networks"><a href="#Progressive-Neural-Networks" class="headerlink" title="Progressive Neural Networks"></a>Progressive Neural Networks</h3><p>这是最早的做法，当任务一训练完成之后，我们就不要再动里面的参数了，我们可以再新开一个模型，这个模型使用任务一隐藏层中的输出作为输入，然后再训练自己的参数。任务三亦然。这个方法的缺点是模型随着训练任务数量的增多而增大，最后可能难以保存。但在任务量没有太多的时候，这个也是可以派上用场的。</p> <img src="/2021/07/14/ji-qi-zhong-shen-xue-xi-yu-zai-nan-xing-yi-wang/9.png" class=""><h3 id="PackNet"><a href="#PackNet" class="headerlink" title="PackNet"></a>PackNet</h3><p>这种做法是和Progressive Neural Networks相反，首先就建立一个比较大的Network，每次训练任务只使用一小部分的参数。</p> <img src="/2021/07/14/ji-qi-zhong-shen-xue-xi-yu-zai-nan-xing-yi-wang/10.png" class=""><h3 id="Compacting-Picking-and-Growing（CPG）"><a href="#Compacting-Picking-and-Growing（CPG）" class="headerlink" title="Compacting,Picking,and Growing（CPG）"></a>Compacting,Picking,and Growing（CPG）</h3><p>这种做法是上两种的结合。生成一个比较大的网络但是我们一边只使用部分参数，一边新增新的网络，确保参数不会用完。</p> <img src="/2021/07/14/ji-qi-zhong-shen-xue-xi-yu-zai-nan-xing-yi-wang/11.png" class=""><h3 id=""><a href="#" class="headerlink" title=""></a></h3><h2 id="Memory-Reply"><a href="#Memory-Reply" class="headerlink" title="Memory Reply"></a>Memory Reply</h2><h3 id="Generating-Data"><a href="#Generating-Data" class="headerlink" title="Generating Data"></a>Generating Data</h3><p>这种做法是直接训练一个Generator，这个Generator可以直接产生过去任务的资料，因此我们就不用保存过去的资料，直接用这个Generator生成过去的资料和现在任务的资料混合进行训练，以达到同时学习所有数据的效果。这种做法是非常有效的，经过实验证明，往往可以达到跟Multi-Task Learning差不多的结果。</p> <img src="/2021/07/14/ji-qi-zhong-shen-xue-xi-yu-zai-nan-xing-yi-wang/12.png" class=""><h3 id="-1"><a href="#-1" class="headerlink" title=""></a></h3><h3 id="Adding-new-classes"><a href="#Adding-new-classes" class="headerlink" title="Adding new classes"></a>Adding new classes</h3><p>当我们每个任务需要分类的数量不一致应该怎么办？详情请参考以下链接的论文。</p> <img src="/2021/07/14/ji-qi-zhong-shen-xue-xi-yu-zai-nan-xing-yi-wang/13.png" class=""><h3 id="-2"><a href="#-2" class="headerlink" title=""></a></h3><hr><h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><p>life-long-learning的讲解到这里告一段落，前面讲的只是life-long-learning三个情景中最简单的一种，如果想要深入学习这个领域，可以查看论文：<a href="https://arxiv.org/abs/1904.07734%E3%80%82">https://arxiv.org/abs/1904.07734。</a></p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>强化学习概述（Reinforcement Learning）</title>
      <link href="2021/07/08/qiang-hua-xue-xi-gai-shu-reinforcement-learning/"/>
      <url>2021/07/08/qiang-hua-xue-xi-gai-shu-reinforcement-learning/</url>
      
        <content type="html"><![CDATA[<p> 视频课程链接：<a href="https://www.bilibili.com/video/BV1Wv411h7kN?p=73">https://www.bilibili.com/video/BV1Wv411h7kN?p=73</a></p><h2 id="序章"><a href="#序章" class="headerlink" title="序章"></a>序章</h2><p>一般我们做监督式学习（supervised-learning），你不仅需要数据，还需要对应的标签，这样才能训练一个模型。这样我们在实际应用时，我们就能做正确率很高的分类。但是在强化学习领域（以下简称RL），给定一个输入，我们需要自己寻找一个最佳的输出，例如，给定一个围棋棋盘的局势作为输入，让你选择一个落子的位置作为输出。这种我们人类也不知道正确答案的时候，我们希望可以让模型自己在环境中进行学习，和环境做互动，不断地尝试去做有利于自己的事情，通过人类的理解得出一个评分，我们想办法让这个评分越高越好，这样模型就懂得如何寻找一个更优秀的输出，从而形成“进化”。RL的框架和深度学习是一样的。</p><img src="/2021/07/08/qiang-hua-xue-xi-gai-shu-reinforcement-learning/1.png" class><p>这里举一个外星人大战游戏的例子：我们需要训练的model叫做Actor。它输入的是游戏中的实时状况，输出只有三种可能：左移右移和开火。游戏的画面每一秒都在变，它每一秒都会获得不同的输入，它要根据这个输入来决定输出，而最终目标是能够尽可能多得获取分数。这个分数就是Reward，这个分数决定了model的进化方向，例如Actor通过开火获得了比较高的分数，那么以后它就会更倾向于开火这个输出。这样通过游戏画面不断得到反馈，直到最后满足游戏终止的条件，当游戏终止时，我们期望model通过不断学习，获取到的reward越高越好。</p><img src="/2021/07/08/qiang-hua-xue-xi-gai-shu-reinforcement-learning/2.png" class><p>通常来说，model的输入并不是输入游戏画面，通常是一种人为定义的游戏状况，例如：敌人的位置，朝向，距离等等。这样训练神经网络会容易得多。而网络的输出是一个产生各个类别动作的几率，通过这个几率去做出选择。</p><p>那么如何控制actor的动作呢，如果我们希望在某一个输入时规范一个行为，那么我们就可以直接把这个当做深度学习中的分类问题即可，通过能产生固定行为的输出label来训练并且改变model的参数使其符合我们的预期。通过收集一堆这种对应的数据就能规范各种行为，要做什么，不要做什么，不要做的事情给Loss加上符号即可。</p><img src="/2021/07/08/qiang-hua-xue-xi-gai-shu-reinforcement-learning/3.png" class><img src="/2021/07/08/qiang-hua-xue-xi-gai-shu-reinforcement-learning/4.png" class><p>不仅如此，我们也可以调整它的程度。例如我们非常期待模型去改变，则用大一点的值，反之用较小的值。</p><img src="/2021/07/08/qiang-hua-xue-xi-gai-shu-reinforcement-learning/5.png" class><hr><h2 id="Cumulated-Reward"><a href="#Cumulated-Reward" class="headerlink" title="Cumulated-Reward"></a>Cumulated-Reward</h2><p>为了避免actor只重视短期利益忽视长期利益，我们将一个行为的分数评估改为cumulated-reward，也就是累积分。计算方式是执行了当前行为后（即model输出）所获得的所有reward的累加。这样即使是左移右移这种不杀死敌人没有获得任何reward的行为，也会被actor学习到。</p><img src="/2021/07/08/qiang-hua-xue-xi-gai-shu-reinforcement-learning/6.png" class><p>但这个办法有不妥之处，如果流程较长，那么后面的reward根本不能说都归功于第一个行为，因此我们需要加上一个系数，前面的行为对越后面的reward影响越小，也就是说能获得的cumulated-reward越小，这就是Discounted-Cumulated-Reward。事实上RL就是在不断地调整这个奖励机制，以达到各种学习目的。</p><img src="/2021/07/08/qiang-hua-xue-xi-gai-shu-reinforcement-learning/7.png" class><p>我们还需要对reward进行标准化处理，因为好坏是比较出来的，我们在所有reward都为正的时候，并不能认为所有的行为都是好的，我们必须发扬分数更高的那些行为。</p><img src="/2021/07/08/qiang-hua-xue-xi-gai-shu-reinforcement-learning/8.png" class><hr><h2 id="实现思路"><a href="#实现思路" class="headerlink" title="实现思路"></a>实现思路</h2><p>1、建立一个神经网络模型，参数随机，输入的是游戏实况，输出游戏控制项，中间层由自己决定。</p><p>2、在环境中运行这个AI模型，收集资料，每收集一次资料就计算一次reward。</p><p>3、我们用自己的方法对这些reward做处理，然后用处理结果更新我们的参数，分数高的就继承，分数低的摒弃。</p><p>4、每更新一次参数就要重新收集资料，经过不断地参数更新，我们期待最终得到一个比较智能的AI模型。</p><hr><h2 id="off-policy"><a href="#off-policy" class="headerlink" title="off-policy"></a>off-policy</h2><p>这里有一种叫做off-policy的方法，相对于我们用的每收集一次资料就更新一次参数的on-policy，它的负责互动的actor和负责训练的actor是分开的，这样收集一次资料就能用来更新多次参数，训练速度大大加快，这里不细讲。有一个非常经典的off-policy方法叫做Proximal-Policy-optimization（PPO）。</p><img src="/2021/07/08/qiang-hua-xue-xi-gai-shu-reinforcement-learning/9.png" class><hr><h2 id="Exploration"><a href="#Exploration" class="headerlink" title="Exploration"></a>Exploration</h2><p>这是一个很重要的概念，actor采取行为是要有随机性的，这个随机性十分关键，很多时候由于随机性不够而训练不出好结果。如果有一个行为对actor来说是更好的选择，但是actor从来都没有进行过这种行为，而且也没有到达这种行为的途径，这样训练就会卡死在一个局部最优点，为了model能从这个点跳出来，我们往往鼓励actor去尝试更多的选择，这样我们才能收集到比较丰富的资料。我们可以在actor参数上加noise，让它每一次行为不一样，这样可能就能随机到一些更好的行为。</p><hr><h2 id="Critic"><a href="#Critic" class="headerlink" title="Critic"></a>Critic</h2><img src="/2021/07/08/qiang-hua-xue-xi-gai-shu-reinforcement-learning/10.png" class><p>Critic的任务是预测，在当前的actor下，现在的状况能够获得多少的Discounted-Cumulated-Reward。不同的actor在不同的状况下的预测值都有所不同，这里的预测值我们称为$V^θ$。它的训练方法是在游戏进行过程中收集资料，每一个游戏状况所对应的Discounted-Cumulated-Reward是多少，用这样的多笔训练资料来训练模型$V^θ$，这个叫做<strong>Monte-Carlo（MC）</strong>。</p><img src="/2021/07/08/qiang-hua-xue-xi-gai-shu-reinforcement-learning/11.png" class><p>还有一种做法是<strong>Temporal-difference（TD）</strong>,不用玩完整场游戏就可以得到训练资料，只需要得到一个游戏状况和对应输出、分数以及下一个游戏状况时，就能进行训练，预测值我们称为$V^π$，这种方法可以用来处理流程很长的游戏。通过式子计算可以得到：<br>$$<br>V^{\theta}(s_t) - \gamma V^{\theta}(s_{t+1})  =  r_t<br>$$<br>我们要尽可能使得等式两边相等，这样我们就能使得$V^θ$得到不断训练。</p><img src="/2021/07/08/qiang-hua-xue-xi-gai-shu-reinforcement-learning/12.png" class><p>这两种方法计算出来的reward的结果也会不同：</p><img src="/2021/07/08/qiang-hua-xue-xi-gai-shu-reinforcement-learning/13.png" class><p>在上面的画面中总共看到八次游戏画面$S_b$，总得分为6，所以平均为四分之三。但是对于$S_a$，如果用MC计算出来是0，但是用TD的算法，由于后面的分数也要按照一定比例加到$S_a$中，所以$S_a$也就继承了$S_b$的四分之三。这里$S_b$没有用0是因为我们看的是全局，它的期望值是四分之三，只是这里的随机出来的一个行为的得分是0而已。MC和TD没有孰优孰劣，只是角度不同。<br>$$<br>V^{\theta}(s_t)  =  r +  V^{\theta}(s_{t+1})<br>$$</p><h3 id="Advantage-Actor-Critic"><a href="#Advantage-Actor-Critic" class="headerlink" title="Advantage Actor-Critic"></a>Advantage Actor-Critic</h3><p>回到我们实现Discounted-Cumulated-Reward的地方，我们需要对分数做normalization，因为在所有行为的得分为正的情况下不代表所有的行为都是正确的，我们必须有选择地学习更好的行为。因此我们会在Discounted-Cumulated-Reward基础上减去一个常数。这个数的计算方式就是Critic。这是因为我们对于输入的同一个状况，由于输出要具有一定随机性的存在，我们每次的输出都是有所不同的，输出的是一个distribution（分布）。那么其实这些所有可能所能获得的Reward的平均值就是$V^θ$，这就是Critic的含义。我们用来更新参数的$A_t$是用Discounted-Cumulated-Reward减去这个平均值，也就是<strong>如果对于一个状况的行为的得分比我们critic预测的要高，则采纳，反之舍弃</strong>。</p><img src="/2021/07/08/qiang-hua-xue-xi-gai-shu-reinforcement-learning/14.png" class><img src="/2021/07/08/qiang-hua-xue-xi-gai-shu-reinforcement-learning/15.png" class><p>上面的版本还有一个缺陷，就是用特殊减去平均，我们已经知道Critic是看到一个游戏状况后对以往的reward的期望。而我们新更新的model之后，这个游戏状况输入model之后的评分也应该是期望，而不是上面所说的一个某种情况的特殊值，因为上面的Discounted-Cumulated-Reward是固定游戏状况下，model输出分布中的一个特殊值而已，如果想要得到一个平均值，我们需要收集资料，多次运行同样的状况。这样我们用这个model更新后的reward的平均值减去model更新前reward的平均值，这样才能衡量我们更新的model是否优于之前的model。而这个更新后的平均值就是<br>$$<br>r_t + V^{\theta}(s_{t+1})<br>$$</p><img src="/2021/07/08/qiang-hua-xue-xi-gai-shu-reinforcement-learning/16.png" class><p>因此最后用来更新的公式为：<br>$$<br>A_t = r_t + V^{\theta}(s_{t+1}) - V^{\theta}(s_t)<br>$$<br>，<strong>这就是大名鼎鼎的常用方法，$Advantage Actor-Critic$。</strong>如果$A_t$为正，则表明使用$A_t$这个模型得到的reward比我们尚未使用这个模型时reward的期望值要高，我们应该采纳，反之亦然。</p><img src="/2021/07/08/qiang-hua-xue-xi-gai-shu-reinforcement-learning/17.png" class><p>实际上由于Critic和Actor的输入是相同的，因此它们可以共用前面几层的Network。</p><hr><h2 id="Deep-Q-Network（DQN）"><a href="#Deep-Q-Network（DQN）" class="headerlink" title="Deep Q Network（DQN）"></a>Deep Q Network（DQN）</h2><p>在RL中还有一种犀利的做法，就是直接用Critic就可以决定用什么样的Action。最知名的就是DQN，这里不细讲，感兴趣可以查看原论文，但是现在已经有了更新更好的方法，叫做A3C（Asynchronous Advantage Actor-Critic），我们学习也可以直接学最新的A3C的内容。</p><img src="/2021/07/08/qiang-hua-xue-xi-gai-shu-reinforcement-learning/18.png" class><hr><h2 id="Reward-Shaping"><a href="#Reward-Shaping" class="headerlink" title="Reward Shaping"></a>Reward Shaping</h2><p>假设我们遇到的是一个Sparse-Reward的问题，也就是评分机制非常稀疏，例如一局游戏结束赢了才能得分，输了不得分，这样我们在训练过程中很难得到有效的反馈，从而导致network训练不起来。这种时候<strong>我们就需要提供额外的reward来引导模型进行学习，这件事情就叫做Reward-Shaping。</strong>我们要做Reward-Shaping，往往需要用到人类自己的理解，来加快机器的训练进程。</p><p>例如，训练一个第一人称射击游戏的AI，我们不仅需要在人物死掉时扣分，击杀对手是加分，还需要在扣血时也进行相应的扣分，否则actor需要很长的时间才能学会扣血和死亡直接的联系。为了防止AI消极比赛，我们需要鼓励其进行移动，因此移动时可以增加少量分数，并且每过一段时间就扣除一定分数。在捡到有益的道具时我们也会设置reward来鼓励这种行为。</p><p>在Reward-Shaping中有一个做法叫做Curiosity-based。其实就是鼓励AI去发现新的事物，当AI发现有意义的新的东西，就应该被加分。光是利用这一项内容，就足以通关马里奥的一些关卡，可见Curiosity对AI的重要性。同时我们也要克服噪声这种没意义的新。详细展开请查看论文原文：</p><p><a href="https://arxiv.org/abs/1705.05363">https://arxiv.org/abs/1705.05363</a></p><hr><h2 id="No-Reward-Learning-from-Demonstation"><a href="#No-Reward-Learning-from-Demonstation" class="headerlink" title="No Reward:Learning from Demonstation"></a>No Reward:Learning from Demonstation</h2><p>在游戏中，我们往往有一个计分板，很容易就能定义哪些事情是好的，哪些是不好的。但现实中，定义Reward有可能是非常困难的，并且人定的reward也有可能存在许多意想不到的缺陷。在没有reward的情况下，让AI跟环境互动的一个方法叫做<strong>Imitation-Learning</strong>。在没有reward的前提下，我们可以找人类进行示范，AI可以凭借这些示范以及跟环境的互动进行学习。</p><p>这跟supervised-learning有类似之处，如果采用这种做法，我们叫做Behavior-Cloning，也就是复制人类的行为。首先，这样的问题就是没有办法对人类没有经历过的情况进行处理，例如人类驾驶车不会去撞墙，那么AI就无法学会即将撞墙时的情形以及处理办法。第二，机器无需对人类的所有行为进行模仿，否则人类某些不应该被学习的个人习惯也会被学习。</p><h3 id="Inverse-Reinforcement-Learning"><a href="#Inverse-Reinforcement-Learning" class="headerlink" title="Inverse Reinforcement Learning"></a>Inverse Reinforcement Learning</h3><p>因此这里有一个算法叫Inverse Reinforcement Learning，这个算法并不是根据reward去学习，而是根据expert的Demonstration和Environment去反推reward长什么样子。也就是说，Reward Function是学出来的。Reward Funciton学出来后，就可以用一般的RL来训练模型了。</p><img src="/2021/07/08/qiang-hua-xue-xi-gai-shu-reinforcement-learning/19.png" class><img src="/2021/07/08/qiang-hua-xue-xi-gai-shu-reinforcement-learning/20.png" class><p>这个算法的假设前提是：<strong>老师的行为是最好的，也就是能得到最高的reward。</strong></p><p>在定义Reward Function的时候，我们要让老师的reward始终大于训练的AI。而训练的AI要学会去根据这个Function去获得更高的reward（这里要用到RL的方法），而这个Function要不断调整，始终保持老师的reward是最高的。</p><img src="/2021/07/08/qiang-hua-xue-xi-gai-shu-reinforcement-learning/21.png" class><p>这和GAN有一定的相似之处，我们可以把Actor当成Generator，把Reward Funciton当成Discriminator。这有异曲同工之处。首先Reward Funciton的任务是给老师高分，给Actor低分。而Actor是想办法获得高分，这两者交替更新，形成对抗，从而使得既能训练出好的Reward Funciton，又能训练处优秀的Actor。</p><p>如果你想要用写程序的方法操控机械手臂，虽然对人来说操控自己的手臂是很简单的事情，但是用代码实现机械臂的动作往往并不是那么容易。这时候你就可以用到RL的技术，直接把动作示范给机器看，看机器是否能借此学会这个动作。我们可以直接拖动机械手臂来让它达到某个效果，从而让其收集足够的数据进行学习模仿。</p><img src="/2021/07/08/qiang-hua-xue-xi-gai-shu-reinforcement-learning/22.png" class><p>这里有一个更新的做法，就是给机器直接看一个画面，它会想办法达到这个画面中的动作，从而完成学习，这里不细讲，可以查看原始论文：</p><img src="/2021/07/08/qiang-hua-xue-xi-gai-shu-reinforcement-learning/23.png" class><hr><img src="/2021/07/08/qiang-hua-xue-xi-gai-shu-reinforcement-learning/24.png" class>]]></content>
      
      
      <categories>
          
          <category> 强化学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 强化学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>领域自适应概述（Domain Adaptation）</title>
      <link href="2021/07/08/ling-yu-zi-gua-ying-gai-shu-domain-adaptation/"/>
      <url>2021/07/08/ling-yu-zi-gua-ying-gai-shu-domain-adaptation/</url>
      
        <content type="html"><![CDATA[<p>  当训练和测试资料的分布不一样，得到的正确率将大大减小。当训练资料和测试资料分布不同的时候，这种状况叫做Domain-shift。在日常任务中测试资料和训练资料的分布通常并不相同。</p><img src="/2021/07/08/ling-yu-zi-gua-ying-gai-shu-domain-adaptation/1.png" class=""><p>Transfer-learning就是在A任务上学到的技能能够用在B任务上。除了输入的分布有变化，输出的分布也可能有变化，例如在有些事情上每一个数字的概率不是一样的，对应的方式也不一定一样。但现在我们只专注于输入的分布变化的情况。</p><img src="/2021/07/08/ling-yu-zi-gua-ying-gai-shu-domain-adaptation/2.png" class=""><p>当我们拥有大量的有标注的测试集资料，我们直接拿来训练就好。当我们只有少量的有标注的测试集资料时，处理的方式是用测试集资料对已经训练好的模型进行微调。但由于资料过少，我们不能训练太多的Iteration。否则容易overfitting。</p><p>但是往往的情景是我们有大量的测试集资料，但是这些资料都是没有标注的。这时候我们需要一个Feature-Extractor，使得原来的训练集的资料和测试集的资料映射到同一个分布上。</p><img src="/2021/07/08/ling-yu-zi-gua-ying-gai-shu-domain-adaptation/3.png" class=""><p>这样我们就可以把网络分成Feature-Extractor和Label-Predictor两部分。我们的要求是两种数据在经过Feature-Extractor后都分不出差异，例如形成的二维坐标系上的点的分布一样。具体做法类似GAN，训练一个Domain-Classifier对这两种图片进行分类，并让它们进行对抗，直到Domain-Classifier分不出两种图片的区别为止。</p><img src="/2021/07/08/ling-yu-zi-gua-ying-gai-shu-domain-adaptation/4.png" class=""><p>但这未必设最好的做法，因为Feature-Extractor和Domain-Classifier的作用实际上都是把两种domain分开。</p><hr><p>我们希望测试集的图片经过分类后，减少不确定性，能够很确定自己的分类，这样的结果是比较好的。具体的自行研究。</p><img src="/2021/07/08/ling-yu-zi-gua-ying-gai-shu-domain-adaptation/5.png" class=""><hr><p>有的时候，两个Domain之间不一定拥有一样的类别，包含的类别可能交叉或者是包含关系，这样上面的方法就不适用了，因为类别的数量的不一致，强行要求数量上的一致显得不太合理，解决方法见图中文章。</p><img src="/2021/07/08/ling-yu-zi-gua-ying-gai-shu-domain-adaptation/6.png" class=""><hr><p>上面的情况是基于有大量的未标注数据的情况下的，如果这种为标注的数据很少，有一种方法是Testing-Time-Training。论文如下：</p><img src="/2021/07/08/ling-yu-zi-gua-ying-gai-shu-domain-adaptation/7.png" class=""><hr><p>还有一种更为严峻的情况，就是我们对新的Domain一无所知，这叫做Domain-Generalization。</p><img src="/2021/07/08/ling-yu-zi-gua-ying-gai-shu-domain-adaptation/8.png" class=""><hr>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>机器学习的可解释性（Explainable ML）</title>
      <link href="2021/07/07/ji-qi-xue-xi-de-ke-jie-shi-xing-explainable-ml/"/>
      <url>2021/07/07/ji-qi-xue-xi-de-ke-jie-shi-xing-explainable-ml/</url>
      
        <content type="html"><![CDATA[<p>我们需要机器学习的可解释性，原因是就算现在机器能够做出正确的答案，也不代表它非常聪明。现在银行用机器学习的模型来辨别是否贷款给一个用户，但政策规定必须给出一个理由，这是我们需要机器学习的模型是具有解释力的。有些重要的事情，机器学习不给出一个理由，我们很难相信是正确的判断。</p><p>当机器学习具有解释力的时候，我们可以凭借解释的结果来修正我们的模型。</p><p>Explanation分为两种。一种是Local-Explanation，一种是Global-Explanation。前者是根据某一个数据回答问题（为什么这是猫），后面是没有给具体数据，先给一个分类一个定义（什么图片叫做猫）。</p><h2 id="Local-Explanation"><a href="#Local-Explanation" class="headerlink" title="Local-Explanation"></a>Local-Explanation</h2><img src="/2021/07/07/ji-qi-xue-xi-de-ke-jie-shi-xing-explainable-ml/1.png" class=""><p>如果你想要知道图片中每个区域的重要性的时候，一个方法是把每部分分别拿掉。再看分类正确的几率。</p><img src="/2021/07/07/ji-qi-xue-xi-de-ke-jie-shi-xing-explainable-ml/2.png" class=""><p>图中蓝色的区域表明拿掉之后识别的准确率大大降低，说明了其重要性，可解释性大大提高。</p><p>还有一个比较直接的方法是直接测试每一个pixels（像素）的梯度，把某一个pixel的值直接作一个小小的变化，观察输出结果跟正确答案的差距的变化，变化程度越大，重要性越高。</p><img src="/2021/07/07/ji-qi-xue-xi-de-ke-jie-shi-xing-explainable-ml/3.png" class=""><p>这就是<strong>Saliency-Map</strong>。</p><p>有时我们画的图亮点可能会比较分散，让人疑惑，这里有可以把图画得更好的方式。SmoothGrad是一种。方法是在图片上加上各种各样不同的噪声。每张图片都计算Saliency-Map。平均起来就可以得到比较明显的结果。</p><img src="/2021/07/07/ji-qi-xue-xi-de-ke-jie-shi-xing-explainable-ml/4.png" class=""><p>有的时候光看梯度是无法察觉一件事物的重要程度的。论文链接如下图：</p><img src="/2021/07/07/ji-qi-xue-xi-de-ke-jie-shi-xing-explainable-ml/5.png" class=""><p>有时我们可以把一个高维的向量降导二维，然后放到图中观察，这样就可以用肉眼观察的方式看出区别。</p><img src="/2021/07/07/ji-qi-xue-xi-de-ke-jie-shi-xing-explainable-ml/6.png" class=""><p>这里有一个Probing的方法，就是用探针插入network看看发生什么事。我们可以去训练一个分类器，插入中间层查看Embedding之后的结果是否包含我们需要的信息，如果分类器怎么的得不到好结果，可能中间层已经不包含我们需要的信息。但要注意也有可能是model没有train好的缘故。</p><img src="/2021/07/07/ji-qi-xue-xi-de-ke-jie-shi-xing-explainable-ml/7.png" class=""><img src="/2021/07/07/ji-qi-xue-xi-de-ke-jie-shi-xing-explainable-ml/8.png" class=""><p>通过probbing的复现，我们可以发现每一层的神经网络的作用（例如过滤噪音）的影响有多大。</p><h2 id="Global-Explanation"><a href="#Global-Explanation" class="headerlink" title="Global-Explanation"></a>Global-Explanation</h2><p>Global-Explanation并不是根据某一个数据给出解释，而是把训练好的模型拿出来，检查其中的参数，得出对一个分类的定义。</p><img src="/2021/07/07/ji-qi-xue-xi-de-ke-jie-shi-xing-explainable-ml/9.png" class=""><p>例如上图，卷积层的输出有很多的filters。如果某一层的filter中的一些位置有比较大的值，说明这个部位负责侦测某些特征。如果fillter1看到了这些pattern，那么就在feature-map看到比较大的值。如果我们要比较直观看到这种模式，我们需要创造一张图片，这张图片包含Filter1需要Detect的Pattern。</p><p>因此我们需要找一张图片，使得其中输出每一个点的总和越大越好。</p><img src="/2021/07/07/ji-qi-xue-xi-de-ke-jie-shi-xing-explainable-ml/10.png" class=""><img src="/2021/07/07/ji-qi-xue-xi-de-ke-jie-shi-xing-explainable-ml/11.png" class=""><p>把每一个filter对应的图片画出来，就能看出每个filter所要侦测的pattern。可以看出有的filter的任务是侦测竖线，有的是侦测横线。</p><p>然而你想要找一个某分类最高分的图片来查看识别的pattern，往往看到的是一堆杂讯，而且很多杂讯的信心分数非常高，这部分涉及Adversarial-Attack，有时候微小的噪声变化都能使输出产生翻天覆地的变化。</p><img src="/2021/07/07/ji-qi-xue-xi-de-ke-jie-shi-xing-explainable-ml/12.png" class=""><p>这时候我们需要人为加入限制，让这种pattern符合人的习惯，我们可以让白色像素点越少越好。</p><img src="/2021/07/07/ji-qi-xue-xi-de-ke-jie-shi-xing-explainable-ml/13.png" class=""> <p>往往我们要得到更加令人满意的结果，我们就需要更加自己对一件事物的了解下非常多的限制。</p><p>如果你想要看到非常清晰的图片，你可以训练Generator。这时候你的任务是找一个z使得这个z产生的图片丢到分类器中的信心分数越大越好。这样你就能得到一张非常标准的图片。</p><img src="/2021/07/07/ji-qi-xue-xi-de-ke-jie-shi-xing-explainable-ml/14.png" class=""><img src="/2021/07/07/ji-qi-xue-xi-de-ke-jie-shi-xing-explainable-ml/15.png" class="">]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>抵御来自人类的恶意攻击（Adversial Attack）</title>
      <link href="2021/07/06/di-yu-lai-zi-ren-lei-de-e-yi-gong-ji-adversial-attack/"/>
      <url>2021/07/06/di-yu-lai-zi-ren-lei-de-e-yi-gong-ji-adversial-attack/</url>
      
        <content type="html"><![CDATA[<h2 id="攻击方式"><a href="#攻击方式" class="headerlink" title="攻击方式"></a>攻击方式</h2><p>一个模型想要实际应用，不仅仅需要较高的准确率，还需要能应对人类的恶意攻击。例如分辨垃圾邮件，发件方也会尽量让邮件看起来不像垃圾邮件。又例如在图片中加入一些噪声，模型要想办法让噪声也不影响输出。</p><img src="/2021/07/06/di-yu-lai-zi-ren-lei-de-e-yi-gong-ji-adversial-attack/1.png" class=""><img src="/2021/07/06/di-yu-lai-zi-ren-lei-de-e-yi-gong-ji-adversial-attack/2.png" class=""><p>有时候即使是人肉眼难以分辨的微小噪声，也能使得输出天差地别。这种攻击的做法就是找到一张新的图片输入到模型中，使得输出根正确答案差距越大越好。如果是有目标的攻击，我们不仅要让输出远离正确答案，还要靠近我们想要的答案。而这张新的图片我们希望加入的噪声越小越好。</p><img src="/2021/07/06/di-yu-lai-zi-ren-lei-de-e-yi-gong-ji-adversial-attack/3.png" class=""><img src="/2021/07/06/di-yu-lai-zi-ren-lei-de-e-yi-gong-ji-adversial-attack/4.png" class=""><p>对于图片距离的衡量有多种方式，其中infinity的方式最适合，并且符合人眼观察的习惯。</p><p>如果不管输入的图片，那么我们同样是用原来的梯度下降法，只需要将图片像素设定为需要优化的参数即可，把参数初始化为我们需要接近的图片。但是图片要加上一个限制使得图片的距离小于一个人眼能识别的阈值。方法就是当图片的距离大于一个阈值后进行修正。</p><img src="/2021/07/06/di-yu-lai-zi-ren-lei-de-e-yi-gong-ji-adversial-attack/5.png" class=""><p>这里有一个只需要update一次参数的方法，往往能一次性达到目的。</p><img src="/2021/07/06/di-yu-lai-zi-ren-lei-de-e-yi-gong-ji-adversial-attack/6.png" class=""><p>只需要直接往梯度方向直接更新到人眼识别的极限即可，优点是速度大大提升，缺点是与原来的图片偏差较大。</p><hr><p>上面的方法的前提是需要知道模型的参数，这种攻击叫做White-Box-Attack。而不知道模型参数的攻击叫做Black-Box-Attack。但是如果我们知道这个Network是用什么训练资料训练的，我们就可以自己训练一个Proxy的Network，这样可能就会和要攻击的对象有一定的相似性。这样如果我们对这个Proxy的Network进行攻击并成功，那么就可以也适用于我们的攻击对象。</p><p>但如果我们完全没有训练资料，那么就需要不断测试输入输出，然后把这些成对的资料用来训练自己的模型，那么也有可能训练一个类似的模型。</p><p>这种黑箱攻击非常容易成功。</p><img src="/2021/07/06/di-yu-lai-zi-ren-lei-de-e-yi-gong-ji-adversial-attack/7.png" class=""><p>其中的百分比是被攻击对象的识别成果率，其中如果Proxy-Network使用相同的模型相当于White-Box-Attack，一定成功，在Black-Box-Attack的情况下使用其他模型攻击成果的概率也较大。但是这是在Non-Target的情况下，如果指定目标，例如把狗识别成兔子，就比较难。</p><p>如果采用Esemble-Attack，将使攻击成果的概率大大增加。</p><img src="/2021/07/06/di-yu-lai-zi-ren-lei-de-e-yi-gong-ji-adversial-attack/8.png" class=""><p>这种方法是同时训练多个种类的Network，使得我们的攻击数据在每个Network上都成功，图中左边的数据前面的减号是指用除了这种模型以外的几个模型训练成功。所以对角线才是Black-Box-Attack，其他的地方是White-Box-Attack。所以结论是如果我们的数据在多个模型上的攻击都成功了，那么在我们的目标模型上的攻击也很大概率是成功的。</p><hr><p>下面是原因：</p><img src="/2021/07/06/di-yu-lai-zi-ren-lei-de-e-yi-gong-ji-adversial-attack/9.png" class=""><p>其中的蓝色区域是模型成功辨识的区域，我们发现不同模型都有一定的相似程度，在一个方向上的辨识范围特别窄，我们稍微动一下这个维度，那么就会导致模型识别失败，而这个维度在所有模型上的识别范围都是类似的。</p><p>这种观点把成功的原因归功于data而不是model。模型之所以会产生误判是因为资料本身的特征，所以模型们都会学习到这种特征而产生误判。当有足够的资料，就有可能避免这种攻击。不过这是部分人的观点，没有得到公认。</p><hr><p>这些攻击不仅运用在图片上，也可以运用在文字和语音上。</p><img src="/2021/07/06/di-yu-lai-zi-ren-lei-de-e-yi-gong-ji-adversial-attack/10.png" class=""><p>以上的攻击是基于数位的世界，我们需要在机器获取数据后对数据进行处理才能骗过机器，如果现实时间中我们没有办法对既定的图片或数据进行修改，那么有没有可以化个妆就把系统欺骗过去呢？这是有可能的。不过化妆是一种不稳定的修改，有人发现了一种通过戴特殊眼镜的方法。</p><img src="/2021/07/06/di-yu-lai-zi-ren-lei-de-e-yi-gong-ji-adversial-attack/11.png" class=""><p>也有人对车牌辨识系统进行攻击：</p><img src="/2021/07/06/di-yu-lai-zi-ren-lei-de-e-yi-gong-ji-adversial-attack/12.png" class=""><p>还有一种攻击方式是Adversarial-Reprogramming。论文中做了一个方块辨识系统数图中有几个方块。但不训练自己的模型，可以寄生在一个已有的模型上面。当输入的图片中检测出几个方块时，就使模型输出对应一定的结果，这样就能操控别的模型做本来不是训练要做的事情。只需要把图片嵌入一堆杂讯的中间，就能时原本的模型按自己的要求进行输出。</p><img src="/2021/07/06/di-yu-lai-zi-ren-lei-de-e-yi-gong-ji-adversial-attack/13.png" class=""><p>还有一种攻击是从训练阶段就展开攻击，在一堆正常的训练资料中事先加入我们精心设定的图片，看起来没什么问题，但是机器训练完成后，就会对特定的一个事物产生误判，但是也有一定限制。</p><img src="/2021/07/06/di-yu-lai-zi-ren-lei-de-e-yi-gong-ji-adversial-attack/14.png" class=""><hr><h2 id="防御方式"><a href="#防御方式" class="headerlink" title="防御方式"></a>防御方式</h2><p>防御方式分为被动防御和主动防御。</p><h3 id="Passive-Defense"><a href="#Passive-Defense" class="headerlink" title="Passive-Defense"></a>Passive-Defense</h3><p><strong>被动防御</strong>的方式是模型训练好之后不再更改，而是在数据中加入一个Filter（过滤器）。普通的数据经过过滤器后不受影响，但攻击数据经过过滤器后会大大削减威力，让你的Network不会辨识错误。一个最简单的方法是把图片稍微模糊化，这就可以做到很好的防御效果了。缺点是模糊化后造成的副作用是加强了识别的不确定性，可能会导致正常的图片辨识错误，所以模糊不能过头。第二种方式是把图片做某种会造成失真的压缩，然后解压缩，失真本身就能使攻击图片失去威力。第三种方式是图片用Generator重新生成。</p><img src="/2021/07/06/di-yu-lai-zi-ren-lei-de-e-yi-gong-ji-adversial-attack/15.png" class=""><img src="/2021/07/06/di-yu-lai-zi-ren-lei-de-e-yi-gong-ji-adversial-attack/16.png" class=""><p>被动防御有很大缺陷，如果别人知道你使用了某种防御方式，例如模糊化，那么相当于在网络前加上一层。别人也把这一层加入攻击过程中，产生的数据也可以骗过我们的模型。</p><p>一种方法是我们自己都不知道自己用什么方式来过滤。一种具有随机性的方式可以在一定程度上解决这个问题：</p><img src="/2021/07/06/di-yu-lai-zi-ren-lei-de-e-yi-gong-ji-adversial-attack/17.png" class=""><p>但如果别人知道你的随机分布，也是有可能攻破这种方式的。方式是用Univeral-Attack。</p><h3 id="Proactive-Defense"><a href="#Proactive-Defense" class="headerlink" title="Proactive-Defense"></a>Proactive-Defense</h3><p>首先，我们用正常的资料对模型进行训练，训练完成后，我们自己对模型进行攻击。但我们把具有攻击性的图片都标上正确的label。这样训练出来的model就有办法识别具有攻击性的图片。这第二次训练完成后再重复进行攻击，如此反复。这其实是一种Data-Augmentation的方式，因此有人把Adversarial-Training当成单纯的资料增强的方式。就算没有人攻击你的模型，也可以用这种方法产生更多的资料，避免overfitting。</p><p>这种防御的方法也是有可能被攻破的，我们必须实现考虑到别人采用的攻击方式，如果我们在训练的时候没有考虑到别人的攻击算法，别人用了新的方式进行攻击，往往就能成功。并且需要大量的运算资源，很花时间。有一种方式是Adersarial-Training-for-free不用占用太多的运算资源，这里不细讲，文献链接在图片中。</p><img src="/2021/07/06/di-yu-lai-zi-ren-lei-de-e-yi-gong-ji-adversial-attack/18.png" class="">]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>自监督式学习（Self-supervised Learning）</title>
      <link href="2021/07/01/zi-jian-du-shi-xue-xi-self-supervised-learning/"/>
      <url>2021/07/01/zi-jian-du-shi-xue-xi-self-supervised-learning/</url>
      
        <content type="html"><![CDATA[<h2 id="Self-supervised-learning"><a href="#Self-supervised-learning" class="headerlink" title="Self-supervised-learning"></a>Self-supervised-learning</h2><p>在《李宏毅机器学习2021》中前面讲解的方法都是监督式的学习。给定数据和标签，这样才能训练supervised的model。</p><p>而self-supervised是在自己没有label的情况下想办法做supervised。</p><p>方法是把没有标注的资料分成两部分，一部分作为模型的输入，一部分作为模型的标注。然后让模型的输出跟模型的标注越接近越好。</p><img src="/2021/07/01/zi-jian-du-shi-xue-xi-self-supervised-learning/1.png" class=""><p><strong>下面用BERT来举例：</strong></p><p>Transformer的Encoder就是BERT的架构。这就意味着输入和输出的序列长度一样。这种结构一般用于自然语言处理。</p><img src="/2021/07/01/zi-jian-du-shi-xue-xi-self-supervised-learning/2.png" class=""><p>把 一句话的某些字盖起来，用其他的符号代替，我们尽量输出原本那句话。这就是Masking。除了填空这种任务外，对BERT进行调整后可以适用于各种各样的任务，这叫做Fine-tune。</p><img src="/2021/07/01/zi-jian-du-shi-xue-xi-self-supervised-learning/3.png" class=""><p>其中Linear的参数才做随机的初始化，BERT的参数是做填空题的参数直接拿过来进行初始化。这就是pre-train。这样得到的结果往往比随机初始化好。接下来的例子类似：</p><img src="/2021/07/01/zi-jian-du-shi-xue-xi-self-supervised-learning/4.png" class=""><img src="/2021/07/01/zi-jian-du-shi-xue-xi-self-supervised-learning/5.png" class=""><p>那么为什么BERT的pre-train有用：</p><img src="/2021/07/01/zi-jian-du-shi-xue-xi-self-supervised-learning/6.png" class=""><p>这意味着训练过程中BERT已经可以了解句子中每个字的含义。这是基于上下文的训练得出的经验。</p><img src="/2021/07/01/zi-jian-du-shi-xue-xi-self-supervised-learning/7.png" class=""><p><strong>然后简单说一下GPT系列的模型：</strong></p><p>这个系列模型的任务是预测接下来的Token：</p><img src="/2021/07/01/zi-jian-du-shi-xue-xi-self-supervised-learning/8.png" class=""><p>这样不断预测下一个token可以产生完整的文章。</p><img src="/2021/07/01/zi-jian-du-shi-xue-xi-self-supervised-learning/19.png" class=""><p>还有进行翻译的功能。</p><img src="/2021/07/01/zi-jian-du-shi-xue-xi-self-supervised-learning/20.png" class=""><h2 id="Auto-encoder"><a href="#Auto-encoder" class="headerlink" title="Auto-encoder"></a>Auto-encoder</h2><p>不用标注资料的学习叫做self-supervised-Learning。例如做填空。而且训练完后能够用到下游的任务中。还有一种古老的不需要标注资料的任务叫做Auto-encoder。因此也可以视作Self-supervised-learning的一部分。</p><img src="/2021/07/01/zi-jian-du-shi-xue-xi-self-supervised-learning/9.png" class=""><p>这种把高维度转换成低维度的东西叫做dimension reduction。能够做这种变化的原因是因为特定类型的图片是有规律的，只有能小一部分的图片符合这个规律，因此我们可以通过模型降维，来提取出这个规律。然后就可以再通过一个模型进行还原。这个降维的好处是把复杂的向量用简单的方法来表示。这样我们只需要比较少的训练资料就可以让模型完成训练。这就是Auto-Encoder的概念。</p><img src="/2021/07/01/zi-jian-du-shi-xue-xi-self-supervised-learning/10.png" class=""><img src="/2021/07/01/zi-jian-du-shi-xue-xi-self-supervised-learning/11.png" class=""><p>这种方法不仅能从高维向量中提取数据，还能够去除噪声。</p><img src="/2021/07/01/zi-jian-du-shi-xue-xi-self-supervised-learning/12.png" class=""><p>因此BERT是一个De-Noising的Auto-Encoder。</p><h3 id="Feature-Disentangle"><a href="#Feature-Disentangle" class="headerlink" title="Feature Disentangle"></a>Feature Disentangle</h3><p>上面的Auto-encoder虽然对数据进行了降维，但是我们无法得知降维后的向量的哪一部分代表了什么信息。为了使数据可以分开成一组组代表特定特征的向量，我们就有了Feature-Disentangle的技术。</p><p>这种计算的应用是Voice-Conversion语者转换。可以将一个人的声音转换为另一个人的声音，甚至同时转换语言。做法是在提取出表示声音信号的向量后，分解为表示内容和声音特征的两部分。这样把一个人的内容部分和另一个人的声音特征部分进行拼接，就能用一个人的声音讲另一个人的内容。</p><h3 id="Discrete-Latent-Representation"><a href="#Discrete-Latent-Representation" class="headerlink" title="Discrete Latent Representation"></a>Discrete Latent Representation</h3><img src="/2021/07/01/zi-jian-du-shi-xue-xi-self-supervised-learning/13.png" class=""><p>如果强制使得提取出来的向量是二进制的（Binary），甚至是One-hot的，我们就可以十分简单的表示有还是没有这个概念。例如有没有眼睛，男生还是女生。解释输出更为容易。甚至可以做unsupervised-learning。例如手写数字不用给标签，然后使其提取一个十维的one-hot向量，那么每一维就可能对应到一个数字。</p><img src="/2021/07/01/zi-jian-du-shi-xue-xi-self-supervised-learning/14.png" class=""><p>这个Codebook也是资料中学习的，计算相似度，然后用Codebook中相似度最高的向量来生成图片，和原来越接近越好。好处是降维后的向量只有有限种可能。如果输入是语音，那么可以学到最基本的发音单位。</p><p>如果不用向量做Embedding，而是一串文字也可以。好处是输入一篇文章，降维成一串文字，如果这串文章能还原文章，这串文字可以是文章的摘要。但通常产生的不是摘要，而是人看不懂的文字，但能还原文章。</p><img src="/2021/07/01/zi-jian-du-shi-xue-xi-self-supervised-learning/15.png" class=""><p>解决办法是用GAN，把人写的摘要和机器的摘要输入给Discriminator来识别。由于输出是一段文字，接给Discriminator和Decoder的方法是用RL硬做。没办法train的问题都用RL硬做。</p><img src="/2021/07/01/zi-jian-du-shi-xue-xi-self-supervised-learning/16.png" class=""><p>我们刚刚用的都是Encoder，<strong>如果把Decoder单独拿出来，就是一个Generator。</strong>当图片太大的时候，一个压缩方法是把Encoder的输出当做压缩的结果，而Decoder就是解压缩。缺点是可能会失真。</p><p>这里一个技术是Anomaly Detection（异常检测）。就是每进来一笔新的资料，检测与之前的资料相不相似。前提是我们必须收集到一大堆正常的资料而没有异常的资料。</p><img src="/2021/07/01/zi-jian-du-shi-xue-xi-self-supervised-learning/17.png" class=""><img src="/2021/07/01/zi-jian-du-shi-xue-xi-self-supervised-learning/18.png" class=""><p>我们训练时让Decoder产生的输出越接近输入的图片越好，在检测时如果输出越解决输入则表明模型学习过类似的图片。如果相差很远，Reconstruction Loss很大，那么就是异常的图片。这个是异常检测的一个方法，实际上异常检测不一定用Auto-Encoder，还有很多技术。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>生成式对抗网络（GAN）</title>
      <link href="2021/06/10/sheng-cheng-shi-dui-kang-wang-luo-gan/"/>
      <url>2021/06/10/sheng-cheng-shi-dui-kang-wang-luo-gan/</url>
      
        <content type="html"><![CDATA[<p> 原始论文：arXiv:1406.2661v1 </p><p>详细讲解请参考文章：<a href="http://www.gwylab.com/note-gans.html%EF%BC%8C%E8%BF%99%E9%87%8C%E6%96%87%E7%AB%A0%E8%AE%B2%E8%A7%A3%E7%9A%84%E5%86%85%E5%AE%B9%E4%B8%8D%E5%86%8D%E9%87%8D%E5%A4%8D%E8%B5%98%E8%BF%B0%E3%80%82">http://www.gwylab.com/note-gans.html，这里文章讲解的内容不再重复赘述。</a></p><img src="/2021/06/10/sheng-cheng-shi-dui-kang-wang-luo-gan/7.png" class><p>GAN可以用来构造各种数据，包括图片声音等等，应用：</p><img src="/2021/06/10/sheng-cheng-shi-dui-kang-wang-luo-gan/1.png" class><img src="/2021/06/10/sheng-cheng-shi-dui-kang-wang-luo-gan/2.png" class><img src="/2021/06/10/sheng-cheng-shi-dui-kang-wang-luo-gan/3.png" class><img src="/2021/06/10/sheng-cheng-shi-dui-kang-wang-luo-gan/4.png" class><img src="/2021/06/10/sheng-cheng-shi-dui-kang-wang-luo-gan/5.png" class><h2 id="GAN的理解"><a href="#GAN的理解" class="headerlink" title="GAN的理解"></a>GAN的理解</h2><img src="/2021/06/10/sheng-cheng-shi-dui-kang-wang-luo-gan/6.png" class><p>其中左边是一个生成器（Generator Network），负责生成假数据，它最终的目标是造出辨别器辨别不出来的假数据。右边是辨别器（Descriminator Network），负责辨别数据的真假，目标是把所有的假数据辨别出来。这就是对抗，在相互对抗的过程中，双方的辨别能力和造假能力都会不断升级，以达到更高的水准。</p><p>首先生成器输入的是一个随机的向量，通过一个神经网络，得到一个假数据，再输入判别网络，同时把真实数据输入判别网络，判别网络复制判断这两个数据的真假。</p><img src="/2021/06/10/sheng-cheng-shi-dui-kang-wang-luo-gan/8.png" class><p>看上图，绿线是生成样本的概率分布，我们用随机噪声生成随机样本，黑色虚线是真实样本的概率分布，我们的目标是让生成样本的概率分布尽可能靠近真实样本的概率分布。中间的蓝色虚线是判决器，负责把两种样本分开。</p><h2 id="GAN训练方案"><a href="#GAN训练方案" class="headerlink" title="GAN训练方案"></a>GAN训练方案</h2><img src="/2021/06/10/sheng-cheng-shi-dui-kang-wang-luo-gan/9.png" class><p>首先把生成器固定住，训练辨别器，让生成器生成样本和真实数据混在一起，然后给辨别器判决，通过梯度下降法来训练辨别器。第二步是辨别器训练后固定住，训练生成器，目标是让判决器出错。</p><p>先了解下纳什均衡，<strong>纳什均衡</strong>是指博弈中这样的局面，对于每个参与者来说，只要其他人不改变策略，他就无法改善自己的状况。对应的，对于GAN，情况就是生成模型 G 恢复了训练数据的分布（造出了和真实数据一模一样的样本），判别模型再也判别不出来结果，准确率为 50%，约等于乱猜。这是双方网路都得到利益最大化，不再改变自己的策略，也就是不再更新自己的权重。</p><p>GAN模型的目标函数如下：</p><p>$$<br>min_Gmax_D(D,G) = E_{x ~ p_{data}(x)}[logD(x)] + E_{z ~ p_{z}(x)}[log(1 - D(G(x)))]<br>$$<br>在这里，训练网络D使得最大概率地分对训练样本的标签（最大化log D(x)和log(1—D(G(z))))，训练网络G最小化log(1-D(G(z))），即最大化D的损失。而训练过程中固定一方，更新另一个网络的参数，交替迭代，使得对方的错误最大化，最终，G 能估测出样本数据的分布，也就是生成的样本更加的真实。</p><p>这就是GAN的最基础的流程，由此延伸出来的算法成百上千，百花齐放，各种各样的应用不一而足。</p><p>代码参考：<a href="https://blog.csdn.net/zandaoguang/article/details/102645230">https://blog.csdn.net/zandaoguang/article/details/102645230</a></p><h2 id="GAN的诸多变种"><a href="#GAN的诸多变种" class="headerlink" title="GAN的诸多变种"></a>GAN的诸多变种</h2><h3 id="Cycle-GAN"><a href="#Cycle-GAN" class="headerlink" title="Cycle GAN"></a>Cycle GAN</h3><img src="/2021/06/10/sheng-cheng-shi-dui-kang-wang-luo-gan/10.png" class>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深度学习中的优化算法串讲</title>
      <link href="2021/05/19/shen-du-xue-xi-zhong-de-you-hua-suan-fa-chuan-jiang/"/>
      <url>2021/05/19/shen-du-xue-xi-zhong-de-you-hua-suan-fa-chuan-jiang/</url>
      
        <content type="html"><![CDATA[<p> 本文默认您已了解深度学习中的随机梯度下降算法的基本原理，在对深度学习有基本认识的基础上。如果尚未了解，可以查看我另外的文章《李宏毅机器学习2021》，《Python神经网络编程》。</p><h2 id="基本框架"><a href="#基本框架" class="headerlink" title="基本框架"></a>基本框架</h2><p>首先优化算法的基本框架是：</p><p>定义当前待优化的参数为$\theta_t \in R^d$，损失函数为J（θ），学习率为$\eta$，参数更新的框架为：</p><ol><li><p>计算损失函数关于当前参数的梯度：<br>$$<br>g_t = \nabla J(\theta_t)<br>$$</p></li><li><p>根据历史梯度计算一阶和二阶动量：<br>$$<br>m_t = \phi(g_1,g_2,…,g_t) \<br>V_t = \psi(g_1,g_2,…,g_t)<br>$$<br>这里一阶动量是关于历史梯度的一阶函数，二阶动量是关于历史梯度的二阶函数。</p></li><li><p>计算当前时刻的下降梯度：<br>$$<br>\Delta \theta_t = -\eta \frac{m_t}{\sqrt{V_t}}<br>$$<br>所有的优化算法都是基于这个公式，只不过是一阶动量和二阶动量的计算方式不同。</p></li><li><p>根据下降梯度更新参数：<br>$$<br>\theta_{t+1} = \theta_t + \Delta \theta_t<br>$$</p></li></ol><h2 id="随机梯度下降（SGD）（Stochastic-Gradient-Descent）"><a href="#随机梯度下降（SGD）（Stochastic-Gradient-Descent）" class="headerlink" title="随机梯度下降（SGD）（Stochastic Gradient Descent）"></a>随机梯度下降（SGD）（Stochastic Gradient Descent）</h2><p>随机梯度下降算法没有动量的概念，也没有考虑历史梯度，所以一阶动量等于当前时刻梯度$m_t = g_t$，且二阶动量$V_t = 1$。所以更新公式为：<br>$$<br>\Delta \theta_t = -\eta \frac{m_t}{\sqrt{V_t}} = -\eta g_t<br>$$<br>还有一个比较能让人看懂的等价的公式，这是我们平常的表达形式：<br>$$<br>v_{n+1} = - \eta \frac{dL}{dW_n}<br>$$</p><p>$$<br>W_{n+1} = W_n + v_{n+1}<br>$$</p><p>这里说一下标准梯度下降和随机梯度下降的区别，标准梯度下降是把数据全部读取一遍然后全部计算Loss，然后进行的梯度更新，缺点是容易陷入鞍点，且一次计算量很大，数据有溢出的风险。随机梯度下降是读取每一个样本计算Loss后都进行一次更新，但是由于是分开训练更新的波动会较大，且一个epoch训练次数过多，会导致训练时间过长。小批量随机梯度下降是把50~256个样本为一批数据，一批批进行训练，这样就能很好平衡两者，一般都是采用这种方法。</p><p>这个算法的缺点是容易陷入局部最优。</p><h2 id="Momentum"><a href="#Momentum" class="headerlink" title="Momentum"></a>Momentum</h2><p>为了解决这个问题，我们引入一个惯性，使得这一时刻的梯度和以前时刻的梯度有关。<br>$$<br>v_{n+1} = av_{n} - \eta \frac{dL}{dW_n}<br>$$</p><p>$$<br>W_{n+1} = W_n + v_{n+1}<br>$$</p><p>其中a是大于0小于1的值，这个方法在权重变换上加上了上一次的变化，可以让权重越过一些局部最小或者变化较为平稳的点，到达全局最优点。这个权重更新时是一定会冲过Loss的最小值到达另一边的，而且梯度要大一些后才往回运动。这样波动会比没有动量会小一些。  </p><h2 id="AdaGrad"><a href="#AdaGrad" class="headerlink" title="AdaGrad"></a>AdaGrad</h2><p>学习率过大，在算法前期会加速学习，容易接近最优解，但是在后期会有较大波动，甚至出现损失函数的值围绕最小值徘徊，始终难以达到最优，因此我们的方法是在前期采用较大学习率，随着迭代次数的增加，学习率要逐渐衰减。这个时候AdaGrad算法的优势就出来了：<br>$$<br>W_{n+1} = W_n- \eta  \frac{1}{\sqrt{h_n}} \frac{dL}{dW_n}<br>$$<br>$$<br>h_n = h_{n-1} + \frac{dL}{dW_n} *  \frac{dL}{dW_n}<br>$$</p><p>这里面的权重的变化多除了一个$\sqrt{h}$，这就是用来改变学习率的。其中h为以前所有梯度的平方和，随着迭代次数的增加，h会越来越大，因此学习率会越来越小。如果目标函数有关自变量中某个元素的偏导数一直都较大，那么该元素的学习率讲下降较快；反之，如果目标函数有关自变量中某个元素的偏导数一直都较少，那么该元素的学习率将下降较慢。侧面说明了二阶动量就是控制步长(学习率的)。但AdaGrad算法有个明显的缺点，由于 一直在累加按元素平方的梯度，学习率在迭代过程中一直在下降(或不变)，所以即使后面的梯度突然变大了，但由于AdaGrad算法在迭代后期由于学习率过小，较难找到一个有用解。</p><h2 id="Nesterov-accelerated-gradient-NAG"><a href="#Nesterov-accelerated-gradient-NAG" class="headerlink" title="Nesterov accelerated gradient (NAG)"></a>Nesterov accelerated gradient (NAG)</h2><p> 带冲量的随机梯度下降算法的缺点是不能在Loss的最低点停住，一定会冲过头，必须经过多次反复才有可能找到最优点。那么我们可以提前预测是否要到达最优点。<br>$$<br>\tilde W = W_{n-1} - \eta v_{n-1}<br>$$<br>这里对权重作了一个预测，用上一次的梯度对下一步到达的位置作了一个预测。<br>$$<br>v_n = \alpha v_{n-1} + \eta \frac{dL(\tilde W_n)}{d\tilde W_n}<br>$$</p><p>$$<br>W_n = W_{n-1} - v_n<br>$$</p><p>和Momentum类似，不过是<strong>用预测的梯度对现在的梯度进行更新，而不是取决于现在的梯度</strong>。如果预测的下一步已经在最低点另一侧了，那么符号相反，那么速度减小，结合设置的参数，能达到较好的效果。</p><h2 id="RMSProp"><a href="#RMSProp" class="headerlink" title="RMSProp"></a>RMSProp</h2><p>为了解决AdaGrad到迭代后期梯度消失的问题，同样是这条公式：<br>$$<br>W_{n+1} = W_n- \eta  \frac{1}{\sqrt{h_n}} \frac{dL}{dW_n}<br>$$<br>现在我们对h进行修改，不是用以前所有梯度的平方和，而是用历史梯度的移动平均：<br>$$<br>h_n = \beta h_{n-1} + (1 - \beta)\frac{dL}{dW_n} *  \frac{dL}{dW_n}<br>$$<br>其中β是大于0小于1的数，一般大概在0.9左右。当现在所处的梯度较小时，h不会增大而是朝着现在的方向慢慢减小，学习率增大，这样有利于冲出局部最优点和鞍点，并且能够在找到最优点后迅速收敛。当所处梯度较大时，慢慢增大，学习率减小，这样又不会使其冲过头，使得无法收敛。h初始通常加上一个小常数防止零除。但是在梯度较小时h过小会导致学习率过大而在最低点附近震荡，最优点附近坡度越陡表现越好。在$L = x^2$这样的函数中由于底部过于平坦，h下降速度过快，大于梯度的下降速度的时候，x下降到一定程度会越振荡越大，但不会无限增大，当$\sqrt{h} = g_t$时，振荡幅度不变，振荡范围取决于学习率，如果学习率为0.01，则x在$\pm$0.005之间振荡。如果Loss函数底部比较陡峭，如$L = x^3$则$g_t$下降的速度大于h下降的速度，学习率会一直减小到0，实现完全收敛。</p><h2 id="AdaGrad-AdaDelta"><a href="#AdaGrad-AdaDelta" class="headerlink" title="AdaGrad AdaDelta"></a>AdaGrad AdaDelta</h2><p>AdaDelta算法也针对AdaGrad算法在迭代后期可能较难找到有用解的问题做了改进 。有意思的是，AdaDelta算法没有学习率这一超参数。<br>$$<br>\boldsymbol{x}<em>t = \boldsymbol{x}</em>{t-1} + \Delta\boldsymbol{x}<br>$$</p><p>$$<br>\Delta\boldsymbol{x} = - \sqrt{\frac{ E(\Delta\boldsymbol{x}^2)_t  + \epsilon}{E(g^2)_t  + \epsilon}} g_t<br>$$</p><p>$$<br>E(g^2)<em>t =\rho E({g}^2)</em>{t-1} + (1 - \rho) \boldsymbol{g}_t \odot \boldsymbol{g}_t<br>$$</p><p>$$<br>E(\Delta\boldsymbol{x}^2)<em>t = \rho E(\Delta\boldsymbol{x}^2)</em>{t-1} + (1 - \rho) \boldsymbol \Delta{x}_t \odot \boldsymbol \Delta{x}_t<br>$$</p><p>$g_t$即这一时刻的梯度，其中的点乘是矩阵各个元素分别乘积，和我们理解的数与数相乘一致。$\epsilon$是一个较小的常数，用来防止零除，或者在其他值为0时整体也不为0。其中：$\boldsymbol{v}_0 = 0$，$E(g^2)_t = 0$。这个算法和RMSProp英雄所见略同，但是学习率变成了动态调整的了，省去了人工调节超参数的麻烦，在x的变化较小的情况下，自动把学习率降低，有利于减小振荡，达到最优点。</p><h2 id="Adam（Adaptive-Moment-Estimation）"><a href="#Adam（Adaptive-Moment-Estimation）" class="headerlink" title="Adam（Adaptive Moment Estimation）"></a>Adam（Adaptive Moment Estimation）</h2><p>Adam算法相当于AdaDelta和Momentum的合体。把上面一阶动量和二阶动量的计算方法都加进来。<br>$$<br>m_t = \beta_1 m_{t-1} + (1-\beta_1)g_t<br>$$</p><p>$$<br>v_t = \beta_2 v_{t-1} + (1 - \beta_2) g_t \odot g_t<br>$$</p><p>$$<br>\hat{m_t} = \frac{m_t}{1- \beta_1^t}<br>$$</p><p>$$<br>\hat{v_t} = \frac{v_t}{1- \beta_2^t}<br>$$</p><p>$$<br>\boldsymbol{x}_{t+1} = x_t - \frac{\eta}{\sqrt{\hat v_t  + \epsilon}} \hat{m_t}<br>$$</p><p>$\beta_1$和$\beta_2$是梯度一阶矩估计值和二阶矩估计值的指数衰减速率，在0到1之间。每一步的有效学习率在一定范围变动。这个算法适用于大多数非凸环境的优化，是目前最流行的算法。之所以还要除以一项计算估计值是因为这样可以保证里面每一个梯度或者梯度的平方前面的参数之和为1！越往前的梯度前面的参数就越小，呈指数衰减。这就是一个指数加权移动平均的概念。这样随着梯度的降低，越来越解决最优点的同时，分子在不断减小，学习率降低，并保留一部分之前的冲量，让其能冲出鞍点。同时保留了分母中RMSProp的优点。</p><h2 id="Adamax"><a href="#Adamax" class="headerlink" title="Adamax"></a>Adamax</h2><p>Adamax是Adam的一种变体，此方法对学习率的上限提供了一个更简单的范围。公式上的变化如下：<br>$$<br>n_t = max(\beta n_{t-1},|g_t|)<br>$$</p><p>$$<br>\Delta x = -\frac{\hat m_t}{n_t + \epsilon} * \eta<br>$$</p><p>其中$n_0 = 0$，这样当梯度变化较为缓的情况下，我们取后面的梯度，当梯度变化较为剧烈的情况下，我们取较大的梯度。这样就能实现前期变化幅度大，后期变化幅度小。</p><h2 id="Nadam"><a href="#Nadam" class="headerlink" title="Nadam"></a>Nadam</h2><p>Nadam是Adam和NAG的合体，只需要把Adam的分子部分的梯度换成预测的梯度，把往往比Adam能产生更好的效果。其实也不一定换梯度，只需要在公式中的一个因素换成未来的因素即可。</p><img src="/2021/05/19/shen-du-xue-xi-zhong-de-you-hua-suan-fa-chuan-jiang/1.png" class="">]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深度学习使用GPU加速的注意事项</title>
      <link href="2021/05/17/shen-du-xue-xi-shi-yong-gpu-jia-su-de-zhu-yi-shi-xiang/"/>
      <url>2021/05/17/shen-du-xue-xi-shi-yong-gpu-jia-su-de-zhu-yi-shi-xiang/</url>
      
        <content type="html"><![CDATA[<p>CUDA（Compute Unified Device Architecture），是显卡厂商<a href="https://baike.baidu.com/item/NVIDIA">NVIDIA</a>推出的运算平台。 CUDA是一种由NVIDIA推出的通用<a href="https://baike.baidu.com/item/%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97/113443">并行计算</a>架构，该架构使<a href="https://baike.baidu.com/item/GPU">GPU</a>能够解决复杂的计算问题。近些年来，显卡的计算能力越来越强大，如果只是进行图形计算未免有些浪费性能，这个并行运算架构应运而生。首先，使用GPU加速前，确认自己硬件是否支持CUDA，可以自己去百度自己的显卡类型。可以在cmd窗口输入nvidia-smi命令来确认自己的显卡是否有CUDA。</p><img src="/2021/05/17/shen-du-xue-xi-shi-yong-gpu-jia-su-de-zhu-yi-shi-xiang/1.png" class=""><p>看第一行右边，如果没有显示CUDA版本，则需要自己安装CUDA。</p><p>然后安装CUDA。网址：<a href="https://developer.nvidia.com/zh-cn/cuda-downloads%EF%BC%8C%E5%8F%AF%E4%BB%A5%E8%87%AA%E8%A1%8C%E4%B8%8B%E8%BD%BD%E5%AE%89%E8%A3%85%E5%8C%85%E5%B9%B6%E5%AE%89%E8%A3%85%E3%80%82%E5%AE%89%E8%A3%85%E5%A5%BD%E5%90%8E%EF%BC%8C%E5%86%8D%E6%AC%A1%E8%BE%93%E5%85%A5nvidia-smi%E5%91%BD%E4%BB%A4%E6%A3%80%E6%9F%A5%E7%89%88%E6%9C%AC%E3%80%82">https://developer.nvidia.com/zh-cn/cuda-downloads，可以自行下载安装包并安装。安装好后，再次输入nvidia-smi命令检查版本。</a></p><p>然后安装Pytorch，必须安装的有torch和torchvision两个包，注意不要直接在Pycharm中自动下载安装，否则安装的是CPU版本，无法进行GPU加速。可以直接到官网上下载包：<a href="https://download.pytorch.org/whl/torch_stable.html%E3%80%82%E9%80%89%E6%8B%A9%E5%90%88%E9%80%82%E8%87%AA%E5%B7%B1%E7%9A%84%E7%89%88%E6%9C%AC%E7%9B%B4%E6%8E%A5%E4%B8%8B%E8%BD%BD%E5%88%B0%E7%94%B5%E8%84%91%EF%BC%8C%E7%84%B6%E5%90%8E%E6%8A%8A%E7%9B%AE%E5%BD%95%E5%88%87%E6%8D%A2%E5%88%B0%E5%8C%85%E6%89%80%E5%9C%A8%E7%9A%84%E4%BD%8D%E7%BD%AE%EF%BC%8C%E4%BD%BF%E7%94%A8">https://download.pytorch.org/whl/torch_stable.html。选择合适自己的版本直接下载到电脑，然后把目录切换到包所在的位置，使用</a></p><pre class=" language-cmd"><code class="language-cmd">pip install 文件名带后缀</code></pre><p>即可把包装到电脑上。安装时注意把pip更新到最新版本。</p><p>如果对包名不熟悉，无法在众多的包中做出选择，也可以智能安装：<a href="https://pytorch.org/get-started/locally/">https://pytorch.org/get-started/locally/</a></p><p>依旧是选择适合自己的版本</p><img src="/2021/05/17/shen-du-xue-xi-shi-yong-gpu-jia-su-de-zhu-yi-shi-xiang/2.png" class=""><p>然后把最后的pip命令复制到控制台执行即可。但这种方法通常网速较慢，推荐使用上一种做法。注意CUDA版本的选择和你安装的显卡CUDA版本相匹配，否则可能无法使用GPU加速。</p><p>然后打开Pycharm或任意编译器，执行以下代码：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>__version__<span class="token punctuation">)</span></code></pre><p>如果第一行输出为True，则可以使用CUDA来进行加速，后面的是安装的torch的版本。如果为False，则安装不成功，需要检查之前的步骤是否存在问题。</p><p>在代码中把模型和数据放入GPU中即可使用加速：</p><pre class=" language-python"><code class="language-python">device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">"cuda:0"</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">"cpu"</span><span class="token punctuation">)</span>model<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token operator">-</span><span class="token operator">-</span>snip<span class="token operator">-</span><span class="token operator">-</span>inputs<span class="token punctuation">,</span>target <span class="token operator">=</span> inputs<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">,</span>target<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token operator">-</span><span class="token operator">-</span>snip<span class="token operator">-</span><span class="token operator">-</span></code></pre><h2 id="切换CUDA版本"><a href="#切换CUDA版本" class="headerlink" title="切换CUDA版本"></a>切换CUDA版本</h2><p>通常许多项目用的CUDA版本都互不相同，因此我们时常需要切换CUDA版本来运行程序。切换CUDA版本的步骤如下：</p><ol><li><p>先安装好多个版本的CUDA。</p></li><li><p>打开环境变量。把CUDA_PATH这个系统变量的路径设定到我们需要的版本，例如这里假设我需要使用11.1的版本。</p><img src="/2021/05/17/shen-du-xue-xi-shi-yong-gpu-jia-su-de-zhu-yi-shi-xiang/3.png" class=""></li><li><p>双击系统变量的PATH，弹出一个窗口，我们要把11.1版本的内容置于其他版本上方。</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pytorch教学及示例</title>
      <link href="2021/05/13/pytorch-jiao-xue-ji-shi-li/"/>
      <url>2021/05/13/pytorch-jiao-xue-ji-shi-li/</url>
      
        <content type="html"><![CDATA[<p> 理论基础可以参考我另一篇文章《李宏毅机器学习2021》。</p><p>参考视频：<a href="https://www.bilibili.com/video/BV1Y7411d7Ys?p=5&amp;spm_id_from=pageDriver">https://www.bilibili.com/video/BV1Y7411d7Ys?p=5&amp;spm_id_from=pageDriver</a></p><p>PyTorch是一个<a href="https://baike.baidu.com/item/%E5%BC%80%E6%BA%90/246339">开源</a>的<a href="https://baike.baidu.com/item/Python">Python</a>机器学习库，基于Torch，用于自然语言处理等应用程序。它是一个基于Python的可续计算包，提供两个高级功能：1、具有强大的GPU加速的张量计算（如NumPy）。2、包含自动求导系统的深度神经网络。</p><p>PyTorch和TensorFlow作对比，PyTorch开发商是Facebook，TensorFlow是Google。PyTorch的接口有Python和C++，而TensorFlow接口有Python，C++，JavaScript，Swift。PyTorch调试较简单，TensorFlow在2.0以上版本调试较简单。PyTorch主要用于研究，TensorFlow主要用于生产</p><p>张量(Tensor)相当于一个矩阵，它可以是比二维更高的。Tensor的目的是<strong>能够创造更高维度的矩阵、向量</strong>。举个简单的例子，彩色图像文件（RGB）一般都会处理成3-d tensor，每个2d array中的element表示一个像素，R代表Red，G代表Green，B代表Blue。</p><p>具体可参考文档：<a href="https://pytorch.org/docs/stable/tensors.html">https://pytorch.org/docs/stable/tensors.html</a></p><p>建立Tensor的方法：</p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#直接把List放进去</span>x <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#把numpy矩阵放进from_numpy函数中</span>x <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#产生一个全零tensor（二维）</span>x <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#产生一个全一tensor（三维）</span>x <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><p>操作Tensor的方法：</p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#看Tensor每一维的元素个数</span>x<span class="token punctuation">.</span>shape<span class="token comment" spellcheck="true">#把某一维去掉(这里去掉第一维，只有在这一维只有一个元素的情况下降维且不改变原数据)</span>x <span class="token operator">=</span> x<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#在某个位置新加入一个维度，元素个数为1，不改变原数据</span>x <span class="token operator">=</span> x<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#把两个维度对调，当只有两维的矩阵对调时即求转置</span>x <span class="token operator">=</span> x<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#把几个矩阵的某一维度元素拼接在一起，前提是其他维度元素个数相同(下面拼成2*6*3的Tensor)</span>x <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>y <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>z <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>w <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>x<span class="token punctuation">,</span>y<span class="token punctuation">,</span>z<span class="token punctuation">]</span><span class="token punctuation">,</span>dim <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#常规运算</span>z <span class="token operator">=</span> x <span class="token operator">+</span> yy <span class="token operator">=</span> x<span class="token punctuation">.</span>pow<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#x矩阵中所有元素求和</span>y <span class="token operator">=</span> x<span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#x矩阵中每一列元素相加</span>y <span class="token operator">=</span> x<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#x矩阵中每一行元素相加</span>y <span class="token operator">=</span> x<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#求每一列平均值（二维）（axis=1求行的平均值）</span>y <span class="token operator">=</span> x<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>axis <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#重新塑造3*4矩阵（元素总个数必须一致，否则报错）</span>x <span class="token operator">=</span> x<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#重新塑造2*2矩阵（元素总个数不用一致，可以只截取前面的一部分）</span>x <span class="token operator">=</span> x<span class="token punctuation">.</span>resize_<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span></code></pre><h3 id="怎么计算梯度Gradient"><a href="#怎么计算梯度Gradient" class="headerlink" title="怎么计算梯度Gradient"></a>怎么计算梯度Gradient</h3><p>求梯度即求z对x矩阵的导数，结果是对x的各个元素求导，也是一个矩阵。其中z为x各个元素之和。</p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#requires_grad=True表示需要计算梯度</span>x <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#Loss计算公式（构建计算图），这是前馈过程Forward</span>z <span class="token operator">=</span> x<span class="token punctuation">.</span>pow<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#反向传播backward，计算各个梯度</span>z<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#读出x的梯度</span>x<span class="token punctuation">.</span>grad</code></pre><p>注意tensor在进行运算时会构建计算图，之后.backward()之后这个图会从内存中释放。但是，不要在后面直接用张量来计算存标量数据，防止产生向量图，而是把标量取出来计算，应当使用.item()来取出数据或.data更新权重。最后要用到.grad.data.zero_()来对梯度进行清零，否则下一次计算会一直累加，一个简单的例子：</p><img src="/2021/05/13/pytorch-jiao-xue-ji-shi-li/1.png" class=""><h3 id="第一步：创建Dataset"><a href="#第一步：创建Dataset" class="headerlink" title="第一步：创建Dataset"></a>第一步：创建Dataset</h3><img src="/2021/05/13/pytorch-jiao-xue-ji-shi-li/14.png" class=""><p> Dataset需要调用到Dataloader里面。</p><img src="/2021/05/13/pytorch-jiao-xue-ji-shi-li/15.png" class=""><p>shuffle的意思是每次读数据的顺序是乱的，Testing的时候应使其固定，否则结果会有误差。</p><h3 id="第二步：建立神经网络"><a href="#第二步：建立神经网络" class="headerlink" title="第二步：建立神经网络"></a>第二步：建立神经网络</h3><p>初始的方法可以参考我的另一篇文章《Python神经网络编程》。</p><img src="/2021/05/13/pytorch-jiao-xue-ji-shi-li/16.png" class=""><pre class=" language-python"><code class="language-python">layer <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">64</span><span class="token punctuation">)</span>   <span class="token comment" spellcheck="true">#建立输入32节点，输出64节点的一部分神经网络</span>layer<span class="token punctuation">.</span>weight<span class="token punctuation">.</span>shape   <span class="token comment" spellcheck="true">#输出为torch.Size([64,32])</span>layer<span class="token punctuation">.</span>bias<span class="token punctuation">.</span>shape     <span class="token comment" spellcheck="true">#输出为torch.Size([64])</span><span class="token comment" spellcheck="true">#激活函数</span>nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><p>建立神经网络的具体例子：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">LinearModel</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true">#初始化函数</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true">#调用父类的__init__()函数，必用</span>        super<span class="token punctuation">(</span>LinearModel<span class="token punctuation">,</span>self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token comment" spellcheck="true">#构建1输入1输出的线性层，即y=wx+b，可以设置bias=True/False</span>        self<span class="token punctuation">.</span>linear <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>     <span class="token comment" spellcheck="true">#必须定义的函数，后面直接model(x)可以直接算出估计值y</span>    <span class="token comment" spellcheck="true">#这是因为这个函数是放在python的__call__()函数中的</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true">#函数重写，计算y=wx+b</span>        y_pred <span class="token operator">=</span> self<span class="token punctuation">.</span>linear<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> y_predmodel <span class="token operator">=</span> LinearModel<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#model是callable可调用的，直接调用例：model(x)使用的是forward函数</span></code></pre><h3 id="第三步：最优化"><a href="#第三步：最优化" class="headerlink" title="第三步：最优化"></a>第三步：最优化</h3><pre class=" language-python"><code class="language-python">criterion <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>MSELoss<span class="token punctuation">(</span>size_average <span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">)</span>optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>lr <span class="token operator">=</span> <span class="token number">0.01</span><span class="token punctuation">,</span>momentum <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">)</span></code></pre><p>MSELoss即预测的数值和真实值之差求平方然后加和，后面的参数决定是否求平均。SGD即随机梯度下降，后面的第一个参数是传入需要进行训练优化的参数，直接用model.parameters可以直接把模型中定义的所以参数都加入训练中，lr是学习因子，决定学习速率，第三个参数是冲量。用这些参数构建了优化器之后，我们之后可以直接用这个封装好的optimizer对象对整个模型进行优化。</p><p>训练过程如下：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">for</span> epoch <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true">#计算y的预测值</span>    y_pred <span class="token operator">=</span> model<span class="token punctuation">(</span>x_data<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#用上面定义好的损失函数对象传入预测值和真实值来计算Loss值</span>    loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>y_pred<span class="token punctuation">,</span>y_data<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#打印Loss时自动调用__str__()函数，因此不会产生计算图</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>epoch<span class="token punctuation">,</span>loss<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#梯度清零</span>    optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#反向传播，计算梯度</span>    loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#对所有我们传入的参数进行梯度更新</span>    optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><h3 id="第四步：测试"><a href="#第四步：测试" class="headerlink" title="第四步：测试"></a>第四步：测试</h3><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 打印权重和偏置值，.item()函数把矩阵转换为数值</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'w='</span><span class="token punctuation">,</span>model<span class="token punctuation">.</span>linear<span class="token punctuation">.</span>weight<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'b='</span><span class="token punctuation">,</span>model<span class="token punctuation">.</span>linear<span class="token punctuation">.</span>bias<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 计算预测输出值</span>x_test <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">4.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>y_test <span class="token operator">=</span> model<span class="token punctuation">(</span>x_test<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'y_pred = '</span><span class="token punctuation">,</span>y_test<span class="token punctuation">.</span>data<span class="token punctuation">)</span></code></pre><h3 id="总体程序示例"><a href="#总体程序示例" class="headerlink" title="总体程序示例"></a>总体程序示例</h3><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> torchx_data <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">2.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">3.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>y_data <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">2.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">4.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">6.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">LinearModel</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>LinearModel<span class="token punctuation">,</span>self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>            self<span class="token punctuation">.</span>linear <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>     <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>        y_pred <span class="token operator">=</span> self<span class="token punctuation">.</span>linear<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> y_predmodel <span class="token operator">=</span> LinearModel<span class="token punctuation">(</span><span class="token punctuation">)</span>    criterion <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>MSELoss<span class="token punctuation">(</span>size_average <span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">)</span>optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>lr <span class="token operator">=</span> <span class="token number">0.01</span><span class="token punctuation">,</span>momentum <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token keyword">for</span> epoch <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    y_pred <span class="token operator">=</span> model<span class="token punctuation">(</span>x_data<span class="token punctuation">)</span>    loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>y_pred<span class="token punctuation">,</span>y_data<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>epoch<span class="token punctuation">,</span>loss<span class="token punctuation">)</span>    optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>    loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>    optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'w='</span><span class="token punctuation">,</span>model<span class="token punctuation">.</span>linear<span class="token punctuation">.</span>weight<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'b='</span><span class="token punctuation">,</span>model<span class="token punctuation">.</span>linear<span class="token punctuation">.</span>bias<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>x_test <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">4.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>y_test <span class="token operator">=</span> model<span class="token punctuation">(</span>x_test<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'y_pred = '</span><span class="token punctuation">,</span>y_test<span class="token punctuation">.</span>data<span class="token punctuation">)</span>   </code></pre><p>除了SGD优化器，Pytorch还提供了很多优化器。可以试一试它们的效果</p><img src="/2021/05/13/pytorch-jiao-xue-ji-shi-li/2.png" class=""><h2 id="逻辑回归（Logistic-Regression）"><a href="#逻辑回归（Logistic-Regression）" class="headerlink" title="逻辑回归（Logistic Regression）"></a>逻辑回归（Logistic Regression）</h2><p>这是一个分类问题并非字面意义的回归问题。在做分类问题的时候，把神经网络输出的数值转化为分类的方法是计算每一个分类的概率，最后决定的分类是概率最大的一项。</p><p>Mnist数据集是手写数字的一个数据集，是最基础的数据集之一，可以用来测量各个学习器的性能指标。</p><p>Pytorch配套有torchvision的工具包，里面有一个模块可以提供数据集，常用的数据集在里面都有。在运行程序的时候会自动下载。第一个参数是存放的文件夹的位置，第二个参数设定是训练集还是测试集，第三个参数是是否自动下载。如果数据集已经存在则不会重新下载。</p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> torchvisiontrain_set <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">'../dataset/mnist'</span><span class="token punctuation">,</span>train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>download <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span>test_set <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">'../dataset/mnist'</span><span class="token punctuation">,</span>train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>download <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span></code></pre><p>除了这个MNIST数据集，还有分类动物的CIFAR10数据集。</p><p>为了找一个函数把实数空间的值映射到0到1的区间内代表概率，因此需要在线性模型后加入Sigmoid函数，这个叫做Logistic函数。 它的导数类似于正态分布函数。</p><p>交叉熵损失函数公式（二分类）：<br>$$<br>L = \sum_i - [ylog\hat{y} + (1-y)log(1-\hat{y})]<br>$$<br>首先L一定是正数。其中$\hat{y}$和y都是0到1的值，为了明确分类y不是0就是1。当y=0时，$\hat{y}$尽可能趋近于0，才能使得L最小；当y=1时，$\hat{y}$需要尽可能趋近于0。这样预测值y才能趋近于真实值。</p><p><strong>编程上的改动</strong>：</p><p>搭建模型的函数中（一层线性+SIgmoid）：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F                          <span class="token comment" spellcheck="true">#载入函数包</span><span class="token keyword">class</span> <span class="token class-name">LogisticRegressionModel</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>LogisticRegressionModel<span class="token punctuation">,</span>self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>            self<span class="token punctuation">.</span>linear <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>               <span class="token comment" spellcheck="true">#这里无需改变，因为Sigmoid不含参数</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>        y_pred <span class="token operator">=</span> F<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>self<span class="token punctuation">.</span>linear<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>               <span class="token comment" spellcheck="true">#输出形式改变</span>        <span class="token keyword">return</span> y_pred</code></pre><p>最优化：</p><pre class=" language-python"><code class="language-python">criterion <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>BCELoss<span class="token punctuation">(</span>size_average<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>         <span class="token comment" spellcheck="true">#此处求不求均值会影响后面学习率的设置，不求均值学习率须设小一些</span></code></pre><p>最终结构：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F                        x_data <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">2.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">3.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>y_data <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">0.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">1.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>nbsp<span class="token punctuation">;</span> <span class="token operator">&amp;</span>nbsp<span class="token punctuation">;</span> <span class="token operator">&amp;</span>nbsp<span class="token punctuation">;</span> <span class="token operator">&amp;</span>nbsp<span class="token punctuation">;</span> <span class="token operator">&amp;</span>nbsp<span class="token punctuation">;</span> <span class="token operator">&amp;</span>nbsp<span class="token punctuation">;</span> <span class="token operator">&amp;</span>nbsp<span class="token punctuation">;</span> <span class="token operator">&amp;</span>nbsp<span class="token punctuation">;</span> <span class="token operator">&amp;</span>nbsp<span class="token punctuation">;</span> <span class="token operator">&amp;</span>nbsp<span class="token punctuation">;</span> <span class="token operator">&amp;</span>nbsp<span class="token punctuation">;</span> <span class="token operator">&amp;</span>nbsp<span class="token punctuation">;</span> <span class="token operator">&amp;</span>nbsp<span class="token punctuation">;</span><span class="token keyword">class</span> <span class="token class-name">LogisticRegressionModel</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token operator">&amp;</span>nbsp<span class="token punctuation">;</span> <span class="token operator">&amp;</span>nbsp<span class="token punctuation">;</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token operator">&amp;</span>nbsp<span class="token punctuation">;</span> <span class="token operator">&amp;</span>nbsp<span class="token punctuation">;</span> <span class="token operator">&amp;</span>nbsp<span class="token punctuation">;</span> <span class="token operator">&amp;</span>nbsp<span class="token punctuation">;</span>        super<span class="token punctuation">(</span>LogisticRegressionModel<span class="token punctuation">,</span>self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>nbsp<span class="token punctuation">;</span> <span class="token operator">&amp;</span>nbsp<span class="token punctuation">;</span> <span class="token operator">&amp;</span>nbsp<span class="token punctuation">;</span> <span class="token operator">&amp;</span>nbsp<span class="token punctuation">;</span> <span class="token operator">&amp;</span>nbsp<span class="token punctuation">;</span> <span class="token operator">&amp;</span>nbsp<span class="token punctuation">;</span>        self<span class="token punctuation">.</span>linear <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>nbsp<span class="token punctuation">;</span> <span class="token operator">&amp;</span>nbsp<span class="token punctuation">;</span> <span class="token operator">&amp;</span>nbsp<span class="token punctuation">;</span> <span class="token operator">&amp;</span>nbsp<span class="token punctuation">;</span> <span class="token operator">&amp;</span>nbsp<span class="token punctuation">;</span> <span class="token operator">&amp;</span>nbsp<span class="token punctuation">;</span> <span class="token operator">&amp;</span>nbsp<span class="token punctuation">;</span> <span class="token operator">&amp;</span>nbsp<span class="token punctuation">;</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token operator">&amp;</span>nbsp<span class="token punctuation">;</span> <span class="token operator">&amp;</span>nbsp<span class="token punctuation">;</span> <span class="token operator">&amp;</span>nbsp<span class="token punctuation">;</span> <span class="token operator">&amp;</span>nbsp<span class="token punctuation">;</span>        y_pred <span class="token operator">=</span> F<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>self<span class="token punctuation">.</span>linear<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>nbsp<span class="token punctuation">;</span> <span class="token operator">&amp;</span>nbsp<span class="token punctuation">;</span> <span class="token operator">&amp;</span>nbsp<span class="token punctuation">;</span> <span class="token operator">&amp;</span>nbsp<span class="token punctuation">;</span> <span class="token operator">&amp;</span>nbsp<span class="token punctuation">;</span> <span class="token operator">&amp;</span>nbsp<span class="token punctuation">;</span> <span class="token operator">&amp;</span>nbsp<span class="token punctuation">;</span>        <span class="token keyword">return</span> y_predmodel <span class="token operator">=</span> LogisticRegressionModel<span class="token punctuation">(</span><span class="token punctuation">)</span>    criterion <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>BCELoss<span class="token punctuation">(</span>size_average<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>       optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>lr <span class="token operator">=</span> <span class="token number">0.01</span><span class="token punctuation">,</span>momentum <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token keyword">for</span> epoch <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    y_pred <span class="token operator">=</span> model<span class="token punctuation">(</span>x_data<span class="token punctuation">)</span>    loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>y_pred<span class="token punctuation">,</span>y_data<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>epoch<span class="token punctuation">,</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>    loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>    optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>  </code></pre><p>绘图：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt<span class="token comment" spellcheck="true">#x的范围0到10，取200个点</span>x <span class="token operator">=</span> np<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">200</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#把x变成200行1列的矩阵（张量）</span>x_t <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">200</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#输出预测值y的矩阵</span>y_t <span class="token operator">=</span> model<span class="token punctuation">(</span>x_t<span class="token punctuation">)</span>y <span class="token operator">=</span> y_t<span class="token punctuation">.</span>data<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#打印图表</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x<span class="token punctuation">,</span>y<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">0.5</span><span class="token punctuation">,</span><span class="token number">0.5</span><span class="token punctuation">]</span><span class="token punctuation">,</span>c<span class="token operator">=</span><span class="token string">'r'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'Hours'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'Probability of Pass'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>grid<span class="token punctuation">(</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><img src="/2021/05/13/pytorch-jiao-xue-ji-shi-li/3.png" class=""><h2 id="处理多维特征的输入"><a href="#处理多维特征的输入" class="headerlink" title="处理多维特征的输入"></a>处理多维特征的输入</h2><p>上面的程序都是基于单输入的，下面讲解多输入。多输入时输出变成<br>$$<br>\hat{y} =  \sigma (\sum_i w_i x_i +b)<br>$$<br>这样我们就可以利用矩阵运算这种并行计算方式大大提高运算速度，也增加程序可读性。</p><img src="/2021/05/13/pytorch-jiao-xue-ji-shi-li/4.png" class=""><p><strong>读取数据</strong>：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token comment" spellcheck="true">#读取文件，第一个参数是文件名，也可以是压缩包，第二个参数是数据分隔符，第三个是数据类型，通常是float32</span>xy <span class="token operator">=</span> np<span class="token punctuation">.</span>loadtxt<span class="token punctuation">(</span><span class="token string">'diabetes.csv'</span><span class="token punctuation">,</span>delimiter<span class="token operator">=</span><span class="token string">','</span><span class="token punctuation">,</span>dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>x_data <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>xy<span class="token punctuation">{</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">}</span><span class="token punctuation">)</span>y_data <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>xy<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>         <span class="token comment" spellcheck="true">#用中括号是因为要用矩阵形式而非向量</span></code></pre><p><strong>定义模型</strong>:</p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">class</span> <span class="token class-name">Model</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>Model<span class="token punctuation">,</span>self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>linear1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>linear2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>linear3 <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>sigmoid <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span>       <span class="token comment" spellcheck="true">#没有参数，只需要一个来构建计算图，这里可以改变激活函数</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>self<span class="token punctuation">.</span>linear1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>self<span class="token punctuation">.</span>linear2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>self<span class="token punctuation">.</span>linear3<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> xmodel <span class="token operator">=</span> Model<span class="token punctuation">(</span><span class="token punctuation">)</span>        </code></pre><p><strong>优化器</strong>：</p><pre class=" language-python"><code class="language-python">criterion <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>BCELoss<span class="token punctuation">(</span>size_average <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span>optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>lr <span class="token operator">=</span> <span class="token number">0.1</span><span class="token punctuation">)</span></code></pre><p><strong>训练</strong>：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">for</span> epoch <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true">#这里没有使用Mini-Bash进行训练，而是全部数据一次训练完成，后面会用到DataLoader进行Mini-Batch的训练</span>    y_pred <span class="token operator">=</span> model<span class="token punctuation">(</span>x_data<span class="token punctuation">)</span>              loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>y_pred<span class="token punctuation">,</span>y_data<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>epoch<span class="token punctuation">,</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>    loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>    optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>  </code></pre><p>可以尝试不同的激活函数，例如除了Sigmoid常用的是ReLU，对应的代码是torch.nn.ReLU()。它对应小于0的输入输出为0，大于0的则直接输出对应值。注意最后的输出层不能用ReLU，否则计算Loss的时候有可能因为ln0而出错。</p><h2 id="加载数据集"><a href="#加载数据集" class="headerlink" title="加载数据集"></a>加载数据集</h2><p>为了训练时能够跨越鞍点达到全局最优，我们需要分堆进行训练，也就是Mini-Batch的训练。其中一个Epoch代表所有的样本都进行过一次训练，一个Iteration是一个Batch堆进行一次训练，Batch-Size指的是Batch中的样本数。</p><p>首先我们要生成一个DataLoader，其中一个参数就是batch_size，第二个参数是shuffle，即是否每次epoch生成的batch都具有随机性，都有所不同，样本都是随机打乱的。还有一个num_workers参数，决定用几个线程读取数据。</p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> torch <span class="token comment" spellcheck="true">#Dataset为抽象类，不能实例化，只能继承</span><span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> Dataset<span class="token comment" spellcheck="true">#DataLoader帮助我们加载数据</span><span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader<span class="token keyword">class</span> <span class="token class-name">DiabetesDataset</span><span class="token punctuation">(</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">pass</span>    <span class="token comment" spellcheck="true">#这个函数为了让我们能通过dataset[index]把数据拿出来</span>    <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>index<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">pass</span>    <span class="token comment" spellcheck="true">#这个函数为了让我们能通过len(dataset)返回数据条数</span>    <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">pass</span>dataset <span class="token operator">=</span> DiabetesDataset<span class="token punctuation">(</span><span class="token punctuation">)</span>train_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token operator">=</span>dataset<span class="token punctuation">,</span>batch_size<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>num_workers<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span></code></pre><p>文件不大时可以通过init函数把数据都读到内存中，如果数据文件过大，通常只记载标签，然后在后面再把一个个文件读取进来。</p><p>注意：Linux和Windows处理多线程的方式不一样，我们需要将用loader迭代的代码封装到if语句中，否则会报错：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>    <span class="token keyword">for</span> epoch <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true">#enumerate把可迭代对象组合成索引序列，索引从0开始，同时输出索引和值</span>        <span class="token keyword">for</span> i<span class="token punctuation">,</span>data <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>train_loader<span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token comment" spellcheck="true"># prepare data</span></code></pre><p><strong>Database数据集实现：</strong></p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> torch <span class="token comment" spellcheck="true">#Dataset为抽象类，不能实例化，只能继承</span><span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> Dataset<span class="token comment" spellcheck="true">#DataLoader帮助我们加载数据</span><span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader<span class="token keyword">class</span> <span class="token class-name">DiabetesDataset</span><span class="token punctuation">(</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>filepath<span class="token punctuation">)</span><span class="token punctuation">:</span>        xy <span class="token operator">=</span> np<span class="token punctuation">.</span>loadtxt<span class="token punctuation">(</span>filepath<span class="token punctuation">,</span>delimiter<span class="token operator">=</span><span class="token string">','</span><span class="token punctuation">,</span>dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">#shape[0]取出行数，即第一个维度值</span>        self<span class="token punctuation">.</span>len <span class="token operator">=</span> xy<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>        self<span class="token punctuation">.</span>x_data <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>xy<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>y_data <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>xy<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>         <span class="token comment" spellcheck="true">#用中括号是因为要用矩阵形式而非向量</span>    <span class="token comment" spellcheck="true">#这个函数为了让我们能通过dataset[index]把数据拿出来</span>    <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>index<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>x_data<span class="token punctuation">[</span>index<span class="token punctuation">]</span><span class="token punctuation">,</span>self<span class="token punctuation">.</span>y_data<span class="token punctuation">[</span>index<span class="token punctuation">]</span>  <span class="token comment" spellcheck="true">#返回(x,y)形式的元组</span>    <span class="token comment" spellcheck="true">#这个函数为了让我们能通过len(dataset)返回数据条数</span>    <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>lendataset <span class="token operator">=</span> DiabetesDataset<span class="token punctuation">(</span><span class="token string">'diabetes.csv.gz'</span><span class="token punctuation">)</span>train_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token operator">=</span>dataset<span class="token punctuation">,</span>batch_size<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>num_workers<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span></code></pre><p><strong>训练</strong>:</p><pre class=" language-python"><code class="language-python"><span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>    <span class="token keyword">for</span> epoch <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true">#每次循环一个batch</span>        <span class="token keyword">for</span> i<span class="token punctuation">,</span>data <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>train_loader<span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token comment" spellcheck="true">#取出x,y数据的方法,每次取出的是一个batch的数据,并自行组合为两个Tensor赋给inputs和labels</span>            inputs<span class="token punctuation">,</span>labels <span class="token operator">=</span> data                   <span class="token comment" spellcheck="true">#这个输入x的Tensor传给model进行计算，model会执行矩阵运算计算出y的Tensor</span>            y_pred <span class="token operator">=</span> model<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>                      loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>y_pred<span class="token punctuation">,</span>labels<span class="token punctuation">)</span>            <span class="token keyword">print</span><span class="token punctuation">(</span>epoch<span class="token punctuation">,</span>i<span class="token punctuation">,</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>            optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>            loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>            optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>  </code></pre><p><strong>完整代码</strong>：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> torch <span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> Dataset<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader<span class="token keyword">class</span> <span class="token class-name">DiabetesDataset</span><span class="token punctuation">(</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>filepath<span class="token punctuation">)</span><span class="token punctuation">:</span>        xy <span class="token operator">=</span> np<span class="token punctuation">.</span>loadtxt<span class="token punctuation">(</span>filepath<span class="token punctuation">,</span>delimiter<span class="token operator">=</span><span class="token string">','</span><span class="token punctuation">,</span>dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>len <span class="token operator">=</span> xy<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>        self<span class="token punctuation">.</span>x_data <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>xy<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>y_data <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>xy<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>             <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>index<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>x_data<span class="token punctuation">[</span>index<span class="token punctuation">]</span><span class="token punctuation">,</span>self<span class="token punctuation">.</span>y_data<span class="token punctuation">[</span>index<span class="token punctuation">]</span>      <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>lendataset <span class="token operator">=</span> DiabetesDataset<span class="token punctuation">(</span><span class="token string">'diabetes.csv.gz'</span><span class="token punctuation">)</span>train_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token operator">=</span>dataset<span class="token punctuation">,</span>batch_size<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>num_workers<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">Model</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>Model<span class="token punctuation">,</span>self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>linear1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>linear2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>linear3 <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>sigmoid <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span>           <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>self<span class="token punctuation">.</span>linear1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>self<span class="token punctuation">.</span>linear2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>self<span class="token punctuation">.</span>linear3<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> xmodel <span class="token operator">=</span> Model<span class="token punctuation">(</span><span class="token punctuation">)</span>   criterion <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>BCELoss<span class="token punctuation">(</span>size_average <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span>optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>lr <span class="token operator">=</span> <span class="token number">0.01</span><span class="token punctuation">)</span><span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>    <span class="token keyword">for</span> epoch <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">for</span> i<span class="token punctuation">,</span>data <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>train_loader<span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            inputs<span class="token punctuation">,</span>labels <span class="token operator">=</span> data                   y_pred <span class="token operator">=</span> model<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>                      loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>y_pred<span class="token punctuation">,</span>labels<span class="token punctuation">)</span>            <span class="token keyword">print</span><span class="token punctuation">(</span>epoch<span class="token punctuation">,</span>i<span class="token punctuation">,</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>            optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>            loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>            optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>  </code></pre><p>官方数据集的使用方法：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> torchvision <span class="token keyword">import</span> datasets<span class="token comment" spellcheck="true">#设置测试和训练集，是否下载，是否转换为张量，可以转换为0~1或-1~1</span>train_dataset <span class="token operator">=</span> datasets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">'../dataset/mnist'</span><span class="token punctuation">,</span>train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>transform <span class="token operator">=</span> transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>download <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span>test_dataset <span class="token operator">=</span> datasets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">'../dataset/mnist'</span><span class="token punctuation">,</span>train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>transform <span class="token operator">=</span> transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>download <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#分batch训练，否则内存不够加载所有数据</span>train_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token operator">=</span>train_dataset<span class="token punctuation">,</span>batch_size<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>num_workers<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>test_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token operator">=</span>test_dataset<span class="token punctuation">,</span>batch_size<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>num_workers<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span></code></pre><h2 id="多分类问题"><a href="#多分类问题" class="headerlink" title="多分类问题"></a>多分类问题</h2><p>在多分类问题上，于二分类不同的在于，二分类只有一个输出即概率，多分类中如果有10个分类，需要设置10个输出。我们希望输出具有竞争性，且符合分布。这里可以引入Softmax层，满足所有输出大于等于0且相加等于1。Softmax层的公式为：<br>$$<br>P(y=i) = \frac{e^{Z_i}}{\sum_{j=0}^{k-1} e^{Z_i}}<br>$$<br>其中$Z_i$是最后一个线性层的输出。这就是Softmax函数。</p><p>对于损失函数，参考二分类：<br>$$<br>L = -Ylog\hat{Y}<br>$$<br>其中$\hat{Y}$是真实值输出为1的节点的预测值（概率），Y=1。</p><p>算法举例：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> npy <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>z <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.2</span><span class="token punctuation">,</span><span class="token number">0.1</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">0.1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>y_pred <span class="token operator">=</span> np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>z<span class="token punctuation">)</span> <span class="token operator">/</span> np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>z<span class="token punctuation">)</span><span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token punctuation">)</span>loss <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token operator">-</span>y <span class="token operator">*</span> np<span class="token punctuation">.</span>log<span class="token punctuation">(</span>y_pred<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>loss<span class="token punctuation">)</span></code></pre><p>实际运用举例：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token comment" spellcheck="true">#y必须是长整形的张量，当中存放的是最后真实分类的索引，范围是0到输出节点数-1</span>y <span class="token operator">=</span> torch<span class="token punctuation">.</span>LongTensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>z <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.2</span><span class="token punctuation">,</span><span class="token number">0.1</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">0.1</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#交叉熵损失，注意：神经网络最后一层直接是线性层即可</span>criterion <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>   loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>z<span class="token punctuation">,</span>y<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>loss<span class="token punctuation">)</span></code></pre><p>NLLLoss损失函数是CrossEntropyLoss损失函数的最后一步，即Softmax和log之后的，所有项相加，去掉负号，再求均值。</p><h3 id="实例：MNIST数据集"><a href="#实例：MNIST数据集" class="headerlink" title="实例：MNIST数据集"></a>实例：MNIST数据集</h3><p>下面是对手写MNIST数据集进行训练的例子，原式方法可以查看我另一篇文章《Python神经网络编程》。</p><p>导入数据：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token comment" spellcheck="true">#这是一个对图像进行原始数据处理的工具</span><span class="token keyword">from</span> torchvision <span class="token keyword">import</span> transforms<span class="token keyword">from</span> torchvision <span class="token keyword">import</span> datasets<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F<span class="token keyword">import</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">as</span> optim</code></pre><p><strong>准备数据：</strong></p><p>神经网络要求输入最好比较小，并且遵从正态分布，因此要先把PIL图片转换成Tensor做归一化处理。在多通道图像中有RGB，因此转换的Tensor是三维，第一维是选择RGB,后面的两维就是整张图片灰度。这里的单通道图片变成的是1 * 28 * 28。这里构建Compose类实例，上面的整个过程可以通过第一个ToTensor对象来实现，后面的Normalize中的两个数是进行数据标准化中常用的量，这里均值用0.1307，标准差用0.3081，这些是对整个样本计算的结果，这样可以把样本映射到（0，1）分布上，便于训练。公式为$Pixel_{norm} = \frac{prxel_{orgin} - mean}{std}$，mean是均值，std是标准差。用映射后的数据去做训练能够得到更好的训练效果。</p><pre class=" language-python"><code class="language-python">batch_size<span class="token operator">=</span> <span class="token number">64</span>transform <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>    transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">0.1307</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">0.3081</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>train_dataset <span class="token operator">=</span> datasets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">'../dataset/mnist'</span><span class="token punctuation">,</span>train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>transform <span class="token operator">=</span> transform<span class="token punctuation">,</span>download <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span>test_dataset <span class="token operator">=</span> datasets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">'../dataset/mnist'</span><span class="token punctuation">,</span>train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>transform <span class="token operator">=</span> transform<span class="token punctuation">,</span>download <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span>train_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token operator">=</span>train_dataset<span class="token punctuation">,</span>batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span>shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>test_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token operator">=</span>test_dataset<span class="token punctuation">,</span>batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span>shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span></code></pre><p>可以用以下程序计算平均值标准差：</p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#算一下数据的均值和标准差</span>sum1 <span class="token operator">=</span> <span class="token number">0</span>sum2 <span class="token operator">=</span> <span class="token number">0</span><span class="token keyword">for</span> record <span class="token keyword">in</span> training_data_list<span class="token punctuation">:</span>        all_values <span class="token operator">=</span> record<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">','</span><span class="token punctuation">)</span>        inputs <span class="token operator">=</span> <span class="token punctuation">(</span>numpy<span class="token punctuation">.</span>asfarray<span class="token punctuation">(</span>all_values<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">255.0</span><span class="token punctuation">)</span>        sum1 <span class="token operator">+=</span> inputs<span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token punctuation">)</span>        sum2 <span class="token operator">+=</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>inputs <span class="token operator">-</span> mean<span class="token punctuation">)</span><span class="token operator">**</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token punctuation">)</span>mean <span class="token operator">=</span> sum1 <span class="token operator">/</span><span class="token number">784</span> <span class="token operator">/</span>len<span class="token punctuation">(</span>training_data_list<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"平均值："</span><span class="token punctuation">,</span>mean<span class="token punctuation">)</span>std <span class="token operator">=</span> <span class="token punctuation">(</span>sum2 <span class="token operator">/</span> <span class="token number">784</span> <span class="token operator">/</span>len<span class="token punctuation">(</span>training_data_list<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">**</span> <span class="token number">0.5</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"标准差："</span><span class="token punctuation">,</span>std<span class="token punctuation">)</span></code></pre><p><strong>模型</strong>：</p><p>激活函数采用ReLU函数，view函数把Tensor转换为元素总数不变，列数为784的Tensor。</p><pre class=" language-Python"><code class="language-Python">class Net(torch.nn.Module):    def __init__(self):        super(Net,self).__init__()        self.l1 = torch.nn.Linear(784,512)        self.l2 = torch.nn.Linear(512,256)        self.l3 = torch.nn.Linear(256,128)        self.l4 = torch.nn.Linear(128,64)        self.l5 = torch.nn.Linear(64,10)    def forward(self,x):        x = x.view(-1,784)        x = F.relu(self.l1(x))        x = F.relu(self.l2(x))        x = F.relu(self.l3(x))        x = F.relu(self.l4(x))        return self.l5(x)model = Net()</code></pre><p><strong>优化器</strong>：</p><p>损失函数为交叉熵函数，优化器带冲量momentum可以优化训练过程</p><pre class=" language-python"><code class="language-python">criterion <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>lr <span class="token operator">=</span> <span class="token number">0.01</span><span class="token punctuation">,</span>momentum<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span></code></pre><p><strong>训练</strong>：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>epoch<span class="token punctuation">)</span><span class="token punctuation">:</span>    running_loss <span class="token operator">=</span> <span class="token number">0.0</span>      <span class="token keyword">for</span> batch_idx<span class="token punctuation">,</span>data <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>train_loader<span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            inputs<span class="token punctuation">,</span>target <span class="token operator">=</span> data                   optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>            outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>                      loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span>target<span class="token punctuation">)</span>            loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>            optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>              running_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token keyword">if</span> batch_idx <span class="token operator">%</span> <span class="token number">300</span> <span class="token operator">==</span> <span class="token number">299</span><span class="token punctuation">:</span>                <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'[%d,%5d] loss: %.3f'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>epoch <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span>batch_idx <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span>running_loss <span class="token operator">/</span> <span class="token number">300</span><span class="token punctuation">)</span><span class="token punctuation">)</span>                running_loss <span class="token operator">=</span> <span class="token number">0</span></code></pre><p><strong>测试</strong>：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">test</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    correct <span class="token operator">=</span> <span class="token number">0</span>    total <span class="token operator">=</span> <span class="token number">0</span>    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>     <span class="token comment" spellcheck="true">#这部分代码不会计算梯度</span>        <span class="token keyword">for</span> data <span class="token keyword">in</span> test_loader<span class="token punctuation">:</span>            images<span class="token punctuation">,</span>labels <span class="token operator">=</span> data            outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>images<span class="token punctuation">)</span>            <span class="token comment" spellcheck="true">#这里用max函数找输出节点中的最大值（即输出矩阵中每一行的最大值），返回该值和对应下标</span>            _<span class="token punctuation">,</span>predicted <span class="token operator">=</span> torch<span class="token punctuation">.</span>max<span class="token punctuation">(</span>outputs<span class="token punctuation">.</span>data<span class="token punctuation">,</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>            <span class="token comment" spellcheck="true">#labels.size(0)返回行数，也即是样本个数</span>            total <span class="token operator">+=</span> labels<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>            <span class="token comment" spellcheck="true">#把两个N*1的Tensor做比较相等是1否则是0，把所有结果相加就是正确的个数</span>            correct <span class="token operator">+=</span> <span class="token punctuation">(</span>predicted <span class="token operator">==</span> labels<span class="token punctuation">)</span><span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Accuracy on test set: %d %%'</span> <span class="token operator">%</span> <span class="token punctuation">(</span><span class="token number">100</span> <span class="token operator">*</span> correct <span class="token operator">/</span> total<span class="token punctuation">)</span><span class="token punctuation">)</span>    </code></pre><p><strong>整体程序</strong>：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">from</span> torchvision <span class="token keyword">import</span> transforms<span class="token keyword">from</span> torchvision <span class="token keyword">import</span> datasets<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F<span class="token keyword">import</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">as</span> optimbatch_size<span class="token operator">=</span> <span class="token number">64</span>transform <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>    transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">0.1307</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">0.3081</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>train_dataset <span class="token operator">=</span> datasets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">'../dataset/mnist'</span><span class="token punctuation">,</span>train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>transform <span class="token operator">=</span> transform<span class="token punctuation">,</span>download <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span>test_dataset <span class="token operator">=</span> datasets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">'../dataset/mnist'</span><span class="token punctuation">,</span>train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>transform <span class="token operator">=</span> transform<span class="token punctuation">,</span>download <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span>train_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token operator">=</span>train_dataset<span class="token punctuation">,</span>batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span>shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>test_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token operator">=</span>test_dataset<span class="token punctuation">,</span>batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span>shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">Net</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>Net<span class="token punctuation">,</span>self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>l1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">784</span><span class="token punctuation">,</span><span class="token number">512</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>l2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span><span class="token number">256</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>l3 <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span><span class="token number">128</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>l4 <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span><span class="token number">64</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>l5 <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>        x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">784</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>l1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>l2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>l3<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>l4<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>l5<span class="token punctuation">(</span>x<span class="token punctuation">)</span>model <span class="token operator">=</span> Net<span class="token punctuation">(</span><span class="token punctuation">)</span>criterion <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>lr <span class="token operator">=</span> <span class="token number">0.01</span><span class="token punctuation">,</span>momentum<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>epoch<span class="token punctuation">)</span><span class="token punctuation">:</span>    running_loss <span class="token operator">=</span> <span class="token number">0.0</span>      <span class="token keyword">for</span> batch_idx<span class="token punctuation">,</span>data <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>train_loader<span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            inputs<span class="token punctuation">,</span>target <span class="token operator">=</span> data                   optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>            outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>                      loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span>target<span class="token punctuation">)</span>            loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>            optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>              running_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token keyword">if</span> batch_idx <span class="token operator">%</span> <span class="token number">300</span> <span class="token operator">==</span> <span class="token number">299</span><span class="token punctuation">:</span>                <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'[%d,%5d] loss: %.3f'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>epoch <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span>batch_idx <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span>running_loss <span class="token operator">/</span> <span class="token number">300</span><span class="token punctuation">)</span><span class="token punctuation">)</span>                running_loss <span class="token operator">=</span> <span class="token number">0</span><span class="token keyword">def</span> <span class="token function">test</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    correct <span class="token operator">=</span> <span class="token number">0</span>    total <span class="token operator">=</span> <span class="token number">0</span>    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>     <span class="token comment" spellcheck="true">#这部分代码不会计算梯度</span>        <span class="token keyword">for</span> data <span class="token keyword">in</span> test_loader<span class="token punctuation">:</span>            images<span class="token punctuation">,</span>labels <span class="token operator">=</span> data            outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>images<span class="token punctuation">)</span>            <span class="token comment" spellcheck="true">#这里用max函数找输出节点中的最大值（即输出矩阵中每一行的最大值），返回该值和对应下标</span>            _<span class="token punctuation">,</span>predicted <span class="token operator">=</span> torch<span class="token punctuation">.</span>max<span class="token punctuation">(</span>outputs<span class="token punctuation">.</span>data<span class="token punctuation">,</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>            <span class="token comment" spellcheck="true">#labels.size(0)返回行数，也即是样本个数</span>            total <span class="token operator">+=</span> labels<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>            <span class="token comment" spellcheck="true">#把两个N*1的Tensor做比较相等是1否则是0，把所有结果相加就是正确的个数</span>            correct <span class="token operator">+=</span> <span class="token punctuation">(</span>predicted <span class="token operator">==</span> labels<span class="token punctuation">)</span><span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Accuracy on test set: %d %%'</span> <span class="token operator">%</span> <span class="token punctuation">(</span><span class="token number">100</span> <span class="token operator">*</span> correct <span class="token operator">/</span> total<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>    <span class="token keyword">for</span> epoch <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        train<span class="token punctuation">(</span>epoch<span class="token punctuation">)</span>        test<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><p>当自己拥有数据集时的根据上面改写的程序：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> Dataset<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F<span class="token keyword">import</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">as</span> optim<span class="token keyword">import</span> numpy <span class="token keyword">as</span> npbatch_size <span class="token operator">=</span> <span class="token number">64</span><span class="token keyword">class</span> <span class="token class-name">DiabetesDataset</span><span class="token punctuation">(</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> filepath<span class="token punctuation">)</span><span class="token punctuation">:</span>        xy <span class="token operator">=</span> np<span class="token punctuation">.</span>loadtxt<span class="token punctuation">(</span>filepath<span class="token punctuation">,</span> delimiter<span class="token operator">=</span><span class="token string">','</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>len <span class="token operator">=</span> xy<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>        self<span class="token punctuation">.</span>x_data <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>xy<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>y_data <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>xy<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>y_data <span class="token operator">=</span> self<span class="token punctuation">.</span>y_data <span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>long<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> index<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>x_data<span class="token punctuation">[</span>index<span class="token punctuation">]</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>y_data<span class="token punctuation">[</span>index<span class="token punctuation">]</span>    <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>lentrain_dataset <span class="token operator">=</span> DiabetesDataset<span class="token punctuation">(</span><span class="token string">'mnist_train.csv'</span><span class="token punctuation">)</span>train_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token operator">=</span>train_dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>test_dataset <span class="token operator">=</span> DiabetesDataset<span class="token punctuation">(</span><span class="token string">'mnist_test.csv'</span><span class="token punctuation">)</span>test_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token operator">=</span>test_dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">Net</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>Net<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>l1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">784</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>l2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>l3 <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>l4 <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>l5 <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">784</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>l1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>l2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>l3<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>l4<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>l5<span class="token punctuation">(</span>x<span class="token punctuation">)</span>model <span class="token operator">=</span> Net<span class="token punctuation">(</span><span class="token punctuation">)</span>criterion <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>lr <span class="token operator">=</span> <span class="token number">0.01</span><span class="token punctuation">,</span>momentum<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>epoch<span class="token punctuation">)</span><span class="token punctuation">:</span>    running_loss <span class="token operator">=</span> <span class="token number">0.0</span>    <span class="token keyword">for</span> batch_idx<span class="token punctuation">,</span> data <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>train_loader<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        inputs<span class="token punctuation">,</span> target <span class="token operator">=</span> data        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>        outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>        loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> target<span class="token punctuation">)</span>        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>        running_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> batch_idx <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'The initial loss: %.3f'</span> <span class="token operator">%</span>  running_loss <span class="token punctuation">)</span>        <span class="token keyword">if</span> batch_idx <span class="token operator">%</span> <span class="token number">150</span> <span class="token operator">==</span> <span class="token number">149</span><span class="token punctuation">:</span>            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'[%d,%5d] loss: %.3f'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>epoch <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> batch_idx <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> running_loss <span class="token operator">/</span> <span class="token number">300</span><span class="token punctuation">)</span><span class="token punctuation">)</span>            running_loss <span class="token operator">=</span> <span class="token number">0</span><span class="token keyword">def</span> <span class="token function">test</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    correct <span class="token operator">=</span> <span class="token number">0</span>    total <span class="token operator">=</span> <span class="token number">0</span>    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment" spellcheck="true"># 这部分代码不会计算梯度</span>        <span class="token keyword">for</span> data <span class="token keyword">in</span> test_loader<span class="token punctuation">:</span>            images<span class="token punctuation">,</span> labels <span class="token operator">=</span> data            outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>images<span class="token punctuation">)</span>            <span class="token comment" spellcheck="true"># 这里用max函数找输出节点中的最大值（即输出矩阵中每一行的最大值），返回该值和对应下标</span>            _<span class="token punctuation">,</span> predicted <span class="token operator">=</span> torch<span class="token punctuation">.</span>max<span class="token punctuation">(</span>outputs<span class="token punctuation">.</span>data<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>            <span class="token comment" spellcheck="true"># labels.size(0)返回行数，也即是样本个数</span>            total <span class="token operator">+=</span> labels<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>            <span class="token comment" spellcheck="true"># 把两个N*1的Tensor做比较相等是1否则是0，把所有结果相加就是正确的个数</span>            correct <span class="token operator">+=</span> <span class="token punctuation">(</span>predicted <span class="token operator">==</span> labels<span class="token punctuation">)</span><span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Total:"</span><span class="token punctuation">,</span>total<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Corrcet:"</span><span class="token punctuation">,</span>correct<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Accuracy on test set: %.2f %%'</span> <span class="token operator">%</span> <span class="token punctuation">(</span><span class="token number">100</span> <span class="token operator">*</span> correct <span class="token operator">/</span> total<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>    <span class="token keyword">for</span> epoch <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        train<span class="token punctuation">(</span>epoch<span class="token punctuation">)</span>        test<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><p>如果把上面的ReLU函数变成Sigmoid函数，则收敛速度会大大降低，ReLU函数能让Loss在20代收敛到0，准确率达到98.33%，Sigmoid函数则500个epoch都不能完全收敛，准确率97.14%。而且Loss的下降速度和batch_size的取值也有很大关系，上面batch_size取值是64能得到很好的收敛速度，不能取得过小，取成10都会使Loss的值出现nan的情况，而且训练速度过慢。因此取大一些是有好处的，取128和256的结果没有太多改变但训练速度大大加快。</p><h2 id="卷积神经网络（Convolutional-Neural-Network）"><a href="#卷积神经网络（Convolutional-Neural-Network）" class="headerlink" title="卷积神经网络（Convolutional Neural Network）"></a>卷积神经网络（Convolutional Neural Network）</h2><p>全连接的神经网络，意思是网络中用的都是线性层串行的方式连接，如上面学过的内容。这里来探讨处理图像时用到的二维卷积神经网络。上面的手写数字是1*28*28的张量，但是我们强行把它拆成一维来训练了。这里我们建议先通过一个卷积层，保留图像的空间结构。可以先把它5*5卷积成4*24*24的三维张量，然后可以进行2*2的下采样，变成4*12*12，下采样不改变通道数，但改变图像的宽高，这样可以减少数据量，降低运算需求。然后再进行5 * 5卷积变成8 * 8 * 8，进行2 * 2下采样变成8*4*4，然后按一定顺序把它们展开成一维Tensor，通过全连接层，最终映射到10个输出节点，通过交叉熵损失解决分类问题。前面的卷积下采样的工作称为<strong>特征提取</strong>（Feature Extraction），后面的全连接网络称为<strong>分类器</strong>（Classification）。</p><img src="/2021/05/13/pytorch-jiao-xue-ji-shi-li/5.png" class=""><p>成像的原理：</p><img src="/2021/05/13/pytorch-jiao-xue-ji-shi-li/6.png" class=""><p>利用透镜把一束束光打到光敏电阻上，通过电流的变化可以求得电阻值，从而求得对应的光照强度。一个像素就需要红绿蓝三种不同的光敏传感器，从而得到彩色图像。这就是RGB图片。每个颜色都有0到255的灰度级别，这就是栅格图像。还有一种矢量图像，不能直接捕获大部分靠人工生成。描述的时候按照图片的圆心、直径、边框颜色、填充颜色等，因此放大时也是圆滑的而不是栅格的，因为这就是现画的。</p><h3 id="卷积层"><a href="#卷积层" class="headerlink" title="卷积层"></a>卷积层</h3><p>我们每次取一个小区域做卷积，从左到右从上到下依次卷积，每一个小区域都含三通道，最后把每一个区域输出的卷积结果拼到一起。</p><p>其中一个区域做3 * 3的卷积运算过程如下：</p><img src="/2021/05/13/pytorch-jiao-xue-ji-shi-li/7.png" class=""><p>首先中间第二列的矩阵是3 * 3卷积核，RGB每一个通道各有一个卷积核。每个通道从左到右从上到下依次拿出和卷积核大小相同的矩阵，和卷积核做乘法，这个乘法是矩阵中的每个元素和另一个矩阵相同位置的元素相乘，得到9个数，然后把它们相加得到一个数，因此做3 * 3的卷积可以把原矩阵减小两行两列，5 * 5的矩阵做3*3的卷积可以得到3*3的矩阵。最后把三个通道卷积出来的矩阵相加，就可以得到输出结果，并使通道数减小到1。相同通道的图像块用的是一个卷积核，这也叫做共享权重的机制。</p><p>如果想要得到多个输出通道，把上面的过程再进行重复即可，输出通道有几个，就需要几组卷积核。</p><img src="/2021/05/13/pytorch-jiao-xue-ji-shi-li/8.png" class=""><p>因此<strong>卷积核是一个四维的张量</strong>，形式是：输出通道数 * 输入通道数 * 卷积核宽度 * 卷积核高度。</p><p>程序的计算过程：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> torch in_channels<span class="token punctuation">,</span>out_channels <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">,</span><span class="token number">10</span>    <span class="token comment" spellcheck="true">#输入输出通道数</span>width<span class="token punctuation">,</span>height <span class="token operator">=</span> <span class="token number">100</span><span class="token punctuation">,</span><span class="token number">100</span>             <span class="token comment" spellcheck="true">#图像大小</span>kernel_size <span class="token operator">=</span> <span class="token number">3</span>                    <span class="token comment" spellcheck="true">#卷积核大小</span>batch_size <span class="token operator">=</span> <span class="token number">1</span>                     <span class="token comment" spellcheck="true">#注意输入是四维的，第一维是第几个batch</span>inputs <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span>in_channels<span class="token punctuation">,</span>width<span class="token punctuation">,</span>height<span class="token punctuation">)</span>         <span class="token comment" spellcheck="true">#用Conv2d模块来生成卷积核</span>conv_layer <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span>out_channels<span class="token punctuation">,</span>kernel_size<span class="token operator">=</span>kernel_size<span class="token punctuation">)</span>output <span class="token operator">=</span> conv_layer<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>inputs<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>                 <span class="token comment" spellcheck="true">#torch.Size([1,5,100,100])</span><span class="token keyword">print</span><span class="token punctuation">(</span>output<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>                 <span class="token comment" spellcheck="true">#torch.Size([1,10,98,98])</span><span class="token keyword">print</span><span class="token punctuation">(</span>conv_layer<span class="token punctuation">.</span>weight<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>      <span class="token comment" spellcheck="true">#torch.Size([10,5,3,3])</span></code></pre><p><strong>输出图像宽高等于输入图像（padding参数的使用）</strong></p><p>如果需要输出图像的大小要等于输入图像，我们需要在输入图像外面填充一圈0数据再做卷积，具体的填充层数和卷积核大小有关。</p><img src="/2021/05/13/pytorch-jiao-xue-ji-shi-li/9.png" class=""><p>程序：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> torchin_channels<span class="token punctuation">,</span>out_channels <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span>   width<span class="token punctuation">,</span>height <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">,</span><span class="token number">5</span>             kernel_size <span class="token operator">=</span> <span class="token number">3</span>                    batch_size <span class="token operator">=</span> <span class="token number">1</span> inputs <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span>in_channels<span class="token punctuation">,</span>width<span class="token punctuation">,</span>height<span class="token punctuation">)</span>         <span class="token comment" spellcheck="true">#这里多了一个padding也就是填充的层数，bias是是否设置卷积后有偏置值</span>conv_layer <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span>out_channels<span class="token punctuation">,</span>kernel_size<span class="token operator">=</span>kernel_size<span class="token punctuation">,</span>padding <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">,</span>bias <span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">)</span>kernel <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">,</span><span class="token number">7</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">,</span><span class="token number">9</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#设定卷积核的值</span>conv_layer<span class="token punctuation">.</span>weight<span class="token punctuation">.</span>data <span class="token operator">=</span> kernel<span class="token punctuation">.</span>dataoutput <span class="token operator">=</span> conv_layer<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>                 <span class="token keyword">print</span><span class="token punctuation">(</span>output<span class="token punctuation">)</span>                 </code></pre><p><strong>调整步长（stride参数的使用）</strong></p><p>卷积是的步长是指，在卷积核对输入的一个通道做卷积时，往左右上下移动的时候都是挑一格来进行。</p><img src="/2021/05/13/pytorch-jiao-xue-ji-shi-li/10.png" class=""><p>例如上图的卷积中心就在输入的4，8，7，6四个点处，因此输出的图像是2*2的。可以有效降低图像的数据量。代码只需要添加参数即可：</p><pre class=" language-python"><code class="language-python">conv_layer <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span>out_channels<span class="token punctuation">,</span>kernel_size<span class="token operator">=</span>kernel_size<span class="token punctuation">,</span>stride <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span>bias <span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">)</span></code></pre><h3 id="下采样"><a href="#下采样" class="headerlink" title="下采样"></a>下采样</h3><p>用得最多的叫最大池化层（MaxPooling），这个层是没有权重的。</p><img src="/2021/05/13/pytorch-jiao-xue-ji-shi-li/11.png" class=""><p>这里使用2*2的MaxPooling是将原来的矩阵数据划分为一个个2*2的区域，然后每个区域取其中最大值，这样可以把数据量减少4倍。</p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> torchinputs <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span>in_channels<span class="token punctuation">,</span>width<span class="token punctuation">,</span>height<span class="token punctuation">)</span>         maxpooling_layer <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#kernel_size决定划分的区域是几乘几</span>output <span class="token operator">=</span> maxpooling_layer<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>                 <span class="token keyword">print</span><span class="token punctuation">(</span>output<span class="token punctuation">)</span>      </code></pre><h3 id="总体实现"><a href="#总体实现" class="headerlink" title="总体实现"></a>总体实现</h3><img src="/2021/05/13/pytorch-jiao-xue-ji-shi-li/12.png" class=""><img src="/2021/05/13/pytorch-jiao-xue-ji-shi-li/13.png" class=""><p><strong>模型</strong>：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Net</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>Net<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>pooling <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>fc <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">320</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true">#这里拿出第1维的个数即(n,1,28,28)中的第一个元素，是样本一个batch的样本个数</span>        <span class="token comment" spellcheck="true">#注意输入数据是四维的</span>        batch_size <span class="token operator">=</span> x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>pooling<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>pooling<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">#把它变成全连接网络batch * 320</span>        x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>fc<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> xmodel <span class="token operator">=</span> Net<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><p>除了模型以外，其他程序都和上一章的多分类问题一致。如果要切换到显卡计算，提高运算速度，程序如下：</p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#这里cuda:0指用的第一块显卡，把模型的参数缓存都放到cuda里计算</span>device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">"cuda:0"</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">"cpu"</span><span class="token punctuation">)</span>model<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span></code></pre><p>还需要把输入和输出迁移到GPU上，注意模型和数据使用同一块显卡：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>epoch<span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token operator">&amp;</span>nbsp<span class="token punctuation">;</span> <span class="token operator">&amp;</span>nbsp<span class="token punctuation">;</span>    <span class="token operator">-</span><span class="token operator">-</span>snip<span class="token operator">-</span><span class="token operator">-</span> <span class="token operator">&amp;</span>nbsp<span class="token punctuation">;</span> <span class="token operator">&amp;</span>nbsp<span class="token punctuation">;</span>    inputs<span class="token punctuation">,</span>target <span class="token operator">=</span> data <span class="token operator">&amp;</span>nbsp<span class="token punctuation">;</span> <span class="token operator">&amp;</span>nbsp<span class="token punctuation">;</span>    inputs<span class="token punctuation">,</span>target <span class="token operator">=</span> inputs<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">,</span>target<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>    <span class="token operator">-</span><span class="token operator">-</span>snip<span class="token operator">-</span><span class="token operator">-</span></code></pre><pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">test</span><span class="token punctuation">(</span>epoch<span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token operator">&amp;</span>nbsp<span class="token punctuation">;</span> <span class="token operator">&amp;</span>nbsp<span class="token punctuation">;</span>    <span class="token operator">-</span><span class="token operator">-</span>snip<span class="token operator">-</span><span class="token operator">-</span> <span class="token operator">&amp;</span>nbsp<span class="token punctuation">;</span> <span class="token operator">&amp;</span>nbsp<span class="token punctuation">;</span>    inputs<span class="token punctuation">,</span>target <span class="token operator">=</span> data <span class="token operator">&amp;</span>nbsp<span class="token punctuation">;</span> <span class="token operator">&amp;</span>nbsp<span class="token punctuation">;</span>    inputs<span class="token punctuation">,</span>target <span class="token operator">=</span> inputs<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">,</span>target<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>    <span class="token operator">-</span><span class="token operator">-</span>snip<span class="token operator">-</span><span class="token operator">-</span></code></pre><p>最终模型改进：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Net</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>Net<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>pooling <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>l1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">320</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>l2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>l3 <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true">#这里拿出第1维的个数即(n,1,28,28)中的第一个元素，是样本一个batch的样本个数</span>        <span class="token comment" spellcheck="true">#注意输入数据是四维的</span>        batch_size <span class="token operator">=</span> x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>pooling<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>pooling<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">#把它变成全连接网络batch * 320</span>        x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>l1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>l2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>l3<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> x</code></pre><p>经过改进后，经过30个epoch的训练，MINIST数据集的准确率达到了99.11%！！！这是一个巨大的提升。</p><h2 id="卷积神经网络（高级篇）（Advanced-CNN）"><a href="#卷积神经网络（高级篇）（Advanced-CNN）" class="headerlink" title="卷积神经网络（高级篇）（Advanced CNN）"></a>卷积神经网络（高级篇）（Advanced CNN）</h2><h3 id="GoogleNet"><a href="#GoogleNet" class="headerlink" title="GoogleNet"></a>GoogleNet</h3><img src="/2021/05/13/pytorch-jiao-xue-ji-shi-li/17.png" class=""><p>如上图就是GoogleNet的结构，由非常多的分支组成，但是其中有迹可循，很多结构都是重复的。我们可以把这种重复的结构封装使用，进行响应特征提取处理，减少代码冗余，这种结构叫做Inception Module。</p><p>Inception Module有各种各样的构建方式，由于我们在选择卷积核的时候不知道哪个结构是最优的，因此我们把几个结构拼接到一起，让模型自己选择。</p><img src="/2021/05/13/pytorch-jiao-xue-ji-shi-li/18.png" class=""><p>四条路径是四个张量，最后沿着通道拼成一个张量。这就要要求图像和高度一致，经过卷积和下采样都不变化，卷积可以通过设置对应的pedding来保证宽高不变，均值池化（Average Pooling）,不用默认的步长，设为Stride = 1即可避免缩小一半宽高，然后再通过pedding进行调整，例如3<em>3的AveragePooling可以通过Stride = 1，Pedding = 1，然后求得的是九个格子的均值。然后是1\</em>1的卷积：</p><img src="/2021/05/13/pytorch-jiao-xue-ji-shi-li/19.png" class=""><p>这个卷积把每个通道的灰度值加权求和，得出的宽高不变，每个通道的卷积代表一个通道色彩在分类中的重要程度。</p><img src="/2021/05/13/pytorch-jiao-xue-ji-shi-li/20.png" class=""><p>可以看出在加了一层1*1的卷积层之后，把通道数先降下来，计算结果没变计算量反而减少了一个数量级，因此1*1的卷积对减少计算量有着显著作用，这种计算量的减少意味着我们可以尝试更多地权重组合，做出更加复杂的网络。</p><p>InceptionModule程序实现：</p><img src="/2021/05/13/pytorch-jiao-xue-ji-shi-li/21.png" class=""><p>这样均值池化和三种卷积核的优化路径都齐了，拼在一起，梯度下降算法会自行选择最为合适的参数进行优化。</p><h4 id="Inception模型："><a href="#Inception模型：" class="headerlink" title="Inception模型："></a>Inception模型：</h4><pre class=" language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">InceptionA</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>in_channels<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>InceptionA<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>branch1x1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span><span class="token number">16</span><span class="token punctuation">,</span>kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>branch5x5_1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span><span class="token number">16</span><span class="token punctuation">,</span>kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>branch5x5_2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span><span class="token number">24</span><span class="token punctuation">,</span>kernel_size<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>branch3x3_1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span><span class="token number">16</span><span class="token punctuation">,</span>kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>branch3x3_2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span><span class="token number">24</span><span class="token punctuation">,</span>kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>branch3x3_3 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">24</span><span class="token punctuation">,</span><span class="token number">24</span><span class="token punctuation">,</span>kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>branch_pool <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span><span class="token number">24</span><span class="token punctuation">,</span>kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        branch1x1 <span class="token operator">=</span> self<span class="token punctuation">.</span>branch1x1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        branch5x5 <span class="token operator">=</span> self<span class="token punctuation">.</span>branch5x5_1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        branch5x5 <span class="token operator">=</span> self<span class="token punctuation">.</span>branch5x5_2<span class="token punctuation">(</span>branch5x5<span class="token punctuation">)</span>        branch3x3 <span class="token operator">=</span> self<span class="token punctuation">.</span>branch3x3_1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        branch3x3 <span class="token operator">=</span> self<span class="token punctuation">.</span>branch3x3_2<span class="token punctuation">(</span>branch3x3<span class="token punctuation">)</span>        branch3x3 <span class="token operator">=</span> self<span class="token punctuation">.</span>branch3x3_3<span class="token punctuation">(</span>branch3x3<span class="token punctuation">)</span>        branch_pool <span class="token operator">=</span> F<span class="token punctuation">.</span>avg_pool2d<span class="token punctuation">(</span>x<span class="token punctuation">,</span>kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>        branch_pool <span class="token operator">=</span> self<span class="token punctuation">.</span>branch_pool<span class="token punctuation">(</span>branch_pool<span class="token punctuation">)</span>        outputs <span class="token operator">=</span> <span class="token punctuation">[</span>branch1x1<span class="token punctuation">,</span>branch5x5<span class="token punctuation">,</span>branch3x3<span class="token punctuation">,</span>branch_pool<span class="token punctuation">]</span>        <span class="token keyword">return</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span></code></pre><p>把四个路径得出来的通道都合在一起，根据梯度下降算法，有利于降低Loss的通道中的值会升高，不利于降低Loss的会降低，这就是四条路径的好处。另外，构造函数中包含了输入通道数，这样就可以适应各种输入。输出通道数是88。</p><h4 id="整体网络"><a href="#整体网络" class="headerlink" title="整体网络"></a>整体网络</h4><pre class=" language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Net</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>Net<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">88</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>incep1 <span class="token operator">=</span> InceptionA<span class="token punctuation">(</span>in_channels <span class="token operator">=</span> <span class="token number">10</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>incep2 <span class="token operator">=</span> InceptionA<span class="token punctuation">(</span>in_channels <span class="token operator">=</span> <span class="token number">20</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>mp <span class="token operator">=</span> nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>              self<span class="token punctuation">.</span>fc <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">1408</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        in_size <span class="token operator">=</span> x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">#变成10*12*12</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>mp<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">#变成88*12*12</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>incep1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">#变成20*4*4</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>mp<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">#变成88*4*4</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>incep2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">#展开成全连接层</span>        x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span>in_size<span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>fc<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> x</code></pre><p>换了这个网络之后，正确率是98.9%。。。而上一个CNN是99.1%，因此我们应当选取合适的网络，不是越复杂越好。</p><p><strong>注意：如果Loss输出为nan说明训练不收敛，学习率太大导致梯度爆炸。因此需要降低学习率。</strong></p><h3 id="深度残差学习Deep-Residual-Learning"><a href="#深度残差学习Deep-Residual-Learning" class="headerlink" title="深度残差学习Deep Residual Learning"></a>深度残差学习Deep Residual Learning</h3><img src="/2021/05/13/pytorch-jiao-xue-ji-shi-li/22.png" class=""><p>如上图所示，这是一个残差网络（ResNet），其存在的意义在于解决梯度消失问题，当网络做得越深，靠近输入端的权重因为求导的链式法则使得其值接近于0，导数权值不更新，这样相当于只设置了后面的层而前面的层失去意义，这就是梯度消失。为了解决这个问题，可以把前面层的输出直接跨越一些层加到后面当中，前提数张量大小须一致，这样求梯度时后面加进来的一项相当于一个较为浅层的神经网络，前面的梯度依旧可以更新。</p><img src="/2021/05/13/pytorch-jiao-xue-ji-shi-li/23.png" class=""><img src="/2021/05/13/pytorch-jiao-xue-ji-shi-li/24.png" class=""><p><strong>ResidualBlock的编程实现</strong>：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">ResidualBlock</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>channels<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>ResidualBlock<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>channels <span class="token operator">=</span> channels        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>channels<span class="token punctuation">,</span> channels<span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>channels<span class="token punctuation">,</span> channels<span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        y <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>        y <span class="token operator">=</span> self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>y<span class="token punctuation">)</span>        <span class="token keyword">return</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>x <span class="token operator">+</span> y<span class="token punctuation">)</span></code></pre><p><strong>整体网络：</strong></p><pre class=" language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Net</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>Net<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>rblock1 <span class="token operator">=</span> ResidualBlock<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>rblock2 <span class="token operator">=</span> ResidualBlock<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">)</span>            self<span class="token punctuation">.</span>mp <span class="token operator">=</span> nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>              self<span class="token punctuation">.</span>fc <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        in_size <span class="token operator">=</span> x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">#变成16*12*12</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>mp<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">#变成16*12*12</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>rblock1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">#变成32*4*4</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>mp<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">#变成32*4*4</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>rblock2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">#展开成全连接层</span>        x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span>in_size<span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>fc<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> x</code></pre><p>这个网络的效果异常显著，可以将正确率提高到99.2%！！还可以将全连接层多加线性层，可以再次优化网络结构！</p><p>我们从以上程序还能学习到的是如果网络结构非常复杂，可以用新的类进行封装。</p><h4 id="论文推荐"><a href="#论文推荐" class="headerlink" title="论文推荐"></a>论文推荐</h4><p>1、$Identity Mappings in Deep Residual Networks$</p><p>论文中给了非常多的ResidualBlock的设计。可以自己尝试去实现几种看看效果。</p><img src="/2021/05/13/pytorch-jiao-xue-ji-shi-li/25.png" class=""><p>2、$Desely Connected Convolutional Networks$</p><img src="/2021/05/13/pytorch-jiao-xue-ji-shi-li/26.png" class=""><p>这也是一种值得探究的实现方式。</p><h2 id="循环神经网络（RNN）Recurrent-Neural-Network"><a href="#循环神经网络（RNN）Recurrent-Neural-Network" class="headerlink" title="循环神经网络（RNN）Recurrent Neural Network"></a>循环神经网络（RNN）Recurrent Neural Network</h2><p>以前使用的全连接网络叫做Dense或Deep网络，也叫DNN。</p><p>现在假如我们要预测明天的天气情况，我们是拿不到明天的温度气压等信息的，我们的输入信息只能是前几天的温度气压等信息，然后输出明天的天气情况，这时候把几天的数据拼接在一起使用全连接网络也可以，但是全连接网络的权重信息是非常多的，比CNN都还要多得多。这是DNN因为输入的每一个节点都和输出节点建立权重，而CNN是因为是卷积核共享权重的机制使得权重数量较少。</p><p>因此RNN专门用来处理这种<strong>序列模式</strong>的数字，我们也要用这种权重共享的概念来减少需要训练的权重数字。如果我们拥有前三天的天气数据，我们假定第一天和第二天有联系，第二天和第三天有联系，也就是说后一天的情况依赖于前一天，也就是说这种带有序列，后者依赖前者的数据是RNN的处理对象。</p><img src="/2021/05/13/pytorch-jiao-xue-ji-shi-li/27.png" class=""><p>RNN的本质上是一个线性层，不同于CNN它的权重是共享的，流程可以看右边的图，输入和线性层和前面的先验值进行线性变换，进行输出并且传递到下一层，下一层的x，和这一层的x进行某种融合。第一个先验值可以通过CNN+FC进行生成（例如图像到文本），或者设置全0，注意里面进行运算的RNN Cell是同一个线性层。</p><img src="/2021/05/13/pytorch-jiao-xue-ji-shi-li/28.png" class=""><p>上图是CNN Cell的构造，首先先验证$h^-$是h<em>1的矩阵，这一次的输入是 i  *  1的矩阵，输出必须也是h*1的矩阵，因此和先验值相乘的权值矩阵$w_1$是h\</em>h，和输入x相乘的权重矩阵$w_2$是h*i，在进行这样的线性变换后，再通过一个激活函数tanh，输出值<br>$$<br>h = tanh(w_1 h^- + b_1 + w_2x + b_2) = tanh(\left[ \begin{matrix} w_1 &amp; w_2 \end{matrix} \right] \left[ \begin{matrix} b_1 \ b_2 \end{matrix} \right])<br>$$<br>不断循环这个过程，就可以不断输出下一天的预测值。</p><p>定义RNN：</p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#input_size是输入的维度i，hidden_size是先验值的维度h</span>cell <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>RNNCell<span class="token punctuation">(</span>input_size <span class="token operator">=</span> input_size <span class="token punctuation">,</span> hidden_size <span class="token operator">=</span> hidden_size<span class="token punctuation">)</span> </code></pre><p>使用RNN：</p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#第一个是输入的向量，第二个是先验值的向量</span>hidden <span class="token operator">=</span> cell<span class="token punctuation">(</span>inputs<span class="token punctuation">,</span>hidden<span class="token punctuation">)</span></code></pre><p><strong>注意：由于数据是分batch进行训练的，一个batch中有多条数据，因此实际上程序中输入的维度应该为batch_size * i，h的维度是batch_size * h。要注意这种数据的构造形式，否则程序会发生错误。</strong></p><p>处理RNN时，整个序列构造成：</p><pre class=" language-python"><code class="language-python">dataset<span class="token punctuation">.</span>shape <span class="token operator">=</span> <span class="token punctuation">(</span>seqLen<span class="token punctuation">,</span>batchSize<span class="token punctuation">,</span>inputSize<span class="token punctuation">)</span></code></pre><p>这种形式，第一维是序列长度，第二个是batch长度，最后第三个才是输入的维度。</p><p>举例：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> torchbatch_size <span class="token operator">=</span> <span class="token number">1</span>seq_len <span class="token operator">=</span> <span class="token number">3</span>input_size <span class="token operator">=</span> <span class="token number">4</span>hidden_size <span class="token operator">=</span> <span class="token number">2</span>cell <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>RNNCell<span class="token punctuation">(</span>input_size <span class="token operator">=</span> input_size <span class="token punctuation">,</span> hidden_size <span class="token operator">=</span> hidden_size<span class="token punctuation">)</span> dataset <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>seq_len<span class="token punctuation">,</span>batch_size<span class="token punctuation">,</span>input_size<span class="token punctuation">)</span>hidden <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span>hidden_size<span class="token punctuation">)</span><span class="token comment" spellcheck="true">#对dataset进行遍历，这样把数据一组组拿出来，从三维变成二维，就能进行RNNCell的运算</span><span class="token keyword">for</span> idx<span class="token punctuation">,</span>inputs <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'='</span> <span class="token operator">*</span> <span class="token number">20</span><span class="token punctuation">,</span>idx <span class="token string">'='</span> <span class="token operator">*</span> <span class="token number">20</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'input.size:'</span><span class="token punctuation">,</span>input<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>    hidden <span class="token operator">=</span> cell<span class="token punctuation">(</span>inputs<span class="token punctuation">,</span>hidden<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'outputs size:'</span><span class="token punctuation">,</span>hidden<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>hidden<span class="token punctuation">)</span></code></pre><p>注意里面的hidden是输出值，是不断迭代变化的，输出后进入下一个RNNCell运算。</p><img src="/2021/05/13/pytorch-jiao-xue-ji-shi-li/29.png" class=""><p>在<strong>实际应用</strong>时如果使用RNN类而不是RNNCell类，还需要在后面加一个num_layers参数，代表RNN向上叠的层数，但不建议太多层因为RNN运算非常耗时。在执行</p><pre class=" language-python"><code class="language-python">cell <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>RNN<span class="token punctuation">(</span>input_size <span class="token operator">=</span> input_size <span class="token punctuation">,</span> hidden_size <span class="token operator">=</span> hidden_size<span class="token punctuation">,</span>num_layers <span class="token operator">=</span> num_layers<span class="token punctuation">)</span> out<span class="token punctuation">,</span>hidden <span class="token operator">=</span> cell<span class="token punctuation">(</span>inputs<span class="token punctuation">,</span>hidden<span class="token punctuation">)</span></code></pre><p>的代码时，这时我们<strong>不用自己写循环</strong>，只需要传入的<strong>inputs是三维seqLen*batchSize*inputSize</strong>的，输入的<strong>hidden是numLayers*batch*input_size</strong>，numLayer是RNN的层数，因为有可能RNN有多层，一个RNNCell就需要输入多个h。然后它会自己进行迭代。其中out的输出是<strong>h的序列seqLen*batchSize*hidden_size</strong>，而hidden输出的是<strong>最后一个h，维度是numLayers*batch*input_size</strong>。下面是多层RNN的图。</p><img src="/2021/05/13/pytorch-jiao-xue-ji-shi-li/30.png" class=""><p><strong>改进的程序：</strong></p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> torchbatch_size <span class="token operator">=</span> <span class="token number">1</span>seq_len <span class="token operator">=</span> <span class="token number">3</span>input_size <span class="token operator">=</span> <span class="token number">4</span>hidden_size <span class="token operator">=</span> <span class="token number">2</span>num_layers <span class="token operator">=</span> <span class="token number">1</span>cell <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>RNN<span class="token punctuation">(</span>input_size <span class="token operator">=</span> input_size <span class="token punctuation">,</span> hidden_size <span class="token operator">=</span> hidden_size<span class="token punctuation">,</span>num_layers <span class="token operator">=</span> num_layers<span class="token punctuation">)</span> inputs <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>seq_len<span class="token punctuation">,</span>batch_size<span class="token punctuation">,</span>input_size<span class="token punctuation">)</span>hidden <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>num_layers<span class="token punctuation">,</span>batch_size<span class="token punctuation">,</span>hidden_size<span class="token punctuation">)</span>out<span class="token punctuation">,</span>hidden <span class="token operator">=</span> cell<span class="token punctuation">(</span>inputs<span class="token punctuation">,</span>hidden<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'outputs size:'</span><span class="token punctuation">,</span>out<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Output:"</span><span class="token punctuation">,</span>out<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Hidden size:'</span><span class="token punctuation">,</span>hidden<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Hidden"</span><span class="token punctuation">,</span>hidden<span class="token punctuation">)</span></code></pre><p>RNN类的其他参数，例如batch_first = true，可以设置batch_size在第一个维度，将它和第一个维度进行交换。这样方便在输出时再接一层线性层。这样设置后注意要把输入的维度进行转置以适应改变。</p><h3 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h3><p>我们的目标是训练一个循环神经网络来适应一个序列变化规律，例如把hello变成ohlol。</p><img src="/2021/05/13/pytorch-jiao-xue-ji-shi-li/31.png" class=""><p>首先，把字符进行向量化。在做自然语言处理时要把字符构造成词典，把每一个分配索引。 </p><img src="/2021/05/13/pytorch-jiao-xue-ji-shi-li/32.png" class=""><p>分配索引后，每一个字母都可以用一个one-hot向量代表，词典中有几个字母这个向量就有几个元素（这里是四个），然后把这个one-hot向量作为输入input。hello有五个字母，输入序列长度是5。因此输出也是一个四维的one-hot向量。这个向量可以接交叉熵来进行分类。</p><img src="/2021/05/13/pytorch-jiao-xue-ji-shi-li/33.png" class=""><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> torchinput_size <span class="token operator">=</span> <span class="token number">4</span>hidden_size <span class="token operator">=</span> <span class="token number">4</span>batch_size <span class="token operator">=</span> <span class="token number">1</span><span class="token comment" spellcheck="true">#准备数据</span>idx2char <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'e'</span><span class="token punctuation">,</span><span class="token string">'h'</span><span class="token punctuation">,</span><span class="token string">'l'</span><span class="token punctuation">,</span><span class="token string">'o'</span><span class="token punctuation">]</span>x_data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span>y_data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token comment" spellcheck="true">#查询one-hot向量</span>one_hot_lookup <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                 <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                 <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                 <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token comment" spellcheck="true">#根据数据构建one-hot向量组</span>x_one_hot <span class="token operator">=</span> <span class="token punctuation">[</span>one_hot_lookup<span class="token punctuation">[</span>x<span class="token punctuation">]</span> <span class="token keyword">for</span> x <span class="token keyword">in</span> x_data<span class="token punctuation">]</span>inputs <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span>x_one_hot<span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span>batch_size<span class="token punctuation">,</span>input_size<span class="token punctuation">)</span><span class="token comment" spellcheck="true">#在直接输入的是标签而非one-hot向量时要用LongTensor否则出错</span>labels <span class="token operator">=</span> torch<span class="token punctuation">.</span>LongTensor<span class="token punctuation">(</span>y_data<span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">Model</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>input_size<span class="token punctuation">,</span>hidden_size<span class="token punctuation">,</span>batch_size<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>Model<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>batch_size <span class="token operator">=</span> batch_size        self<span class="token punctuation">.</span>input_size <span class="token operator">=</span> input_size        self<span class="token punctuation">.</span>hidden_size <span class="token operator">=</span> hidden_size        self<span class="token punctuation">.</span>rnncell <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>RNNCell<span class="token punctuation">(</span>input_size<span class="token operator">=</span>self<span class="token punctuation">.</span>input_size<span class="token punctuation">,</span>hidden_size <span class="token operator">=</span> self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> inputs<span class="token punctuation">,</span>hidden<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true">#注意这只做了一个RNNCell，输入注意是batchSize*inputSize，输出batch_size*hiddenSize</span>        hidden <span class="token operator">=</span> self<span class="token punctuation">.</span>rnncell<span class="token punctuation">(</span>inputs<span class="token punctuation">,</span>hidden<span class="token punctuation">)</span>        <span class="token keyword">return</span> hidden    <span class="token comment" spellcheck="true">#这个函数用来生成默认的h0</span>    <span class="token keyword">def</span> <span class="token function">init_hidden</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>self<span class="token punctuation">.</span>batch_size<span class="token punctuation">,</span>self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">)</span>net <span class="token operator">=</span> Model<span class="token punctuation">(</span>input_size<span class="token punctuation">,</span>hidden_size<span class="token punctuation">,</span>batch_size<span class="token punctuation">)</span>criterion <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#这里用的是改进的随机梯度下降的优化器</span>optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>lr <span class="token operator">=</span> <span class="token number">0.1</span><span class="token punctuation">)</span><span class="token keyword">for</span> epoch <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">15</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    loss <span class="token operator">=</span> <span class="token number">0</span>    optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>    hidden <span class="token operator">=</span> net<span class="token punctuation">.</span>init_hidden<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Predicted string:'</span><span class="token punctuation">,</span>end<span class="token operator">=</span><span class="token string">""</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> inputs<span class="token punctuation">,</span>label <span class="token keyword">in</span> zip<span class="token punctuation">(</span>inputs<span class="token punctuation">,</span>labels<span class="token punctuation">)</span><span class="token punctuation">:</span>        hidden <span class="token operator">=</span> net<span class="token punctuation">(</span>inputs<span class="token punctuation">,</span>hidden<span class="token punctuation">)</span>        loss <span class="token operator">+=</span> criterion<span class="token punctuation">(</span>hidden<span class="token punctuation">,</span>label<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">#这里用max函数找输出节点中的最大值（即输出矩阵中每一行的最大值dim=1），列是batch_size，此处仅有一行</span>        <span class="token comment" spellcheck="true">#返回该值和对应下标的列表，此处列表元素只有一个</span>        _<span class="token punctuation">,</span>idx <span class="token operator">=</span> hidden<span class="token punctuation">.</span>max<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span>idx2char<span class="token punctuation">[</span>idx<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span>end <span class="token operator">=</span> <span class="token string">""</span><span class="token punctuation">)</span>    loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>    optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">',Epoch [%d/15] loss=%.4f'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>epoch<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><p>如果不用RNNCell，而是用RNN程序会简洁很多：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> torchinput_size <span class="token operator">=</span> <span class="token number">4</span>hidden_size <span class="token operator">=</span> <span class="token number">4</span>batch_size <span class="token operator">=</span> <span class="token number">1</span><span class="token comment" spellcheck="true">#准备数据</span>idx2char <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'e'</span><span class="token punctuation">,</span><span class="token string">'h'</span><span class="token punctuation">,</span><span class="token string">'l'</span><span class="token punctuation">,</span><span class="token string">'o'</span><span class="token punctuation">]</span>x_data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span>y_data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token comment" spellcheck="true">#查询one-hot向量</span>one_hot_lookup <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                 <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                 <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                 <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token comment" spellcheck="true">#根据数据构建one-hot向量组</span>x_one_hot <span class="token operator">=</span> <span class="token punctuation">[</span>one_hot_lookup<span class="token punctuation">[</span>x<span class="token punctuation">]</span> <span class="token keyword">for</span> x <span class="token keyword">in</span> x_data<span class="token punctuation">]</span>inputs <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span>x_one_hot<span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span>batch_size<span class="token punctuation">,</span>input_size<span class="token punctuation">)</span><span class="token comment" spellcheck="true">#输出直接用一维的，因为后面已经将维度合并</span>labels <span class="token operator">=</span> torch<span class="token punctuation">.</span>LongTensor<span class="token punctuation">(</span>y_data<span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">Model</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>input_size<span class="token punctuation">,</span>hidden_size<span class="token punctuation">,</span>batch_size<span class="token punctuation">,</span>num_layers <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>Model<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>num_layers <span class="token operator">=</span> num_layers        self<span class="token punctuation">.</span>batch_size <span class="token operator">=</span> batch_size        self<span class="token punctuation">.</span>input_size <span class="token operator">=</span> input_size        self<span class="token punctuation">.</span>hidden_size <span class="token operator">=</span> hidden_size        self<span class="token punctuation">.</span>rnn <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>RNN<span class="token punctuation">(</span>input_size<span class="token operator">=</span>self<span class="token punctuation">.</span>input_size<span class="token punctuation">,</span>hidden_size <span class="token operator">=</span> self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">,</span>num_layers<span class="token operator">=</span>self<span class="token punctuation">.</span>num_layers<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> inputs<span class="token punctuation">)</span><span class="token punctuation">:</span>        hidden <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>self<span class="token punctuation">.</span>num_layers<span class="token punctuation">,</span>self<span class="token punctuation">.</span>batch_size<span class="token punctuation">,</span>self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">#我们要的是整个序列的输出，而不是最后的输出</span>        out<span class="token punctuation">,</span>_ <span class="token operator">=</span> self<span class="token punctuation">.</span>rnn<span class="token punctuation">(</span>inputs<span class="token punctuation">,</span>hidden<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">#batch_size=1，因此用二维即可，好处是用交叉熵方便，输出标签直接是一维的即可</span>        <span class="token keyword">return</span> out<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span>self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">)</span>net <span class="token operator">=</span> Model<span class="token punctuation">(</span>input_size<span class="token punctuation">,</span>hidden_size<span class="token punctuation">,</span>batch_size<span class="token punctuation">)</span>criterion <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>lr <span class="token operator">=</span> <span class="token number">0.05</span><span class="token punctuation">)</span><span class="token keyword">for</span> epoch <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">15</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>    outputs <span class="token operator">=</span> net<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>    loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span>labels<span class="token punctuation">)</span>    loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>    optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>    _<span class="token punctuation">,</span>idx <span class="token operator">=</span> outputs<span class="token punctuation">.</span>max<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#变成numpy数组</span>    idx <span class="token operator">=</span> idx<span class="token punctuation">.</span>data<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#join把列表中的元素练成一个</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>   <span class="token string">'Predicted string:'</span><span class="token punctuation">,</span><span class="token string">''</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token punctuation">[</span>idx2char<span class="token punctuation">[</span>x<span class="token punctuation">]</span> <span class="token keyword">for</span> x <span class="token keyword">in</span> idx<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>end <span class="token operator">=</span> <span class="token string">""</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">',Epoch [%d/15] loss=%.4f'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>epoch<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><p>One-hot编码的缺点：维度太高，一旦种类过多将很难训练。且向量过于稀疏，只有一个元素是1。而且是硬编码的，哪个字符对应的编码固定，不是学习出来的。</p><p>因此我们考虑的改进方向是：低维、稠密、可学习。一个流行的方法是<strong>嵌入层</strong>（EMBEDDING）。意思是把高维稀疏的样本映射到低维稠密的空间中中，这就是<strong>数据降维</strong>。</p><img src="/2021/05/13/pytorch-jiao-xue-ji-shi-li/34.png" class=""><p>嵌入层可以把数据降维，也可以升维。上图是一个升维的例子，行数是原来的one-hot向量的维度，列数是转换的新的向量的向量的维度，生成这个矩阵W后，只需要进行查询，one-hot向量哪个元素为1把对应行向量取出来即可，设one-hot向量为A，转换之后向量为E，转换公式为：<br>$$<br>E = W^TA<br>$$<br>这样即可升维或降维。</p><p>进行降维后，模型改变如下：</p><img src="/2021/05/13/pytorch-jiao-xue-ji-shi-li/35.png" class=""><p>模型在输入x的上方加入一个嵌入层进行降维，有时候需要在序列中的每一个输出后面加一个线性层，这是因为输出的维度不一定和分类数量一致，我们可以将输出的维度放大一些增强拟合能力，然后用线性层进行转换，变成分类的维度。需要注意的是Embed的输入层必须是LongTensor类型。</p><p>embedding的初始化：</p><img src="/2021/05/13/pytorch-jiao-xue-ji-shi-li/36.png" class=""><p>其中前两个参数是必须的，构成转换矩阵的高度和宽度。输出会在原来的Tensor的维度上加上一维表示embedding_dim。</p><p>线性层可以是任意维度，输出的维度和输入维度一致，除了最后一个维度之外输出和输入每个维度的元素个数一致。交叉熵的计算同理。</p><p><strong>模型程序：</strong></p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> torchnum_class <span class="token operator">=</span> <span class="token number">4</span>input_size <span class="token operator">=</span> <span class="token number">4</span>hidden_size <span class="token operator">=</span> <span class="token number">8</span>embedding_size <span class="token operator">=</span> <span class="token number">10</span><span class="token comment" spellcheck="true">#这里用了两层RNN</span>num_layers <span class="token operator">=</span> <span class="token number">2</span>batch_size <span class="token operator">=</span> <span class="token number">1</span>seq_len <span class="token operator">=</span> <span class="token number">5</span><span class="token comment" spellcheck="true">#准备数据</span>idx2char <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'e'</span><span class="token punctuation">,</span><span class="token string">'h'</span><span class="token punctuation">,</span><span class="token string">'l'</span><span class="token punctuation">,</span><span class="token string">'o'</span><span class="token punctuation">]</span><span class="token comment" spellcheck="true">#注意x需要变成二维即（batch,seq_len）</span>x_data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token comment" spellcheck="true">#y是一维的即 batch*seq_len</span>y_data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token comment" spellcheck="true">#embedding输入长整形，直接是下标的Tensor即可，自动转换成one-hot</span>inputs <span class="token operator">=</span> torch<span class="token punctuation">.</span>LongTensor<span class="token punctuation">(</span>x_data<span class="token punctuation">)</span>labels <span class="token operator">=</span> torch<span class="token punctuation">.</span>LongTensor<span class="token punctuation">(</span>y_data<span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">Model</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>Model<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>emb <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>input_size<span class="token punctuation">,</span>embedding_size<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">#这里既然把batch放在第一个，后面就需要按照这个顺序排列</span>        self<span class="token punctuation">.</span>rnn <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>RNN<span class="token punctuation">(</span>input_size <span class="token operator">=</span> embedding_size<span class="token punctuation">,</span> hidden_size <span class="token operator">=</span> hidden_size<span class="token punctuation">,</span>num_layers <span class="token operator">=</span> num_layers<span class="token punctuation">,</span>batch_first<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>fc <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_size<span class="token punctuation">,</span>num_class<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        hidden <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>num_layers<span class="token punctuation">,</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>hidden_size<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>emb<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x<span class="token punctuation">,</span>_ <span class="token operator">=</span> self<span class="token punctuation">.</span>rnn<span class="token punctuation">(</span>x<span class="token punctuation">,</span>hidden<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>fc<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span>num_class<span class="token punctuation">)</span>net <span class="token operator">=</span> Model<span class="token punctuation">(</span><span class="token punctuation">)</span>criterion <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>lr <span class="token operator">=</span> <span class="token number">0.05</span><span class="token punctuation">)</span><span class="token keyword">for</span> epoch <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">15</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>    outputs <span class="token operator">=</span> net<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>    loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span>labels<span class="token punctuation">)</span>    loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>    optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>    _<span class="token punctuation">,</span>idx <span class="token operator">=</span> outputs<span class="token punctuation">.</span>max<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#变成numpy数组</span>    idx <span class="token operator">=</span> idx<span class="token punctuation">.</span>data<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#join把列表中的元素练成一个</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>   <span class="token string">'Predicted string:'</span><span class="token punctuation">,</span><span class="token string">''</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token punctuation">[</span>idx2char<span class="token punctuation">[</span>x<span class="token punctuation">]</span> <span class="token keyword">for</span> x <span class="token keyword">in</span> idx<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>end <span class="token operator">=</span> <span class="token string">""</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">',Epoch [%d/15] loss=%.4f'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>epoch<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><p>因为输入的维数较低，所以可以从四维升到十维，这个嵌入层可以调节的，避免了硬编码，梯度下降可以寻找适合的嵌入层参数。输入嵌入层的数据是二维batch_size * seq_len的，输出是三维的 batch_size * seq_len * embedding ，这是由于x中的每一个数都变成了一个10维向量。batch_first=true的变化是inputs和outputs都把batch_size放在第一个维度。注意RNN的序列输出是三维的，model中直接强制变成两位，是因为labels只有一维，只有一个样本，这样就可以做交叉熵，如果有多个batch，则需要labels有二维，输出outputs三维。</p><h3 id="使用LSTM"><a href="#使用LSTM" class="headerlink" title="使用LSTM"></a>使用LSTM</h3><p>LSTM是RNN的变种，该算法运算复杂复杂度高，运算时间长，但效果比RNN好得多。由于独特的设计结构，LSTM适合于处理和预测<a href="https://baike.baidu.com/item/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97">时间序列</a>中间隔和延迟非常长的重要事件。</p><p><a href="https://www.jianshu.com/p/4b4701beba92">https://www.jianshu.com/p/4b4701beba92</a></p><h3 id="使用GRU"><a href="#使用GRU" class="headerlink" title="使用GRU"></a>使用GRU</h3><p>GRU是一种基于LSTM和RNN之间的算法，是折中的方案。是LSTM网络的一种效果很好的变体，它较LSTM网络的结构更加简单，而且效果也很好，因此也是当前非常流形的一种网络。GRU既然是LSTM的变体，因此也是可以解决RNN网络中的长依赖问题。</p><p><a href="https://zhuanlan.zhihu.com/p/32481747">https://zhuanlan.zhihu.com/p/32481747</a></p><h2 id="循环神经网络（高级篇）"><a href="#循环神经网络（高级篇）" class="headerlink" title="循环神经网络（高级篇）"></a>循环神经网络（高级篇）</h2><p>现在我们需要做一个名字分类，通过人的名字来分辨具体的国别。</p><img src="/2021/05/13/pytorch-jiao-xue-ji-shi-li/37.png" class=""><p>网络的结构可以变成如上图所示，我们只需要在最后输出一个国别的分类即可，中间的RNNCell的输出不做要求也无法做要求。<strong>这就是处理自然语言的一个方法。</strong></p><img src="/2021/05/13/pytorch-jiao-xue-ji-shi-li/38.png" class=""><p>中间我们使用更为优秀的GRU来代替传统的RNN。另外每个人的名字也是长度不一的，我们要根据不同长度进行不同处理。首先是分隔字符，我们要将名字分割成一个个字符做成列表，然后制作词典，我们可以用ASCII码表来作为它的词典，这个词典共128个字符，然后查找每个字符对应的ASCII值来拼成对应的Tensor。刚好Embedding层输入需要的是LongTensor而不是one-hot向量，所以这个可以直接作为输入。然后由于每个人们字符串长度不一，我们统一把它们用零填充成最长字符的长度，这样就可以统一处理了。然后再把分类的国家做成一个词典。</p><img src="/2021/05/13/pytorch-jiao-xue-ji-shi-li/39.png" class=""><img src="/2021/05/13/pytorch-jiao-xue-ji-shi-li/40.png" class=""><p><strong>什么是双向循环神经网络</strong></p><p>在以往RNN中，后面hidden的输出只包含前面输入的信息，而前面的输出不包含后面的信息。但是在自然语言处理中我们也要考虑后面输入的信息，因为后面将要输入的信息也会对前面造成影响，因此我们需要反向再做一次RNN，然后把它们拼接在一起，拼成一个Tensor。这就是双向循环神经网络。</p><img src="/2021/05/13/pytorch-jiao-xue-ji-shi-li/41.png" class=""><p>因此双向循环神经网络输出是最上面的序列，Tensor长度是原来hidden的两倍，而hidden的输出是$[h_N^f,h_N^b]$。同时出示的hidden也要是这个形式和长度。</p><p><strong>数据送入GRU是做的优化</strong></p><p>为了提高运行效率，后面填充的0参数是没必要参与运算的，原理是0 embedding转换成的向量都是一致的，我们把原来的输入的名字按照长度从大到小排列经过embedding以后，把0的列去掉，然后打包成一个平面，再保存一个关于每一个名字的长度信息即可。这样保存的信息大大减少，以后根据这个长度信息把数据重新拿出来即可。</p><img src="/2021/05/13/pytorch-jiao-xue-ji-shi-li/42.png" class=""><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> gzip<span class="token keyword">import</span> csv<span class="token keyword">import</span> torch<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> Dataset<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>rnn <span class="token keyword">import</span> pack_padded_sequence<span class="token keyword">import</span> time<span class="token keyword">import</span> mathHIDDEN_SIZE <span class="token operator">=</span> <span class="token number">100</span>BATCH_SIZE <span class="token operator">=</span> <span class="token number">256</span>N_LAYER <span class="token operator">=</span> <span class="token number">2</span>N_EPOCHS <span class="token operator">=</span> <span class="token number">100</span>N_CHARS <span class="token operator">=</span> <span class="token number">128</span>USE_GPU <span class="token operator">=</span> <span class="token boolean">True</span><span class="token comment" spellcheck="true"># 数据处理，处理后是未经数据化的和排序的人名，经过数据化按人名对应顺序的的国家</span><span class="token keyword">class</span> <span class="token class-name">NameDataset</span><span class="token punctuation">(</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> is_train_set<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        filename <span class="token operator">=</span> <span class="token string">'names_train.csv.gz'</span> <span class="token keyword">if</span> is_train_set <span class="token keyword">else</span> <span class="token string">'names_test.csv.gz'</span>        <span class="token comment" spellcheck="true"># 读zip文件的方法</span>        <span class="token keyword">with</span> gzip<span class="token punctuation">.</span>open<span class="token punctuation">(</span>filename<span class="token punctuation">,</span> <span class="token string">'rt'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>            <span class="token comment" spellcheck="true"># csv文件的读取的方法</span>            reader <span class="token operator">=</span> csv<span class="token punctuation">.</span>reader<span class="token punctuation">(</span>f<span class="token punctuation">)</span>            <span class="token comment" spellcheck="true"># csv文件读成一个列表</span>            rows <span class="token operator">=</span> list<span class="token punctuation">(</span>reader<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>names <span class="token operator">=</span> <span class="token punctuation">[</span>row<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token keyword">for</span> row <span class="token keyword">in</span> rows<span class="token punctuation">]</span>        self<span class="token punctuation">.</span>len <span class="token operator">=</span> len<span class="token punctuation">(</span>self<span class="token punctuation">.</span>names<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>countries <span class="token operator">=</span> <span class="token punctuation">[</span>row<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token keyword">for</span> row <span class="token keyword">in</span> rows<span class="token punctuation">]</span>        <span class="token comment" spellcheck="true"># set把列表取除重复的元素，sorted进行排序，赋给新的变量</span>        self<span class="token punctuation">.</span>country_list <span class="token operator">=</span> list<span class="token punctuation">(</span>sorted<span class="token punctuation">(</span>set<span class="token punctuation">(</span>self<span class="token punctuation">.</span>countries<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 把上面的列表转换成词典，__getitem__提供索引访问</span>        self<span class="token punctuation">.</span>country_dict <span class="token operator">=</span> self<span class="token punctuation">.</span>getCountryDict<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>country_num <span class="token operator">=</span> len<span class="token punctuation">(</span>self<span class="token punctuation">.</span>country_list<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> index<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># 注意这里是怎么把国家转换成对应索引的</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>names<span class="token punctuation">[</span>index<span class="token punctuation">]</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>country_dict<span class="token punctuation">[</span>self<span class="token punctuation">.</span>countries<span class="token punctuation">[</span>index<span class="token punctuation">]</span><span class="token punctuation">]</span>    <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>len    <span class="token comment" spellcheck="true">#建立一个国家的字典，国家名和数字标签对应上</span>    <span class="token keyword">def</span> <span class="token function">getCountryDict</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># 建立空字典</span>        country_dict <span class="token operator">=</span> dict<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># enumerate() 函数用于将一个可遍历的数据对象组合为一个索引序列，同时返回数据下标和数据</span>        <span class="token keyword">for</span> idx<span class="token punctuation">,</span> country_name <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>self<span class="token punctuation">.</span>country_list<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            country_dict<span class="token punctuation">[</span>country_name<span class="token punctuation">]</span> <span class="token operator">=</span> idx        <span class="token keyword">return</span> country_dict    <span class="token comment" spellcheck="true"># 通过国家名返回一个索引</span>    <span class="token keyword">def</span> <span class="token function">idx2country</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> index<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>country_list<span class="token punctuation">[</span>index<span class="token punctuation">]</span>    <span class="token comment" spellcheck="true"># 返回国家个数</span>    <span class="token keyword">def</span> <span class="token function">getCountriesNum</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>country_numtrainset <span class="token operator">=</span> NameDataset<span class="token punctuation">(</span>is_train_set<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>trainloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>trainset<span class="token punctuation">,</span>batch_size<span class="token operator">=</span>BATCH_SIZE<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>testset <span class="token operator">=</span> NameDataset<span class="token punctuation">(</span>is_train_set<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>testloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>testset<span class="token punctuation">,</span>batch_size<span class="token operator">=</span>BATCH_SIZE<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>N_COUNTRY <span class="token operator">=</span> trainset<span class="token punctuation">.</span>getCountriesNum<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 输入未经数据化的的字母名字Tensor和国家索引Tensor，输出经过转换、填充、排序处理的名字Tensor，名字长度Tensor，国家索引Tensor</span><span class="token keyword">def</span> <span class="token function">make_tensors</span><span class="token punctuation">(</span>names<span class="token punctuation">,</span> countries<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># 由一个个元组组成的列表</span>    sequences_and_lengths <span class="token operator">=</span> <span class="token punctuation">[</span>name2list<span class="token punctuation">(</span>name<span class="token punctuation">)</span> <span class="token keyword">for</span> name <span class="token keyword">in</span> names<span class="token punctuation">]</span>    <span class="token comment" spellcheck="true"># 拿出列表中每个元组的第一个元素，即名字ASCII码列表组成新的列表</span>    name_sequences <span class="token operator">=</span> <span class="token punctuation">[</span>sl<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token keyword">for</span> sl <span class="token keyword">in</span> sequences_and_lengths<span class="token punctuation">]</span>    <span class="token comment" spellcheck="true"># 拿出列表中每个元组的第二个元素，即名字长度组成新的列表,注意是LongTensor</span>    seq_lengths <span class="token operator">=</span> torch<span class="token punctuation">.</span>LongTensor<span class="token punctuation">(</span><span class="token punctuation">[</span>sl<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token keyword">for</span> sl <span class="token keyword">in</span> sequences_and_lengths<span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 转换成LongTensor</span>    countries <span class="token operator">=</span> countries<span class="token punctuation">.</span>long<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 用0填充名字到长度一致</span>    seq_tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>len<span class="token punctuation">(</span>name_sequences<span class="token punctuation">)</span><span class="token punctuation">,</span> seq_lengths<span class="token punctuation">.</span>max<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>long<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> idx<span class="token punctuation">,</span> <span class="token punctuation">(</span>seq<span class="token punctuation">,</span> seq_len<span class="token punctuation">)</span> <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>zip<span class="token punctuation">(</span>name_sequences<span class="token punctuation">,</span> seq_lengths<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        seq_tensor<span class="token punctuation">[</span>idx<span class="token punctuation">,</span> <span class="token punctuation">:</span>seq_len<span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>LongTensor<span class="token punctuation">(</span>seq<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 倒序排序，返回排序好的Tensor以及对应的排完序的索引</span>    seq_lengths<span class="token punctuation">,</span> perm_idx <span class="token operator">=</span> seq_lengths<span class="token punctuation">.</span>sort<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> descending<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 用索引对原来的名字和国家序列进行排序，排完序后名字长度就是倒序的了</span>    seq_tensor <span class="token operator">=</span> seq_tensor<span class="token punctuation">[</span>perm_idx<span class="token punctuation">]</span>    countries <span class="token operator">=</span> countries<span class="token punctuation">[</span>perm_idx<span class="token punctuation">]</span>    <span class="token comment" spellcheck="true"># seq_lengths需要放在CPU上否则报错。。</span>    <span class="token keyword">return</span> create_tensor<span class="token punctuation">(</span>seq_tensor<span class="token punctuation">)</span><span class="token punctuation">,</span> seq_lengths<span class="token punctuation">,</span> create_tensor<span class="token punctuation">(</span>countries<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 如果使用GPU就把tensor放到GPU上</span><span class="token keyword">def</span> <span class="token function">create_tensor</span><span class="token punctuation">(</span>tensor<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">if</span> USE_GPU<span class="token punctuation">:</span>        device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">"cuda:0"</span><span class="token punctuation">)</span>        tensor <span class="token operator">=</span> tensor<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>    <span class="token keyword">return</span> tensor<span class="token comment" spellcheck="true"># 把名字转换为ASCII值的列表，返回列表和列表长度的元组</span><span class="token keyword">def</span> <span class="token function">name2list</span><span class="token punctuation">(</span>name<span class="token punctuation">)</span><span class="token punctuation">:</span>    arr <span class="token operator">=</span> <span class="token punctuation">[</span>ord<span class="token punctuation">(</span>c<span class="token punctuation">)</span> <span class="token keyword">for</span> c <span class="token keyword">in</span> name<span class="token punctuation">]</span>    <span class="token keyword">return</span> arr<span class="token punctuation">,</span> len<span class="token punctuation">(</span>arr<span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">RNNClassifier</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># bidrectional选择循环神经网络单向还是双向</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">,</span> output_size<span class="token punctuation">,</span> n_layers<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> bidirectional<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>RNNClassifier<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>hidden_size <span class="token operator">=</span> hidden_size        self<span class="token punctuation">.</span>n_layers <span class="token operator">=</span> n_layers        self<span class="token punctuation">.</span>n_directions <span class="token operator">=</span> <span class="token number">2</span> <span class="token keyword">if</span> bidirectional <span class="token keyword">else</span> <span class="token number">1</span>        self<span class="token punctuation">.</span>embedding <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>input_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>gru <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>GRU<span class="token punctuation">(</span>hidden_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">,</span> n_layers<span class="token punctuation">,</span> bidirectional<span class="token operator">=</span>bidirectional<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>fc <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_size <span class="token operator">*</span> self<span class="token punctuation">.</span>n_directions<span class="token punctuation">,</span> output_size<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">_init_hidden</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> batch_size<span class="token punctuation">)</span><span class="token punctuation">:</span>        hidden <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>self<span class="token punctuation">.</span>n_layers <span class="token operator">*</span> self<span class="token punctuation">.</span>n_directions<span class="token punctuation">,</span>batch_size<span class="token punctuation">,</span>self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">)</span>        <span class="token keyword">return</span> create_tensor<span class="token punctuation">(</span>hidden<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 这里多了一个序列的长度的参数</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> inputs<span class="token punctuation">,</span> seq_lengths<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># 做矩阵的转置，把batch_size * seq_len变成seqLen * batch_size</span>        inputs <span class="token operator">=</span> inputs<span class="token punctuation">.</span>t<span class="token punctuation">(</span><span class="token punctuation">)</span>        batch_size <span class="token operator">=</span> inputs<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>        hidden <span class="token operator">=</span> self<span class="token punctuation">.</span>_init_hidden<span class="token punctuation">(</span>batch_size<span class="token punctuation">)</span>        embedding <span class="token operator">=</span> self<span class="token punctuation">.</span>embedding<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 为了提高运行效率，所做的优化，这是RNN,LSTM，GRU都能接受的输入</span>        gru_input <span class="token operator">=</span> pack_padded_sequence<span class="token punctuation">(</span>embedding<span class="token punctuation">,</span> seq_lengths<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 这里要的输出是hidden</span>        output<span class="token punctuation">,</span> hidden <span class="token operator">=</span> self<span class="token punctuation">.</span>gru<span class="token punctuation">(</span>gru_input<span class="token punctuation">,</span> hidden<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 如果是双向的，那么就需要把两个hidden连起来作为输出</span>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>n_directions <span class="token operator">==</span> <span class="token number">2</span><span class="token punctuation">:</span>            hidden_cat <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>hidden<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> hidden<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            hidden_cat <span class="token operator">=</span> hidden<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>        fc_output <span class="token operator">=</span> self<span class="token punctuation">.</span>fc<span class="token punctuation">(</span>hidden_cat<span class="token punctuation">)</span>        <span class="token keyword">return</span> fc_output<span class="token keyword">def</span> <span class="token function">trainModel</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    total_loss <span class="token operator">=</span> <span class="token number">0</span>    <span class="token keyword">for</span> i<span class="token punctuation">,</span> <span class="token punctuation">(</span>names<span class="token punctuation">,</span> countries<span class="token punctuation">)</span> <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>trainloader<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        inputs<span class="token punctuation">,</span> seq_lengths<span class="token punctuation">,</span> target <span class="token operator">=</span> make_tensors<span class="token punctuation">(</span>names<span class="token punctuation">,</span> countries<span class="token punctuation">)</span>        output <span class="token operator">=</span> classifier<span class="token punctuation">(</span>inputs<span class="token punctuation">,</span> seq_lengths<span class="token punctuation">)</span>        loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>output<span class="token punctuation">,</span> target<span class="token punctuation">)</span>        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>        total_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> i <span class="token operator">%</span> <span class="token number">10</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>            <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">'[{time_since(start)}] Epoch {epoch} '</span><span class="token punctuation">,</span> end<span class="token operator">=</span><span class="token string">''</span><span class="token punctuation">)</span>            <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">'[{i * len(inputs)}/{len(trainset)}]'</span><span class="token punctuation">,</span> end<span class="token operator">=</span><span class="token string">''</span><span class="token punctuation">)</span>            <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">'loss = {total_loss / (i * len(inputs))}'</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> total_loss<span class="token keyword">def</span> <span class="token function">testModel</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    correct <span class="token operator">=</span> <span class="token number">0</span>    total <span class="token operator">=</span> len<span class="token punctuation">(</span>testset<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"evaluating trained model ..."</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 不求梯度</span>    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">for</span> i<span class="token punctuation">,</span> <span class="token punctuation">(</span>names<span class="token punctuation">,</span> countries<span class="token punctuation">)</span> <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>testloader<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            inputs<span class="token punctuation">,</span> seq_lengths<span class="token punctuation">,</span> target <span class="token operator">=</span> make_tensors<span class="token punctuation">(</span>names<span class="token punctuation">,</span> countries<span class="token punctuation">)</span>            output <span class="token operator">=</span> classifier<span class="token punctuation">(</span>inputs<span class="token punctuation">,</span> seq_lengths<span class="token punctuation">)</span>            <span class="token comment" spellcheck="true"># 输出最大值节点的索引是分类国家的索引，keepdim保持原有的维度不变</span>            <span class="token comment" spellcheck="true"># 最后有个[1]是因为返回值实际上有两个tansor，第一个存储是值，第二个存储索引，我们只需要索引</span>            pred <span class="token operator">=</span> output<span class="token punctuation">.</span>max<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> keepdim<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>            <span class="token comment" spellcheck="true"># view_as把Tensor转变成对应Tensor的形式</span>            <span class="token comment" spellcheck="true"># eq看两个Tensor对应的位置是否相当，返回相同形式的Tensor，对应位置相同为True,不相同为FALSE</span>            correct <span class="token operator">+=</span> pred<span class="token punctuation">.</span>eq<span class="token punctuation">(</span>target<span class="token punctuation">.</span>view_as<span class="token punctuation">(</span>pred<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>        percent <span class="token operator">=</span> <span class="token string">'%.2f'</span> <span class="token operator">%</span> <span class="token punctuation">(</span><span class="token number">100</span> <span class="token operator">*</span> correct <span class="token operator">/</span> total<span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">'Test set: Accuracy {correct}/{total} {percent}%'</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> correct <span class="token operator">/</span> total<span class="token comment" spellcheck="true"># 计算训练时长</span><span class="token keyword">def</span> <span class="token function">time_since</span><span class="token punctuation">(</span>since<span class="token punctuation">)</span><span class="token punctuation">:</span>    s <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> since    m <span class="token operator">=</span> math<span class="token punctuation">.</span>floor<span class="token punctuation">(</span>s <span class="token operator">/</span> <span class="token number">60</span><span class="token punctuation">)</span>    s <span class="token operator">-=</span> m <span class="token operator">*</span> <span class="token number">60</span>    <span class="token keyword">return</span> <span class="token string">'%dm %ds'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>m<span class="token punctuation">,</span> s<span class="token punctuation">)</span><span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># N_CHARS是输入字符的长度，N_CHARS是GRU输出隐藏的维度，N_COUNTRY是具体国家的分类数，N_LAYER是GRU的层数</span>    classifier <span class="token operator">=</span> RNNClassifier<span class="token punctuation">(</span>N_CHARS<span class="token punctuation">,</span> HIDDEN_SIZE<span class="token punctuation">,</span> N_COUNTRY<span class="token punctuation">,</span> N_LAYER<span class="token punctuation">)</span>    <span class="token keyword">if</span> USE_GPU<span class="token punctuation">:</span>        device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">"cuda:0"</span><span class="token punctuation">)</span>        classifier<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>    criterion <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>    optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>classifier<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 记录开始训练的时间</span>    start <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Train for %d epochs..."</span> <span class="token operator">%</span> N_EPOCHS<span class="token punctuation">)</span>    acc_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token keyword">for</span> epoch <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> N_EPOCHS <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        trainModel<span class="token punctuation">(</span><span class="token punctuation">)</span>        acc <span class="token operator">=</span> testModel<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 把准确率记录到列表中</span>        acc_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>acc<span class="token punctuation">)</span></code></pre><p>如果需要绘制Loss变化曲线，需要加上以下代码：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token comment" spellcheck="true"># arange第一个参数是起点，第二个是重点，第三个是步长</span>epoch <span class="token operator">=</span> np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>len<span class="token punctuation">(</span>acc_list<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>acc_list <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>acc_list<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>epoch<span class="token punctuation">,</span>acc_list<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">"Epoch"</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'Accuracy'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>grid<span class="token punctuation">(</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><p>注意：模型的输入为（seqLen，batchSize），Embedding的输出为（seqLen，batchSize，hiddenSize）同时也是GRU的输入，GRU的输入输出都和原始RNN相同。</p><p>如果训练准确度是最高的，我们需要保存模型，可以用</p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#保存</span>torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>model<span class="token punctuation">,</span>PATH<span class="token punctuation">)</span><span class="token comment" spellcheck="true">#载入</span>model <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>PATH<span class="token punctuation">)</span></code></pre><h3 id="拓展"><a href="#拓展" class="headerlink" title="拓展"></a>拓展</h3><p>Kaggle上一个数据集：<a href="https://www.kaggle.com/c/setiment-analysis-on-movie-reviews/data">https://www.kaggle.com/c/setiment-analysis-on-movie-reviews/data</a></p><p>这个数据集的训练任务是根据电影评论的文本判断用户对电影的态度。</p><p>当掌握了RNN后，我们可以用RNN做很多不同的语言模型，例如作诗的神经网络，只需要输入第一个字，就能自动做出一首诗。</p><p>我们首先先做一个关于汉字的词典，还要加一个休止符，这个符号代表诗已经作完了。首先需要大量的诗句进行训练，前面的字作为RNNCell输入，输出必须是下一个字，然后把下一个字再送进RNNCell中反复循环，以此类推。因此，<strong>只要有足够的数据，我们就能做各种文本的生成器。</strong></p><h2 id="关于手写数字集识别的究极完整版"><a href="#关于手写数字集识别的究极完整版" class="headerlink" title="关于手写数字集识别的究极完整版"></a>关于手写数字集识别的究极完整版</h2><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> Dataset<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> scipy<span class="token punctuation">.</span>ndimage<span class="token keyword">import</span> time<span class="token keyword">import</span> math<span class="token keyword">import</span> csv<span class="token keyword">import</span> os<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> pltbatch_size <span class="token operator">=</span> <span class="token number">64</span><span class="token keyword">class</span> <span class="token class-name">DiabetesDataset</span><span class="token punctuation">(</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> filepath<span class="token punctuation">,</span>UseRotation <span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        xy <span class="token operator">=</span> np<span class="token punctuation">.</span>loadtxt<span class="token punctuation">(</span>filepath<span class="token punctuation">,</span> delimiter<span class="token operator">=</span><span class="token string">','</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">#self.len = xy.shape[0]</span>        self<span class="token punctuation">.</span>x_data <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>xy<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> UseRotation<span class="token punctuation">:</span>            <span class="token comment" spellcheck="true">#加上左右旋转10度的图片数据</span>            self<span class="token punctuation">.</span>x_data_plus10 <span class="token operator">=</span> self<span class="token punctuation">.</span>x_data            <span class="token keyword">for</span> i<span class="token punctuation">,</span> x <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>self<span class="token punctuation">.</span>x_data_plus10<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                x1 <span class="token operator">=</span> scipy<span class="token punctuation">.</span>ndimage<span class="token punctuation">.</span>interpolation<span class="token punctuation">.</span>rotate<span class="token punctuation">(</span>x<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> cval<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">,</span>                                                        reshape<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">784</span><span class="token punctuation">)</span>                self<span class="token punctuation">.</span>x_data_plus10<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>x1<span class="token punctuation">)</span>            self<span class="token punctuation">.</span>x_data_minus10 <span class="token operator">=</span> self<span class="token punctuation">.</span>x_data            <span class="token keyword">for</span> i<span class="token punctuation">,</span> x <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>self<span class="token punctuation">.</span>x_data_minus10<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                x1 <span class="token operator">=</span> scipy<span class="token punctuation">.</span>ndimage<span class="token punctuation">.</span>interpolation<span class="token punctuation">.</span>rotate<span class="token punctuation">(</span>x<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">10</span><span class="token punctuation">,</span> cval<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">,</span>                                                        reshape<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">784</span><span class="token punctuation">)</span>                self<span class="token punctuation">.</span>x_data_minus10<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>x1<span class="token punctuation">)</span>            self<span class="token punctuation">.</span>x_data <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>self<span class="token punctuation">.</span>x_data<span class="token punctuation">,</span> self<span class="token punctuation">.</span>x_data_plus10<span class="token punctuation">,</span> self<span class="token punctuation">.</span>x_data_minus10<span class="token punctuation">]</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>x_data <span class="token operator">=</span> <span class="token punctuation">(</span>self<span class="token punctuation">.</span>x_data<span class="token operator">/</span><span class="token number">255</span> <span class="token operator">-</span> <span class="token number">0.1307</span><span class="token punctuation">)</span><span class="token operator">/</span><span class="token number">0.3081</span>    <span class="token comment" spellcheck="true">#映射到（0，1）分布，很多时候可以加快收敛速度（玄学）</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"x_data.shape = "</span><span class="token punctuation">,</span>self<span class="token punctuation">.</span>x_data<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>x_data <span class="token operator">=</span> self<span class="token punctuation">.</span>x_data<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">28</span><span class="token punctuation">,</span><span class="token number">28</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true">#如果使用CNN需要加上这一句</span>        self<span class="token punctuation">.</span>y_data <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>xy<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>y_data <span class="token operator">=</span> self<span class="token punctuation">.</span>y_data<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>long<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> UseRotation<span class="token punctuation">:</span>            self<span class="token punctuation">.</span>y_data <span class="token operator">=</span> torch<span class="token punctuation">.</span>tile<span class="token punctuation">(</span>self<span class="token punctuation">.</span>y_data<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"y_data.shape = "</span><span class="token punctuation">,</span>self<span class="token punctuation">.</span>y_data<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> index<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>x_data<span class="token punctuation">[</span>index<span class="token punctuation">]</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>y_data<span class="token punctuation">[</span>index<span class="token punctuation">]</span>    <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> len<span class="token punctuation">(</span>self<span class="token punctuation">.</span>x_data<span class="token punctuation">)</span>train_dataset <span class="token operator">=</span> DiabetesDataset<span class="token punctuation">(</span><span class="token string">'mnist_train.csv'</span><span class="token punctuation">,</span>UseRotation<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>train_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token operator">=</span>train_dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>test_dataset <span class="token operator">=</span> DiabetesDataset<span class="token punctuation">(</span><span class="token string">'mnist_test.csv'</span><span class="token punctuation">)</span>test_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token operator">=</span>test_dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">InceptionA</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_channels<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>InceptionA<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>branch1x1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>branch5x5_1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>branch5x5_2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>branch3x3_1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>branch3x3_2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>branch3x3_3 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">24</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>branch_pool <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        branch1x1 <span class="token operator">=</span> self<span class="token punctuation">.</span>branch1x1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        branch5x5 <span class="token operator">=</span> self<span class="token punctuation">.</span>branch5x5_1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        branch5x5 <span class="token operator">=</span> self<span class="token punctuation">.</span>branch5x5_2<span class="token punctuation">(</span>branch5x5<span class="token punctuation">)</span>        branch3x3 <span class="token operator">=</span> self<span class="token punctuation">.</span>branch3x3_1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        branch3x3 <span class="token operator">=</span> self<span class="token punctuation">.</span>branch3x3_2<span class="token punctuation">(</span>branch3x3<span class="token punctuation">)</span>        branch3x3 <span class="token operator">=</span> self<span class="token punctuation">.</span>branch3x3_3<span class="token punctuation">(</span>branch3x3<span class="token punctuation">)</span>        branch_pool <span class="token operator">=</span> F<span class="token punctuation">.</span>avg_pool2d<span class="token punctuation">(</span>x<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>        branch_pool <span class="token operator">=</span> self<span class="token punctuation">.</span>branch_pool<span class="token punctuation">(</span>branch_pool<span class="token punctuation">)</span>        outputs <span class="token operator">=</span> <span class="token punctuation">[</span>branch1x1<span class="token punctuation">,</span> branch5x5<span class="token punctuation">,</span> branch3x3<span class="token punctuation">,</span> branch_pool<span class="token punctuation">]</span>        <span class="token keyword">return</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">ResidualBlock</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> channels<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>ResidualBlock<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>channels <span class="token operator">=</span> channels        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>channels<span class="token punctuation">,</span> channels<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>channels<span class="token punctuation">,</span> channels<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        y <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>        y <span class="token operator">=</span> self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>y<span class="token punctuation">)</span>        <span class="token keyword">return</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>x <span class="token operator">+</span> y<span class="token punctuation">)</span><span class="token comment" spellcheck="true">#全连接网络</span><span class="token keyword">class</span> <span class="token class-name">Net</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>Net<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>l1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">784</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>l2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>l3 <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>l4 <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>l5 <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>sigmoid <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">784</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>l1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>l2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>l3<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>l4<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>l5<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token comment" spellcheck="true">#卷积神经网络</span><span class="token keyword">class</span> <span class="token class-name">Net2</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>Net2<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>pooling <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>l1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">320</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>l2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>l3 <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>l4 <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true">#这里拿出第1维的个数即(n,1,28,28)中的第一个元素，是样本一个batch的样本个数</span>        <span class="token comment" spellcheck="true">#注意输入数据是四维的</span>        batch_size <span class="token operator">=</span> x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>pooling<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>pooling<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">#把它变成全连接网络batch * 320</span>        x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>l1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>l2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>l3<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>l4<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> x<span class="token comment" spellcheck="true">#inception网络</span><span class="token keyword">class</span> <span class="token class-name">Net3</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>Net3<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">88</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>incep1 <span class="token operator">=</span> InceptionA<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>incep2 <span class="token operator">=</span> InceptionA<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>mp <span class="token operator">=</span> nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>fc <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">1408</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>l1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">1408</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>l2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>l3 <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>l4 <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        in_size <span class="token operator">=</span> x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 变成10*12*12</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>mp<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 变成88*12*12</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>incep1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 变成20*4*4</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>mp<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 变成88*4*4</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>incep2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 展开成全连接层</span>        x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span>in_size<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>l1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>l2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>l3<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>l4<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> x<span class="token comment" spellcheck="true">#深度残差网络（ResNet）(四个网络中效果最好)</span><span class="token keyword">class</span> <span class="token class-name">Net4</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>Net4<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>rblock1 <span class="token operator">=</span> ResidualBlock<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>rblock2 <span class="token operator">=</span> ResidualBlock<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>mp <span class="token operator">=</span> nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>l1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">#self.l2 = torch.nn.Linear(256, 128)</span>        <span class="token comment" spellcheck="true">#self.l3 = torch.nn.Linear(128, 64)</span>        <span class="token comment" spellcheck="true">#self.l4 = torch.nn.Linear(64, 10)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        in_size <span class="token operator">=</span> x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 变成16*12*12</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>mp<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 变成16*12*12</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>rblock1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 变成32*4*4</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>mp<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 变成32*4*4</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>rblock2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 展开成全连接层</span>        x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span>in_size<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">#x = F.relu(self.l1(x))</span>        <span class="token comment" spellcheck="true">#x = F.relu(self.l2(x))</span>        <span class="token comment" spellcheck="true">#x = F.relu(self.l3(x))</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>l1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> xmodel <span class="token operator">=</span> Net4<span class="token punctuation">(</span><span class="token punctuation">)</span>device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">"cuda:0"</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">"cpu"</span><span class="token punctuation">)</span>model<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>criterion <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#optimizer = torch.optim.SGD(model.parameters(),lr = 0.005,momentum=0.8,nesterov=True)</span>optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>lr <span class="token operator">=</span> <span class="token number">0.00025</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">time_since</span><span class="token punctuation">(</span>since<span class="token punctuation">)</span><span class="token punctuation">:</span>    s <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> since    m <span class="token operator">=</span> math<span class="token punctuation">.</span>floor<span class="token punctuation">(</span>s <span class="token operator">/</span> <span class="token number">60</span><span class="token punctuation">)</span>    s <span class="token operator">-=</span> m <span class="token operator">*</span> <span class="token number">60</span>    <span class="token keyword">return</span> <span class="token string">'%dm %ds'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>m<span class="token punctuation">,</span> s<span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>epoch<span class="token punctuation">,</span>train_loader<span class="token punctuation">)</span><span class="token punctuation">:</span>    running_loss <span class="token operator">=</span> <span class="token number">0.0</span>    <span class="token keyword">for</span> batch_idx<span class="token punctuation">,</span> data <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>train_loader<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        inputs<span class="token punctuation">,</span> target <span class="token operator">=</span> data        inputs<span class="token punctuation">,</span> target <span class="token operator">=</span> inputs<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">,</span> target<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>        outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>        loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> target<span class="token punctuation">)</span>        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>        running_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> batch_idx <span class="token operator">%</span> <span class="token number">300</span> <span class="token operator">==</span> <span class="token number">299</span><span class="token punctuation">:</span>            <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">'[{time_since(start)}] '</span><span class="token punctuation">,</span> end<span class="token operator">=</span><span class="token string">''</span><span class="token punctuation">)</span>            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'[%d,%5d] loss: %.3f'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>epoch <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> batch_idx <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> running_loss <span class="token operator">/</span> <span class="token number">300</span><span class="token punctuation">)</span><span class="token punctuation">)</span>            running_loss <span class="token operator">=</span> <span class="token number">0</span><span class="token keyword">def</span> <span class="token function">test</span><span class="token punctuation">(</span>test_loader<span class="token punctuation">)</span><span class="token punctuation">:</span>    correct <span class="token operator">=</span> <span class="token number">0</span>    total <span class="token operator">=</span> <span class="token number">0</span>    pred <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment" spellcheck="true"># 这部分代码不会计算梯度</span>        <span class="token keyword">for</span> data <span class="token keyword">in</span> test_loader<span class="token punctuation">:</span>            images<span class="token punctuation">,</span> labels <span class="token operator">=</span> data            images<span class="token punctuation">,</span>labels <span class="token operator">=</span> images<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">,</span>labels<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>            outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>images<span class="token punctuation">)</span>            <span class="token comment" spellcheck="true"># 这里用max函数找输出节点中的最大值（即输出矩阵中每一行的最大值），返回该值和对应下标</span>            _<span class="token punctuation">,</span> predicted <span class="token operator">=</span> torch<span class="token punctuation">.</span>max<span class="token punctuation">(</span>outputs<span class="token punctuation">.</span>data<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>            <span class="token comment" spellcheck="true">#转换成列表，并入总的预测列表中</span>            pred <span class="token operator">=</span> pred <span class="token operator">+</span> predicted<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token comment" spellcheck="true"># labels.size(0)返回行数，也即是样本个数</span>            total <span class="token operator">+=</span> labels<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>            <span class="token comment" spellcheck="true"># 把两个N*1的Tensor做比较相等是1否则是0，把所有结果相加就是正确的个数</span>            correct <span class="token operator">+=</span> <span class="token punctuation">(</span>predicted <span class="token operator">==</span> labels<span class="token punctuation">)</span><span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Total:"</span><span class="token punctuation">,</span>total<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Corrcet:"</span><span class="token punctuation">,</span>correct<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Accuracy on test set: %.2f %%'</span> <span class="token operator">%</span> <span class="token punctuation">(</span><span class="token number">100</span> <span class="token operator">*</span> correct <span class="token operator">/</span> total<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> pred<span class="token punctuation">,</span><span class="token number">100</span> <span class="token operator">*</span> correct <span class="token operator">/</span> total<span class="token comment" spellcheck="true"># 保存预测数据</span><span class="token keyword">def</span> <span class="token function">save_pred</span><span class="token punctuation">(</span>preds<span class="token punctuation">,</span> file<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">''' Save predictions to specified file '''</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Saving results to {}'</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>file<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">with</span> open<span class="token punctuation">(</span>file<span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">,</span> newline<span class="token operator">=</span><span class="token string">''</span><span class="token punctuation">)</span> <span class="token keyword">as</span> fp<span class="token punctuation">:</span>        writer <span class="token operator">=</span> csv<span class="token punctuation">.</span>writer<span class="token punctuation">(</span>fp<span class="token punctuation">)</span>        writer<span class="token punctuation">.</span>writerow<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'id'</span><span class="token punctuation">,</span> <span class="token string">'tested_num'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token keyword">for</span> i<span class="token punctuation">,</span> p <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>preds<span class="token punctuation">)</span><span class="token punctuation">:</span>            writer<span class="token punctuation">.</span>writerow<span class="token punctuation">(</span><span class="token punctuation">[</span>i<span class="token punctuation">,</span> p<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#保存训练数据</span><span class="token keyword">def</span> <span class="token function">save_train_data</span><span class="token punctuation">(</span>checkpoint_PATH<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Saving training data......"</span><span class="token punctuation">)</span>    torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">'epoch'</span><span class="token punctuation">:</span> save_epoch <span class="token operator">+</span> epoch <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token string">'state_dict'</span><span class="token punctuation">:</span> model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                <span class="token string">'optimizer'</span><span class="token punctuation">:</span> optimizer<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'max_correct'</span><span class="token punctuation">:</span> max_correct<span class="token punctuation">}</span><span class="token punctuation">,</span>               checkpoint_PATH<span class="token punctuation">)</span><span class="token comment" spellcheck="true">#加载训练数据</span><span class="token keyword">def</span> <span class="token function">load_train_data</span><span class="token punctuation">(</span>checkpoint_PATH<span class="token punctuation">,</span>model<span class="token punctuation">,</span>optimizer<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'loading train data......'</span><span class="token punctuation">)</span>    <span class="token keyword">if</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>isfile<span class="token punctuation">(</span>checkpoint_PATH<span class="token punctuation">)</span><span class="token punctuation">:</span>        model_CKPT <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>checkpoint_PATH<span class="token punctuation">)</span>        model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>model_CKPT<span class="token punctuation">[</span><span class="token string">'state_dict'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        optimizer<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>model_CKPT<span class="token punctuation">[</span><span class="token string">'optimizer'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        maxCorrect <span class="token operator">=</span> model_CKPT<span class="token punctuation">[</span><span class="token string">'max_correct'</span><span class="token punctuation">]</span>        save_epoch <span class="token operator">=</span> model_CKPT<span class="token punctuation">[</span><span class="token string">'epoch'</span><span class="token punctuation">]</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Successfully Loading file,last max_correct is "</span><span class="token punctuation">,</span>maxCorrect<span class="token punctuation">,</span><span class="token string">"%"</span><span class="token punctuation">,</span><span class="token string">'total epoch is'</span><span class="token punctuation">,</span>save_epoch<span class="token punctuation">)</span>    <span class="token keyword">return</span> model<span class="token punctuation">,</span> optimizer<span class="token punctuation">,</span>maxCorrect<span class="token punctuation">,</span>save_epoch<span class="token comment" spellcheck="true"># 绘图函数</span><span class="token keyword">def</span> <span class="token function">plt</span><span class="token punctuation">(</span>train_loss_list<span class="token punctuation">,</span>test_loss_list<span class="token punctuation">)</span><span class="token punctuation">:</span>    epoch <span class="token operator">=</span> np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> len<span class="token punctuation">(</span>train_loss_list<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>    train_loss_list <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>train_loss_list<span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>epoch<span class="token punctuation">,</span> train_loss_list<span class="token punctuation">)</span>    test_loss_list <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>test_loss_list<span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>epoch<span class="token punctuation">,</span> test_loss_list<span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">"Epoch"</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'Accuracy'</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>grid<span class="token punctuation">(</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>    max_correct <span class="token operator">=</span> <span class="token number">0</span>    epochs <span class="token operator">=</span> <span class="token number">50</span>    save_epoch <span class="token operator">=</span> <span class="token number">0</span>    start <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 加载上次的训练数据</span>    model<span class="token punctuation">,</span>optimizer<span class="token punctuation">,</span>max_correct<span class="token punctuation">,</span>save_epoch <span class="token operator">=</span> load_train_data<span class="token punctuation">(</span><span class="token string">"model_AD.tar"</span><span class="token punctuation">,</span>model<span class="token punctuation">,</span>optimizer<span class="token punctuation">)</span>    <span class="token keyword">for</span> epoch <span class="token keyword">in</span> range<span class="token punctuation">(</span>epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>        train<span class="token punctuation">(</span>epoch<span class="token punctuation">,</span>train_loader<span class="token punctuation">)</span>        pred<span class="token punctuation">,</span>correct <span class="token operator">=</span> test<span class="token punctuation">(</span>test_loader<span class="token punctuation">)</span>        <span class="token keyword">if</span> correct <span class="token operator">></span> max_correct<span class="token punctuation">:</span>            max_correct <span class="token operator">=</span> correct            save_train_data<span class="token punctuation">(</span><span class="token string">"model_AD.tar"</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"The Highest correct rate: "</span><span class="token punctuation">,</span> max_correct<span class="token punctuation">,</span><span class="token string">"%"</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#载入模型</span>    model<span class="token punctuation">,</span>optimizer<span class="token punctuation">,</span>max_correct<span class="token punctuation">,</span>save_epoch <span class="token operator">=</span> load_train_data<span class="token punctuation">(</span><span class="token string">"model_AD.tar"</span><span class="token punctuation">,</span>model<span class="token punctuation">,</span>optimizer<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#制作预测文件</span>    pred<span class="token punctuation">,</span> correct <span class="token operator">=</span> test<span class="token punctuation">(</span>test_loader<span class="token punctuation">)</span>    save_pred<span class="token punctuation">(</span>pred<span class="token punctuation">,</span> <span class="token string">'pred.csv'</span><span class="token punctuation">)</span></code></pre><h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><p>至此深度学习图像识别的基础知识基本讲解完毕，本文是从实践的角度进行讲解。</p><ul><li>将来如果想更深一步，需要从理论方面着手，可以看一下深度学习的花书。或者其他理论书籍。</li><li>如果想写更加复杂网络，需要阅读pytorch文档。</li><li>复现经典工作，看经典的论文复现其中的工作，需要通读代码，从中学习写法，然后自己尝试自己去写。</li><li>选特定的研究领域大量阅读论文，看大家的设计神经网络的技巧。看多了才能有自己的创新点并避免重复工作。扩充自己的视野。解决自己知识上的盲点，并解决自己编程上的盲点。把别人的工作变成自己的知识点，形成体系。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>利用神经网络预测新冠确诊率</title>
      <link href="2021/05/11/li-yong-shen-jing-wang-luo-yu-ce-xin-guan-que-zhen-lu/"/>
      <url>2021/05/11/li-yong-shen-jing-wang-luo-yu-ce-xin-guan-que-zhen-lu/</url>
      
        <content type="html"><![CDATA[<p> 本文的数据以及程序均来源于李宏毅老师2021机器学习课程：<a href="https://www.bilibili.com/video/BV1Wv411h7kN?p=7">https://www.bilibili.com/video/BV1Wv411h7kN?p=7</a></p><p>如果看不懂代码，可以先查看我另一篇文章《Pytorch教学及示例》。<a href="https://tianjuewudi.gitee.io/">https://tianjuewudi.gitee.io/</a></p><p>首先看一下给出的数据，一个训练集covid.train.csv，一个测试集covid.test.csv。</p><img src="/2021/05/11/li-yong-shen-jing-wang-luo-yu-ce-xin-guan-que-zhen-lu/1.png" class><p>首先数据的第一列是变换，后面的四十列是state one-hot encoding，意思是只有一个值为1，其余为0。用来代表美国一个州。再往后的18列是第一天的调查数据以及确诊率，一次类推再往后的36列是第二第三天的调查数据以及确诊率。训练和测试数据集的不同在于测试集少了最后一列第三天的结果，需要自己建立神经网络去得出结果。</p><img src="/2021/05/11/li-yong-shen-jing-wang-luo-yu-ce-xin-guan-que-zhen-lu/2.png" class><h2 id="首先导入包："><a href="#首先导入包：" class="headerlink" title="首先导入包："></a><strong>首先导入包：</strong></h2><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># PyTorch</span><span class="token keyword">import</span> torch<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> Dataset<span class="token punctuation">,</span> DataLoader<span class="token comment" spellcheck="true"># For data preprocess</span><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> csv<span class="token keyword">import</span> os<span class="token comment" spellcheck="true"># For plotting</span><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt<span class="token keyword">from</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">import</span> figuremyseed <span class="token operator">=</span> <span class="token number">42069</span>  <span class="token comment" spellcheck="true"># set a random seed for reproducibility</span>torch<span class="token punctuation">.</span>backends<span class="token punctuation">.</span>cudnn<span class="token punctuation">.</span>deterministic <span class="token operator">=</span> <span class="token boolean">True</span>torch<span class="token punctuation">.</span>backends<span class="token punctuation">.</span>cudnn<span class="token punctuation">.</span>benchmark <span class="token operator">=</span> <span class="token boolean">False</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span>myseed<span class="token punctuation">)</span>torch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span>myseed<span class="token punctuation">)</span><span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>manual_seed_all<span class="token punctuation">(</span>myseed<span class="token punctuation">)</span></code></pre><p>为什么使用相同的网络结构，跑出来的效果完全不同，用的学习率，迭代次数，batch size 都是一样？固定随机数种子是非常重要的。但是如果你使用的是PyTorch等框架，还要看一下框架的种子是否固定了。还有，如果你用了cuda，别忘了cuda的随机数种子。这里还需要用到torch.backends.cudnn.deterministic.</p><p>torch.backends.cudnn.deterministic这个 flag 置为<code>True</code>的话，每次返回的卷积算法将是确定的，即默认算法。如果配合上设置 Torch 的随机种子为固定值的话，应该可以保证每次运行网络的时候相同输入的输出是固定的，因此才有了最后的几行。</p><h2 id="一些不用更改的函数："><a href="#一些不用更改的函数：" class="headerlink" title="一些不用更改的函数："></a><strong>一些不用更改的函数：</strong></h2><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#在有GPU的时候使用GPU</span><span class="token keyword">def</span> <span class="token function">get_device</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">''' Get device (if GPU is available, use GPU) '''</span>    <span class="token keyword">return</span> <span class="token string">'cuda'</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">'cpu'</span><span class="token comment" spellcheck="true">#输入的是一个包含训练集Loss列表和开发集的Loss列表</span><span class="token keyword">def</span> <span class="token function">plot_learning_curve</span><span class="token punctuation">(</span>loss_record<span class="token punctuation">,</span> title<span class="token operator">=</span><span class="token string">''</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">''' Plot learning curve of your DNN (train &amp; dev loss) '''</span>    total_steps <span class="token operator">=</span> len<span class="token punctuation">(</span>loss_record<span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    x_1 <span class="token operator">=</span> range<span class="token punctuation">(</span>total_steps<span class="token punctuation">)</span>    x_2 <span class="token operator">=</span> x_1<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">:</span>len<span class="token punctuation">(</span>loss_record<span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">//</span> len<span class="token punctuation">(</span>loss_record<span class="token punctuation">[</span><span class="token string">'dev'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span>    figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x_1<span class="token punctuation">,</span> loss_record<span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> c<span class="token operator">=</span><span class="token string">'tab:red'</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'train'</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x_2<span class="token punctuation">,</span> loss_record<span class="token punctuation">[</span><span class="token string">'dev'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> c<span class="token operator">=</span><span class="token string">'tab:cyan'</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'dev'</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>ylim<span class="token punctuation">(</span><span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">.</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'Training steps'</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'MSE loss'</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'Learning curve of &amp;#123;&amp;#125;'</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>title<span class="token punctuation">)</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#绘制一个表示预测值与真实值插件的散点图，其中斜率为1的直线代表无误差</span><span class="token keyword">def</span> <span class="token function">plot_pred</span><span class="token punctuation">(</span>dv_set<span class="token punctuation">,</span> model<span class="token punctuation">,</span> device<span class="token punctuation">,</span> lim<span class="token operator">=</span><span class="token number">35</span><span class="token punctuation">.</span><span class="token punctuation">,</span> preds<span class="token operator">=</span>None<span class="token punctuation">,</span> targets<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">''' Plot prediction of your DNN '''</span>    <span class="token keyword">if</span> preds <span class="token keyword">is</span> None <span class="token operator">or</span> targets <span class="token keyword">is</span> None<span class="token punctuation">:</span>        model<span class="token punctuation">.</span>eval<span class="token punctuation">(</span><span class="token punctuation">)</span>        preds<span class="token punctuation">,</span> targets <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        <span class="token keyword">for</span> x<span class="token punctuation">,</span> y <span class="token keyword">in</span> dv_set<span class="token punctuation">:</span>            x<span class="token punctuation">,</span> y <span class="token operator">=</span> x<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">,</span> y<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>            <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                pred <span class="token operator">=</span> model<span class="token punctuation">(</span>x<span class="token punctuation">)</span>                preds<span class="token punctuation">.</span>append<span class="token punctuation">(</span>pred<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>                targets<span class="token punctuation">.</span>append<span class="token punctuation">(</span>y<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        preds <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span>preds<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>        targets <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span>targets<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>    figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>targets<span class="token punctuation">,</span> preds<span class="token punctuation">,</span> c<span class="token operator">=</span><span class="token string">'r'</span><span class="token punctuation">,</span> alpha<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.2</span><span class="token punctuation">,</span> lim<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.2</span><span class="token punctuation">,</span> lim<span class="token punctuation">]</span><span class="token punctuation">,</span> c<span class="token operator">=</span><span class="token string">'b'</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>xlim<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">0.2</span><span class="token punctuation">,</span> lim<span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>ylim<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">0.2</span><span class="token punctuation">,</span> lim<span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'ground truth value'</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'predicted value'</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'Ground Truth v.s. Prediction'</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><h2 id="处理数据："><a href="#处理数据：" class="headerlink" title="处理数据："></a>处理数据：</h2><pre class=" language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">COVID19Dataset</span><span class="token punctuation">(</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">''' Dataset for loading and preprocessing the COVID19 dataset '''</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>                 path<span class="token punctuation">,</span>                 mode<span class="token operator">=</span><span class="token string">'train'</span><span class="token punctuation">,</span>                 target_only<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>mode <span class="token operator">=</span> mode        <span class="token comment" spellcheck="true"># Read data into numpy arrays</span>        <span class="token keyword">with</span> open<span class="token punctuation">(</span>path<span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> fp<span class="token punctuation">:</span>            data <span class="token operator">=</span> list<span class="token punctuation">(</span>csv<span class="token punctuation">.</span>reader<span class="token punctuation">(</span>fp<span class="token punctuation">)</span><span class="token punctuation">)</span>            data <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>data<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span>float<span class="token punctuation">)</span>        <span class="token keyword">if</span> <span class="token operator">not</span> target_only<span class="token punctuation">:</span>            feats <span class="token operator">=</span> list<span class="token punctuation">(</span>range<span class="token punctuation">(</span><span class="token number">93</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            <span class="token comment" spellcheck="true"># TODO: Using 40 states &amp; 2 tested_positive features (indices = 57 &amp; 75)</span>            <span class="token keyword">pass</span>        <span class="token keyword">if</span> mode <span class="token operator">==</span> <span class="token string">'test'</span><span class="token punctuation">:</span>            <span class="token comment" spellcheck="true"># Testing data</span>            <span class="token comment" spellcheck="true"># data: 893 x 93 (40 states + day 1 (18) + day 2 (18) + day 3 (17))</span>            data <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> feats<span class="token punctuation">]</span>            self<span class="token punctuation">.</span>data <span class="token operator">=</span> torch<span class="token punctuation">.</span>FloatTensor<span class="token punctuation">(</span>data<span class="token punctuation">)</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            <span class="token comment" spellcheck="true"># Training data (train/dev sets)</span>            <span class="token comment" spellcheck="true"># data: 2700 x 94 (40 states + day 1 (18) + day 2 (18) + day 3 (18))</span>            target <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>            data <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> feats<span class="token punctuation">]</span>            <span class="token comment" spellcheck="true"># Splitting training data into train &amp; dev sets</span>            <span class="token keyword">if</span> mode <span class="token operator">==</span> <span class="token string">'train'</span><span class="token punctuation">:</span>                indices <span class="token operator">=</span> <span class="token punctuation">[</span>i <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>len<span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">if</span> i <span class="token operator">%</span> <span class="token number">10</span> <span class="token operator">!=</span> <span class="token number">0</span><span class="token punctuation">]</span>            <span class="token keyword">elif</span> mode <span class="token operator">==</span> <span class="token string">'dev'</span><span class="token punctuation">:</span>                indices <span class="token operator">=</span> <span class="token punctuation">[</span>i <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>len<span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">if</span> i <span class="token operator">%</span> <span class="token number">10</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">]</span>            <span class="token comment" spellcheck="true"># Convert data into PyTorch tensors</span>            self<span class="token punctuation">.</span>data <span class="token operator">=</span> torch<span class="token punctuation">.</span>FloatTensor<span class="token punctuation">(</span>data<span class="token punctuation">[</span>indices<span class="token punctuation">]</span><span class="token punctuation">)</span>            self<span class="token punctuation">.</span>target <span class="token operator">=</span> torch<span class="token punctuation">.</span>FloatTensor<span class="token punctuation">(</span>target<span class="token punctuation">[</span>indices<span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># Normalize features (you may remove this part to see what will happen)</span>        self<span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">40</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">=</span> \            <span class="token punctuation">(</span>self<span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">40</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">-</span> self<span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">40</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> keepdim<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span> \            <span class="token operator">/</span> self<span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">40</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>std<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> keepdim<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>dim <span class="token operator">=</span> self<span class="token punctuation">.</span>data<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Finished reading the &amp;#123;&amp;#125; set of COVID19 Dataset (&amp;#123;&amp;#125; samples found, each dim = &amp;#123;&amp;#125;)'</span>              <span class="token punctuation">.</span>format<span class="token punctuation">(</span>mode<span class="token punctuation">,</span> len<span class="token punctuation">(</span>self<span class="token punctuation">.</span>data<span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>dim<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> index<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># Returns one sample at a time</span>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>mode <span class="token keyword">in</span> <span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">,</span> <span class="token string">'dev'</span><span class="token punctuation">]</span><span class="token punctuation">:</span>            <span class="token comment" spellcheck="true"># For training</span>            <span class="token keyword">return</span> self<span class="token punctuation">.</span>data<span class="token punctuation">[</span>index<span class="token punctuation">]</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>target<span class="token punctuation">[</span>index<span class="token punctuation">]</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            <span class="token comment" spellcheck="true"># For testing (no target)</span>            <span class="token keyword">return</span> self<span class="token punctuation">.</span>data<span class="token punctuation">[</span>index<span class="token punctuation">]</span>    <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># Returns the size of the dataset</span>        <span class="token keyword">return</span> len<span class="token punctuation">(</span>self<span class="token punctuation">.</span>data<span class="token punctuation">)</span></code></pre><p>这个类继承于dataset类，因此需要重新三个函数。第一个函数是初始化函数init，用来处理数据，把数据集分成训练的数据和标签两部分。然后再getitem中指定索引来确定数据的顺序的样本的标签的对应关系。len函数中返回整个样本集的个数。</p><h2 id="模型构建"><a href="#模型构建" class="headerlink" title="模型构建"></a>模型构建</h2><pre class=" language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">NeuralNet</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">''' A simple fully-connected deep neural network '''</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input_dim<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>NeuralNet<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># Define your neural network here</span>        <span class="token comment" spellcheck="true"># TODO: How to modify this model to achieve better performance?</span>        <span class="token comment" spellcheck="true">#Sequential一个有序的容器，神经网络模块将按照在传入构造器的顺序依次被添加到计算图中执行</span>        <span class="token comment" spellcheck="true">#同时以神经网络模块为元素的有序字典也可以作为传入参数。</span>        self<span class="token punctuation">.</span>net <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>input_dim<span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>        <span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># Mean squared error loss</span>        self<span class="token punctuation">.</span>criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>MSELoss<span class="token punctuation">(</span>reduction<span class="token operator">=</span><span class="token string">'mean'</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#计算输出结果</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">''' Given input of size (batch_size x input_dim), compute output of the network '''</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>net<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#计算Loss</span>    <span class="token keyword">def</span> <span class="token function">cal_loss</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> pred<span class="token punctuation">,</span> target<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">''' Calculate loss '''</span>        <span class="token comment" spellcheck="true"># TODO: you may implement L2 regularization here</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>criterion<span class="token punctuation">(</span>pred<span class="token punctuation">,</span> target<span class="token punctuation">)</span></code></pre><h2 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h2><pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>tr_set<span class="token punctuation">,</span> dv_set<span class="token punctuation">,</span> model<span class="token punctuation">,</span> config<span class="token punctuation">,</span> device<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">''' DNN training '''</span>    n_epochs <span class="token operator">=</span> config<span class="token punctuation">[</span><span class="token string">'n_epochs'</span><span class="token punctuation">]</span>  <span class="token comment" spellcheck="true"># Maximum number of epochs</span>    <span class="token comment" spellcheck="true"># Setup optimizer</span>    optimizer <span class="token operator">=</span> getattr<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>optim<span class="token punctuation">,</span> config<span class="token punctuation">[</span><span class="token string">'optimizer'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">(</span>        model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">**</span>config<span class="token punctuation">[</span><span class="token string">'optim_hparas'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    min_mse <span class="token operator">=</span> <span class="token number">1000</span><span class="token punctuation">.</span>    loss_record <span class="token operator">=</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;'train': [], 'dev': []&amp;#125;      # for recording training loss</span>    early_stop_cnt <span class="token operator">=</span> <span class="token number">0</span>    epoch <span class="token operator">=</span> <span class="token number">0</span>    <span class="token keyword">while</span> epoch <span class="token operator">&lt;</span> n_epochs<span class="token punctuation">:</span>        model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>                           <span class="token comment" spellcheck="true"># set model to training mode</span>        <span class="token keyword">for</span> x<span class="token punctuation">,</span> y <span class="token keyword">in</span> tr_set<span class="token punctuation">:</span>                     <span class="token comment" spellcheck="true"># iterate through the dataloader</span>            optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>               <span class="token comment" spellcheck="true"># set gradient to zero</span>            x<span class="token punctuation">,</span> y <span class="token operator">=</span> x<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">,</span> y<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>   <span class="token comment" spellcheck="true"># move data to device (cpu/cuda)</span>            pred <span class="token operator">=</span> model<span class="token punctuation">(</span>x<span class="token punctuation">)</span>                     <span class="token comment" spellcheck="true"># forward pass (compute output)</span>            mse_loss <span class="token operator">=</span> model<span class="token punctuation">.</span>cal_loss<span class="token punctuation">(</span>pred<span class="token punctuation">,</span> y<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># compute loss</span>            mse_loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>                 <span class="token comment" spellcheck="true"># compute gradient (backpropagation)</span>            optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>                    <span class="token comment" spellcheck="true"># update model with optimizer</span>            loss_record<span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>mse_loss<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># After each epoch, test your model on the validation (development) set.</span>        dev_mse <span class="token operator">=</span> dev<span class="token punctuation">(</span>dv_set<span class="token punctuation">,</span> model<span class="token punctuation">,</span> device<span class="token punctuation">)</span>        <span class="token keyword">if</span> dev_mse <span class="token operator">&lt;</span> min_mse<span class="token punctuation">:</span>            <span class="token comment" spellcheck="true"># Save model if your model improved</span>            min_mse <span class="token operator">=</span> dev_mse            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Saving model (epoch = &amp;#123;:4d&amp;#125;, loss = &amp;#123;:.4f&amp;#125;)'</span>                <span class="token punctuation">.</span>format<span class="token punctuation">(</span>epoch <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> min_mse<span class="token punctuation">)</span><span class="token punctuation">)</span>            <span class="token comment" spellcheck="true">#注意保存模型</span>            torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> config<span class="token punctuation">[</span><span class="token string">'save_path'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># Save model to specified path</span>            early_stop_cnt <span class="token operator">=</span> <span class="token number">0</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            early_stop_cnt <span class="token operator">+=</span> <span class="token number">1</span>        epoch <span class="token operator">+=</span> <span class="token number">1</span>        loss_record<span class="token punctuation">[</span><span class="token string">'dev'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>dev_mse<span class="token punctuation">)</span>        <span class="token keyword">if</span> early_stop_cnt <span class="token operator">&gt;</span> config<span class="token punctuation">[</span><span class="token string">'early_stop'</span><span class="token punctuation">]</span><span class="token punctuation">:</span>            <span class="token comment" spellcheck="true"># Stop training if your model stops improving for "config['early_stop']" epochs.</span>            <span class="token keyword">break</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Finished training after &amp;#123;&amp;#125; epochs'</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>epoch<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> min_mse<span class="token punctuation">,</span> loss_record</code></pre><h2 id="验证集计算Loss"><a href="#验证集计算Loss" class="headerlink" title="验证集计算Loss"></a>验证集计算Loss</h2><p>验证集从训练集中分离而出，这是事先验证用多少个epoch进行训练才不会过拟合，然后再把所有的数据扔进去训练。</p><pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">dev</span><span class="token punctuation">(</span>dv_set<span class="token punctuation">,</span> model<span class="token punctuation">,</span> device<span class="token punctuation">)</span><span class="token punctuation">:</span>    model<span class="token punctuation">.</span>eval<span class="token punctuation">(</span><span class="token punctuation">)</span>                                <span class="token comment" spellcheck="true"># set model to evalutation mode</span>    total_loss <span class="token operator">=</span> <span class="token number">0</span>    <span class="token keyword">for</span> x<span class="token punctuation">,</span> y <span class="token keyword">in</span> dv_set<span class="token punctuation">:</span>                         <span class="token comment" spellcheck="true"># iterate through the dataloader</span>        x<span class="token punctuation">,</span> y <span class="token operator">=</span> x<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">,</span> y<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>       <span class="token comment" spellcheck="true"># move data to device (cpu/cuda)</span>        <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                   <span class="token comment" spellcheck="true"># disable gradient calculation</span>            pred <span class="token operator">=</span> model<span class="token punctuation">(</span>x<span class="token punctuation">)</span>                     <span class="token comment" spellcheck="true"># forward pass (compute output)</span>            mse_loss <span class="token operator">=</span> model<span class="token punctuation">.</span>cal_loss<span class="token punctuation">(</span>pred<span class="token punctuation">,</span> y<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># compute loss</span>        total_loss <span class="token operator">+=</span> mse_loss<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">*</span> len<span class="token punctuation">(</span>x<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># accumulate loss</span>    total_loss <span class="token operator">=</span> total_loss <span class="token operator">/</span> len<span class="token punctuation">(</span>dv_set<span class="token punctuation">.</span>dataset<span class="token punctuation">)</span>              <span class="token comment" spellcheck="true"># compute averaged loss</span>    <span class="token keyword">return</span> total_loss</code></pre><h2 id="测试集预测"><a href="#测试集预测" class="headerlink" title="测试集预测"></a>测试集预测</h2><pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">test</span><span class="token punctuation">(</span>tt_set<span class="token punctuation">,</span> model<span class="token punctuation">,</span> device<span class="token punctuation">)</span><span class="token punctuation">:</span>    model<span class="token punctuation">.</span>eval<span class="token punctuation">(</span><span class="token punctuation">)</span>                                <span class="token comment" spellcheck="true"># set model to evalutation mode</span>    preds <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token keyword">for</span> x <span class="token keyword">in</span> tt_set<span class="token punctuation">:</span>                            <span class="token comment" spellcheck="true"># iterate through the dataloader</span>        x <span class="token operator">=</span> x<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>                        <span class="token comment" spellcheck="true"># move data to device (cpu/cuda)</span>        <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                   <span class="token comment" spellcheck="true"># disable gradient calculation</span>            pred <span class="token operator">=</span> model<span class="token punctuation">(</span>x<span class="token punctuation">)</span>                     <span class="token comment" spellcheck="true"># forward pass (compute output)</span>            preds<span class="token punctuation">.</span>append<span class="token punctuation">(</span>pred<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>   <span class="token comment" spellcheck="true"># collect prediction</span>    preds <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span>preds<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>     <span class="token comment" spellcheck="true"># concatenate all predictions and convert to a numpy array</span>    <span class="token keyword">return</span> preds</code></pre><h2 id="设置超参数"><a href="#设置超参数" class="headerlink" title="设置超参数"></a>设置超参数</h2><pre class=" language-python"><code class="language-python">device <span class="token operator">=</span> get_device<span class="token punctuation">(</span><span class="token punctuation">)</span>                 <span class="token comment" spellcheck="true"># get the current available device ('cpu' or 'cuda')</span>os<span class="token punctuation">.</span>makedirs<span class="token punctuation">(</span><span class="token string">'models'</span><span class="token punctuation">,</span> exist_ok<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># The trained model will be saved to ./models/</span>target_only <span class="token operator">=</span> <span class="token boolean">False</span>                   <span class="token comment" spellcheck="true"># TODO: Using 40 states &amp; 2 tested_positive features</span><span class="token comment" spellcheck="true"># TODO: How to tune these hyper-parameters to improve your model's performance?</span>config <span class="token operator">=</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>    <span class="token string">'n_epochs'</span><span class="token punctuation">:</span> <span class="token number">3000</span><span class="token punctuation">,</span>                <span class="token comment" spellcheck="true"># maximum number of epochs</span>    <span class="token string">'batch_size'</span><span class="token punctuation">:</span> <span class="token number">270</span><span class="token punctuation">,</span>               <span class="token comment" spellcheck="true"># mini-batch size for dataloader</span>    <span class="token string">'optimizer'</span><span class="token punctuation">:</span> <span class="token string">'SGD'</span><span class="token punctuation">,</span>              <span class="token comment" spellcheck="true"># optimization algorithm (optimizer in torch.optim)</span>    <span class="token string">'optim_hparas'</span><span class="token punctuation">:</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;                # hyper-parameters for the optimizer (depends on which optimizer you are using)</span>        <span class="token string">'lr'</span><span class="token punctuation">:</span> <span class="token number">0.001</span><span class="token punctuation">,</span>                 <span class="token comment" spellcheck="true"># learning rate of SGD</span>        <span class="token string">'momentum'</span><span class="token punctuation">:</span> <span class="token number">0.9</span>              <span class="token comment" spellcheck="true"># momentum for SGD</span>    <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;,</span>    <span class="token string">'early_stop'</span><span class="token punctuation">:</span> <span class="token number">200</span><span class="token punctuation">,</span>               <span class="token comment" spellcheck="true"># early stopping epochs (the number epochs since your model's last improvement)</span>    <span class="token string">'save_path'</span><span class="token punctuation">:</span> <span class="token string">'models/model.pth'</span>  <span class="token comment" spellcheck="true"># your model will be saved here</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;</span></code></pre><h2 id="正式训练前价值数据"><a href="#正式训练前价值数据" class="headerlink" title="正式训练前价值数据"></a>正式训练前价值数据</h2><pre class=" language-python"><code class="language-python">tr_set <span class="token operator">=</span> prep_dataloader<span class="token punctuation">(</span>tr_path<span class="token punctuation">,</span> <span class="token string">'train'</span><span class="token punctuation">,</span> config<span class="token punctuation">[</span><span class="token string">'batch_size'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> target_only<span class="token operator">=</span>target_only<span class="token punctuation">)</span>dv_set <span class="token operator">=</span> prep_dataloader<span class="token punctuation">(</span>tr_path<span class="token punctuation">,</span> <span class="token string">'dev'</span><span class="token punctuation">,</span> config<span class="token punctuation">[</span><span class="token string">'batch_size'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> target_only<span class="token operator">=</span>target_only<span class="token punctuation">)</span>tt_set <span class="token operator">=</span> prep_dataloader<span class="token punctuation">(</span>tt_path<span class="token punctuation">,</span> <span class="token string">'test'</span><span class="token punctuation">,</span> config<span class="token punctuation">[</span><span class="token string">'batch_size'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> target_only<span class="token operator">=</span>target_only<span class="token punctuation">)</span></code></pre><h2 id="正式训练"><a href="#正式训练" class="headerlink" title="正式训练"></a>正式训练</h2><pre class=" language-python"><code class="language-python">model <span class="token operator">=</span> NeuralNet<span class="token punctuation">(</span>tr_set<span class="token punctuation">.</span>dataset<span class="token punctuation">.</span>dim<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span> model_loss<span class="token punctuation">,</span> model_loss_record <span class="token operator">=</span> train<span class="token punctuation">(</span>tr_set<span class="token punctuation">,</span> dv_set<span class="token punctuation">,</span> model<span class="token punctuation">,</span> config<span class="token punctuation">,</span> device<span class="token punctuation">)</span></code></pre><h2 id="绘制两个数据集的Loss图"><a href="#绘制两个数据集的Loss图" class="headerlink" title="绘制两个数据集的Loss图"></a>绘制两个数据集的Loss图</h2><pre class=" language-python"><code class="language-python">plot_learning_curve<span class="token punctuation">(</span>model_loss_record<span class="token punctuation">,</span> title<span class="token operator">=</span><span class="token string">'deep model'</span><span class="token punctuation">)</span></code></pre><h2 id="根据预测值绘制散点图"><a href="#根据预测值绘制散点图" class="headerlink" title="根据预测值绘制散点图"></a>根据预测值绘制散点图</h2><pre class=" language-python"><code class="language-python"><span class="token keyword">del</span> modelmodel <span class="token operator">=</span> NeuralNet<span class="token punctuation">(</span>tr_set<span class="token punctuation">.</span>dataset<span class="token punctuation">.</span>dim<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>ckpt <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>config<span class="token punctuation">[</span><span class="token string">'save_path'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> map_location<span class="token operator">=</span><span class="token string">'cpu'</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># Load your best model</span>model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>ckpt<span class="token punctuation">)</span>plot_pred<span class="token punctuation">(</span>dv_set<span class="token punctuation">,</span> model<span class="token punctuation">,</span> device<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># Show prediction on the validation set</span></code></pre><h2 id="保存预测数据"><a href="#保存预测数据" class="headerlink" title="保存预测数据"></a>保存预测数据</h2><pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">save_pred</span><span class="token punctuation">(</span>preds<span class="token punctuation">,</span> file<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">''' Save predictions to specified file '''</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Saving results to &amp;#123;&amp;#125;'</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>file<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">with</span> open<span class="token punctuation">(</span>file<span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> fp<span class="token punctuation">:</span>        writer <span class="token operator">=</span> csv<span class="token punctuation">.</span>writer<span class="token punctuation">(</span>fp<span class="token punctuation">)</span>        writer<span class="token punctuation">.</span>writerow<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'id'</span><span class="token punctuation">,</span> <span class="token string">'tested_positive'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token keyword">for</span> i<span class="token punctuation">,</span> p <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>preds<span class="token punctuation">)</span><span class="token punctuation">:</span>            writer<span class="token punctuation">.</span>writerow<span class="token punctuation">(</span><span class="token punctuation">[</span>i<span class="token punctuation">,</span> p<span class="token punctuation">]</span><span class="token punctuation">)</span>preds <span class="token operator">=</span> test<span class="token punctuation">(</span>tt_set<span class="token punctuation">,</span> model<span class="token punctuation">,</span> device<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># predict COVID-19 cases with your model</span>save_pred<span class="token punctuation">(</span>preds<span class="token punctuation">,</span> <span class="token string">'pred.csv'</span><span class="token punctuation">)</span>         <span class="token comment" spellcheck="true"># save prediction file to pred.csv</span></code></pre>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Google Colab及其使用</title>
      <link href="2021/05/10/google-colab-ji-qi-shi-yong/"/>
      <url>2021/05/10/google-colab-ji-qi-shi-yong/</url>
      
        <content type="html"><![CDATA[<p>  注意：本文不提供访问外网的方法，默认你已能自由访问外网。</p><ul><li>Colaboratory 是一个 Google 研究项目，旨在帮助传播机器学习培训和研究成果。它是一个 Jupyter 笔记本环境，不需要进行任何设置就可以使用，并且完全在云端运行。</li><li>Colaboratory 笔记本存储在 Google 云端硬盘中，并且可以共享，就如同您使用 Google 文档或表格一样。Colaboratory 可免费使用，包括它的GPU资源。</li><li>利用Colaboratory ，可以方便的使用Keras,TensorFlow,PyTorch,OpenCV等框架进行深度学习应用的开发。</li></ul><img src="/2021/05/10/google-colab-ji-qi-shi-yong/1.png" class=""><p>点击文件可以上传本地的notebook到Google云盘，然后即可打开运行：</p><img src="/2021/05/10/google-colab-ji-qi-shi-yong/2.png" class=""><p>如果想要上传本地保存的训练数据（如csv文件），点击最左边的上传按钮即可，或者可以直接拖拽上传。注意：此时的文件是临时保存的，程序终止运行会自动删除。</p><img src="/2021/05/10/google-colab-ji-qi-shi-yong/3.png" class=""><p>你也可以直接下载文件：</p><img src="/2021/05/10/google-colab-ji-qi-shi-yong/4.png" class=""><p>如果想要永久保存需要链接到Google云盘：</p><img src="/2021/05/10/google-colab-ji-qi-shi-yong/5.png" class=""><p>点击最右边的按钮会出现右边的那一段程序：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> google<span class="token punctuation">.</span>colab <span class="token keyword">import</span> drivedrive<span class="token punctuation">.</span>mount<span class="token punctuation">(</span><span class="token string">'/content/drive'</span><span class="token punctuation">)</span></code></pre><p>运行这一段程序后Google会要求你登录Google账户，并且把产生的授权码贴到运行程序下方的输入框中，这样左边的文件栏会多出一个文件夹。</p><img src="/2021/05/10/google-colab-ji-qi-shi-yong/6.png" class=""><p>当文件保存在这个文件夹中，程序终止后不会消失，并且保存在Google Drive的云端。而且如果不小心覆盖了以前的版本，可以在云盘中点击右键的版本管理，即可找回以前的版本。</p><p>我们需要用到命令行来操作文件，需要记住以下的指令：</p><img src="/2021/05/10/google-colab-ji-qi-shi-yong/7.png" class=""><p>这些指令前面加上!再在程序框中运行即可，除了cd前面加的是%。</p><p>下面要把我们的工作环境移动到云盘里，防止文件丢失：</p><pre class=" language-powershell"><code class="language-powershell"><span class="token operator">%</span>cd <span class="token operator">/</span>content<span class="token operator">/</span>drive<span class="token operator">/</span>MyDrive<span class="token operator">!</span>mkdir ML2021<span class="token operator">%</span>cd <span class="token punctuation">.</span><span class="token operator">/</span>ML2021</code></pre><p>可以用以下指令来确认自己当前所在位置：</p><pre class=" language-powershell"><code class="language-powershell"><span class="token operator">!</span><span class="token function">pwd</span></code></pre><p>这个时候我们下载或者上传都是在这个ML2021的文件夹中。</p><p>运行前要更改运行所需的硬件为GPU，可以大大加快训练速度。</p><img src="/2021/05/10/google-colab-ji-qi-shi-yong/8.png" class=""><img src="/2021/05/10/google-colab-ji-qi-shi-yong/9.png" class=""><p>注意：</p><ol><li>挂载只有12个小时，也就是说12小时之后你就需要重现挂载一次，所以就需要我们在进行模型训练的时候记得要加上checkpoint，不然如果训练的模型超过12小时，Google断开挂载会白白浪费12小时。</li><li>每次使用都需要重新配置上次自己安装的环境，默认环境就不用。还有就是CUDA和Cudnn不需要重新配置。一个方法就是独立出一个页面把你要配的环境的代码都写在该页面下，下次打开只需要运行所有单元格就可以再开一个页面来跑需要跑的程序。</li><li>模型在训练的过程中有可能会出现连接中断需要重新连接的情况，不要怕点击重新连接就行，如果经常出现推荐给大家一个脚本神器<strong>按键精灵，</strong>人不在电脑边上只需要F10启动脚本左键点击功能。</li><li>如果电脑自动关机了，或者是自动更新什么的，只要时间不是很长，只需要重启，恢复网页还是可以继续训练的，比较训练是挂载在Google上，但是时间久了也就要重新训练。</li><li>如果是断网了也只需要联网点击重新连接即可，同上如果断网太久也就只能重新训练了。</li></ol>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Python神经网络编程</title>
      <link href="2021/05/08/python-shen-jing-wang-luo-bian-cheng/"/>
      <url>2021/05/08/python-shen-jing-wang-luo-bian-cheng/</url>
      
        <content type="html"><![CDATA[<h2 id="神经网络基本编程"><a href="#神经网络基本编程" class="headerlink" title="神经网络基本编程"></a>神经网络基本编程</h2><p>采用Sigmod激活函数，建立一个包含一层隐藏层的神经网络通用代码：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> numpy<span class="token comment" spellcheck="true"># scipy.special for the sigmoid function expit()</span><span class="token keyword">import</span> scipy<span class="token punctuation">.</span>special<span class="token keyword">class</span> <span class="token class-name">neuralNetwork</span><span class="token punctuation">:</span>       <span class="token comment" spellcheck="true"># initialise the neural network</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> inputnodes<span class="token punctuation">,</span> hiddennodes<span class="token punctuation">,</span> outputnodes<span class="token punctuation">,</span> learningrate<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># set number of nodes in each input, hidden, output layer</span>        self<span class="token punctuation">.</span>inodes <span class="token operator">=</span> inputnodes        self<span class="token punctuation">.</span>hnodes <span class="token operator">=</span> hiddennodes        self<span class="token punctuation">.</span>onodes <span class="token operator">=</span> outputnodes                <span class="token comment" spellcheck="true"># link weight matrices, wih and who</span>        <span class="token comment" spellcheck="true"># weights inside the arrays are w_i_j, where link is from node i to node j in the next layer</span>        <span class="token comment" spellcheck="true"># w11 w21</span>        <span class="token comment" spellcheck="true"># w12 w22 etc </span>        self<span class="token punctuation">.</span>wih <span class="token operator">=</span> numpy<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token number">0.0</span><span class="token punctuation">,</span> pow<span class="token punctuation">(</span>self<span class="token punctuation">.</span>inodes<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>self<span class="token punctuation">.</span>hnodes<span class="token punctuation">,</span> self<span class="token punctuation">.</span>inodes<span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>who <span class="token operator">=</span> numpy<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token number">0.0</span><span class="token punctuation">,</span> pow<span class="token punctuation">(</span>self<span class="token punctuation">.</span>hnodes<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>self<span class="token punctuation">.</span>onodes<span class="token punctuation">,</span> self<span class="token punctuation">.</span>hnodes<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># learning rate</span>        self<span class="token punctuation">.</span>lr <span class="token operator">=</span> learningrate         <span class="token comment" spellcheck="true"># activation function is the sigmoid function</span>        self<span class="token punctuation">.</span>activation_function <span class="token operator">=</span> <span class="token keyword">lambda</span> x<span class="token punctuation">:</span> scipy<span class="token punctuation">.</span>special<span class="token punctuation">.</span>expit<span class="token punctuation">(</span>x<span class="token punctuation">)</span>            <span class="token comment" spellcheck="true"># train the neural network</span>    <span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> inputs_list<span class="token punctuation">,</span> targets_list<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># convert inputs list to 2d array</span>        inputs <span class="token operator">=</span> numpy<span class="token punctuation">.</span>array<span class="token punctuation">(</span>inputs_list<span class="token punctuation">,</span> ndmin<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>T        targets <span class="token operator">=</span> numpy<span class="token punctuation">.</span>array<span class="token punctuation">(</span>targets_list<span class="token punctuation">,</span> ndmin<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>T                <span class="token comment" spellcheck="true"># calculate signals into hidden layer</span>        hidden_inputs <span class="token operator">=</span> numpy<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>self<span class="token punctuation">.</span>wih<span class="token punctuation">,</span> inputs<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># calculate the signals emerging from hidden layer</span>        hidden_outputs <span class="token operator">=</span> self<span class="token punctuation">.</span>activation_function<span class="token punctuation">(</span>hidden_inputs<span class="token punctuation">)</span>              <span class="token comment" spellcheck="true"># calculate signals into final output layer</span>        final_inputs <span class="token operator">=</span> numpy<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>self<span class="token punctuation">.</span>who<span class="token punctuation">,</span> hidden_outputs<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># calculate the signals emerging from final output layer</span>        final_outputs <span class="token operator">=</span> self<span class="token punctuation">.</span>activation_function<span class="token punctuation">(</span>final_inputs<span class="token punctuation">)</span>               <span class="token comment" spellcheck="true"># output layer error is the (target - actual)</span>        output_errors <span class="token operator">=</span> targets <span class="token operator">-</span> final_outputs        <span class="token comment" spellcheck="true"># hidden layer error is the output_errors, split by weights, recombined at hidden nodes</span>        hidden_errors <span class="token operator">=</span> numpy<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>self<span class="token punctuation">.</span>who<span class="token punctuation">.</span>T<span class="token punctuation">,</span> output_errors<span class="token punctuation">)</span>         <span class="token comment" spellcheck="true"># update the weights for the links between the hidden and output layers</span>        self<span class="token punctuation">.</span>who <span class="token operator">+=</span> self<span class="token punctuation">.</span>lr <span class="token operator">*</span> numpy<span class="token punctuation">.</span>dot<span class="token punctuation">(</span><span class="token punctuation">(</span>output_errors <span class="token operator">*</span> final_outputs <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token number">1.0</span> <span class="token operator">-</span> final_outputs<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> numpy<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span>hidden_outputs<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># update the weights for the links between the input and hidden layers</span>        self<span class="token punctuation">.</span>wih <span class="token operator">+=</span> self<span class="token punctuation">.</span>lr <span class="token operator">*</span> numpy<span class="token punctuation">.</span>dot<span class="token punctuation">(</span><span class="token punctuation">(</span>hidden_errors <span class="token operator">*</span> hidden_outputs <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token number">1.0</span> <span class="token operator">-</span> hidden_outputs<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> numpy<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># query the neural network</span>    <span class="token keyword">def</span> <span class="token function">query</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> inputs_list<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># convert inputs list to 2d array</span>        inputs <span class="token operator">=</span> numpy<span class="token punctuation">.</span>array<span class="token punctuation">(</span>inputs_list<span class="token punctuation">,</span> ndmin<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>T        <span class="token comment" spellcheck="true"># calculate signals into hidden layer</span>        hidden_inputs <span class="token operator">=</span> numpy<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>self<span class="token punctuation">.</span>wih<span class="token punctuation">,</span> inputs<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># calculate the signals emerging from hidden layer</span>        hidden_outputs <span class="token operator">=</span> self<span class="token punctuation">.</span>activation_function<span class="token punctuation">(</span>hidden_inputs<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># calculate signals into final output layer</span>        final_inputs <span class="token operator">=</span> numpy<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>self<span class="token punctuation">.</span>who<span class="token punctuation">,</span> hidden_outputs<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># calculate the signals emerging from final output layer</span>        final_outputs <span class="token operator">=</span> self<span class="token punctuation">.</span>activation_function<span class="token punctuation">(</span>final_inputs<span class="token punctuation">)</span>        <span class="token keyword">return</span> final_outputs<span class="token comment" spellcheck="true"># number of input, hidden and output nodes</span>input_nodes <span class="token operator">=</span> <span class="token number">3</span>hidden_nodes <span class="token operator">=</span> <span class="token number">3</span>output_nodes <span class="token operator">=</span> <span class="token number">3</span><span class="token comment" spellcheck="true"># learning rate is 0.3</span>learning_rate <span class="token operator">=</span> <span class="token number">0.3</span><span class="token comment" spellcheck="true"># create instance of neural network</span>n <span class="token operator">=</span> neuralNetwork<span class="token punctuation">(</span>input_nodes<span class="token punctuation">,</span>hidden_nodes<span class="token punctuation">,</span>output_nodes<span class="token punctuation">,</span> learning_rate<span class="token punctuation">)</span>    n<span class="token punctuation">.</span>query<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1.0</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.5</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><p>这里神经网络的训练是基于<strong>梯度下降</strong>的算法的。通过误差的反向传递最终得到一个最优解。公式为：<br>$$<br>w_{jk} = w_{jk} - \alpha \frac{dE}{dw_{jk}}<br>$$</p><p>$$<br>E = \sum_n (t_n - o_n)^2<br>$$</p><p>其中α代表学习率，决定了训练的速度。后面的求导代表$w_{jk}$在误差中的梯度，通过这个式子可以使得输出的值和真实值相比误差不断减小。算得<br>$$<br>\frac{dE}{dw_{jk}} = - 2(t_k - o_k) * sigmoid(\sum_j w_{jk}o_j)(1-sigmoid(\sum_j w_{jk}o_j)) * o_j<br>$$<br>其中$t_k$为该权重对应输出节点的真实值，$o_k$为现在该输出节点预测值，$o_j$是隐藏层的输出值。可以写成：<br>$$<br>\frac{dE}{dw_{jk}} = - e_k * sigmoid(\sum_j w_{jk}o_j)(1-sigmoid(\sum_j w_{jk}o_j)) * o_j<br>$$</p><p>$$<br>\Delta w_{jk} = \alpha * \frac{dE}{dw_{jk}}<br>$$</p><p>可以看到更新的权重矩阵的梯度是一个一维的列向量乘以一维行向量。</p><h2 id="识别手写数字"><a href="#识别手写数字" class="headerlink" title="识别手写数字"></a>识别手写数字</h2><p>代码及相关资源来源：<a href="https://www.epubit.com/bookDetails?id=N34292&amp;typeName=%E6%90%9C%E7%B4%A2">https://www.epubit.com/bookDetails?id=N34292&amp;typeName=%E6%90%9C%E7%B4%A2</a></p><p><a href="https://link.zhihu.com/?target=http://www.pjreddie.com/media/files/mnist_train.csv">https://link.zhihu.com/?target=http%3A//www.pjreddie.com/media/files/mnist_train.csv</a></p><p><a href="https://link.zhihu.com/?target=http://www.pjreddie.com/media/files/mnist_test.csv">https://link.zhihu.com/?target=http%3A//www.pjreddie.com/media/files/mnist_test.csv</a></p><p>数据用CSV文件存放，数字是28*28像素，每行第一个值是标签，后面的都是灰度值。训练集有100条，测试集10条。</p><p>样式展示：</p><img src="/2021/05/08/python-shen-jing-wang-luo-bian-cheng/1.png" class><p>代码：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> numpy<span class="token comment" spellcheck="true"># scipy.special for the sigmoid function expit()</span><span class="token keyword">import</span> scipy<span class="token punctuation">.</span>special<span class="token comment" spellcheck="true"># library for plotting arrays</span><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot<span class="token comment" spellcheck="true"># ensure the plots are inside this notebook, not an external window</span><span class="token operator">%</span>matplotlib inline<span class="token operator">-</span><span class="token operator">-</span>snip<span class="token operator">-</span><span class="token operator">-</span><span class="token comment" spellcheck="true"># number of input, hidden and output nodes</span>input_nodes <span class="token operator">=</span> <span class="token number">784</span>hidden_nodes <span class="token operator">=</span> <span class="token number">200</span>output_nodes <span class="token operator">=</span> <span class="token number">10</span><span class="token comment" spellcheck="true"># learning rate</span>learning_rate <span class="token operator">=</span> <span class="token number">0.1</span><span class="token comment" spellcheck="true"># create instance of neural network</span>n <span class="token operator">=</span> neuralNetwork<span class="token punctuation">(</span>input_nodes<span class="token punctuation">,</span>hidden_nodes<span class="token punctuation">,</span>output_nodes<span class="token punctuation">,</span> learning_rate<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># load the mnist training data CSV file into a list</span>training_data_file <span class="token operator">=</span> open<span class="token punctuation">(</span><span class="token string">"mnist_dataset/mnist_train.csv"</span><span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">)</span>training_data_list <span class="token operator">=</span> training_data_file<span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span>training_data_file<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># train the neural network</span><span class="token comment" spellcheck="true"># epochs is the number of times the training data set is used for training</span>epochs <span class="token operator">=</span> <span class="token number">10</span><span class="token keyword">for</span> e <span class="token keyword">in</span> range<span class="token punctuation">(</span>epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># go through all records in the training data set</span>    <span class="token keyword">for</span> record <span class="token keyword">in</span> training_data_list<span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># split the record by the ',' commas</span>        all_values <span class="token operator">=</span> record<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">','</span><span class="token punctuation">)</span>                      <span class="token comment" spellcheck="true"># scale and shift the inputs</span>        inputs <span class="token operator">=</span> <span class="token punctuation">(</span>numpy<span class="token punctuation">.</span>asfarray<span class="token punctuation">(</span>all_values<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">255.0</span> <span class="token operator">*</span> <span class="token number">0.99</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">0.01</span>        <span class="token comment" spellcheck="true"># create the target output values (all 0.01, except the desired label which is 0.99)</span>        targets <span class="token operator">=</span> numpy<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>output_nodes<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">0.01</span>        <span class="token comment" spellcheck="true"># all_values[0] is the target label for this record</span>        targets<span class="token punctuation">[</span>int<span class="token punctuation">(</span>all_values<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0.99</span>        n<span class="token punctuation">.</span>train<span class="token punctuation">(</span>inputs<span class="token punctuation">,</span> targets<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># load the mnist test data CSV file into a list</span>test_data_file <span class="token operator">=</span> open<span class="token punctuation">(</span><span class="token string">"mnist_dataset/mnist_test.csv"</span><span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">)</span>test_data_list <span class="token operator">=</span> test_data_file<span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span>test_data_file<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># scorecard for how well the network performs, initially empty</span>scorecard <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token comment" spellcheck="true"># go through all the records in the test data set</span><span class="token keyword">for</span> record <span class="token keyword">in</span> test_data_list<span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># split the record by the ',' commas</span>    all_values <span class="token operator">=</span> record<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">','</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># correct answer is first value</span>    correct_label <span class="token operator">=</span> int<span class="token punctuation">(</span>all_values<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># scale and shift the inputs</span>    inputs <span class="token operator">=</span> <span class="token punctuation">(</span>numpy<span class="token punctuation">.</span>asfarray<span class="token punctuation">(</span>all_values<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">255.0</span> <span class="token operator">*</span> <span class="token number">0.99</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">0.01</span>    <span class="token comment" spellcheck="true"># query the network</span>    outputs <span class="token operator">=</span> n<span class="token punctuation">.</span>query<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># the index of the highest value corresponds to the label</span>    label <span class="token operator">=</span> numpy<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>outputs<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># append correct or incorrect to list</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span>label <span class="token operator">==</span> correct_label<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># network's answer matches correct answer, add 1 to scorecard</span>        scorecard<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>    <span class="token keyword">else</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># network's answer doesn't match correct answer, add 0 to scorecard</span>        scorecard<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># calculate the performance score, the fraction of correct answers</span>scorecard_array <span class="token operator">=</span> numpy<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span>scorecard<span class="token punctuation">)</span><span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">"performance = "</span><span class="token punctuation">,</span> scorecard_array<span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">/</span> scorecard_array<span class="token punctuation">.</span>size<span class="token punctuation">)</span></code></pre><p>要注意的点：</p><ul><li><p>这里输入节点为28*28=784，输出节点为10个，分别代表0到9这10个数字，那个输出节点数值最大那么分类结果就是这个数字。</p></li><li><p>激活函数不可能产生0或1的输出。因此需要使用0.01和0.99代替0和1。因此训练目标是让除了目标输出节点为0.99，其他节点为0.01。</p></li><li><p>查看图片的代码为</p><pre class=" language-python"><code class="language-python">image_array <span class="token operator">=</span> numpy<span class="token punctuation">.</span>asfarray<span class="token punctuation">(</span>all_values<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">28</span><span class="token punctuation">,</span><span class="token number">28</span><span class="token punctuation">)</span><span class="token punctuation">)</span>                  matplotlib<span class="token punctuation">.</span>pyplot<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>image_array<span class="token punctuation">,</span> cmap<span class="token operator">=</span><span class="token string">'Greys'</span><span class="token punctuation">,</span> interpolation<span class="token operator">=</span><span class="token string">'None'</span><span class="token punctuation">)</span>  </code></pre></li><li><p>过高和过低的学习率都是有害的。过高会使得在梯度下降的过程中的来回震动加剧，难以找到最优点。过低会导致学习缓慢，迟迟达不到最优点。</p></li><li><p>多次运行会因为初始点的不同，得到不同的结果，这就是多个局部的最优点，我们从这些最优点中，挑选最好的即可。</p></li><li><p>过多的训练会过犹不及，出现过拟合现象，导致网络在新数据上表现不佳。</p></li><li><p>改变隐藏层的节点数目可以优化训练结果，过少的隐藏节点会使得网络学习能力不足，过多会使得网络难以训练。</p></li></ul><h2 id="识别自己手写的数字"><a href="#识别自己手写的数字" class="headerlink" title="识别自己手写的数字"></a>识别自己手写的数字</h2><p>我们可以尝试着自己的笔迹，或者是故意做一些扭曲和噪声的处理，来测试网络的辨别能力。当我们得到这种图片后首先需要把它们处理成28*28像素的图片，你可以使用图像编辑器做到这一点，然后要转换成灰度数字表现的形式代码如下：</p><pre class=" language-Python"><code class="language-Python">import scipy.miscimg_array = scipy.misc.imread(image_file_name,flatten = True)img_data = 255.0 - img_array.reshape(784)img_data = (img_data / 255.0 * 0.99) + 0.01</code></pre><p>其中imread函数从图像文件中读取数据，”flatten=True”把图像变成简单的浮点数数组。如果图像是彩色的，颜色值会自动转换为灰度值。这样就可以把这些数据运用到我们的模型中了。</p><h2 id="旋转图像可以创建新的训练数据"><a href="#旋转图像可以创建新的训练数据" class="headerlink" title="旋转图像可以创建新的训练数据"></a>旋转图像可以创建新的训练数据</h2><p>收集更多的手写样本固然可以提高模型的准确率，但是工作量太大了。一个很好的做法是通过顺时针或逆时针旋转它们，可以创建新的样本，通过这些新的样本进行训练，同样可以很好地提高模型的准确率。但要注意旋转的角度不能过大，否则会降低神经网络的性能，因为这意味创建了不能代表数字的图像，建议旋转10°，这个角度比较理想。同样的，我们在识别其他有关物体的图片时也可以进行左右翻转或者放大的操作来创造更多地样本。</p><p>​    ndimage.interpolation.rotate()可以将数组转过一个角度：</p><pre class=" language-python"><code class="language-python">inputs_plus10_img <span class="token operator">=</span> scipy<span class="token punctuation">.</span>ndimage<span class="token punctuation">.</span>interpolation<span class="token punctuation">.</span>rotate<span class="token punctuation">(</span>scaled_input<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">28</span><span class="token punctuation">,</span><span class="token number">28</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">,</span>cval<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">,</span>reshape<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span></code></pre><p>原来的numpy数字被重新转换成28*28的数组后，逆时针旋转10度，reshape=false可以防止将图像压扁。cval= 0意思是用零来填补旋转后多出的空白部分。把在源代码上加几行就行了。</p><pre class=" language-python"><code class="language-python"><span class="token keyword">for</span> e <span class="token keyword">in</span> range<span class="token punctuation">(</span>epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># go through all records in the training data set</span>    <span class="token keyword">for</span> record <span class="token keyword">in</span> training_data_list<span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># split the record by the ',' commas</span>        all_values <span class="token operator">=</span> record<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">','</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># scale and shift the inputs</span>        inputs <span class="token operator">=</span> <span class="token punctuation">(</span>numpy<span class="token punctuation">.</span>asfarray<span class="token punctuation">(</span>all_values<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">255.0</span> <span class="token operator">*</span> <span class="token number">0.99</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">0.01</span>        <span class="token comment" spellcheck="true"># create the target output values (all 0.01, except the desired label which is 0.99)</span>        targets <span class="token operator">=</span> numpy<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>output_nodes<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">0.01</span>        <span class="token comment" spellcheck="true"># all_values[0] is the target label for this record</span>        targets<span class="token punctuation">[</span>int<span class="token punctuation">(</span>all_values<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0.99</span>        n<span class="token punctuation">.</span>train<span class="token punctuation">(</span>inputs<span class="token punctuation">,</span> targets<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">## create rotated variations</span>        <span class="token comment" spellcheck="true"># rotated anticlockwise by x degrees</span>        inputs_plusx_img <span class="token operator">=</span> scipy<span class="token punctuation">.</span>ndimage<span class="token punctuation">.</span>interpolation<span class="token punctuation">.</span>rotate<span class="token punctuation">(</span>inputs<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">28</span><span class="token punctuation">,</span><span class="token number">28</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> cval<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">,</span> order<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> reshape<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>        n<span class="token punctuation">.</span>train<span class="token punctuation">(</span>inputs_plusx_img<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">784</span><span class="token punctuation">)</span><span class="token punctuation">,</span> targets<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># rotated clockwise by x degrees</span>        inputs_minusx_img <span class="token operator">=</span> scipy<span class="token punctuation">.</span>ndimage<span class="token punctuation">.</span>interpolation<span class="token punctuation">.</span>rotate<span class="token punctuation">(</span>inputs<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">28</span><span class="token punctuation">,</span><span class="token number">28</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">10</span><span class="token punctuation">,</span> cval<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">,</span> order<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> reshape<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>        n<span class="token punctuation">.</span>train<span class="token punctuation">(</span>inputs_minusx_img<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">784</span><span class="token punctuation">)</span><span class="token punctuation">,</span> targets<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># rotated anticlockwise by 10 degrees</span>        <span class="token comment" spellcheck="true">#inputs_plus10_img = scipy.ndimage.interpolation.rotate(inputs.reshape(28,28), 10, cval=0.01, order=1, reshape=False)</span>        <span class="token comment" spellcheck="true">#n.train(inputs_plus10_img.reshape(784), targets)</span>        <span class="token comment" spellcheck="true"># rotated clockwise by 10 degrees</span>        <span class="token comment" spellcheck="true">#inputs_minus10_img = scipy.ndimage.interpolation.rotate(inputs.reshape(28,28), -10, cval=0.01, order=1, reshape=False)</span>        <span class="token comment" spellcheck="true">#n.train(inputs_minus10_img.reshape(784), targets)</span>        <span class="token keyword">pass</span>    <span class="token keyword">pass</span></code></pre>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>李宏毅机器学习2021</title>
      <link href="2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/"/>
      <url>2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/</url>
      
        <content type="html"><![CDATA[<p>  原课程网址：<a href="https://www.bilibili.com/video/BV1Wv411h7kN?p=1">https://www.bilibili.com/video/BV1Wv411h7kN?p=1</a></p><p>本课程专注于深度学习。</p><h2 id="机器学习基本概念"><a href="#机器学习基本概念" class="headerlink" title="机器学习基本概念"></a>机器学习基本概念</h2><p>机器学习的本质是<strong>找到一个对应的函数</strong>。例如声音辨识，输入是声音，输出是文字，这种输入是非常复制的，无法用手写的方法表达，需要借助机器的力量。又如AlphaGo本质也是一个函数，输入是棋盘所有子的位置，输出是下一步落子的位置。</p><p>如果一个函数的输出是一个数值，找这个函数的任务叫<strong>回归</strong>（regression）。</p><p>如果给几个选项，让函数的输出选择几个选项，那么这种方法叫<strong>分类</strong>（classfication）。</p><p>如果机器学习要产生一个有结构的物件，例如画图，学文章，就是让机器学会创造（Structured Learning）</p><h3 id="找函数的步骤"><a href="#找函数的步骤" class="headerlink" title="找函数的步骤"></a><strong>找函数的步骤</strong></h3><p>首先需要一个猜测，这个猜测是建立在对其模型有一定程度上的了解的基础上的，然后再去计算其中的参数。然后用这个模型计算的结果和实际值对比，算出差距e，差距越大效果越差。衡量这种差距的函数叫做Loss：<br>$$<br>L = \frac{1}{N}\sum e_n<br>$$<br>其中e可以取$|y-\hat{y}|$，也可以取$(y-\hat{y})^2$。</p><p>可以根据不同的参数制作出关于Loss的等高线图来观察哪个参数的效果最好，这种图叫做Error Surface：</p><img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/1.png" class><p>然后我们要做的第三部是<strong>最优化</strong>的过程，任务是把使得Loss最小的参数找出来。在这门课中唯一用到的方法是梯度递减（Gradient Descent）。</p><img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/2.png" class><img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/3.png" class><p>梯度递减的方法是先让Loss函数对参数求导，这个导数为正时，我们就让这个参数减小一定数值，反之增大，导数越大其变化幅度也就越大，这个变换还要乘上我们自己设定的学习率。这样Loss每一步都会随之减小。但是缺点是只能找到局部最优解（local minima），而不一定找到全局最优解（global minima）。</p><p>这三个步骤合起来称为训练，是在已知数据的基础上进行的拟合，目标是用这个拟合的函数去预测不知道的数据。</p><h2 id="深度学习基本概念"><a href="#深度学习基本概念" class="headerlink" title="深度学习基本概念"></a>深度学习基本概念</h2><p>通过对模型运行结果的观察，我们对事物规律会越发了解，这时，我们就有必要更换模型来达到更准确的预测值。而上面用到的都是线性模型（Linear Model），都是权重（weight）乘以已知数据相加，然后再加上偏置值（bias）。这种拟合存在一定局限性（Model Bias）。没有办法模拟很多非线性的真实情况。</p><p>但是，一些折线都可以用常数项加上若干的线性函数组成。</p><img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/4.png" class><p>对于曲线也可以用若干的直线去逼近它：</p><img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/5.png" class><p>这些若干的函数可以用SIgmoid函数代替，通过调整不同的c,b,w的数值，就可以实现各种各样的sigmoid函数：</p><img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/6.png" class><img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/7.png" class><p>改变w可以改变sigmoid函数的倾斜程度，改变b可以使其左右移动，改变c可以改变其最终高度以及倾斜度。一系列这种函数的加和，就可以很好拟合出任意的函数：</p><img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/8.png" class><p>当系统大于一维的情况同理，只是不能用平面表示而已，这样由原来的线性拟合<br>$$<br>y= b+ \sum_jw_jx_j<br>$$<br>变成了：<br>$$<br>y= b + \sum c_i sigmoid(b_i + \sum_j w_{ij}x_j)<br>$$</p><img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/9.png" class><p>这个函数比较准确地拟合出多维输入的情况下的各种变换了。这个式子是神经网络的基础：<br>$$<br>y = b + c^T \sigma(b + Wx)<br>$$<br>其中里面所有自己定义的参数拿出来拼成一个很长的向量叫做θ。这样需要设定的参数会比原来的线性拟合多得多，这样我们的目标变成了，找到这么一个θ向量，使得Loss的值最小。</p><p>同样最优化的过程和线性拟合的方法一样，采用梯度下降法，不断更新参数，最终得到一个最优解。</p><img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/10.png" class><p>但是在实际操作时，可以对所有的数据进行分组，每次操作一组数据。每次用一组数据算loss进行参数的更新，称为一个update。当所有的数据都进行过一次更新时，称为一个epoch。此处运用的是随机梯度下降的算法。</p><img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/11.png" class><hr><p>如果我们不用Sigmoid函数，也可以直接使用专注分明的函数，我们称为ReLU（Rectified Linear Unit）。一个sigmoid要替换成两个ReLU才能做到一样的事情。</p><img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/12.png" class><p>式子变成<br>$$<br>y = b + \sum_{2i} c_i max(0,b_i+ \sum_j w_{ij}x_j)<br>$$<br>这里max和Sigmoid都称为激活函数（Activation Funcion）。接下来的实验都使用了ReLU，后面会解释为什么选择这种。</p><hr><p>我们可以继续改进模型。当我们把上面得出来的数据再进行同样形式的运算，具体做多少次取决于自己，第二层的参数又是于第一层完全不同的，这就是含有隐藏层的<strong>神经网络</strong>。层数越多，神经网络就越复杂，往往也能实现更多地逻辑，会得模型准确率提高，但是也会有过拟合的问题，注意层数要适当。</p><img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/13.png" class><p>这一套基于神经网络的技术，我们称为<strong>深度学习</strong>。</p><h3 id="反向传播（Backpropagation）"><a href="#反向传播（Backpropagation）" class="headerlink" title="反向传播（Backpropagation）"></a>反向传播（Backpropagation）</h3><p>参考视频：<a href="https://www.youtube.com/watch?v=ibJpTrp5mcE&amp;ab_channel=Hung-yiLee">https://www.youtube.com/watch?v=ibJpTrp5mcE&amp;ab_channel=Hung-yiLee</a></p><p>可参考另一篇文章《Python神经网络编程》</p><p>误差反向传播的方法是使用<strong>梯度下降法</strong>，即需要求总误差对一个权值的导数。当所在权值在输出层之前，那么：<br>$$<br>\frac{dE}{dw_{jk}} = - (t_k - o_k) * sigmoid(\sum_j w_{jk}o_j)(1-sigmoid(\sum_j w_{jk}o_j)) * o_j<br>$$<br>其中$t_k$为该权重对应输出节点的真实值，$o_k$为现在该输出节点预测值，$o_j$是隐藏层的输出值。更新权重为<br>$$<br>\Delta w_{jk} = \alpha * \frac{dE}{dw_{jk}}<br>$$<br>如果是更加前面层级的权重，更新方法为：先通过后面的层级一直往前推算，算出该权重后的一个节点的隐藏层误差，而这个误差的计算可以直接忽略激活函数，直接按照后面的权值的比例进行计算即可。然后再运用上面的公式。当然也可以运用链式法则不断的向前递推来算梯度，计算量会大一些。</p><p><strong>随机梯度下降</strong></p><p>损失函数不计算全部样本的，而是每次随机找一个样本计算。这个方法在更新的过程中有可能跨过鞍点到达全集最优，因此在神经网络中证明非常有效。但是由于每次只能计算一个样本，因此时间复杂度太高。因此我们在实际运用中取随机梯度下降的算法的时候，我们将两者结合，把样本分成一个个batch，分批进行训练。</p><h2 id="Google-Colab"><a href="#Google-Colab" class="headerlink" title="Google Colab"></a>Google Colab</h2><p>请参考我的另一篇文章《Google-Colab及其使用》。</p><h2 id="Pytorch教学"><a href="#Pytorch教学" class="headerlink" title="Pytorch教学"></a>Pytorch教学</h2><p><strong>这部分内容请务必参考我的另一篇文章《Pytorch教学及示例》。</strong>这篇文章不仅详细讲解了Pytorch的用法和手把手的实战教学，还浅显易懂的讲解了各种基础的深度学习模型，相信对你有很大帮助。</p><h2 id="作业一"><a href="#作业一" class="headerlink" title="作业一"></a>作业一</h2><p>请查看我的另一篇文章《用神经网络预测新冠确诊率》。</p><h2 id="训练注意事项"><a href="#训练注意事项" class="headerlink" title="训练注意事项"></a>训练注意事项</h2><p>在训练的时候要记住，务必不要用测试集的结果来调节你的模型，过多地根据测试集来调节模型会因为过拟合的问题，在测试集上表现好了，但是在应用的时候表现很差。因此在训练的时候我们不要让测试集进行参与，一般我们把训练集分成两部分，一部分用来训练，一部分用来验证，这时候我们可以用N折交叉验证的方法（N-fold Cross Validation）。先把训练集三等分，三分之一用来验证，三分之二用来训练，每次用不同的三分之一来验证，取这三种情况结果的平均值作为评价模型的标准，选出最好的模型，然后用最好的模型对全部的数据进行训练，这样就不会过拟合（overfitting）在测试集上。</p><img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/14.png" class><p>训练的模型还有一种情况使其在测试集上表现糟糕：那就是Mismatch，测试集和训练集的分布不同，也就是出现了反常的情况，以往的经验已经不能作为判断的标准，就算增加再多的训练资料也无济于事。</p><h2 id="类神经网络训练不起来怎么办"><a href="#类神经网络训练不起来怎么办" class="headerlink" title="类神经网络训练不起来怎么办"></a>类神经网络训练不起来怎么办</h2><h3 id="局部最小值和鞍点"><a href="#局部最小值和鞍点" class="headerlink" title="局部最小值和鞍点"></a>局部最小值和鞍点</h3><p>当一个神经网络的Loss不再下降时，可能是卡在了局部最小点（local minima），也可能卡在鞍点（saddle point），也有可能是局部最大点（local maxima）。这些点统称Critical Point。 在Critical Point时有导数为0但二阶导不为0， 有：</p><img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/15.png" class><img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/16.png" class><p>我们可以通过公式中二阶导的项的正负来判断具体是什么点，如果对于在CriticalPoint附近的任意θ，都使得这个二阶项大于0，即H是正定矩阵，该点一定是Local Minima。如果H是负定矩阵，那么该点一定是LocalMaxima。如果H非正定也非负定，那么该点是一个SaddlePoint。判定正定负定的标准只需看矩阵的特征值（eigen values）是全正还是全负即可。而这个矩阵叫做Hessian矩阵。H矩阵不仅指出了该点所处的状态，还指出了参数更新的方向。</p><img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/17.png" class><img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/18.png" class><p>结论：在处于鞍点时，只需要参数往负特征值对应的特征向量方向更新，就能找到更小的Loss。这就是当梯度为0的时候参数的更新方法。但通常我们在计算时不会采用这个方法，因为运算量过大。</p><p>在一个神经网络模型中，参数动即上百万上千万，我们在平面上遇到的局部最小点往往是高维中的鞍点，维度越高，就有越多的路可以走，因此对于一个参数较多的神经网络，阻碍训练进程的往往是鞍点，而不是局部最小点。</p><h3 id="batch"><a href="#batch" class="headerlink" title="batch"></a>batch</h3><p>结论：batch_size较大时，训练速度较快，但是训练结果较差，这是optimization的问题。batch_size较小时，训练速度较慢，但训练结果较好。原因是大batch_size容易卡在鞍点出不来，而小的batch_size因为每个batch的差异性，往往另一个batch就能越过原来batch的鞍点使得训练继续下去。而且采用大的batch_size时容易在测试集上表现较差，这就是overfitting。</p><img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/19.png" class><p>其中有一篇paper的解释是小的batch_size容易跳出较为狭窄的localMnima而倾向于宽阔的localMinima，而大的batch_size容易陷入狭窄的localMinima，而train出来的function和test或者实际的function是有差距的，而狭窄地带周围梯度较大，一点差距就会导致Loss迅速变大，泛化性变差。这就是为什么小的batch_size训练结果较好的原因。</p><h3 id="momentum"><a href="#momentum" class="headerlink" title="momentum"></a>momentum</h3><p>参考《深度学习中的优化算法串讲》。</p><h3 id="自动调整学习率"><a href="#自动调整学习率" class="headerlink" title="自动调整学习率"></a>自动调整学习率</h3><img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/20.png" class><p>在训练的后期往往会在localMinima的附近来回震动，导致Loss没有办法继续下降，这时就要改进我们的优化算法了。</p><p>如果在某一个方向上的梯度较大，那么我们的学习率调小一些也不会妨碍我们的学习进程，如果在某一个方向上的梯度较小，那么训练就难以展开，我们需要大一些的学习率来维持训练进度。</p><p>更新学习率有几种方法：</p><img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/21.png" class><p>一种是初始学习率除以一个以往梯度平方的平均值再开根号，可以满足上述要求。这就是Adagrad的方法。缺点是更新速度较慢，以及在过于平衡的地方呆太久时会出现学习率的暴增，冲出原来的点一段距离，然后再慢慢回到原点，往往隔一段时间就会出现一次学习率暴增的现象。</p><img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/22.png" class><p>第二个方法是RMSProp，用了指数加权移动平均的概念。我们可以调整α这一项来决定之前的梯度占用的比例。这个方法的学习率变化速度要比Adarad快得多，特别是训练后期。但还是会出现学习率暴增的现象。</p><img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/23.png" class><p>第三个方法是Adam，这个是最流行的算法，是Momentum和RMSProp的合体，性能比上面的都好得多。</p><img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/24.png" class><p>解决学习率暴增现象的一个方法是上面的初始学习率也可以动态调整，随着训练的进行慢慢调小（Learning Rate Dacay），可以解决这个问题。还一个方法叫做WarmUp，主张学习率先变大后变小。这是一个黑科技，很多论文都用这个方法，但不解释原因，但用了就是好。一个解释是开始的时候先让数据不要离原点太远，先进行一些探索，然后再决定方向。详细可以查看一篇RAdam的论文，有更多解释。</p><img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/25.png" class><p>这个RAdam就是现在我们要用的优化算法的最终版本。</p><img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/37.png" class><h3 id="两种Loss函数的-比较"><a href="#两种Loss函数的-比较" class="headerlink" title="两种Loss函数的 比较"></a>两种Loss函数的 比较</h3><img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/26.png" class><p>做分类需要用到的是one-hot向量而不是简单地用数字表示，我们期待输入对应的输出跟one-hot向量一致。</p><img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/27.png" class><p>这部分的内容可以参考《pytoch教学及示例》的logisitic回归的内容。softmax的作用是可以让y映射到0和1直接并且所有的输出节点的值加起来等于1。</p><p>这个时候有两个计算Loss的方法，一个是Mean Square Error（MSE），一个是交叉熵Cross Entropy，和最大化可能性等价（maximizing likelihood）</p><img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/28.png" class><p>这两个方法比较，交叉熵损失更为优秀，最常用在分类问题中，以至于softmax和Cross Entropy都被绑定成一个函数了。</p><img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/29.png" class><p>上图是比较当输出预测值y在两种方法相同的情况下，随着y的变化各种Loss的变化。在MSE中Loss较大和Loss较小的地方梯度都是很小的，即这就导致了如果初始点在左上角的话，训练的进展会非常缓慢，甚至会训练失败；而交叉熵损失即使在Loss较大的地方梯度都都仍然有明显的梯度变化，更利于训练。</p><h3 id="批次标准化（Batch-Normalization）"><a href="#批次标准化（Batch-Normalization）" class="headerlink" title="批次标准化（Batch Normalization）"></a>批次标准化（Batch Normalization）</h3><img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/30.png" class><p>通常梯度的变化跟输入的数据息息相关，即使w变化相同的范围，x的数值大小不同也决定y的变化不同，往往x较大的时候，对应的权重w变化一点点就会造成y巨大的变化，因此x的大小就是造成不同的w梯度变化不一的原因，而如果梯度都是这样大小不一的状态，我们一般的优化算法就很难得到好的结果。如果我们能限制x的范围，使得不同x尽量在一个数量级上，那么梯度的差距就不会这么明显，训练起来就更加容易。这些方法通常为Feature Normalization。</p><img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/31.png" class><p>步骤是计算输入x每一个维度的平均值和标准差，通过公式映射到（0，1）分布：<br>$$<br>\hat{x_i^r} = \frac{x_i^r - m_i}{\sigma_i}<br>$$<br>对每一个维度i都进行这样的变化，可以使训练更加顺利。在我的文章《pytorch教学及示例》中，对全部的x使用了这个映射。</p><img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/32.png" class><p>同理我们不仅可以对原来的x进行映射，我们也可以对x进行线性变化后的层进行映射，这样又有利于下一层的线性层进行训练，一般来说我们每次只用一个batch进行计算，这就是Batch Normalization。</p><p>如果不需要平均值是0，或许这样对训练会产生负面影响，我们可以再加入线性层进行调节。</p><img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/33.png" class><p>当程序真正上线应用的时候，我们需要对传进来的每一笔资料都做一次测试，我们无法等待凑足一个batch再进行测试，而不凑足一个batch是无法进行平均值和方程的计算的，也自然不能进行Batch Normalization。这是就需要用到往常的资料了：</p><img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/34.png" class><p>这就是根据以往的平均值和方差计算指数加权移动平均值的方式，这样就可以对新进来的测试数据进行标准化变换。</p><img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/35.png" class><p>可以看到，进行标准化处理的数据的训练速度要比没有做标准化处理的数据的训练速度快得多。</p><p>Batch Normalization不是唯一的标准化方法，还有一些方法如图：</p><img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/36.png" class><h2 id="卷积神经网络（CNN）"><a href="#卷积神经网络（CNN）" class="headerlink" title="卷积神经网络（CNN）"></a>卷积神经网络（CNN）</h2><p>这部分内容请参考《Pytorch教学及示例》，请和结合起来看，有非常详细的讲解。</p><p>如果对一张图像三个通道的每个像素都使用DNN进行链接，那么模型的弹性太大，很容易过拟合Overfitting。而对一张图片来说分类重要的是识别出图片中的某一个特征，而不局限于一个像素点，很多时候我们不需要看整张图片，只需要看图片的某一部分就可以很肯定地做出分类。因此模型弹性太大反而因为选择过多而坏事，根据样本的特点选择适合的模型可以使得模型的泛化性更强。</p><p>因此我们需要卷积核（kernel）对特征进行提取，一般的卷积核大小都是3<em>3的。也可以是其他n\</em>n的（n为奇数）。</p><p>在同一个通道内的所有区域都共享一个卷积核，因此当不同区域出现相似的特征时，它们的输出也将会是相似的，它们共用的这组参数叫做fiter。当三个卷积核分别扫描了三个通道过后，产生的值相加，这时就产生了一个Feature Map。这样的操作可以进行很多次，每一次都产生一个新的通道，具体计算之后产生多少个通道是我们自己决定了，n个通道就对应n个特征的提取，通道数越多，特征数提取的越多。有n个通道就有3<em>n个卷积核。上面就是一个卷积层的计算，模型中可以有很多个卷积层。这是因为一个图片特征的大小都是不固定的，如果在3\</em>3的区域内无法找到有效的特征，这就需要做第二次的卷积，由于第二次卷积是基于第一次卷积的特征结果之上的，第一次卷积已经把九个像素的内容重叠成一个特征了，因此如果第二次卷积也是用3*3的卷积核，它的特征提取范围将要比原来大一些，卷积层叠的越深，特征提取的范围越大。</p><p>第二个特征提取的方式是池化层Pooling，其实质是把图片缩小。方法是把图片分成一个个n*n的像素单元，然后每个单元取最大值代替整个单元，这就是最大池化（Max Pooling）。这样就能把图片的宽和高同时缩小n倍，使得数据量变小，特征更明显，但如果特征太小，这样做特征会丢失。所以池化层的层数和大小要控制。好处是大大减小数据量和运算量，如果硬件允许，甚至可以不用做Pooling。</p><p>经过若干层的卷积层和池化层以后，我们再把数据展平放进全连接层中，最后通过softmax输出。这样就完成了分类。</p><p>应用：AlphaGo，机器下围棋，围棋盘就可以看成一张图片，黑子看成1，白子看成-1，没有子看成0，输入就是19*19的Tensor，输出就是下一步落子的位置。我们用CNN比DNN效果更好。但实际上AlphaGo没有用1或-1这种简单的方式来表示输入，在AlphaGo论文中，每一个位置都用了48个元素来表示此时的状态。第一个输入用的是5*5的卷积核，而为了不遗失信息，没有用Pooling。</p><p>然而CNN有一个缺点，那就是不能处理图片放大缩小后的分类，分类的物品必须在图片上的大小保持一致才行。因此在训练的时候，数据要进行Data Augmentation。就是把图片进行旋转，翻转，放大，缩小的操作，再放入训练集中。</p><p>拓展：有一个架构Special Transformer Layer，可以处理图片放大缩小等操作后的识别问题。<a href="https://youtu.be/SoCywZ1hZak">https://youtu.be/SoCywZ1hZak</a></p><h3 id="拓展：半监督学习"><a href="#拓展：半监督学习" class="headerlink" title="拓展：半监督学习"></a>拓展：半监督学习</h3><p>我们可以在将已知标签的数据训练好模型后，对为标签的数据进行预测，在预测的数据中挑选出比较可信的数据用预测的结果再加入训练中，这样有可能得到准确率更高的模型。</p><h3 id="Special-Transformer-Layer"><a href="#Special-Transformer-Layer" class="headerlink" title="Special Transformer Layer"></a>Special Transformer Layer</h3><p>这也是神经网络中的一个层，接在CNN的前面负责对图像的缩放旋转的处理。</p><img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/55.png" class><img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/56.png" class><img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/57.png" class><img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/58.png" class><p>因此只要用一个2*2矩阵加上一个二维向量作为参数，输入一张图片的灰度的索引，输出的索引就可以让一张图片任意旋转缩放。</p><img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/59.png" class><img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/60.png" class><p>待完善。。。。</p><h2 id="自注意力转移机制（Self-attention）（未经验证）"><a href="#自注意力转移机制（Self-attention）（未经验证）" class="headerlink" title="自注意力转移机制（Self attention）（未经验证）"></a>自注意力转移机制（Self attention）（未经验证）</h2><p><a href="https://www.bilibili.com/video/BV1Wv411h7kN?p=24&amp;spm_id_from=pageDriver">https://www.bilibili.com/video/BV1Wv411h7kN?p=24&amp;spm_id_from=pageDriver</a></p><p>这部分内容请参考《pytorch教学及示例》的RNN部分。很多事情Self attention可以取代RNN。从运算速度来说Self Attention会更有效率。</p><p>这部分内容往往用在自然语言处理中。如果每次输入的序列长度不一怎么处理？而且输出不仅考虑一个输入，还需要考虑一整个seqence的资讯。</p><img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/38.png" class><p>我们需要两两计算两个输入的相关程度，通过softmax输出。</p><img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/40.png" class><p>比较常见的是用Dot-product:</p><img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/39.png" class><img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/41.png" class><img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/47.png" class><p>其中里面的参数都可以通过梯度下降法自行调整，如果a1和a2相关性较高，那么a’12就会趋近于1，b1的值也就会趋近于v2。</p><p>这样重复多次这样的步骤就能计算每个b。</p><img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/42.png" class><img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/43.png" class><img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/44.png" class><p>每个输入可以弄更多的q,k,v，一组参数可以看成负责一个相关性，可以得到更好的效果。最后再把多个b进行线性变化变成一个b送到下一层。</p><img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/45.png" class><img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/46.png" class><p>这个时候，这个网络是没有位置的信息的，例如输入几个字这个字是在句首句尾是判断不出来的。如果你决定位置信息是分类的重要依据，就要把位置信息加进去，你可以为每一个位置设置不同的Vector,然后把这个信息直接加进输入中就行了。这个Vector是人为设计的，叫做（Positional Encoding），这是尚待研究的问题。</p><p>其实CNN是Self-attention的特例，Self-attention设置特定的参数可以做到和CNN一样的事情。</p><h3 id="拓展：LSTM（Long-Short-term-Memory）"><a href="#拓展：LSTM（Long-Short-term-Memory）" class="headerlink" title="拓展：LSTM（Long Short-term Memory）"></a>拓展：LSTM（Long Short-term Memory）</h3><img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/61.png" class><img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/62.png" class><img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/63.png" class><img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/64.png" class><img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/65.png" class><img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/66.png" class><p>待完善。。。。。。</p><h3 id="拓展：GNN（Graph-Neural-Network）"><a href="#拓展：GNN（Graph-Neural-Network）" class="headerlink" title="拓展：GNN（Graph Neural Network）"></a>拓展：GNN（Graph Neural Network）</h3><p>self Attention 可以用在Graph上面。</p><img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/48.png" class><p>在Graph中输入和输入直接的连接关系是事先就已经订好的，因此我们只需要计算有关系节点之间的α值，没有关系的直接设为0，有关系的再由网络训练得到具体的数值。</p><img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/67.png" class><p>待完善。。。。。。。</p><h2 id="研究领域：（Unsupervised-Learning-Word-Embedding）"><a href="#研究领域：（Unsupervised-Learning-Word-Embedding）" class="headerlink" title="研究领域：（Unsupervised Learning:Word Embedding）"></a>研究领域：（Unsupervised Learning:Word Embedding）</h2><img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/49.png" class><p>在NLP领域，如果每个词都用一个one-hot向量来表示会导致输入的维度过大，计算量过大，并且没有办法表示词与词之间的关系，我们倾向于把它们映射到一个更小维度的向量中，这个向量是比较连续的，它们直接的距离就代表了相关性。这是一种聚类，无监督学习。</p><p>首先这个算法需要阅读大量的文章。如果两个词语常常一起出现，那它们的距离会比较接近，因此我们会尽量找两个向量使它们接近，这就是Count based。还有一种叫做Prediction based。我们输入前一个单词的one-hot向量，通过模型计算下一个最有可能出现的单词，输入的one-hot向量可以用过线性变化转换为更低维的稠密的向量，进行输入，通过大量的文章的学习，由于这两个不同输入的学习到的输出是相近的，因此这个稠密的向量在梯度下降法的学习下会变得更加相近。</p><img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/50.png" class><img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/51.png" class><img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/52.png" class><img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/53.png" class><img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/54.png" class><p>待完善。。。。。。。。。。。。</p><h2 id="Transformer"><a href="#Transformer" class="headerlink" title="Transformer"></a>Transformer</h2><p>Transformer的中文意思是变形金刚，它是一个sequence-to-sequence的model，也就是说输入是一个序列，输出也是一个序列，但我们不知道输出序列的长度。一个应用是语音辨识。输入语音信号所转换的Vector，输出对应的文字。输入的长度和输出的长度没有绝对的关系。另一个是机器翻译，输入一个语言的句子，输出另一个语言的句子。还有一个是语音翻译，例如声音讯号是英文，输出的是中文的文字，这在对于有些没有文字的语言尤其适用。许多问题都可以用sequence-to-sequence的方法硬做，例如给一个句子分析语法结构。又例如给机器一张图片，把图片中所有物体选出来分类。</p><img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/68.png" class><p>一般的sequence-to-sequence分为两块，一块Encoder，一块Decoder。</p><p>Encoder的作用是输入一排向量，输出另外一排个数相同的向量，用的是self-attention。</p><img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/69.png" class><img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/70.png" class><p>其中一个Block包含着一个Self-attention和一个fully-connectted，但实际上Transformer还要更复杂一些。</p><img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/71.png" class><p>在Transformer的Block中，self-attention和fully-connected都要进行残差连接（residual connection），然后还要进行标准化normalization映射到（0，1）分布，注意这里做的是layer-normalization而不是batch-normalization。同时在输入之前还要加上Input-Embedding来进行词嵌入，然后进行Positional-Encoding来加入位置信息。</p><p>接下来讲解Decoder的部分，这里有两种，着重介绍Autoregressive（自回归）的Decoder。首先我们需要把Encoder的信号读进去，然后给一个开始信号，输出一个结果，然后把这个结果作为下一次的输入来尝试下一个输出，这样反复下去。</p><img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/72.png" class><img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/73.png" class><p>可以看到Encoder和Decoder的区别不是很大，其中中间多了一个步骤，self-attention也略有不同。</p><img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/74.png" class><p>也就是说Masked-Self-attention不能像self-attention一样每个b1都由四个a决定，b只由前面的a决定而不能受后面的a影响。以b2为例：</p><img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/75.png" class><p>这是由于前一个的输出当做后一个的输入。所以在计算b的时候根本不能把后面的a考虑进来，因为只有计算了前一个b才存在后一个a。</p><p>接下来的问题是确定输出的长度。为了让输出停下来，我们需要确定终止符，当输出的向量为这个终止符时，不再继续输出结果，这个终止符和起始符可以共用一个向量。这就是Autoregressive-Decoder的运作方式。</p><p>如果是Non-Autoregressive的Decoder（NAT）。我们可以一次性输入一排的起始符来产生一排输出。但是没有办法知道应该输出几个字，需要另外的Classifier来输入Encoder的输入产生一个数字的输出决定Decoder的输入输出序列的长度。或者另外的处理办法是假设输出的长度不大于300，可以令输入序列为300个起始符，当输出产生终止符时则忽略后面的输出。</p><p>NAT的好处是不用一个个字产生结果，一个步骤产生完整句子，速度比AT要快，而且能够控制输出的长度。但是AT的表现往往比NAT要好。</p><p>然后接下来是Decoder的下一个部分，也是和Encoder最大的不同之处，这是连接Encoder和Decoder的桥梁。其中的两个输入来自Encoder一个输入来自上一个Masked-Self-attention块。</p><img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/76.png" class><p>上图就是Muti-head-Attention的运作过程，Encoder输出序列中的每一个输出都通过线性变换产生两个输出，然后和q做cross-attention，这也是一种self-attention，输出一个向量，然后再把这个向量丢到下一个线性层进行处理。然后把最后的输出结果再丢进Decoder做相同处理。</p><p>在训练的时候：</p><img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/77.png" class><hr><p>有的时候，例如聊天机器人，输出的语句只需要从输入中复制，这样训练较为容易：</p><img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/78.png" class><hr><img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/79.png" class><hr><img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/80.png" class><img src="/2021/05/07/li-hong-yi-ji-qi-xue-xi-2021/81.png" class><hr><h2 id="生成对抗网络（GAN）"><a href="#生成对抗网络（GAN）" class="headerlink" title="生成对抗网络（GAN）"></a>生成对抗网络（GAN）</h2><h2 id="自监督式学习（Self-supervised-Learning）"><a href="#自监督式学习（Self-supervised-Learning）" class="headerlink" title="自监督式学习（Self-supervised Learning）"></a>自监督式学习（Self-supervised Learning）</h2><h2 id="强化学习（Reinforcement-Learning）"><a href="#强化学习（Reinforcement-Learning）" class="headerlink" title="强化学习（Reinforcement Learning）"></a>强化学习（Reinforcement Learning）</h2><p>这几部分的内容是我的特别是RL是我的研究重点，我另开文章进行叙述。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>卡尔曼滤波器</title>
      <link href="2021/04/29/qia-er-man-lu-bo-qi/"/>
      <url>2021/04/29/qia-er-man-lu-bo-qi/</url>
      
        <content type="html"><![CDATA[<p> 卡尔曼滤波器是一种最优化递归数字处理算法（Optimal Recursive Data Processing Algorithm），更像是观测器。应用十分广泛，特别是在导航中。这是一种利用线性系统状态方程，通过系统输入输出观测数据，对系统状态进行最优估计的算法。由于观测数据中包括系统中的噪声和干扰的影响，所以最优估计也可看作是滤波过程。</p><p>原因是世界存在非常多的不确定性。一是不存在完美的数学模型，二是系统的扰动往往是不可控的，也很难建模的。三是传感器本身存在误差。</p><h2 id="递归算法"><a href="#递归算法" class="headerlink" title="递归算法"></a>递归算法</h2><img src="/2021/04/29/qia-er-man-lu-bo-qi/1.png" class=""><p>可以看到，随着测量次数的增加，最后一次测量结果会变得越来越不重要，也就是说k越大，新的估计值越接近上一次的估计值，反之则接近这一次的测量值，<strong>k反应了这两个数据的重要程度</strong>。把其中的$\frac{1}{k}$表示成一个系数后：</p><img src="/2021/04/29/qia-er-man-lu-bo-qi/2.png" class=""><p>其中的$k_k$就是卡尔曼增益/因数，这次的估计值只和上一次的估计值和这一次的测量值有关，这是一种递归算法，不需要追溯很久以前的数据。</p><img src="/2021/04/29/qia-er-man-lu-bo-qi/3.png" class=""><p>关于卡尔曼增益的公式是卡尔曼滤波器的核心公式。它和上一次的估计误差，以及这一次的测量误差有关，当上一次的估计误差较大，则$k_k$趋近于1，这一次的估计值会越接近这一次的测量值。当这一次的测量误差较大，$k_k$趋近于0，这一次的估计值会趋近于上一次的估计值。</p><p>因此解决问题步骤如下（相关公式推导会在后面章节给出）：</p><ol><li><p>计算$Kalman Gain $：<br>$$<br>k_k = \frac{e_{EST_{k-1}}}{e_{EST_{k-1}} + e_{MEA_k}}<br>$$</p></li><li><p>计算这一次的估计值：<br>$$<br>\hat{x_k} = \hat{x_{k-1}} + k_k(z_k - \hat{x_{k-1}})<br>$$</p></li><li><p>更新这一次的估计误差：<br>$$<br>e_{EST_{k}} = （1-k_k）e_{EST_{k-1}}<br>$$</p></li></ol><img src="/2021/04/29/qia-er-man-lu-bo-qi/4.png" class=""><p>在不断地递归计算中，可以得出越来越接近真实值的结果。</p><img src="/2021/04/29/qia-er-man-lu-bo-qi/5.png" class=""><h2 id="数学基础"><a href="#数学基础" class="headerlink" title="数学基础"></a>数学基础</h2><h3 id="数据融合（Data-Fus’ion）"><a href="#数据融合（Data-Fus’ion）" class="headerlink" title="数据融合（Data Fus’ion）"></a>数据融合（Data Fus’ion）</h3><img src="/2021/04/29/qia-er-man-lu-bo-qi/6.png" class=""><img src="/2021/04/29/qia-er-man-lu-bo-qi/7.png" class=""><img src="/2021/04/29/qia-er-man-lu-bo-qi/8.png" class=""><p>根据两个称的结果，我们对真实数据进行了预测，这个预测是30.4g，并且在数学上证明了这是最优解。这种把数按一定权重融合在一起进行预测的方法就是数据融合。融合后的图形具有更小的标准差，预测更准确。</p><h3 id="协方差矩阵（Covarince-Matrix）"><a href="#协方差矩阵（Covarince-Matrix）" class="headerlink" title="协方差矩阵（Covarince Matrix）"></a>协方差矩阵（Covarince Matrix）</h3><p>$$<br>cov(X,Y) = \frac{\sum_{i=1}^n (Xi-\bar{X})(Y_i - \bar{Y})}{n-1}<br>$$</p><p>协方差的意义：如果结果为正值，则说明两者是正相关的（从协方差可以引出“相关系数”的定义）。如果结果为负值， 就说明两者是负相关。如果为0，则两者之间没有关系，就是统计上说的“相互独立”。 </p><p>协方差矩阵把方差、协方差在一个矩阵中表现出来，它表现了变量之间的联动关系。</p><img src="/2021/04/29/qia-er-man-lu-bo-qi/9.png" class=""><p>通过矩阵运算计算协方差：</p><img src="/2021/04/29/qia-er-man-lu-bo-qi/10.png" class=""><p>举例：</p><img src="/2021/04/29/qia-er-man-lu-bo-qi/11.png" class=""><p>可以看出球员身高、体重、年龄的方差都较大，说明职业球员和这三方面的关系不大。体重和身高的协方差较大，说明体重和身高的相关性较大。年龄和体重、身高的协方差较小，说明虽然它们正相关，但相关性较小。</p><h3 id="状态空间表达（State-Space-Representation）"><a href="#状态空间表达（State-Space-Representation）" class="headerlink" title="状态空间表达（State Space Representation）"></a>状态空间表达（State Space Representation）</h3><p>具体内容可查看《现代控制理论精讲》的内容。</p><img src="/2021/04/29/qia-er-man-lu-bo-qi/12.png" class=""><img src="/2021/04/29/qia-er-man-lu-bo-qi/13.png" class=""><p>世界因为充满了不确定性，我们的模型不准确，就需要在状态空间方程后面加上一项，前面的模型加上过程噪音（Process Noise），后面有用测量误差，需要加上测量噪音（Measurement Noise）。在这两个不确定的情况下，如何去估计一个精确的$\hat{x}$，这就是卡尔曼滤波器要解决的问题。</p><h2 id="卡尔曼增益详细数学推导"><a href="#卡尔曼增益详细数学推导" class="headerlink" title="卡尔曼增益详细数学推导"></a>卡尔曼增益详细数学推导</h2><p>首先记住方差和期望的公式：<br>$$<br>D(X) = E[(X-E(x))^2] = E[X^2-2XE(X)+[E(x)]^2] = E(X^2)-[E(x)]^2<br>$$<br>同理，协方差：<br>$$<br>cov(X,Y) = E[(X-E(X))(Y-E(Y))] = E(XY) - E(X)E(Y)<br>$$<br>在上一章中，我们发现因为不确定性系统附有过程噪音$w_{k-1}$和测量噪音$v_{k}$。<br>$$<br>x_k = Ax_{k-1} + Bu_{k-1}+ w_{k-1}<br>$$</p><p>$$<br>z_k = Hx_k + v_k<br>$$</p><p>过程噪声和测量噪声都是不可测的，但是我们可以假设它符合正态分布。因此它的概率分布符合$P(w)~(0,Q)$，其中0代表期望，Q是协方差矩阵,求法：<br>$$<br>Q = E[w  w^T] = E[\begin{matrix} w_1^2 &amp; w_1w_2 \ w_2w_1 &amp; w_2^2 \end{matrix}] =[\begin{matrix} E(w_1^2) &amp; E(w_1w_2) \ E(w_2w_1) &amp; E(w_2^2) \end{matrix}] = [\begin{matrix} \sigma_{w1}^2 &amp; \sigma_{w1}\sigma_{w2} \ \sigma_{w2}\sigma_{w1} &amp; \sigma_{w2}^2 \end{matrix}]<br>$$<br>注意里面的$\sigma_{w1}\sigma_{w2}$不是两个标准差相乘，而是协方差。$v_k$的协方差矩阵为R，算法同上。</p><p>由于噪音是没办法建模的，我们只能去掉噪音计算直接计算（像往常一样），得出来的值称为<strong>先验估计值</strong>$\hat{x_k^-} $：<br>$$<br>\hat{x_k^-} = A\hat{x_{k-1}} + Bu_{k-1}<br>$$</p><p>$$<br>\hat{x_{kmea}} = H^{-1} z_k<br>$$</p><p>这样$x_k$存在两个结果，一个是算出来的，一个是测出来的。这两个结果都是不准确的，因此卡尔曼滤波器的任务是从这两个不太准确的结果，来得出一个更加准确的结果。这里称为后验估计值$\hat{x_k}$：<br>$$<br>\hat{x_k} = \hat{x_k^-} + G(H^{-1} z_k - \hat{x_k^-})<br>$$<br>G是0到1的一个数，这个数决定了估计值是偏向于算出来的结果还是测出来的结果。教科书上令$G=k_kH$，则有：<br>$$<br>\hat{x_k} = \hat{x_k^-} + k_k( z_k - H\hat{x_k^-})<br>$$<br>这里$k_k = GH^{-1}$的取值范围是[0,$H^{-1}$]，这是一个矩阵。同样当这个数趋近0时更相信算出来的结果，当趋向$H^{-1}$时更相信测出来的结果。</p><p><strong>目标：选择一个合适的$k_k$，使得新的估计值趋向于实际值</strong>。</p><p>为了量化误差，引入$e_k$，同样它符合正态分布$p(e_k)~(0,P)$：<br>$$<br>e_k = x_k - \hat{x_k}<br>$$</p><p>$$<br>P = E[e  e^T] = E[(x_k - \hat{x_k})(x_k - \hat{x_k})^T] =  [\begin{matrix} \sigma_{e1}^2 &amp; \sigma_{e1}\sigma_{e2} \ \sigma_{e2}\sigma_{e1} &amp; \sigma_{e2}^2 \end{matrix}]<br>$$</p><p>为了使得估计值和实际值的差距最小，必须使得数值的方差最小。因此我们目标是<strong>选取合适的$k_k$使得这个P矩阵的迹$tr(P)$最小</strong>，方差就是最小的。</p><img src="/2021/04/29/qia-er-man-lu-bo-qi/14.png" class=""><p>计算出来$x_k - \hat{x_k}$代入原式：</p><img src="/2021/04/29/qia-er-man-lu-bo-qi/15.png" class=""><p>之后是分布求每个部分的期望：</p><img src="/2021/04/29/qia-er-man-lu-bo-qi/16.png" class=""><p>然后开始计算迹$tr(P)$：</p><img src="/2021/04/29/qia-er-man-lu-bo-qi/17.png" class=""><p>在对迹进行矩阵求导时，我们需要储备线性代数矩阵求导的知识：</p><img src="/2021/04/29/qia-er-man-lu-bo-qi/18.png" class=""><p>然后求极值点，迹对矩阵求导：</p><img src="/2021/04/29/qia-er-man-lu-bo-qi/19.png" class=""><p>最后得出结论：<br>$$<br>k_k = \frac{P_k^- H^T}{HP_k^-H^T + R}<br>$$<br>其中$P_k^-$是$e_k^-$的协方差矩阵，R是噪声矩阵的协方差矩阵，H是测量矩阵。</p><p>当R越大时，说明噪声方差特别大，因此$k_k$会趋近于0，估计值趋近计算值。当R特别小时，$k_k$趋近于$H_{-1}$，估计值趋近于测量值。</p><h2 id="误差协方差矩阵数学推导-卡尔曼滤波器的五个公式"><a href="#误差协方差矩阵数学推导-卡尔曼滤波器的五个公式" class="headerlink" title="误差协方差矩阵数学推导_卡尔曼滤波器的五个公式"></a>误差协方差矩阵数学推导_卡尔曼滤波器的五个公式</h2><p>复习：</p><p>原系统：<br>$$<br>x_k = Ax_{k-1} + Bu_{k-1} + w_{k-1}<br>$$</p><p>$$<br>z_k = Hx_k + v_k<br>$$</p><p>其中w~P（0,Q），v~P（0,R）</p><p>先验估计：<br>$$<br>\hat{x_k^-} = A\hat{x_{k-1}} + Bu_{k-1}<br>$$<br>后验估计：<br>$$<br>\hat{x_k} = \hat{x_k^-} + k_k( z_k - H\hat{x_k^-})<br>$$<br>卡尔曼增益：<br>$$<br>k_k = \frac{P_k^- H^T}{HP_k^-H^T + R}<br>$$<br>上一章中，误差的协方差矩阵是我们还没有找出来的。<br>$$<br>e_k^- = x_k - \hat{x_k^-}  = A{x_{k-1}} + Bu_{k-1} + w_{k-1} - A\hat{x_{k-1}} - Bu_{k-1} = Ae_{k-1} + w_{k-1}<br>$$</p><p>$$<br>P_k^- = E[e_k^- (e_k^-)^T]<br>$$</p><img src="/2021/04/29/qia-er-man-lu-bo-qi/20.png" class=""><p>因此得出公式：<br>$$<br>P_k^- = AP_{k-1} A^T + Q<br>$$</p><img src="/2021/04/29/qia-er-man-lu-bo-qi/21.png" class=""><p>自此，卡尔曼滤波器的五个公式全部推导出来了。它分为预测和校正两个阶段，一开始要给x和P赋予一个初值，然后进行预测。通过预测得出x和P的先验值，通过这两个先验值可以进入校正阶段，求出卡尔曼增益和x的后验估计。最后还要更新一下误差协方差P。通过不断重复这两个阶段，x会逐渐趋近真实值。</p><h2 id="直观理解和二维实例"><a href="#直观理解和二维实例" class="headerlink" title="直观理解和二维实例"></a>直观理解和二维实例</h2><img src="/2021/04/29/qia-er-man-lu-bo-qi/22.png" class=""><p>在这个例子中，我们建立了一个人走路时关于位置和速度的数学模型，并且用卫星测量它。由于模型和测量的不准确性，存在一定的过程噪声，所以需要用到卡尔曼滤波器。</p><img src="/2021/04/29/qia-er-man-lu-bo-qi/23.png" class=""><img src="/2021/04/29/qia-er-man-lu-bo-qi/24.png" class=""><img src="/2021/04/29/qia-er-man-lu-bo-qi/25.png" class=""><p>可以看到，每一步的测量值和先验估计值通过卡尔曼滤波器之后，都可以得到一个更加准确的后验估计值。</p><p>卡尔曼滤波器是最优化的线性滤波器，用在线性系统中可以得到最优估计值。</p><h2 id="扩展卡尔曼滤波器（Extended-Kalman-Filter）"><a href="#扩展卡尔曼滤波器（Extended-Kalman-Filter）" class="headerlink" title="扩展卡尔曼滤波器（Extended Kalman Filter）"></a>扩展卡尔曼滤波器（Extended Kalman Filter）</h2><p>任务：将非线性系统线性化，然后才能使用卡尔曼滤波器。</p><img src="/2021/04/29/qia-er-man-lu-bo-qi/26.png" class=""><img src="/2021/04/29/qia-er-man-lu-bo-qi/27.png" class=""><img src="/2021/04/29/qia-er-man-lu-bo-qi/28.png" class=""><p><strong>这部分的理解待完善。。。</strong></p>]]></content>
      
      
      <categories>
          
          <category> 自控 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 自控 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>刻意练习读书笔记</title>
      <link href="2021/04/24/ke-yi-lian-xi-du-shu-bi-ji/"/>
      <url>2021/04/24/ke-yi-lian-xi-du-shu-bi-ji/</url>
      
        <content type="html"><![CDATA[<ul><li>练习并非不断重复，不断重复是“天真的练习”，无法带来进步。正确的练习需要好导师，有目标，有反馈…</li><li>无论何时练习都不晚，只要掌握正确的方法，梦想就能实现。</li></ul><h3 id="推荐序"><a href="#推荐序" class="headerlink" title="推荐序"></a>推荐序</h3><p>从来不存在一万小时定理，它仅仅是畅销书作家对心理科学研究的一次不太严谨的演绎而已。成功和练习时间不完全成正比，天赋虽然不起决定性作用，但也是一大影响因子。练习的成果也不和时间成正相关，取决于练习的方法。称为专家的时间也往往随着不同的专业技能领域而变化。</p><p><strong>长时工作记忆</strong>是区分卓越者和一般人的一个重要能力，这才是可以练习的指向和本质。首先刻意练习的<strong>任务难度要适中，能收到反馈，有足够次数的重复练习，学习者能够纠正自己的错误</strong>。多数不靠谱的成功学选择的是错误的练习方式，因为它们没有激活长时工作记忆，比如，下象棋的次数毫无作用，10个1万小时，也成不了国手，但是，如果看着已经发表的棋谱，推测国手的下法，这种刻意练习的方式，激活了长时记忆功能。</p><p><strong>认知复杂度高（销售、管理）与认知复杂度低（象棋、钢琴）的学习活动的差异很大程度上表现为隐形知识的多少和比重。</strong>隐形知识需要在情景中寻找。人的学习受情景的制约或促进。要把学习的知识应用在什么情境中，就应当在什么情景中学习。<strong>成人的最佳学习方式并非独自学习，而是在情景中学习。</strong>要点如下：</p><ul><li><strong>找到学习共同体</strong>：有效的学习不是关门苦练，而是找到属于自己的学习小团体，如程序员在GitHub这样的网站练习编程。</li><li><strong>隐性知识显性化</strong>：隐性知识使人们能利用概念解决现实问题，也称策略知识。</li><li><strong>模仿榜样</strong>：可以是现实的导师，也可以是网上的导师。</li><li><strong>培养多样性</strong>：在多种场景中实践。</li></ul><h3 id="天才存在吗"><a href="#天才存在吗" class="headerlink" title="天才存在吗"></a>天才存在吗</h3><p>天才是每个人与生俱来的才能，通过适当的方法，我们也一样可以充分利用。例如莫扎特的完美音高不是只有少数幸运儿才能拥有的天赋，而是一种只要经过适度的接触和训练，几乎人人都可以培养和发展的能力。天才只是比我们更多地利用了大脑和身体的适应能力而已。</p><p><strong>学习不再是挖掘某人潜力的方式，而是开发这种潜力的方式，我们可以创造自己的潜力。</strong>不论在什么行业和领域，提高表现与水平的最有效的方法，全部遵循一系列普遍原则，我们把这种通用的方法称为“刻意练习”。</p><h2 id="有目的的练习"><a href="#有目的的练习" class="headerlink" title="有目的的练习"></a>有目的的练习</h2><p>持续的刻意练习可以突破极限，各领域的杰出人物都靠大量练习，我们生活的这个世界，很多人都拥有超常的能力，胜过历史上任何时代的人们，会被当时的人们认为“不可能”。随着时代的发展，我们训练的方法越来越高级，训练的数量和精细度上与时俱进，使不同行业或领域的人们能力稳定提高。<strong>在任何行业中最有效的练习都通过充分利用人类身体和大脑的适应能力，逐步塑造和提升他们的技能，以做到一些从前不可能做到的事情。</strong>对刻意练习原则的运用是任何行业涉及训练方法的最佳方式。</p><p>但是，研究表明，一旦你已经达到令你自己满意的技能水平，而且能够自然而然表现出你的水平（即自动化），你就已经不再进步了。<strong>一旦某人的表现达到“可接受”的水平，并且可以做到自动化，那么，再多练习几年，也不会有什么进步。</strong>原因在于，如果没有刻意去提高，这些自动化的能力就会慢慢退化。</p><p>因此我们需要“有目的的练习”，所谓“天真的练习”，基本上只是反复做某件事情，并指望只靠那种反复，就能提高表现和水平。</p><ul><li><strong>有目的的训练需要有明确的目标</strong>，这可以有效引导你的练习。</li><li><strong>有目的的训练是专注的</strong>，想要取得进步必须把注意力集中在你的任务上。</li><li><strong>有目的的训练包含反馈</strong>，不论你在努力做什么事情，都需要反馈来准确辨别你在哪些地方还有不足，以及怎么会存在这些不足。</li><li><strong>有目的的训练需要走出舒适区</strong>，如果你从来不迫使自己走出舒适区，便永远无法进步。走出舒适区，意味要试着做一些自己以前没做过的事情，你会发现，一些没做过的事情做起来相对容易，你就会继续逼迫自己。有时遇到让你感到很困难的事情，想办法去逾越这些障碍，这是通向有目的的练习的隐藏钥匙。</li></ul><p>通常情况下，逾越障碍的方法不是“试着做更难的事情”，而是“<strong>试着做不同的事情</strong>”，不管什么障碍，越过它的最好办法是从不同方向去想办法，这也是需要导师的原因，因为他们可以为你提供克服障碍的方法。</p><p>有些时候，你根本不知道自己该做什么才能提高水平，你觉得那是不可逾越的障碍。但是，没有证据表明，在任何行业，人们真的会遇到绩效和表现完全不变的极限，但人们往往会在努力提高自己的时候放弃。这个时候的放弃并非是达到了极限，而是动机不足，<strong>要想办法保持你的动机</strong>。</p><p>有目的的训练还不够，人们通常忽略了练习中其他一些同等重要的方面。要改进各种类型的心理表现，至关重要的是心理结构的构建，这样可以避免短时记忆的局限，高效处理信息，例如高效的记忆方法。经过对特定的训练方法的研究之后，该方法已被证明是提高人们在各个领域的能力的最有效的方法，这就是“刻意练习”，后面会详细描述。</p><h2 id="大脑的适应能力"><a href="#大脑的适应能力" class="headerlink" title="大脑的适应能力"></a>大脑的适应能力</h2><p>大脑的结构和运行都会为了应对各种不同的心理训练而改变，就像肌肉和心血管系统响应体育运动一样。大脑就像肌肉，越练越大。长期从事一件事情的人比别人更擅长是因为大脑的对应区别变得更加的发达了。大脑和身体一样，拥有无限的适应能力。<strong>如果你是足够多地练习某件事情，你的大脑会改变某些神经元的用途，以帮助你完成那项任务</strong>。</p><p>人的身体有一种偏爱稳定性的趋向，单个细胞和组织在尽最大的努力使一切保存相同。当被迫走出舒适区后，细胞的生物化学反应和平常完全不同，它们通过提高细胞中不同的基因来适应，因为DNA大多数基因是不活动的，<strong>细胞打开和关闭对应的基因取决于那个时候需要什么</strong>。由系统改变细胞的行为，细胞和周围的系统就被迫走出了它们的舒适区。要使改变不断进行下去，就要给自己不断加码，如果不继续给自己施加压力，身体就会保持体内平衡，你将停下改进的脚步。</p><p>但是，如果在过长时间过分地逼迫自己，可能导致倦怠和学习低效。<strong>大脑和身体一样，处于舒适区之外但又离得不太远的“甜蜜点”上的挑战，改变最为迅速。</strong></p><ul><li>训练对大脑的影响，可能随着年龄的增长在几个方面有所不同：儿童和青少年的大脑比成年人的大脑更具适应能力，因此年纪越小，训练产生的影响越大。</li><li>超长时间的练习来发展大脑的某些部位，可能会导致大脑其他功能的退化。</li><li><strong>由训练引起的认知和生理变化需要继续保持</strong>，如果停止训练，它们会开始消失。</li></ul><p>对于刻意练习，我们的目标不仅仅是挖掘自己的潜力，而是要构筑它，让以前不可能做到的事情变得可能做到。下一个问题就是：挑战体内平衡和发展那种潜力的最佳方式是什么？余下的大部分内容会回答这个问题。</p><h2 id="心理表征"><a href="#心理表征" class="headerlink" title="心理表征"></a>心理表征</h2><p>国际象棋大师处理和解释棋子位置的方式，是心理表征的一个例子，他们和新手看到的是同一个棋盘，理解却全然不同。心理表征既使大师着眼于全局来观察，又使大师可以在必要时把注意力集中在具体的招法上，这就是“既见树木，又见森林”。</p><p>心理表征是一种与我们大脑正在思考的某个物体、某个观点、某些信息或者其他任何事物对应的心理结构，或具体或抽象。<strong>大多数的刻意练习包括创建更加有效的心理表征</strong>，例如你听到狗这个单词，便能想起狗的各种细节，这些信息被整合到一个全面的概念中；在体育运动上，也需要创建心理表征来事先想象当时的体位和动量给人的感觉是怎么样的，才能正确地控制身体的动作。</p><p><strong>心理表征是行业或领域特定的</strong>，只应用于专为它们而培养出来的技能。这些<strong>心理表征是信息预先存在的模式</strong>（比如事实、图片、关系、规则等等），这些模式存在于长时记忆中，用于有效且快速地顺应某些类型的局面。尽管短时记忆存在极限，但心理表征可以让人们迅速处理大量信息。每个人都拥有并使用心理表征，否则无法协调肌肉活动，无法生活下去。精心创建的心理表征的一个主要优势在于：你可以立刻吸收和考虑更多信息。</p><p>将杰出人物与其他人区分开的因素，正是前者心理表征的质量和数量。他们针对本行业中自己可能遇到的各种不同情况，创造了高度复杂和精密的表征。<strong>他们经过年复一年的练习，已经改变了大脑中的神经回路，以创造高度专业化的心理表征，使得令人难以置信的记忆，规律的识别成为可能，也使得他们能够培养和发展各种高级的能力，以便在特定的专业领域中实现卓越。</strong></p><p>心理表征的一个重要好处在于可以帮助我们处理信息：理解和解读它，把它保存在记忆中，组织它，分析它，并用它来决策。当你阅读一篇专业的文章，读完之后看自己记住了多少内容时，其结果并非取决于你的语言能力，而是<strong>取决于你个人对这个专业事物的理解或了解程度</strong>。</p><p><strong>心理表征可以用来为很多行业和领域做计划，表征越好，计划就越高效。</strong>杰出人物运用心理表征提高技能水平，监测并评估自己的技能水平，在必要时候调整心理表征，使之更加有效。</p><p><strong>心理表征有助于高效学习。</strong>学生之间的差别，在很大程度上取决于他们能够多敏锐的察觉自己所犯的错误，这也是心理表征的好处。<strong>技能和心理表征使一个良性循环：你的技能越娴熟，创建的心理表征就越好；而心理表征越好，就能更有效地练习，以磨炼技能。</strong></p><h2 id="黄金标准"><a href="#黄金标准" class="headerlink" title="黄金标准"></a>黄金标准</h2><p>在本章，我们探索所有方法中最有效的：刻意练习。它是黄金标准，对任何一个渴望学习某种技能的人们来说，都是理想的方法。</p><p>一些活动如：音乐演奏、数学等，必须采用高度发展的、被人们广泛接受的训练方法。如果某人谨慎勤奋地遵循这些方法，那几乎一定能称为该行业的专家，这些行业有几个共同的特点：</p><ul><li>对于<strong>绩效的测量，总是存在客观的方面</strong>。因为只有确切知道人们表现的提高的组成，才能提出改进表现的方法。</li><li>这些行业往往具有足够的<strong>竞争性</strong>，从业人员有强烈的动机来训练和提高。</li><li>这些行业通常都是已经<strong>形成规模</strong>的，相关技能已经得到数十年甚至数世纪的培养。</li><li>这些行业中，一些人还担任<strong>导师和教练</strong>，他们已经发展出日渐复杂的一整套训练方法，使得该行业的技能水平稳步提高。</li></ul><p>对提高水平产生影响的大多数因素，都需要付出艰辛努力，而且并非是那么有趣的因素。每个人都不喜欢艰苦的练习，之所以学生们激情四射进行练习，是因为他们发现，这样的练习是提高他们水平不可或缺的因素。<strong>最杰出的人是在各种有目的的练习中花了最多时间的人。</strong></p><p>刻意练习和其它有目的的练习有两个重要的区别，首先，它需要一个已经得到合理发展的行业或领域；其次，需要一位能够布置练习作业的导师。刻意练习有以下特点：</p><ul><li>刻意练习发展的技能已经有一套<strong>行之有效的训练方法</strong>，训练的方案应由导师乎或教练来设计和监督。</li><li>刻意练习发生在人们的<strong>舒适区之外</strong>，需要人们付出近乎最大限度的努力，一般并不使人心情愉快。</li><li>刻意练习<strong>包含特定目标</strong>，通常包括目标表现的各个方面，并非只是模糊的总体改进。一旦设立了总目标，导师会制订一个计划以实现一系列微小的改变，最后累积起来，实现之前期望的更大变化。并应当使从业者能够观察到他的表现和变化。</li><li>刻意练习需要人们<strong>完全地专注和有意识地行动</strong>，学生必须紧跟他的练习的特定目标，以便做出适当的调整，控制练习。</li><li>刻意练习<strong>包含反馈</strong>，以及应对反馈而进行的调整。在练习的早期，反馈来自导师，后面学生必须学会自己监测自己，发现错误并作出调整，这需要高效的心理表征。</li><li>刻意练习产生有效的心理表征，又依靠有效的心理表征，提高水平和改进心理表征<strong>相辅相成</strong>。</li><li>刻意练习致力于针对性提高技能的某些特定方面，构建或修改过去那些已经获取的技能，这种<strong>逐步的改进造就卓越的表现</strong>。</li></ul><p>在你所在的领域满足条件的情况下，应当采用刻意练习，否则也应尽量应用刻意练习的原则。</p><p>在你已经熟悉的领域，你应仔细思考杰出的表现有哪些特点，尝试<strong>采用一些方法进行度量</strong>，然后寻找所在行业中评分最高的人。理想情况是找到客观的、可复制的测量指标，以便前后一致地从普通从业者中挑选出最优异的从业者。思考他们到底做了什么，什么使得这个人和其他人表现不同，那些差别就可以解释他的杰出成就。你越是调整自己的练习方法，模仿自己行业中的杰出人物，你的练习也可能越是有效。并且，无论什么时候，最佳的方法几乎总是找一位优秀的导师。</p><p>虽然一万小时定律不完全正确，但在任何一个有悠久历史的行业，想要成就一番事业，成为领域中的杰出人物，需要付出许多年艰苦卓绝的努力，也许并不需要恰好一万小时，但也要花很长时间，这只为了与那些同类工作中同样勤奋的人有平等竞争的机会。而且人们成就的门槛在不断提高，潜力随之提高，没有迹象表明这个门槛不能再提高。</p><h2 id="在工作中运用刻意练习原则"><a href="#在工作中运用刻意练习原则" class="headerlink" title="在工作中运用刻意练习原则"></a>在工作中运用刻意练习原则</h2><p>要让练习变成日常工作的一部分，首先从思维方式开始改变，要提高绩效，需要辨认并拒绝三种流行的错误思想。</p><ul><li><strong>第一种错误思想是某人的能力通常受到基因的限制。</strong>在任何一个人们选择着重发展的行业，人人可以通过正确的训练帮助自己大幅度提高，我们可以塑造自己的潜力。</li><li><strong>第二种错误思想是如果你足够长时间做某件事情，一定会更加擅长。</strong>这样不是提高绩效和表现的秘诀，相反会使人停下前进的脚步，并且缓慢地下滑。</li><li><strong>第三种错误思想是想要提高，只需要努力。</strong>有很多技能，除非你运用一些专门用于提升那些特定技能的练习方法，否则即使加倍努力也无法取得进步。</li></ul><p>有一种方法是<strong>边干边学</strong>，商界人士都很忙，很难挤出时间练习技能，所以需要将练习融入工作，例如公司会议的幻灯片展示。这种方法的好处是它使人们熟悉练习的习惯，并思考如何练习。一旦理解了可以用练习实现多大的进步，他们找机会将其他商业活动转变成练习活动。到最后，练习成了日常工作的一部分。</p><p>用<strong>即时反馈</strong>（导师提出或精心设计的电脑程序提供）来强化的练习，可以成为提高绩效的强大方法。可以获得反馈，这是经验日渐丰富的原因。</p><p>很多时候，用反复多次的<strong>“离线练习”</strong>的方式练习使人们受益匪浅，这种练习并不是在真正的工作中练习，即使犯了错，也不会产生严重后果，因此可以使用仿真器等来提高技术水平。</p><p>传统的方法一直是先找出关于正确方法，然后再让学生应用。刻意练习只聚焦于绩效和表现，以及怎样提高绩效和表现。但是<strong>很多人过于重视知识，而不重视技能</strong>，主要原因是传统和方便：向一大群人介绍知识，比起创造条件让人们通过练习提升技能，要容易得多。例如医生已经花了15年时间接受教育，几乎所有的教育都聚焦于提供知识，而几乎没有直接运用他们行医之后的必备技能，一旦医学院毕业之后，又要花好几年学习课程，接触临床诊治，这才终于开始提升医学技能。其中<strong>最有效的练习方法是一些具有互动因子的练习</strong>，例如讨论小组，案例分析，实习培训等，效率最低的是说教式的练习，基本上是聆听讲座，但这个最常见的教育活动。原因在于缺少反馈，没有机会去尝试新的技能，纠错并发展新的技能。</p><p>很多人认为，只有简单积累更多知识，就能容易地熟练掌握技能，但实际上从业者会发现自己需要大量时间提升工作中的技能。在提高绩效和表现时，<strong>正确的问题是“我们怎样改进相关技能”，而不是“我们这样传授相关知识”。</strong></p><h2 id="在生活中运用刻意练习原则"><a href="#在生活中运用刻意练习原则" class="headerlink" title="在生活中运用刻意练习原则"></a>在生活中运用刻意练习原则</h2><h3 id="找导师"><a href="#找导师" class="headerlink" title="找导师"></a>找导师</h3><p>首先，<strong>需要找一位好导师</strong>。导师只是能够引导你达到他们或者他们学生曾经达到过的水平，不一定是最出色的，但应当在所在领域中具有一些技能和经验。导师可以做的最重要的事情是帮你创建心理表征，以便你能监测和纠正自己的表现。并且当你自己改变了的时候，可能会需要更换导师。</p><h3 id="专注和投入"><a href="#专注和投入" class="headerlink" title="专注和投入"></a>专注和投入</h3><p><strong>如果你在走神，或者你很放松，并且只是为了好玩，你可能不会进步。</strong>不专注，就没效果，这是最大限度改进你练习的秘诀。但是，人很难长时间保持专注，我们要指定明确计划，尽量把练习时间缩短，是更加迅速提升技能水平的最佳方式。<strong>在较短时间内百分百投入，比在更长时间百分之七十投入效果更好</strong>。一旦发现自己无法专注练习，就停下来，一定确保每天足够的睡眠，以便能够最大限度集中精力练习。</p><h3 id="没有导师时"><a href="#没有导师时" class="headerlink" title="没有导师时"></a>没有导师时</h3><p>没有导师怎么办？为了提高，我们必须自己创造机会，<strong>没有导师，你必须自己想出自己的练习。</strong>在这个互联网时代，我们很容易能找到人们感兴趣的大多数常见技能的练习方法。反复做同一件事，目的是<strong>找出你在哪些方面存在不足</strong>，并且聚焦在那些方面取得进步，而不是毫无目的一遍遍做同一件事情。试着采用<strong>不同的方法</strong>提高，直到你最终找到适合自己的方法。</p><p>练习技能时，记住三个F：<strong>专注(focus)、反馈(feedback)、纠正(fix it)**。将技能分解成一些组成部分，以便反复练习，并且有效分析，确定你的不足之处，然后想出各种方法解决它们。我们</strong>只有努力去复制杰出人物的成就，失败了就停下来思考为什么会失败**，思考其原因，如此一而再再而三地尝试，才能创建有效的心理表征。</p><h3 id="跨越停滞阶段"><a href="#跨越停滞阶段" class="headerlink" title="跨越停滞阶段"></a>跨越停滞阶段</h3><p>当你觉得自己的提升达到了瓶颈，<strong>要越过这种停滞阶段，最好的办法是以新的方式挑战你的大脑和身体。</strong>有些时候你发现自己再难以有所提高时，可能只是技能中的一两个组成部分在妨碍你。为了弄懂是哪个部分，首先要走出舒适区，逼自己一下，搞清楚自己的停滞点在哪里。然后设计一种特定的练习方法，专门改进那个特定的弱点。</p><h3 id="保持动机"><a href="#保持动机" class="headerlink" title="保持动机"></a>保持动机</h3><p><strong>保持动机是每个投入刻意练习中的人最终要面对的最大问题。</strong>有动机，练习才能持久。我们以为能够年复一年坚持高强度训练的人，可能具有一些罕见的“持之以恒”的品质，具有罕见的意志力，但这种假设是错误的。几乎没有科学证据证明，这个世间存在一种可在任何情形下运用的一般的“意志力”。意志力和天生才华，都是人们在事实发生了之后再赋予某个人的优点，无论什么情况，我们都不能在各种可能性成为现实之前作出这样的判断。因此，把问题聚焦在动机上，更加合理。</p><p>对于长期保持刻意练习的人来说，他们通常都<strong>培养了各种习惯</strong>，帮助自己前行。所有希望在某一领域提高技能水平的人，应当<strong>每天花1个小时或更多时间</strong>，专心练习那些需要全神贯注投入才能做好的事情，这是一条经验法则。动机包括两个组成：继续前进的理由和停下脚步的理由。你不再想做自己当初想做的事情，是因为停下脚步的理由战胜了继续前进的理由。**要保持动机，要么强化继续前进的理由，要么弱化停下脚步的理由。 **</p><p><strong>弱化停下脚步的理由最有效的是留出固定时间来练习，不受其他义务和分心的事情所干扰。</strong>杰出的同学比其他同学更能规划时间，更能准确估计参与休闲活动的时间。良好的规划，可以帮助你避免遭受许多占用的大量时间事情的干扰，以便把更多时间留给练习。要找出干扰你练习的事情，把其影响控制到最小，例如：如果你发现早晨的锻炼格外艰难，可以把锻炼安排到晚些时候；而难以在早晨开始练习的人们，往往没有获得足够的睡眠，理想情况是，你每天应当睡到自然醒并且起床后觉得神清气爽，如果不是这样，那应当早点上床睡觉。尽管任何一个特定的因素可能对你产生很微小的影响，但各种因素的影响是会累积的。<strong>杰出的人往往做两件有益的事情：一是保证充足的睡眠和保持健康。二是将练习课的时间限制在一个小时左右，过一个小时就休息，否则无法保持高度专注。</strong>随着时间的推移，继续练习会变得容易，身体和心理会适应那种感觉，越来越接近自然。</p><p>增强继续前进的理由：一旦你已经练习一段时间了，并且可以看到结果了，你对自己做的事情感到骄傲，从朋友的称赞中感到愉悦，这是你的身份感变了，你开始将自己看成公开演讲者，竖笛演奏者或折纸制作者，<strong>只要你能认识到这种新的身份来自你长时间的刻苦训练，那么进一步训练给你的感觉更像一种投资，而不是一种代价，这本身可以成为你动机的一部分。刻意练习另一个重要动机是相信自己可以成功。</strong>你必须相信你可以提高自己，跻身最优秀者的行列，这种信念的力量十分强大，甚至可以战胜现实。如果你不再相信自己可以实现某个目标时，要么是因为你陷入停滞状态，要么你的水平已经倒退了，此时千万不要半途而废。和你自己达成一个协议，你将尽自己的努力回归到之前的状态或跨越停滞阶段，然后你再放弃，到那个时候，或许你就不会放弃了。<strong>外部动机一种最强烈的方式是社会动机，最简单和最直接的是其他人的认可和崇拜。</strong>一种营造和保持社会动机的最好方法，是使你自己身边的人都支持，鼓励你的努力，这在由团体共同完成的活动中的活动最容易做到。将对同一件事情感兴趣的所有人聚集起来，或者吸引他们加入一个现有的群体，并且将团体的同志情谊和共同的目标作为达到你自己目标的额外动机，这使得人们拥有更多的额外动力，但要注意确保团体中的其他人也制订了和你类似的进步目标。</p><p>保持动机最好还要<strong>精心设置目标</strong>。将漫长的旅程分解成一系列可控的目标，并且每次只关注它们中的一个，甚至可以在每次达到一个目标时，给自己一个小小的奖励。总有一条路通向我们的梦想。刻意练习可以创造各种各样的可能性，大胆去闯，去试！</p><h2 id="成为杰出人物的路线图"><a href="#成为杰出人物的路线图" class="headerlink" title="成为杰出人物的路线图"></a>成为杰出人物的路线图</h2><p>本章使读者可以一步步观察，为了充分利用人类能力，接触人类能力的极限，需要做些什么。</p><h3 id="第一阶段：产生兴趣"><a href="#第一阶段：产生兴趣" class="headerlink" title="第一阶段：产生兴趣"></a>第一阶段：产生兴趣</h3><p>对未来的杰出人物来讲，他们小时候与自己感兴趣的任何事物之间的这种好玩的互动，是他们最终对这件事物充满兴趣的第一步。日后成为杰出人物的人的父母，在孩子的成长和发展阶段扮演了至关重要的角色。通常孩子不会自己去练习，但是通过边玩边练习的方式，孩子们在玩耍中踏入了追求卓越的道路。</p><p>兄弟姐妹也具有激励作用，一个孩子看到自己的哥哥姐姐在从事某项活动，并且获得父亲或母亲的关注和表扬时，自然也想加入进来，获得父母同样的关注和表扬。</p><h3 id="第二阶段：变得认真"><a href="#第二阶段：变得认真" class="headerlink" title="第二阶段：变得认真"></a>第二阶段：变得认真</h3><p>对某个行业感兴趣以后，通常要到导师那里上课了，这里大部分学生第一次接触到刻意练习。导师通常擅长激励学生，让学生通过刻意练习提高水平。同时父母也发挥重要作用，帮助孩子确定日程安排，并且可能采用一些较激进的措施（例如不上钢琴课就不能去游乐园），这个时候，未来的杰出人物都决定继续练习下去。虽然父母导师可以采用各种方式激励孩子，但<strong>最后那些动机必须来自孩子内心</strong>，否则它不会长久。</p><p>有些孩子在较大年龄中接触一个科目，这些科目的老师而不是孩子父母，第一次激发了孩子的兴趣，点燃了孩子的智力兴趣。由于这些孩子年龄更大一些，且在没有父母影响的前提下就已经对所学科目产生足够兴趣，因此几乎不需要父母的刺激或鼓励来完成家庭作业，并且能完成老师布置的所有作业。这个阶段的第一部分父母或老师的鼓励至关重要，但最后孩子开始体会到刻苦学习带来的回报，变得越来越能够进行自我激励，动机会开始从外部转向内部。尽管那些长大后才华横溢的艺术家依然需要父母和导师情感和技术的支持，但是他们都有着自我激励的动机从事繁重的工作。在到达这个阶段2~5年后，未来的杰出人物开始根据他们已经发展出来的技能来认同自己，而不再根据其他的兴趣领域来认同自己，他们对自己从事的练习开始认真起来。</p><p>不论如何，在某个领域中发展了特定技能的人们，经过年复一年的练习，都从技能的学习中获得了大量的愉悦感觉。也就是说，只有那些花了数年时间苦练某项技能的人，才能自然而然地喜欢那一技能。</p><h3 id="第三阶段：全力投入"><a href="#第三阶段：全力投入" class="headerlink" title="第三阶段：全力投入"></a>第三阶段：全力投入</h3><p>这个阶段要付出巨大的投入，才能成为自己领域中最杰出的人物，通常有最好的导师或学校指导自己的练习，直到基本能够尽最大可能改进为止，最终目标是接近人类能力的极限，跻身本领域最佳行列。这个阶段，动机完全靠学生自己保持，但家人依然能够发挥重要的支持作用。这个过程花费的代价也是巨大的，无论是时间成本和金钱成本都是难以估量的。但结束了这一艰辛旅程的学生也将获得巨大的回报。</p><h3 id="年龄和适应能力"><a href="#年龄和适应能力" class="headerlink" title="年龄和适应能力"></a>年龄和适应能力</h3><h4 id="身体适应能力受年龄影响大"><a href="#身体适应能力受年龄影响大" class="headerlink" title="身体适应能力受年龄影响大"></a>身体适应能力受年龄影响大</h4><p>在某些领域中，对于那些不从孩提时代开始练习的人们，永远无法练成，理解了这种限制，有助于确定你可能想在哪个领域发展。</p><p>其中最明显的是涉及体能的领域，对一般人而言，体能大约在20岁到达巅峰，随着年龄的增长，身体的柔韧性下降，变得容易受伤。但年龄也不是大家认为的参与体育比赛的限制，年纪大的人只是应当练习时间短一些，强度小一些，技能出现退化的原因很大程度是他们减少或停止了训练，如果定期参加训练，技能水平不会随着年龄增长出现大幅下降。在60多岁的马拉松跑步爱好者中，有四分之一的人可以击败一半以上年纪20~54岁的竞争选手。并且有人超过100岁时仍能在27秒完100米。</p><p>同时如果人们不从儿童时期开始锻炼，除了年龄增大而出现的体能缓慢下降，身体技能也会无法提升到卓越水平。20岁以后骨架结构固定，会对能力的培养有一定的限制。</p><h4 id="心理适应能力比身体更强"><a href="#心理适应能力比身体更强" class="headerlink" title="心理适应能力比身体更强"></a>心理适应能力比身体更强</h4><p>随着年龄的增大，身体的适应能力可能差了许多，但是心理的适应能力依然十分强大。</p><p>一个普遍经验是：随着年纪的增大，学习技能的方式也会发生改变，人类大脑在青少年早期拥有最多的脑灰质，从那以后脑灰质的数量会开始减少，神经细胞的突触会在人生早期达到最大数目，两岁孩子的突触比成年人多50%。大脑的持续改变，学习得以发生的背景也在改变。6岁的孩子，14岁孩子，即使学习同样的知识和成年人的学习方式都是不同的。因此如果成年人足够刻苦，大脑也会找到相应办法进行学习。大脑功能依旧可以十分强悍。</p><h3 id="第四阶段：开拓创新"><a href="#第四阶段：开拓创新" class="headerlink" title="第四阶段：开拓创新"></a>第四阶段：开拓创新</h3><p>有些人做出的杰出贡献，彻底改变了他们所在的领域和行业中现有的知识，做出了独特的创造性贡献，这个阶段也是人们最难理解和最由兴趣理解的阶段。</p><p>首先，创新者无一例外在各自的领域中工作了很长时间，已经成为杰出人物，然后再开始开辟新天地，毕竟新的成就都是站在巨人的肩膀上。这种创造性是刻意练习达到的另一个全新的高度。杰出人物创造新事物的过程中所采取的方式和他们一开始抵达那一界限时所采取的方式极为相似。创新是一个漫长、缓慢、反复的过程。在这过程中，没有这些杰出人物认为的重大飞跃，<strong>他们的进展，只有在局外人看来才是重大进展，因为那些人没有见证过那些微小的进展。而正是这些微小的进展，才能积累成重大的飞跃。</strong>没有大量艰苦卓绝的努力，那些令人惊奇的时刻也不会存在。“不积跬步，无以至千里。不积小流，无以成江海。”</p><p>此外，他们的创造力和工作中保持专注是分不开的，这恰好也是刻意练习的重要组成部分。行业也正是依赖着这些杰出人物，才能不断前进。</p><h2 id="怎样解释天生才华"><a href="#怎样解释天生才华" class="headerlink" title="怎样解释天生才华"></a>怎样解释天生才华</h2><p>杰出人物通过年复一年的刻意练习，在漫长艰苦的过程中一步步改进，终于成就了他们杰出的能力，没有捷径可走。有的人为什么能够最终培养出比别人更强的能力，实际上，刻意练习发挥主要作用，天生的特征比许多人认为的发挥的作用要小得多。没有人能够不经过高强度和广泛的练习，便能培养出杰出的能力。现实中不存在不需要刻苦训练或者严谨的提高，就能称为世界一流。例如自闭症奇才他们训练时的方式，调用了大脑的适应能力，反过来改变了大脑的结构，使他们培养了杰出的能力，自闭症使得他们比普通孩子更加注重细节，更可能孜孜不倦进行练习，这和专门刻意练习的人采用的方式是一样的。跳高天才、音乐天才等小时候无不经历了家庭的熏陶或者刻苦的练习。</p><p>相对地，也有一些人被认为天生就不具备某种才能。例如音盲，唱不好歌。其实原因通常只是他们从来没有练习过，没有想办法提高自己的技巧。人们停下学习和进步的脚步，并不是因为他们达到了某种天生的极限，而是因为他们停止了训练，或者出于某种原因，从来没有开始过训练。</p><p>研究表明，智商和棋艺无关，训练时间比智商更加重要。当孩子刚刚学习国际象棋时，智商可以在他们快速学习达到一定棋力发挥作用。有了足够的单独练习，棋手们的心理表征十分有益和强大，区分两位棋手的最重要因素不再是他们的智商，而是心理表征的质量和数量，以及有效运用这些表征。<strong>心理表征的作用远比简单运用记忆力和逻辑有效得多。</strong>而心理表征往往是通过数千小时的刻意练习积累起来的。</p><p>在训练早期，智力的确发挥着作用，智力更高的孩子更胜一筹。智力更低的孩子，练习需要更加刻苦一些，会养成比同伴练得更多的习惯，而智商较高的孩子，最初并没有感受到这种要去追赶别人的压力，更加勤奋的孩子最终会超过那些智商较高的孩子。因此，<strong>从长远看，占上风的是练习更加勤奋的人，而不是一开始在智商或者其他方面才华稍有优势的人。</strong>智商较高的孩子可能会比智商较低的孩子在科学课上的成绩好一些，但是在那些已经成为某领域专家的人中，智商并不占优势。</p><p>事实上，如果说人与人之间存在一种基因的差异，影响到某些人的表现，这些差别也不可能直接作用于相关的技能，最有可能是通过发展某技能所必须付出的练习和努力来表现。例如有的孩子天生能从绘画或音乐中获得更大乐趣，那么这些孩子就有更大可能从事绘画或音乐工作，花更多时间训练自己。也就是说，<strong>不是他们本拥有音乐或绘画的基因，而是某些东西在促使他们刻苦练习，因此培养和发展了技能。</strong></p><p><strong>练习是决定某人在某个特定领域最终成就的唯一最重要因素</strong>，基因就算有发挥作用，这些作用也会渐渐消失。</p><p><strong>相信天生才华具有危险性。</strong>这种假设会指向一些决定和行动，当你认为那些不具备某些才华的人绝不可能擅长这方面的事情时，就会建议他不去做这件事，鼓励他去做别的事。当这些人长大以后，他们自己也相信了，不去进行练习，于是这些语言会自然而然成真了。因此，从父母和老师那里得到更多地支持和鼓励能够更快提升一个人的能力，最初的表扬是有重大意义的。人的天性是希望在他们做的最好的方面投入自己的努力，这时最好的办法是意识到我们每个人都有潜力，并努力开发这些潜力。</p><h2 id="用刻意练习创造全新的世界"><a href="#用刻意练习创造全新的世界" class="headerlink" title="用刻意练习创造全新的世界"></a>用刻意练习创造全新的世界</h2><p>在学习上，刻意练习的方法和传统方法的重要区别是对技能和知识点的着重点不同，一个强调你可以做什么，另一个强调的知道什么。<strong>刻意练习是强调技能的，你选择学习必要的知识，是为了培育技能，知识本身绝不是学习的目的。</strong></p><p>当你在教学生一些事实、概念、法则。那些单独的信息进入长时记忆中。后来学生想要用那些知识解决一个问题，注意力和短时记忆的局限就会显现出来。学生在用它们解决办法的时候，还得牢牢记住所有这些不同、相互之间没有联系的信息。但是如果这些信息都被学生消化，成为学生做好某件事情创建的心理表征的一部分，这些单独的信息就会成为相互联系的一部分，这种模式可以为信息提供背景和意义，使学生更容易运用信息。几乎在每一个教育领域，<strong>最有益的学习目标是那些帮助学生创建有效心理表征的目标。</strong></p><p>课程问题和学习任务的设计，还有一个目的：将学生推出舒适区，但又不是推得太远。对学生来讲，那些问题并不是能够轻松回答的，但也不至于完全不知道回答，而是需要花费一番功夫进行思考，导师让学生说出推理过程然后给出反馈，反复多次，学生就能够创建自己的心理表征。心理表征创建好了，就能够自由探索那些技能，不需要别人的帮助。这个在所有领域都适用。一旦学生懂得了在某个领域要达到足够高的水平必须要做什么，那么他们至少从原则上理解了在其他领域追求卓越也需要做些什么。</p><p>如果人人都理解了刻意练习，新的世界和现在的世界相比，更多地领域之中，将涌现出更多地杰出人物，其社会意义是深远的。对个人的好处也是无穷无尽的，杰出人物逼着自己发展新技能，特别是行业中的尖端技能，往往会有巨大的个人成就感，就像走在一条不断有刺激出现的大路上，永远不会感觉到疲倦。</p><p>所谓“练习人”，是反映人在一生之中能够通过练习来掌握自己的命运，使得人生充满各种可能。为快速的社会变迁做好准备，大部分人除了不断学习新的技能之外别无选择，因此如何更有效地学习至关重要，因此我们需要从现在开始改变，<strong>你可以掌握自己的潜力</strong>。</p>]]></content>
      
      
      <categories>
          
          <category> 学习方法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 研究方法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>非线性控制理论精讲</title>
      <link href="2021/04/17/fei-xian-xing-kong-zhi-li-lun-jing-jiang/"/>
      <url>2021/04/17/fei-xian-xing-kong-zhi-li-lun-jing-jiang/</url>
      
        <content type="html"><![CDATA[<p> 参考视频：<a href="https://space.bilibili.com/230105574/channel/detail?cid=35996">非线性控制理论</a></p><h2 id="Lyapunov直接方法"><a href="#Lyapunov直接方法" class="headerlink" title="Lyapunov直接方法"></a>Lyapunov直接方法</h2><img src="/2021/04/17/fei-xian-xing-kong-zhi-li-lun-jing-jiang/1.png" class=""><p>以上就是正定，半正定，负定，半负定的定义。</p><img src="/2021/04/17/fei-xian-xing-kong-zhi-li-lun-jing-jiang/2.png" class=""><img src="/2021/04/17/fei-xian-xing-kong-zhi-li-lun-jing-jiang/3.png" class=""><p> 例子（钟摆）：</p><img src="/2021/04/17/fei-xian-xing-kong-zhi-li-lun-jing-jiang/4.png" class=""><p>对于一个非线性系统，一般来说没有固定的方法找V，但可以从能量入手。</p><img src="/2021/04/17/fei-xian-xing-kong-zhi-li-lun-jing-jiang/5.png" class=""><p>这里说明了$x_1$,$x_2$有界，但不代表$x_1$,$x_2$会随着时间趋向于0,这里李雅普诺夫函数设计的是它的能量，那么$\dot{V}$是能量随时间的变化，它等于0。系统符合能量守恒，自然是稳定的。</p><p>在有摩擦力的情况下：</p><img src="/2021/04/17/fei-xian-xing-kong-zhi-li-lun-jing-jiang/6.png" class=""><p>当$x_1$取任意值，$x_2=0$时，$\dot{V} = 0$。这时系统是半负定的，系统稳定，但在这里没有在数学上得出渐进稳定的结论。</p><h2 id="不变性原理（The-Invariance-Principle-LaSalle’s-Theorem）"><a href="#不变性原理（The-Invariance-Principle-LaSalle’s-Theorem）" class="headerlink" title="不变性原理（The Invariance Principle-LaSalle’s Theorem）"></a>不变性原理（The Invariance Principle-LaSalle’s Theorem）</h2><p>因此我们要引入一个新理论来扩大李雅普诺夫稳定性的判定。</p><p>当满足下列三点要求，系统渐进稳定：</p><ol><li>$V(x)$在区域D正定。</li><li>$\dot{V} (x)$在一个区域$R \in D$内半负定。</li><li>$\dot{V} (x)$在R中的任何轨迹不等于0，除了x =0。</li></ol><img src="/2021/04/17/fei-xian-xing-kong-zhi-li-lun-jing-jiang/7.png" class=""><p>因此满足以上三个条件，系统渐进稳定。</p><p>另外的例子：</p><img src="/2021/04/17/fei-xian-xing-kong-zhi-li-lun-jing-jiang/8.png" class=""><img src="/2021/04/17/fei-xian-xing-kong-zhi-li-lun-jing-jiang/9.png" class=""><h2 id="非线性系统稳定性设计"><a href="#非线性系统稳定性设计" class="headerlink" title="非线性系统稳定性设计"></a>非线性系统稳定性设计</h2><img src="/2021/04/17/fei-xian-xing-kong-zhi-li-lun-jing-jiang/10.png" class=""><p>这个方法中a必须知道，而且方法很直接简单粗暴地把非线性的部分抵消掉，但不一定最佳，这种方法叫做<strong>反馈系统线性化</strong>$(Feedback Linerization)$。</p><p>代替方法是李雅普诺夫的直接方法：</p><img src="/2021/04/17/fei-xian-xing-kong-zhi-li-lun-jing-jiang/11.png" class=""><img src="/2021/04/17/fei-xian-xing-kong-zhi-li-lun-jing-jiang/12.png" class=""><p>这里又设计出两种方案，对这三种方案进行仿真看运行效果。</p><img src="/2021/04/17/fei-xian-xing-kong-zhi-li-lun-jing-jiang/13.png" class=""><p>第一种方案虽然可以稳定，但是u初始值过大，这就是为什么要避免简单粗暴地方式设计控制器。所以才有了下面两项的替代。</p><img src="/2021/04/17/fei-xian-xing-kong-zhi-li-lun-jing-jiang/14.png" class=""><p>其中$u_1$是黄线，$u_2$是粉线，$u_3$是蓝线，$u_3$输出衰减非常慢，很长时间才会趋近于0，这是由于</p><img src="/2021/04/17/fei-xian-xing-kong-zhi-li-lun-jing-jiang/15.png" class=""><p>前面两项由于是指数变化，收敛速度快很多。</p><h2 id="非线性反步控制（Nonlinear-Backstepping-Control）（重要）"><a href="#非线性反步控制（Nonlinear-Backstepping-Control）（重要）" class="headerlink" title="非线性反步控制（Nonlinear Backstepping Control）（重要）"></a>非线性反步控制（Nonlinear Backstepping Control）（重要）</h2><img src="/2021/04/17/fei-xian-xing-kong-zhi-li-lun-jing-jiang/16.png" class=""><p>这是一个链式控制，力改变物体运动的速度，速度又会导致物体位置上的改变。</p><img src="/2021/04/17/fei-xian-xing-kong-zhi-li-lun-jing-jiang/17.png" class=""><p>为了控制小车沿着指定轨迹行走，需要引入e，并设置控制器使得e最终趋向于0，那么李雅普诺夫函数需要设置为e的函数。要使$\dot{V}_1$满足渐进稳定的条件，可以求得$x_2$的期望值。</p><img src="/2021/04/17/fei-xian-xing-kong-zhi-li-lun-jing-jiang/18.png" class=""><img src="/2021/04/17/fei-xian-xing-kong-zhi-li-lun-jing-jiang/20.png" class=""><p>我们的新目标是让$x_2$的期望值尽量趋近$x_2$，又需要引入误差$\delta$，目的使其趋向于0，在回代之后，把e去掉。然后建立新的李雅普诺夫函数。这个函数可以保证$\delta$和e都趋近于0。</p><img src="/2021/04/17/fei-xian-xing-kong-zhi-li-lun-jing-jiang/19.png" class=""><p>构建新的李雅普诺夫函数之后，利用渐进稳定原则，可以设出$\dot{V}_2$的形式，从而求得u的解。</p><p>验证：</p><img src="/2021/04/17/fei-xian-xing-kong-zhi-li-lun-jing-jiang/21.png" class=""><img src="/2021/04/17/fei-xian-xing-kong-zhi-li-lun-jing-jiang/22.png" class=""><p>这就是通过反馈系统线性化。最后得到的是一个线性系统。</p><p>仿真：</p><img src="/2021/04/17/fei-xian-xing-kong-zhi-li-lun-jing-jiang/23.png" class=""><img src="/2021/04/17/fei-xian-xing-kong-zhi-li-lun-jing-jiang/24.png" class=""><img src="/2021/04/17/fei-xian-xing-kong-zhi-li-lun-jing-jiang/25.png" class=""><img src="/2021/04/17/fei-xian-xing-kong-zhi-li-lun-jing-jiang/26.png" class=""><img src="/2021/04/17/fei-xian-xing-kong-zhi-li-lun-jing-jiang/27.png" class=""><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>首先，设计系统的目标是轨迹跟踪，让$x_1$跟随设定的$x_{1d}$。而通过u可以作用到$x_2$，通过$x_2$又可以控制$x_1$，这是一个控制链。因此设计控制器需要两步：第一步是通过让$x_1$趋近 $x_{1d}$来设计$x_{2d}$，这个可以理解为中间输入。第二步是通过让$x_2$趋近$x_{2d}$来设计u。</p><img src="/2021/04/17/fei-xian-xing-kong-zhi-li-lun-jing-jiang/28.png" class=""><img src="/2021/04/17/fei-xian-xing-kong-zhi-li-lun-jing-jiang/29.png" class=""><h2 id="非线性自适应控制器（Nonlinear-Adaptive-Controller）"><a href="#非线性自适应控制器（Nonlinear-Adaptive-Controller）" class="headerlink" title="非线性自适应控制器（Nonlinear Adaptive Controller）"></a>非线性自适应控制器（Nonlinear Adaptive Controller）</h2><img src="/2021/04/17/fei-xian-xing-kong-zhi-li-lun-jing-jiang/30.png" class=""><p>这个就是只有一层的反馈控制，用的是之前的反步控制法。前提是参数a必须已知，那么如果a不是已知怎么办？</p><img src="/2021/04/17/fei-xian-xing-kong-zhi-li-lun-jing-jiang/31.png" class=""><p>由于参数a未知，我们可以设一个预设a。</p><img src="/2021/04/17/fei-xian-xing-kong-zhi-li-lun-jing-jiang/32.png" class=""><p>然后再根据李雅普诺夫直接方法，并采用<strong>Lyapunov-like引理</strong>把公式中未证明的e趋近于0给证明出来，把a的解出来的预设值代入u中，就可以得到输入了。</p><img src="/2021/04/17/fei-xian-xing-kong-zhi-li-lun-jing-jiang/33.png" class=""><p>这就是自适应控制，无论a怎么变，系统都能够很好地跟随预设值的变化。使得预设的a在一定程度上跟上实际的a，并使e趋近于0。</p><p>练习：如果上一章的第一个系统的参数α未知，如何进行自适应控制?</p><p><a href="https://www.bilibili.com/read/cv909710">答案</a></p><p>总结：按照反步法先设计一个控制器。设计好后，控制器中参数有未知项。然后再设计一个Lyapunov函数，求导，并把设计好的控制器（输入的未知量要替换成估计值，控制器中的e是实际值）代入其中，来求未知参数的估计值，通过不断调整估计值来使误差收敛。根据Barbalats lemma判定Lyapunov函数中除未知量以外的其他变量，都会在t趋近于无穷时收敛到0，从而得出改估计值以及控制器可以使系统渐近稳定，也就完成了基于反步法的自适应控制器设计。</p><h2 id="非线性鲁棒控制器（Robust-Controller）-滑模控制（Sliding-Mode）"><a href="#非线性鲁棒控制器（Robust-Controller）-滑模控制（Sliding-Mode）" class="headerlink" title="非线性鲁棒控制器（Robust Controller）_滑模控制（Sliding Mode）"></a>非线性鲁棒控制器（Robust Controller）_滑模控制（Sliding Mode）</h2><p>鲁棒控制器会存在有界的误差（例如：空调系统、巡航系统）。</p><p>在鲁棒控制中，上一章变化的a值会更加苛刻，它并不是常数，而是一个变化的有界量。</p><img src="/2021/04/17/fei-xian-xing-kong-zhi-li-lun-jing-jiang/34.png" class=""><p>这里设了一个$\rho (x)&gt;|f(x)|$，然后设出一个u，可以得出系统稳定。</p><img src="/2021/04/17/fei-xian-xing-kong-zhi-li-lun-jing-jiang/35.png" class=""><img src="/2021/04/17/fei-xian-xing-kong-zhi-li-lun-jing-jiang/36.png" class=""><p>然后引入松弛变量$S(t)$，可以解出$V(t)$的最大值，从而解出$e(0)$的最大值是一个随着时间指数衰减的函数，也就证明了渐进稳定。这种u的设法是可行的。</p><img src="/2021/04/17/fei-xian-xing-kong-zhi-li-lun-jing-jiang/37.png" class=""><p>这里用相平面分析，如果不看后面两项，相平面上的曲线是一条过原点单调递减的直线。最后一项用来抵消第二项，容易证明e小于0时，e的导数一定大于0，e大于0时，e的导数一定小于0，因此0是e唯一的稳定点。这就是滑模控制(Sliding Mode)。可以看到这种控制不需要知道$f(x)$中确切的参数值，只需知道它的上界即可，满足鲁棒控制的要求。</p><img src="/2021/04/17/fei-xian-xing-kong-zhi-li-lun-jing-jiang/38.png" class=""><p>设计控制器u时只需要找到一个恒大于$f(x)$的函数即可。</p><h2 id="非线性鲁棒控制器（Robust-Controller）-高增益和高频控制器（High-Gain-and-High-Frequency-Controller）"><a href="#非线性鲁棒控制器（Robust-Controller）-高增益和高频控制器（High-Gain-and-High-Frequency-Controller）" class="headerlink" title="非线性鲁棒控制器（Robust Controller）_高增益和高频控制器（High Gain and High Frequency Controller）"></a>非线性鲁棒控制器（Robust Controller）_高增益和高频控制器（High Gain and High Frequency Controller）</h2><img src="/2021/04/17/fei-xian-xing-kong-zhi-li-lun-jing-jiang/39.png" class=""><p>通过设置辅助的$u_{aux}$控制器，可以达到很好的控制效果，上一章令<br>$$<br>u_{aux}=\rho \frac{e}{|e|}<br>$$<br>这是滑膜控制，它的缺点是u的变化幅度过大，会给执行器带来很大的挑战。接下来介绍两种新的辅助控制器：<br>$$<br>u_{aux2}= \frac{1}{\epsilon} \rho^2 e ，\epsilon&gt;0<br>$$<br>这就是High Gain，用足够大的输入抵消不确定性。<br>$$<br>u_{aux3}= \frac{\rho^2 e}{\rho|e| + \epsilon}，\epsilon&gt;0<br>$$<br>这里当$\epsilon=0$时是Silding Mode。当$\epsilon \neq 0$时，$|u_{aux3}| &lt; \rho$，和滑膜控制相比，切换不再那么剧烈，更加平缓一些。</p><img src="/2021/04/17/fei-xian-xing-kong-zhi-li-lun-jing-jiang/40.png" class=""><img src="/2021/04/17/fei-xian-xing-kong-zhi-li-lun-jing-jiang/41.png" class=""><img src="/2021/04/17/fei-xian-xing-kong-zhi-li-lun-jing-jiang/42.png" class=""><img src="/2021/04/17/fei-xian-xing-kong-zhi-li-lun-jing-jiang/43.png" class=""><p>以上就是第二种鲁棒控制器的证明，最后可以看到稳态误差不是一个趋近于0的结果，但误差会小于一个值，当$\epsilon$取值较小可以有效减小稳态误差，但是会给执行机构u带来很大的负担，需要权衡。第三种鲁棒控制器情况类似，因为也是在正负之间跳动，变换频率很高，所以是High Frequency：</p><img src="/2021/04/17/fei-xian-xing-kong-zhi-li-lun-jing-jiang/44.png" class=""><p>可以看到，鲁棒控制器的任务主要是找$\rho (x)&gt;|f(x)|$，确定方案，然后确定是否找$\epsilon$，以及对应值。</p><h2 id="鲁棒控制器分析比较"><a href="#鲁棒控制器分析比较" class="headerlink" title="鲁棒控制器分析比较"></a>鲁棒控制器分析比较</h2><img src="/2021/04/17/fei-xian-xing-kong-zhi-li-lun-jing-jiang/45.png" class=""><img src="/2021/04/17/fei-xian-xing-kong-zhi-li-lun-jing-jiang/46.png" class=""><p>根据题目，我们提供五种控制器方案看实现的效果。</p><p>误差时间响应：</p><img src="/2021/04/17/fei-xian-xing-kong-zhi-li-lun-jing-jiang/47.png" class=""><p>输入：</p><img src="/2021/04/17/fei-xian-xing-kong-zhi-li-lun-jing-jiang/48.png" class=""><p>结论：</p><img src="/2021/04/17/fei-xian-xing-kong-zhi-li-lun-jing-jiang/49.png" class="">]]></content>
      
      
      <categories>
          
          <category> 自控 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 自控 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>现代控制理论精讲</title>
      <link href="2021/04/09/xian-dai-kong-zhi-li-lun-jing-jiang/"/>
      <url>2021/04/09/xian-dai-kong-zhi-li-lun-jing-jiang/</url>
      
        <content type="html"><![CDATA[<p> 参考视频：<a href="https://www.bilibili.com/video/BV1fx41137dA">Advanced控制理论</a></p><h2 id="状态-空间表达（State-Space-Representation）"><a href="#状态-空间表达（State-Space-Representation）" class="headerlink" title="状态-空间表达（State-Space Representation）"></a>状态-空间表达（State-Space Representation）</h2><p>在现代控制理论中我们会选择另外一种和经典控制理论不同的分析方法分析系统，即状态空间，其包含系统的输入、输出和状态变量，然后把它们用一阶微分方程的方式表达出来。如果原来在经典控制理论中有二阶及以上的项，那么要选择合适的状态变量把高阶项消除。</p><img src="/2021/04/09/xian-dai-kong-zhi-li-lun-jing-jiang/1.png" class><img src="/2021/04/09/xian-dai-kong-zhi-li-lun-jing-jiang/2.png" class><p>$$<br>\dot{z} = Az+Bu<br>$$</p><p>$$<br>y = Cz+ Du<br>$$</p><p>这就是系统状态-空间方程的表达方式。</p><img src="/2021/04/09/xian-dai-kong-zhi-li-lun-jing-jiang/3.png" class><p>最终得到传递函数：<br>$$<br>G(s) = \frac{Y(s)}{u(s)} = C(sI-A)^{-1}B+D<br>$$<br>用这条式子可以在已知状态空间方程情况下求传递函数：</p><img src="/2021/04/09/xian-dai-kong-zhi-li-lun-jing-jiang/4.png" class><p>可以看到这个方程和原来拉普拉斯变换算出来的传递函数是一致的。</p><p>其中传递函数的分母部分和|sI-A|是息息相关的。根据线性代数的知识，当|sI-A|=0时，算出来的s就是A矩阵的特征值。当传递函数的分母及特征方程为0时，|sI-A|=0，这时候算出的s就是极点。<strong>结论：A矩阵的特征值可以决定系统的稳定性。</strong></p><h2 id="相图-相轨迹-Phase-Portrait"><a href="#相图-相轨迹-Phase-Portrait" class="headerlink" title="相图/相轨迹(Phase Portrait)"></a>相图/相轨迹(Phase Portrait)</h2><p>这部分内容可以参考《自动控制原理精讲》的非线性系统的相平面法。</p><img src="/2021/04/09/xian-dai-kong-zhi-li-lun-jing-jiang/5.png" class><p>对于状态空间来说:</p><img src="/2021/04/09/xian-dai-kong-zhi-li-lun-jing-jiang/6.png" class><p>当b=c=0时，可以看到a和d大于0或小于0对应了几种不同的变换，当a&lt;0,d&lt;0时系统稳定。</p><p>如果$b\neq 0 $且$c\neq 0$时，可以令x=Py，对A进行对角化，可以参考《特征值和特征向量》。</p><img src="/2021/04/09/xian-dai-kong-zhi-li-lun-jing-jiang/7.png" class><p>进行对角化以后，观察对角矩阵中的两个特征值就能得到其稳定性的判断了，两个小于0则稳定。其中$P=[v_1,v_2]$包含两个特征向量，x=Py相当于y的坐标轴在x平面的表示就在$v_1$和$v_2$上。可以看到x和y平面的性质都是相同的，<strong>结论：可以通过判断A的特征值$\lambda$来判断系统的稳定性。</strong>其原因是|sI-A|=0时求得的s是系统的极点，系统的极点决定系统的稳定性。极点在虚轴左边系统稳定，所以，特征值小于0系统稳定。</p><p>对于特征值为虚数的情况：</p>  <img src="/2021/04/09/xian-dai-kong-zhi-li-lun-jing-jiang/8.png" class><p>解出来的$x_1$和$x_2$是三角函数，取虚部为0，那么$x_1$和$x_2$的相图可以表示为一个椭圆。可以判断这个椭圆是顺时针走的，我们把这样一个平衡点称为中心点(Center)，椭圆的大小和初始位置有关，并且$x_1$,$x_2$是循环往复变化的。</p><p>对于特征值为复数的情况有：</p>  <img src="/2021/04/09/xian-dai-kong-zhi-li-lun-jing-jiang/9.png" class><p>特征值实部大于0时为螺旋向外振荡，同时可以推出当实部小于0时向内螺旋，最后稳定在原点。</p><p>强烈推荐实例：<a href="https://www.bilibili.com/video/BV1ex411g7t3/?spm_id_from=333.788.recommend_more_video.-1">爱情中的数学_Phase Portrait 动态系统分析</a></p><h2 id="系统的可控性"><a href="#系统的可控性" class="headerlink" title="系统的可控性"></a>系统的可控性</h2>  <img src="/2021/04/09/xian-dai-kong-zhi-li-lun-jing-jiang/10.png" class><p>可控性的定义：存在输入u使得从原来$x_0$的状态变成$x_1$的状态。</p><p>对于离散系统：</p>  <img src="/2021/04/09/xian-dai-kong-zhi-li-lun-jing-jiang/11.png" class><p>如果想要u矩阵有解，要求Co矩阵的秩等于n，连续系统也一样。注意这个可控是点对点的可控，轨迹不一定可控，并且只是理论可行，现实系统有物理约束，不一定百分百可控。注意：在连续系统中如果对标离散系统公式Co不和离散系统完全一致，但是可以分解成离散系统的Co再乘以一个满秩方阵，其秩和离散系统的Co是一样的。因此可以直接用离散系统的方法判断连续系统Co的秩。</p>   <img src="/2021/04/09/xian-dai-kong-zhi-li-lun-jing-jiang/12.png" class><p>下面是用一个输入控制两个输出的例子：</p>   <img src="/2021/04/09/xian-dai-kong-zhi-li-lun-jing-jiang/13.png" class>   <img src="/2021/04/09/xian-dai-kong-zhi-li-lun-jing-jiang/14.png" class><p>因此只要用一个小车上施加的力就可以控制两个小车的位置和速度。</p><h2 id="稳定性——李雅普诺夫"><a href="#稳定性——李雅普诺夫" class="headerlink" title="稳定性——李雅普诺夫"></a>稳定性——李雅普诺夫</h2>   <img src="/2021/04/09/xian-dai-kong-zhi-li-lun-jing-jiang/15.png" class><p>意思是点一直稳定在一个圆内称为李雅普诺夫稳定，而渐进稳定意思是随着时间的推移，系统最终会回到原点。</p><p>在相图/相轨迹的章节中，推断出当A特征值的实部大于0，系统不稳定，当实部不大于0，符合李雅普诺夫稳定，当实部小于0，符合渐进稳定。</p><p>而当一个非线性系统无法用特征值的方法判断稳定时，就需要用到李雅普诺夫稳定了：</p><p>这里用到的是李雅普诺夫的直接方法，第一方法是求解微分方程的方法，第二方法是不需要求解微分方程就能判断系统的稳定性。</p>   <img src="/2021/04/09/xian-dai-kong-zhi-li-lun-jing-jiang/16.png" class><p>这里V是自己选定的李雅普诺夫函数，具体怎么选定有规则，非线性系统的公式V由经验决定。只要找到一个V符合条件就能证明稳定，但是很难通过证明V不存在来说明系统不稳定。</p>   <img src="/2021/04/09/xian-dai-kong-zhi-li-lun-jing-jiang/17.png" class><h2 id="线性控制器设计-Linear-controller-Design"><a href="#线性控制器设计-Linear-controller-Design" class="headerlink" title="线性控制器设计(Linear controller Design)"></a>线性控制器设计(Linear controller Design)</h2>   <img src="/2021/04/09/xian-dai-kong-zhi-li-lun-jing-jiang/18.png" class><p>当u是x的函数时，就把系统从开环变为闭环，通过配置u的参数，可以把闭环状态空间矩阵的特征值在一个我们希望的位置上。</p><p>例子：</p>   <img src="/2021/04/09/xian-dai-kong-zhi-li-lun-jing-jiang/19.png" class>   <img src="/2021/04/09/xian-dai-kong-zhi-li-lun-jing-jiang/20.png" class>   <img src="/2021/04/09/xian-dai-kong-zhi-li-lun-jing-jiang/21.png" class><p>倒立摆分析：</p>   <img src="/2021/04/09/xian-dai-kong-zhi-li-lun-jing-jiang/22.png" class>   <img src="/2021/04/09/xian-dai-kong-zhi-li-lun-jing-jiang/23.png" class>   <img src="/2021/04/09/xian-dai-kong-zhi-li-lun-jing-jiang/24.png" class><h2 id="LQR-Linear-Quadratic-Regulater-控制器"><a href="#LQR-Linear-Quadratic-Regulater-控制器" class="headerlink" title="LQR(Linear Quadratic Regulater)控制器"></a>LQR(Linear Quadratic Regulater)控制器</h2><p>从上面的内容可以知道，通过选择输入u和输出x的关系可以改变系统Acl的特征值，从而控制系统的表现，这里讨论如何确定特征值，什么样的特征值是最好的？</p><p>引入目标函数/能量函数(Cost Function)<br>$$<br>J = \int_0^{\infty}(X^TQX + U^T RU) dt<br>$$<br>其中Q内的值都为正。这个代表一个惩罚(Penalty)，当$x\neq 0$时，这个值根据Q里面数值的大小有不同反应。后面的部分代表输入对Cost Function的影响。LQR的意思是在满足系统稳定的同时，我们要去寻找J的最小值。</p><p>运用上面的倒立摆系统进行分析，设g=10,L=1。</p>   <img src="/2021/04/09/xian-dai-kong-zhi-li-lun-jing-jiang/25.png" class>   <img src="/2021/04/09/xian-dai-kong-zhi-li-lun-jing-jiang/26.png" class>   <img src="/2021/04/09/xian-dai-kong-zhi-li-lun-jing-jiang/27.png" class><p>用matlab自带的模块输入参数进行计算，可以直接给出对应的k值，然后把k值输入原来的系统中。系统响应很nice.</p>   <img src="/2021/04/09/xian-dai-kong-zhi-li-lun-jing-jiang/28.png" class><p>但是，如果我们更关心用最小的输入就能达到目的，对角度的收敛速度的要求较低，那么修改新的Q和R：</p>   <img src="/2021/04/09/xian-dai-kong-zhi-li-lun-jing-jiang/29.png" class>   <img src="/2021/04/09/xian-dai-kong-zhi-li-lun-jing-jiang/30.png" class><p>在第二种情况下，我们更关心系统的能耗问题，虽然角度的收敛速度比第一个系统要低，但是大大降低了输入要求，减小了能耗。</p><p><strong>思考：如果让角度始终保存一个非零角度，那么小球会以匀加速前进，此时系统怎么建立？</strong></p>   <img src="/2021/04/09/xian-dai-kong-zhi-li-lun-jing-jiang/31.png" class><p>令$e = x_d - x_1$，代入方程后建立的状态空间方程是由e和$x_2$组成的。</p>   <img src="/2021/04/09/xian-dai-kong-zhi-li-lun-jing-jiang/32.png" class><p>但是通过计算，稳定点的e不是0，那么我们就要通过设计控制器u把其调整为0，只需要消去后面的常数项即可。</p><p>​    <img src="/2021/04/09/xian-dai-kong-zhi-li-lun-jing-jiang/33.png" class></p><p>​    <img src="/2021/04/09/xian-dai-kong-zhi-li-lun-jing-jiang/34.png" class></p><p>​    <img src="/2021/04/09/xian-dai-kong-zhi-li-lun-jing-jiang/35.png" class></p><p>通过改变输入的角度的值可以改变其稳定的角度，从而达到加速前进后退的效果。</p><h2 id="状态观测器的设计"><a href="#状态观测器的设计" class="headerlink" title="状态观测器的设计"></a>状态观测器的设计</h2><p>上面的控制方法的前提是：x的状态可测。</p><p>如果x不可测怎么办？这就要引入观测器(Observer)根据系统的输入和输入估计系统的状态。</p><p><strong>Luenberger Observer</strong></p><p>​    <img src="/2021/04/09/xian-dai-kong-zhi-li-lun-jing-jiang/36.png" class></p><p>​    <img src="/2021/04/09/xian-dai-kong-zhi-li-lun-jing-jiang/37.png" class></p><p>可以计算出估计值和实际值的误差公式，我们的目标是让误差趋近于0.。<strong>建立观测器实际上是建立新的反馈系统使得误差趋近于0</strong>。</p><p>以弹簧阻尼系统为例：</p><p>​    <img src="/2021/04/09/xian-dai-kong-zhi-li-lun-jing-jiang/38.png" class></p><p>​    <img src="/2021/04/09/xian-dai-kong-zhi-li-lun-jing-jiang/39.png" class></p><p>可以设两个特征值都为-1，求出$L_1$,$L_2$之后，然后可以通过观测器得出估计值：</p><p>​    <img src="/2021/04/09/xian-dai-kong-zhi-li-lun-jing-jiang/40.png" class></p><p>Matlab仿真：</p><p>​    <img src="/2021/04/09/xian-dai-kong-zhi-li-lun-jing-jiang/41.png" class></p><p>​    <img src="/2021/04/09/xian-dai-kong-zhi-li-lun-jing-jiang/42.png" class></p><p>可以看到无论给$\dot{z}$估计值设计一个什么初始，最终都会和实际的$\dot{z}$重合。</p><p>上面是实际系统，知道该实际系统的状态空间表达式，但是选的这些个“状态变量”，它可能没有实际的物理意义、或者是只存在于数学上的某种抽象的表达之类，不容易或者没办法直接测量。测不了还必须要得到它，才能有后面的“控制”的事。所以，有了状态观测器这个东西，也就是下面那个系统。这个系统就干一件事：通过上面那个实际系统的输入、输出（实际系统的输入、输出一般是容易获得的），去推测、估计那些个“状态变量”。实际系统不好测，或者测量成本过高为节约成本就用状态观测器了，比如无位置传感器永磁电磁电机控制。</p><h2 id="可观测性和分离原理"><a href="#可观测性和分离原理" class="headerlink" title="可观测性和分离原理"></a>可观测性和分离原理</h2><p>和可控性类似，如果一个系统可观测，则：</p><p>​    <img src="/2021/04/09/xian-dai-kong-zhi-li-lun-jing-jiang/43.png" class></p><p>接下来把可控性和可观性结合，当一个系统可控可观测，但是x不可测量，那么第一步是设计适当的观测器，有了观测出来的结果后，可以设计反馈系统，</p><p>​    <img src="/2021/04/09/xian-dai-kong-zhi-li-lun-jing-jiang/44.png" class></p><p>这样原来的系统变为新的状态空间方程系统，其中因为要让估计值趋近状态值，系统稳定，所以e和x都要趋近于0。这样M矩阵特征值的实部要小于0。</p><p>​    <img src="/2021/04/09/xian-dai-kong-zhi-li-lun-jing-jiang/45.png" class></p><p>​    <img src="/2021/04/09/xian-dai-kong-zhi-li-lun-jing-jiang/46.png" class></p><p>这样控制器的特征值和观测器的特征值分离开了，这就是分离原理。</p><p>设计观测器和控制器合并的系统时，观测器的收敛速度要比控制器快，因为需要准确的观测值指导系统的输入。</p>]]></content>
      
      
      <categories>
          
          <category> 自控 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 自控 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>线性时不变系统的冲击响应和卷积</title>
      <link href="2021/04/09/xian-xing-shi-bu-bian-xi-tong-de-chong-ji-xiang-ying-he-juan-ji/"/>
      <url>2021/04/09/xian-xing-shi-bu-bian-xi-tong-de-chong-ji-xiang-ying-he-juan-ji/</url>
      
        <content type="html"><![CDATA[<p> 参考视频：<a href="https://www.bilibili.com/video/BV1cs411W74f">https://www.bilibili.com/video/BV1cs411W74f</a></p><p>首先解释什么是线性时不变系统(LTI system)，线性说明符合叠加原理，时不变说明无论什么时候给系统施加输入，它的输出都是相同的。</p><p>而冲激响应$h(t)$指的是输入单位冲激信号$\delta (t)$之后系统的响应，其拉普拉斯变换即为传递函数。</p><p>卷积公式如下：<br>$$<br>x(t) = \int_{0}^{t}f(\tau)h(t-\tau)d\tau<br>$$<br>这就是卷积，其中f是系统的输入，h是系统的冲激响应。可以看出卷积其实是把一个函数分成无数个冲激函数，把它们在某一个时刻冲激响应的加和。卷积的运算只是乘积之和，真正令人困惑的在于一个乘积因子是$f(τ)$，而另一个是$h(t-τ)$。这里解释一下为什么是t-τ：τ作为时间微元对应于线性时不变系统一般在t之前，那么这个时间微元τ到时刻t的时间间隔就是t-τ，h(t-τ)也就代表着τ时刻的冲击在t时刻的残余响应。所有τ时刻的残余响应与输入的$f(τ)$结合最终叠加得到的也就是在t时刻前信号的输出。离散状况下要更容易理解些。在理解卷积内涵的基础上再去学习卷积的计算方法会更有意义。一个弹簧，给它一个冲击，它会表现为震动。但是如果给它一个连续作用的变化的力，弹簧当下的震动即是过去所有震动的叠加。这是卷积的根本意思，即过去的响应会影响当下。</p><p>因此，只要我们得到一个系统的冲激响应，和任意一个输入做卷积就可以得到一个系统的输出。这也是变声器的原理，比如在浴室中敲出一个短暂的声音录下来，这个可以当做冲激响应，我们把其他的声音和这个冲激响应做卷积以后，声音听起来就像是浴室中发出的一样。另外录音的音效设置也是一样的道理，把原声和特定环境下的冲激做卷积，在加上一些其他的滤波器，就能做出特定环境的音效。</p><p>卷积的拉普拉斯变换证明：</p><p></p>]]></content>
      
      
      <categories>
          
          <category> 数学 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数学 </tag>
            
            <tag> 自控 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>线性化及泰勒公式</title>
      <link href="2021/04/08/xian-xing-hua-ji-tai-le-gong-shi/"/>
      <url>2021/04/08/xian-xing-hua-ji-tai-le-gong-shi/</url>
      
        <content type="html"><![CDATA[<p> 对于线性系统来说，应该符合叠加原理，分析起来比较简单。非线性系统不符合叠加原理，但是可以在平衡点附近对其进行线性化。</p><p>线性化的原理就是泰勒公式：<br>$$<br>f(x) = f(x_0) + f’(x_0)(x-x_0)+\frac{f’’(x_0)}{2!}(x-x_0)^2 + …+\frac{f^n(x_0)}{n!}(x-x_0)<br>$$<br>泰勒公式的原理是在一个点上的每一阶导数都和原函数相等，就可以拟合出原来的曲线，展开的阶数越高，拟合效果越好。展开到第二项可以对原来的公式进行线性化。注意这种线性化是在展开点附近的线性化，距离越远误差越大。</p><p>在平衡点附近进行线性化首先求出平衡点，令所有阶的导数为0，求x，然后在这一点$x=x_0$进行泰勒展开。把$x= x_0+x_d$代入方程中（$x_d$是无穷小值），解出新的关于$x_d$的方程，这就是在平衡点处线性化的方程。</p><img src="/2021/04/08/xian-xing-hua-ji-tai-le-gong-shi/1.png" class=""><p>对于二维的向量空间有：</p><img src="/2021/04/08/xian-xing-hua-ji-tai-le-gong-shi/2.png" class=""><p>这是二维线性化的方法，包含的思想是二元的泰勒展开，其中包含偏导的矩阵是<strong>雅克比矩阵</strong>，可以看到二维的计算方法结果还是和一维一样的。</p>]]></content>
      
      
      <categories>
          
          <category> 数学 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数学 </tag>
            
            <tag> 自控 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>特征值和特征向量</title>
      <link href="2021/04/07/te-zheng-zhi-he-te-zheng-xiang-liang/"/>
      <url>2021/04/07/te-zheng-zhi-he-te-zheng-xiang-liang/</url>
      
        <content type="html"><![CDATA[<p> 在线性代数中，对于一个给定的线性变换<strong>A</strong>，它的特征向量经过这个线性变换的作用之后，得到的新向量仍然与原来的<strong>v</strong>保持在同一条直线上，但长度或方向也许会改变，即：<br>$$<br>Av = \lambda v<br>$$<br>其中$\lambda$为标量，即特征向量的长度在该线性变换下缩放的比例，称其为<strong>特征值</strong>。</p><p> 求解<strong>A</strong>特征值特征向量的具体步骤查看大学的线性代数。</p><h2 id="应用"><a href="#应用" class="headerlink" title="应用"></a><strong>应用</strong></h2><img src="/2021/04/07/te-zheng-zhi-he-te-zheng-xiang-liang/1.png" class=""><p><strong>结论：特征值特征向量的作用是把一个矩阵化成对角矩阵，起到解耦的作用！即存在可逆矩阵P，使：</strong><br>$$<br>P^{-1}AP = \wedge<br>$$<br>现在考虑微分方程组的解法，在现代控制理论中，状态空间方程中是用一系列微分方程组组成的：</p><img src="/2021/04/07/te-zheng-zhi-he-te-zheng-xiang-liang/2.png" class=""><p>在解x向量的微分方程组时，通过x=Py可以进行解耦，把x的方程变成y的方程，由于对角矩阵的存在，可以直接解出y对于t的函数，然后代回x=Py时，可以解出向量x。</p><p><strong>这是一个非常重要的应用，很多时候我们并不需要解出这个微分方程，可以通过特征值的符号可以判断系统的稳定性和系统的表现形式。</strong></p>]]></content>
      
      
      <categories>
          
          <category> 数学 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数学 </tag>
            
            <tag> 线性代数 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>机器学习之决策树</title>
      <link href="2021/04/04/ji-qi-xue-xi-zhi-jue-ce-shu/"/>
      <url>2021/04/04/ji-qi-xue-xi-zhi-jue-ce-shu/</url>
      
        <content type="html"><![CDATA[<p> 决策树图例：</p><img src="/2021/04/04/ji-qi-xue-xi-zhi-jue-ce-shu/1.png" class=""><p>如果有这样一个图，我们在对数据进行离散化处理后，我们就能很容易地进行分类，那么这样一个图是怎么建立起来的呢？其中的每一个节点都是怎么确定的呢？</p><p>决策树学习的关键其实就是选择最优划分属性，<strong>希望划分后，分支结点的“纯度”越来越高。</strong>也就是说，每分一次，都使得数据越来越纯净，只包含更少类型的数据 ，或者其中的数据都明显具有更加相似的特征。</p><h2 id="ID3算法"><a href="#ID3算法" class="headerlink" title="ID3算法"></a>ID3算法</h2><h3 id="信息量"><a href="#信息量" class="headerlink" title="信息量"></a>信息量</h3><p>信息量是对信息的度量，就跟时间的度量是秒一样，当我们考虑一个离散的随机变量x的时候，当我们观察到的这个变量的一个具体值的时候，我们接收到了多少信息呢？多少信息用信息量来衡量，<strong>我们接受到的信息量跟具体发生的事件有关。</strong>信息的大小跟随机事件的概率有关。<strong>越小概率的事情发生了产生的信息量越大</strong>。</p><p>那么信息量可以用以下公式表示（$p(x_i)$为事情发生的概率）：<br>$$<br>l(x_i) = -log_2p(x_i)<br>$$<br>而所有类别的信息期望值为：<br>$$<br>H = -\sum_{i=1}^{n}p(x_i)log_2p(x_i)<br>$$<br>因此当一个集合中混杂的数据类型越多，这个值就越大，当数据中只有一种类型时，这个值为0，也就完成了分类。因此，我们只要找到一个节点分类后的信息量最小，那么选择这个节点作为分类方法就是最好的选择。</p><h3 id="信息增益"><a href="#信息增益" class="headerlink" title="信息增益"></a>信息增益</h3><p>信息增益其实指的是信息量减少的量，把分支前的信息熵减去分支后信息熵的加权平均：<br>$$<br>G = H - \sum_{i=1}^{n}\frac{D_i}{D}H_i<br>$$<br>其中D是数据总量，$D_i$是一个分支中的数据量。因此信息增益越大，分类效果越好。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>自动控制原理练习题</title>
      <link href="2021/03/04/zi-dong-kong-zhi-yuan-li-lian-xi-ti/"/>
      <url>2021/03/04/zi-dong-kong-zhi-yuan-li-lian-xi-ti/</url>
      
        <content type="html"><![CDATA[<h2 id="给结构图，求响应"><a href="#给结构图，求响应" class="headerlink" title="给结构图，求响应"></a>给结构图，求响应</h2><h3 id="1、"><a href="#1、" class="headerlink" title="1、"></a>1、</h3><img src="/2021/03/04/zi-dong-kong-zhi-yuan-li-lian-xi-ti/1.png" class=""><img src="/2021/03/04/zi-dong-kong-zhi-yuan-li-lian-xi-ti/2.png" class=""><p>单输入单输出求传递函数再求输出的响应的过程不再赘述，下面是零输入状态下的响应。</p><img src="/2021/03/04/zi-dong-kong-zhi-yuan-li-lian-xi-ti/3.png" class=""><img src="/2021/03/04/zi-dong-kong-zhi-yuan-li-lian-xi-ti/4.png" class="">]]></content>
      
      
      <categories>
          
          <category> 自控 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 自控 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>梅森(Mason)公式</title>
      <link href="2021/03/04/mei-sen-mason-gong-shi/"/>
      <url>2021/03/04/mei-sen-mason-gong-shi/</url>
      
        <content type="html"><![CDATA[<p>梅逊(Mason)公式是美国麻省理工学院S.J. Mason于20世纪 50年代提出的。 借助于梅逊公式，不经任何结构变换，可以直接由结构图得到系统的传递函数。<br>$$<br>G(s) = \frac{\sum_{k=1}^{m}P_k\Delta_k}{\Delta}<br>$$<br>其中：<br>$$<br>\Delta = 1-\sum_1^nL_i+\sum_1^{n_2}L_iL_j-\sum_1^{n_3}L_iL_jL_k+…<br>$$<br>$\sum_1^nL_i$，为所有回路的回路增益之和</p><p>$\sum_1^{n_2}L_iL_j$，是所有两两互不接触的回路的增益乘积之和</p><p>$\sum_1^{n_2}L_iL_jL_k$，是所有三三互不接触的回路的增益乘积之和</p><p>$P_k$是从输入节点到输出节点第k条前向通道的增益</p><p>$\Delta_k$是在$\Delta$中将与第k条前向通路相接触的回路去掉后所余下的部分，称为余子式。</p><p>m是从输入节点到输出节点所有前向通路的条数。</p><img src="/2021/03/04/mei-sen-mason-gong-shi/1.png" class=""><img src="/2021/03/04/mei-sen-mason-gong-shi/2.png" class=""><img src="/2021/03/04/mei-sen-mason-gong-shi/3.png" class="">]]></content>
      
      
      <categories>
          
          <category> 自控 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 自控 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>自动控制原理精讲</title>
      <link href="2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/"/>
      <url>2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/</url>
      
        <content type="html"><![CDATA[<p>本文根据视频内容b站UP主DR_CAN的<a href="https://www.bilibili.com/video/BV1jt411M7QU">自动控制原理</a>再辅以卢京潮的课程和自己查找的资料等记录而成，强烈推荐观看该系列视频。本文用到的数学基础拉普拉斯变换的内容在我的另一篇文章《拉普拉斯变换》已经详细说明，在此基础上阅读本文。</p><h2 id="开环和闭环系统"><a href="#开环和闭环系统" class="headerlink" title="开环和闭环系统"></a>开环和闭环系统</h2><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/1.png" class=""><p>开环$(open loop)$系统与闭环$(closed loop)$系统的本质区别是是否存在反馈$(feedback)$。</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/2.png" class=""><p>因此对于闭环系统控制器为$D(s)$，开环传递函数为$G(s)$，反馈环节为$H(s)$，输入为$V(s)$，输出为$X(s)$，其闭环传递函数为：<br>$$<br>\frac {D(s)G(s)} {1+H(s)D(s)G(s)}<br>$$</p><p>$$<br>X(s) = V(s)\frac {D(s)G(s)} {1+H(s)D(s)G(s)}<br>$$</p><p>所以，我们的研究方向是研究闭环系统的传递函数，而$D(s)$是我们要设计的控制器，也是我们研究的重点。从这入手，可以做系统的稳定性分析，误差分析等等。</p><h2 id="稳定性分析"><a href="#稳定性分析" class="headerlink" title="稳定性分析"></a>稳定性分析</h2><p>通过对系统施加单位冲击信号就可以判断系统的稳定性，因为可以通过研究开环或闭环函数本身分析稳定性：<br>$$<br>X(s) = R(s)G(s) = \delta(s)G(s) = G(s)<br>$$<br>假设$D(s)$为$G(s)$的分子，$N(s)$为$G(s)$的分母：<br>$$<br>G(s) = \frac {D(s)} {N(s)}<br>$$<br>当$D(s)=0$时解出来的s称为系统的<strong>零点</strong>，$N(s)=0$时解出来的s称为系统的<strong>极点</strong>。</p><p>此时我们关注系统的极点，当存在系统的极点的实部大于0时为不稳定的状态，都小于0则为稳定状态，实部等于0而虚部不为0则是临界稳定的状态。</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/3.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/4.png" class=""><p>因此我们在设计控制器时的目标是让所有的极点落在左半平面。</p><p><strong>补充</strong>：当系统的初始条件不为0时：</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/5.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/6.png" class=""><p>因此，初始条件不为0相当于给输入端加上幅度为$x(0)$的冲击。<br>$$<br>闭环系统 \phi(s) = \frac{M(s)}{D(s)}<br>$$</p><p>$$<br>稳定判据 D(s) = a_ns^n+a_{n-1}s^{n-1}+…+a_1s+a_0(a_i&gt;0,i=0,1,2…,n)<br>$$</p><p><strong>劳斯判据</strong></p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/58.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/59.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/60.png" class=""><p><strong>习题</strong></p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/61.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/62.png" class=""><p>看第一列全为正系统稳定，有负数或0系统不稳定，且s域右半平面极点个数等于第一列变号的次数。</p><hr><h2 id="实战案例分析（含Matlab仿真）"><a href="#实战案例分析（含Matlab仿真）" class="headerlink" title="实战案例分析（含Matlab仿真）"></a>实战案例分析（含Matlab仿真）</h2><p>参考视频：<a href="https://www.bilibili.com/video/BV1W441167qn/?spm_id_from=333.788.videocard.1">一起燃烧卡路里/科学减肥(1)_系统分析实例_数学建模部分</a></p><hr><h2 id="稳态误差"><a href="#稳态误差" class="headerlink" title="稳态误差"></a>稳态误差</h2><p>$$<br>e_{ss}= r - \lim_{t\to \infty}x(t)<br>$$</p><p>其中$e_{ss}$指稳态误差，r是参考值(reference value)，$x(t)$是输出。</p><p><strong>终值定理</strong>（用拉氏变换微分规则可轻易证明）：<br>$$<br>\lim_{t \to \infty}x(t) = \lim_{s \to 0}sX(s)<br>$$<br> 使用条件：当$\lim_{t \to \infty}x(t)$存在时才能使用，即系统稳定。</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/7.png" class=""><p>有了这个定理，我们就不用进行拉普拉斯逆变换，直接在s域上就可以求得稳态误差的结果了。</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/64.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/65.png" class=""><p><strong>比例控制无法消除稳态误差：</strong></p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/8.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/9.png" class=""><h4 id="静态误差系数法"><a href="#静态误差系数法" class="headerlink" title="静态误差系数法"></a>静态误差系数法</h4><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/66.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/67.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/68.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/69.png" class=""><p><strong>可以看出，当一个系统输入档次确定以后，稳态误差随着系统型别增加而降低，当输入档次和系统型别一致是一个非零常数。如果系统型别高于输入档次，稳态误差为0，反之稳态误差为无穷。</strong></p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/70.png" class=""><p><strong>可以看出，积分环节在减小稳态误差的过程中起着关键作用，每一个积分环节相当于一个挡水坝。想要输出跟上输入的次数，必须至少有对应个数的积分环节。当积分环节和输入档次相当时，才看开环增益K来确定稳态误差。但是开环传递函数中的积分环节越多，要加的微分环节的阶数越高，物理实现越难。通常零型和一型系统比较多，二型不多见，二型以上基本没有。</strong></p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/71.png" class=""><p><strong>按前馈补偿的复合控制方案可以有效提高系统的稳态精度。原因是在稳态误差端输入对应信号，从而抵消掉原来会产生的稳态误差。</strong></p><h4 id="动态误差系数法（一般了解）"><a href="#动态误差系数法（一般了解）" class="headerlink" title="动态误差系数法（一般了解）"></a>动态误差系数法（一般了解）</h4><p>用泰勒展开表示传递函数，展开到某一项就不需要展开了，因为对输入信号的某一阶导数一定等于0。</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/72.png" class=""><p>注意：动态误差不是误差的全部信息，而是误差的稳态分量。</p><h2 id="比例积分控制器"><a href="#比例积分控制器" class="headerlink" title="比例积分控制器"></a>比例积分控制器</h2><p>只使用比例控制器$k_p$无法消除稳态误差，现在我们把控制器设定为$C(s)$:</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/10.png" class=""><p>因此消除稳态误差需要$ \lim_{s \to 0}C(s) = \infty$</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/11.png" class=""><p>这里从一阶系统变成了二阶的系统，用simulink仿真P，I,和PI控制器的效果：</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/12.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/13.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/50.png" class=""><p>此时传递函数：<br>$$<br>G(s) = \frac{2K_p\zeta\omega_ns+\omega_n^2}{s(s+2\zeta\omega_n)+2K_p\zeta\omega_ns+\omega_n^2}<br>$$<br>通过计算当比例环节系数，拆分出来的二阶系统阻尼比就增加相应倍数，可以做到无震荡，除了这个二阶项另一项也会占到一部分，加快了系统的反应速度。</p><p>可以看出PI控制兼具了快速反应，无超调和稳态误差的优点。</p><h2 id="一阶系统的单位阶跃响应"><a href="#一阶系统的单位阶跃响应" class="headerlink" title="一阶系统的单位阶跃响应"></a>一阶系统的单位阶跃响应</h2><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/47.png" class=""><p>这里K决定了积分累积的速度，K越大，累积速度越快，最后输出达到和输入相同的值，不再累积，这就是一阶系统输出跟随输入相同的原理。</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/14.png" class=""><p>a对系统的响应起到决定性作用，决定了系统响应的快慢。</p><p>而闭环增益是把闭环传递函数写成尾一标准形式提出来的系数，此处可以化为$\frac{1}{\frac{1}{a}s+1}$，增益是1。而时间常数$\tau$则是s前面的系数$\frac{1}{a}$，此时上升至稳态值得0.632倍。调节时间$t_s = 3\tau(\Delta = 5 %) $，$t_s = 4\tau(\Delta = 2 %) $。</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/15.png" class=""><p>另外$\frac a {s+a}$其实是一个低通滤波器，可以说有积累的都是低通滤波器，对高速的变换不敏感。</p><p>一阶系统的闭环也是一阶系统，且回产生稳态误差。仅靠比例控制无法消除稳态误差，此部分请查看稳态误差章节。</p><h4 id="换个角度看一阶系统单位阶跃响应"><a href="#换个角度看一阶系统单位阶跃响应" class="headerlink" title="换个角度看一阶系统单位阶跃响应"></a>换个角度看一阶系统单位阶跃响应</h4><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/16.png" class=""><p>这种方法以x为横坐标，x的导数为纵坐标，可以看出当x=0时增加幅度最大，当x=1是导数是0，不再增加，符合原来的曲线。而当t=0时x&gt;1的情况下，因为其导数小于0，所以又会一直减小直到等于1。</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/17.png" class=""><p>而当a&lt;0时它是一条经过1的单调递增的直线，此时当x=0开始时实际x会不断减小，并且衰减越来越快。</p><p>这种方法叫做相图$(phase Portrait)$</p><h2 id="频率响应和滤波器"><a href="#频率响应和滤波器" class="headerlink" title="频率响应和滤波器"></a>频率响应和滤波器</h2><p>对于一个线性时不变系统，输入为正弦信号，在稳定的条件下，系统的输出和输入的频率相同。</p><p>下面证明。对于输入一个正弦信号，有：</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/18.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/19.png" class=""><p>因此频率响应实际上是稳态的响应。</p><p>下面是一系列推导：</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/20.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/21.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/22.png" class=""><p>此处有一个性质：拉普拉斯变换的传递函数$G(s)$s代入共轭的两个数，其结果也一定是共轭的。</p><p>请一定要记住结论：线性时不变系统，输入正弦信号，稳定的条件下输出的信号的**幅值是原来的$|G(jω)|$倍，相角增加了$∠G(jω)$**。</p><p>从另一个角度定义$G(jω)$：</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/86.png" class=""><p>例子：</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/23.png" class=""><p>可以看出对$G(jω)$的傅里叶反变换是原函数。也可以说$G(jω)$是原来的函数傅里叶变换的结果，即它的幅值为$G(jω)$的模，相角为$G(jω)$的角度。</p><hr><p>下面研究一阶系统$\frac a {s+a}$：</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/24.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/25.png" class=""><p>从图中可以看出，随着频率增加振幅不断减小，所以它是个典型的低通滤波器。<strong>其实有积累的东西都可以看作低通滤波器，例如频繁开关空调室温也只会平缓变换，频繁开关水龙头页面高度也只会平缓变化，亦或是典型的电阻电容系统。带有低通滤波器性质的系统都会存在一个容器：房子，水箱，电容等等。这些容器在数学角度讲是积分，拉氏变换是$\frac 1 s$，因此随着频率不断增大，振幅响应不断减小。直观来讲，容器提供了缓冲机制，给系统的反应带来一系列延迟，从而抵消高速变换带来的影响。对我们自己亦是如此，我们要不断积累经验充实自己，否则就会对外界的变化非常敏感，反应剧烈不得章法。通过不断积累曾经沧海，才能在变换莫测的横流中处乱不惊。反过来讲也有所得，过去的经验会称为自己的包袱，只有放下包袱，解放思想，才能在瞬息万变的世界中逐风追电。</strong></p><h2 id="二阶系统的动态响应"><a href="#二阶系统的动态响应" class="headerlink" title="二阶系统的动态响应"></a>二阶系统的动态响应</h2><p>生活中二阶系统随处可见，根据牛顿第二定律F=ma，其中的加速度a就是距离s对时间t的二阶导数，动力学和运动学都是建立在牛顿第二定律的基础上的，所以周围的运动现象普遍都是二阶的。</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/48.png" class=""><p>其中二阶系统可以表示为以下结构图：</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/49.png" class=""><p>可以看出二阶系统可以由一个积分环节，比例环节，和一阶环节的闭环组成。无论二阶系统的经典结构的增益是多少，闭环后的增益都为1。这也是一阶系统加上积分控制变成二阶系统能消除稳态误差的原因。但增加开环增益会降低系统的阻尼比，因为增加增益相当于增强积分环节，导致震荡加剧，但是调节时间不变，上升时间缩短。</p><p>同时这个闭环二阶系统再闭环也会降低增益形成稳态误差，同时阻尼比降低。</p><p>下面是典型的弹簧阻尼质量系统：</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/26.png" class=""><p>此处要求解微分方程：</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/27.png" class=""><p>此处用求根公式：</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/28.png" class=""><p>下面分情况讨论：</p><p>当ζ&gt;1时，称为<strong>过阻尼</strong>系统，在这种情况下阻尼力很大。此时可以解得：<br>$$<br>x(t) = C_1e^{\lambda_1t}+ C_2e^{\lambda_2t}<br>$$<br>这里$\lambda_1,\lambda_2$为负实数且互不相等。收敛速度取决于较大的$\lambda$。</p><p>当ζ=1时，称为<strong>临界阻尼</strong>系统，在这种情况下阻尼力很大。此时可以解得：<br>$$<br>x(t) = (C_1+C_2)e^{\lambda t}<br>$$<br>这里$\lambda$为负实数且大小位于上面的$\lambda_1,\lambda_2$之间，收敛速度快一些。</p><p>当ζ&lt;1时，称为<strong>欠阻尼</strong>系统，这是最常见的情况。此时可以解得：<br>$$<br>x(t) = C_1e^{\lambda_1t}+ C_2e^{\lambda_2t} = e^{-\zeta \omega_nt}(C_1\cos{\omega_n \sqrt{1-\zeta^2}t}+C_2\sin{\omega_n \sqrt{1-\zeta^2}t})<br>$$</p><p>$$<br>\lambda_1,\lambda_2 = -\zeta \omega_n \pm i\omega_n \sqrt{1-\zeta^2}<br>$$</p><p>再定义<strong>阻尼固有频率</strong>(Damped Natural Fraq)：<br>$$<br>\omega_d = \omega_n \sqrt{1-\zeta^2}<br>$$</p><p>此时有：<br>$$<br>x(t) = e^{-\zeta \omega_n t} \sqrt{C_1^2+C_2^2} \sin(\omega_d t+\phi)<br>$$</p><p>$$<br>\phi = arctan{\frac{C_1}{C_2}}<br>$$</p><p>这个函数一边振动一边衰减，它的震动周期就是$\frac{2\pi}{\omega_d}$。</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/29.png" class=""><p>而当$\zeta = 0$即没有阻尼时：</p><p>$$<br>x(t) = e^{0}(C_1\cos{\omega_n t}+C_2\sin{\omega_nt}) = \sqrt{C_1^2+C_2^2}\sin(\omega_n t+\phi)<br>$$</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/30.png" class=""><p>另外当$\zeta &lt; 0 $时都是不稳定系统：</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/31.png" class=""><h4 id="二阶系统的单位阶跃响应-2nd-Order-System-Unit-Step-Response"><a href="#二阶系统的单位阶跃响应-2nd-Order-System-Unit-Step-Response" class="headerlink" title="二阶系统的单位阶跃响应(2nd Order System Unit Step Response)"></a>二阶系统的单位阶跃响应(2nd Order System Unit Step Response)</h4><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/32.png" class=""><p>此处便求出了二阶系统的传递函数为<br>$$<br>H(s) = \frac{X(s)}{U(s)} = \frac {\omega_n^2} {s^2 + 2\zeta \omega_n s + \omega_n^2}<br>$$<br>阶跃响应：<br>$$<br>X(s) = U(s)H(s) = \frac 1 s\frac {\omega_n^2} {s^2 + 2\zeta \omega_n s + \omega_n^2}<br>$$<br>三个极点分别为：0，$-\zeta \omega_n \pm i\omega_n \sqrt{1-\zeta^2}$。</p><p>经过一系列的转化，可以得到：<br>$$<br>X(s) = \frac 1 s - \frac 1 2 (1-\frac{\zeta}{1-\zeta^2}i)\frac 1 {s-p_2}-\frac 1 2 (1+\frac{\zeta}{1-\zeta^2}i)\frac 1 {s-p_3}<br>$$<br>进行拉普拉斯逆变换后可以得到：<br>$$<br>x(t) = 1 - e^{-\zeta \omega_nt}(cos\omega_dt+\frac{\zeta}{\sqrt{1-\zeta^2}}sin\omega_dt) = 1-e^{-\zeta \omega_nt} \sqrt\frac1{1-\zeta^2}sin(\omega_dt+\phi)<br>$$</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/33.png" class=""><p>此外当$\zeta=0$时，是临界稳定状态：<br>$$<br>x(t) = 1- cos{\omega_nt}<br>$$<br>当$\zeta=1$时，没有震荡：<br>$$<br>x(t) = 1-e^{-\omega_nt}(1+\omega_nt)<br>$$<br>当$\zeta&gt;1$时，同样没有震荡：</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/34.png" class=""><p>下面是ζ不同时系统的表现：</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/35.png" class=""><p>极点所在的位置和原点、坐标轴构成的三角形有以下关系：</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/44.png" class=""><h4 id="二阶系统的指标特性（阻尼比0到1）"><a href="#二阶系统的指标特性（阻尼比0到1）" class="headerlink" title="二阶系统的指标特性（阻尼比0到1）"></a>二阶系统的指标特性（阻尼比0到1）</h4><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/36.png" class=""><p>$T_d$延迟时间(Delay time)，达到稳态值50%的时间。</p><p>$T_r$上升时间(Rise time)，第一次达到稳态值的时间。$T_r=\frac{\pi-\phi}{\omega_d}=\frac{\pi-arctan\frac{\sqrt{1-\zeta^2}}{\zeta}}{\omega_n\sqrt{1-\zeta^2}}$</p><p>$M_p$最大超调量(Max overshoot)，$t_p=\frac{\pi}{\omega_d}$，$M_p = e^\frac{-\zeta\pi}{\sqrt{1-\zeta^2}}*100$%。当ζ=0.5，超调量是16.3%，当$ζ=0.707=\frac{\sqrt{2}}{2}$，超调量是4.33%，可以看成5%。当$\zeta = \frac{\sqrt{3}}{2}$，超调量为0.43%。而超调量相同则表明极点落在原点发出的同一条射线上。</p><p>$T_{ss}$调节时间(setting time)，系统进入到稳态误差范围内的时间，一般稳态误差取5%或2%。实际上为了方便取包络线进入误差带。取2%$T_{ss}=\frac{4.5}{\zeta\omega_n}$，取5%$T_{ss}=\frac{3.5}{\zeta\omega_n}$ ，ζ=0.707是最佳阻尼比调节时间最短可以看成$T_{ss}=\frac{2}{\zeta\omega_n}$。</p><p>临界阻尼和过阻尼下的调节时间：</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/51.png" class=""><h4 id="改善二阶系统动态性能的措施"><a href="#改善二阶系统动态性能的措施" class="headerlink" title="改善二阶系统动态性能的措施"></a>改善二阶系统动态性能的措施</h4><p>1、测速反馈：增加阻尼</p><p>2、比例+微分：提前控制</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/52.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/54.png" class=""><p>可以看出测速反馈的无阻尼自然频率不变，但阻尼比增加，导致超调量减小，调节时间减小。比例+微分的极点和测速反馈是一样的，但多出来一个闭环零点，性能指标要采用另外一套零点极点法进行计算。</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/53.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/55.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/56.png" class=""><p>可以看出，与原系统相比，比例+微分多出来的零点的影响是了多微分信号，这个信号减小了系统的上升时间，并使得超调量略微增加，但调节时间略微缩短。</p><h4 id="二阶系统的频率响应"><a href="#二阶系统的频率响应" class="headerlink" title="二阶系统的频率响应"></a>二阶系统的频率响应</h4><p>振幅响应：<br>$$<br>\frac{M_o}{M_i}=|G(j\omega)|<br>$$<br>相角响应：<br>$$<br>\phi_o - \phi_i = ∠G(j\omega)<br>$$<br>因此：<br>$$<br>G(j\omega) = \frac{\omega_n^2}{-\omega^2+2\zeta\omega_n\omega j+\omega^2} = \frac{1}{-\frac{\omega^2}{\omega_n^2}+2\zeta\frac{\omega}{\omega_n}j+1}<br>$$</p><p>$$<br>令  \Omega =  \frac{\omega}{\omega_n}<br>$$</p><p>$$<br>G(j\omega) = \frac{1-\Omega^2}{(1-\Omega^2)^2+4\zeta^2\Omega^2} - \frac{2\zeta\Omega}{(1-\Omega^2)^2+4\zeta^2\Omega^2} j<br>$$</p><p>$$<br>|G(j\omega)| = \sqrt{\frac{1}{(1-\Omega^2)^2+4\zeta^2\Omega^2}}<br>$$</p><p>$$<br>∠G(j\omega) = -arctan\frac{2\zeta\Omega}{1-\Omega^2}<br>$$</p><p>当$\omega = 0$时，$\Omega = 0$，$|G(j\omega)|=1$</p><p>当$\omega = \infty$时，$\Omega = \infty$，$|G(j\omega)| =  0$</p><p>当$\omega = \omega_n$时，$\Omega = 1$，$|G(j\omega)|=\frac{1}{2\zeta}$，此时当$\zeta&lt;0.5$时，$|G(j\omega)|&gt;1$；当$\zeta&gt;0.5$时，$|G(j\omega)|&lt;1$，因此一定存在一个极值点。</p><p>通过对$|G(j\omega)|$分母部分进行求导，可以得出$\Omega= \frac{\omega}{\omega_n}= \sqrt{1-2\zeta^2}$时存在极值。<br>$$<br>\omega = \omega_n\sqrt{1-2\zeta^2}<br>$$<br>我们把这个频率称为<strong>系统的共振频率（谐振频率）</strong>。可以看出在$0\leqζ\leq\frac{\sqrt{2}}{2}$时才存在谐振峰值，才有谐振频率。</p><p>把这个式子代回$|G(j\omega)|$的式子中，得：<br>$$<br>|G(j\omega)|_{\omega = \omega_n\sqrt{1-2\zeta^2}}= \frac 1 {2\zeta\sqrt{1-\zeta^2}}<br>$$<br>当ζ=1时，$\omega=\omega_n$，$|G(j\omega)|=0.5$。</p><p>当ζ=0.5时，$\omega=\omega_n$，$|G(j\omega)|=1$，$\omega=\omega_n\sqrt{1-2\zeta^2}$时$|G(j\omega)|=1.16$。</p><p>当ζ=0时，$\omega=\omega_n$，$|G(j\omega)|=\infty$，同时这也是它的谐振频率。</p><p><strong>因此对阻尼比较小的系统来说，如果外力的频率在共振频率附近，系统就会表现出强烈的振幅响应，因为外力把系统本身的震动潜能激励起来了。</strong>不同的系统有不同的共振频率，对外界的响应也不相同。</p><hr><h2 id="高阶系统的阶跃响应和动态性能（一般了解）"><a href="#高阶系统的阶跃响应和动态性能（一般了解）" class="headerlink" title="高阶系统的阶跃响应和动态性能（一般了解）"></a>高阶系统的阶跃响应和动态性能（一般了解）</h2><p>首先画出高阶系统的零点和极点：</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/57.png" class=""><p>1、挨得较近的零极点（模是相对距离的十倍以上）可以忽略不计。</p><p>2、只留下主导极点，去掉非主导极点。</p><p>3、查零点极点计算公式（各种数量的零点极点都有对应公式可查）。</p><h2 id="伯德图"><a href="#伯德图" class="headerlink" title="伯德图"></a>伯德图</h2><p>为什么大多研究开环伯德图？<br>可以通过开环伯德图较方便地获取系统稳定性信息，通过回路整形（Loop shaping）调整开环伯德图的形状以达到期望的控制性能；<br>闭环伯德图直观展示整个系统输入输出响应特性，也能与时域响应紧密联系，适用于设计结果验证，不适合用于分析控制回路在整个系统中的作用；<br>某些系统开环频域响应数据更容易获取；开环伯德图更适用于控制器设计，因为开环回路就是控制器所需要调整和处理的回路。<br>结论：开环波特图因其直接体现出控制器对系统性能的影响而便于设计，闭环因其直接展现出最终结果而便于分析。</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/37.png" class=""><p>以ω(对数标度即lgω)为横坐标，把振幅响应和相位响应用两个图表达出来，幅值响应的纵坐标进行了对数变换，取20log，以10为底，这两个图组合起来称为伯德图。</p><p>功率或能量是振幅平方的函数。因此对dB的定义可以由能量的部分替换成振幅的部分，因此原本的系数10变成20。</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/38.png" class=""><p>下面是示例：</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/39.png" class=""><p>下面是$G(s) = \frac{a}{s+a}$的分析：<br>$$<br>|G(j\omega)|  = \sqrt\frac{1}{1+(\frac{\omega}{a})^2}<br>$$</p><p>$$<br>∠G(j\omega) = -arctan\frac{\omega}{a}<br>$$</p><p>当ω&lt;&lt;a时，$|G(j\omega)|=1$，$20log|G(j\omega)| = 0$，$∠G(j\omega) = 0$</p><p>当ω=a时，$|G(j\omega)|=\frac{\sqrt 2}{2}$，$20log|G(j\omega)| = -20log\sqrt{2} = -3dB$，$∠G(j\omega) = -45°$，这里幅值达到原来的0.707倍，也被称为截止频率。</p><p>当ω&gt;&gt;a时，$|G(j\omega)|=\frac{a}{\omega}$，$20log|G(j\omega)| = 20loga-20log{\omega}$，$∠G(j\omega) = -90°$</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/40.png" class=""><p>画幅频特性曲线时都是以截止频率为转折点画渐近线的。</p><p><strong>伯德图性质$log_{10}AB=log_{10}A+log_{10}B$非常好，意味着可以把非常复杂的传递函数分解开来。</strong></p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/41.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/42.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/43.png" class=""><h3 id="实际画图规则："><a href="#实际画图规则：" class="headerlink" title="实际画图规则："></a><strong>实际画图规则：</strong></h3><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/99.png" class=""><p>惯性环节对数相频曲线是关于-45°那一点对称的。转折频率为$\frac{1}{T}$，转折后斜率是-20dB。而-45°的点刚刚好是在转折频率上的，可以推断，画典型环节的相频曲线时，确定其起始角度，终止角度，可以画出一条过转折频率，中间角度的曲线。</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/100.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/101.png" class=""><p>振荡环节的转折频率为$\omega_n$。转折后的斜率是-40dB。</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/102.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/103.png" class=""><p>乘-57.3是为了把弧度化成度。</p><h3 id="题目（画图、反求函数、反求Nyquist图）"><a href="#题目（画图、反求函数、反求Nyquist图）" class="headerlink" title="题目（画图、反求函数、反求Nyquist图）"></a>题目（画图、反求函数、反求Nyquist图）</h3><p><strong>截止频率为$|G(jω)| = 1 $对应的频率。</strong></p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/104.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/105.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/106.png" class=""> <img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/108.png" class=""><p>这里的几种手法很重要。要注意中间的$\omega_0$的求法，其中当几何方法不好求时侧重用第二种。</p> <img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/109.png" class=""><p>这里非相角系统（在右半s平面存在开环零极点或纯延时环节的系统，这种系统不能由幅频特性唯一确定G(s)）的零极点在s域左边还是右边要考虑清楚。开始时-270°却是一型系统，只能是有一个极点在右半s平面导致比初始比预期小180°。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>伯德图绘制：</p><ol><li><p>$G(s)$化为尾一标准型，列出转折频率（一阶环节如$\frac{1}{Ts+1}$为$\frac{1}{T}$，二阶环节为$\omega_n$）</p></li><li><p>确定基准线（起始线的延长线必过$\omega=1$,$dB=20lgK$，也必过$\omega^v = K$ ，$L(\omega)| = 0$（当20lgK不好确定时用这个）。再根据型别v确定初始斜率为-20v dB/dec）。</p></li><li><p>叠加：在转折频率处改变斜率，一阶为$\pm20dB$，二阶为$\pm20dB$。</p></li></ol><p>根据伯德图画Nyquist图：</p><p>当极点在原点上时，ω的变化视为从实轴右边无线小的距离开始，沿着无限小的圆弧到虚轴往上走，因此Nyquist图一律是从0°开始的。</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/107.png" class=""><hr><h2 id="幅相特性曲线——Nyquist图"><a href="#幅相特性曲线——Nyquist图" class="headerlink" title="幅相特性曲线——Nyquist图"></a>幅相特性曲线——Nyquist图</h2><p>这幅图相当于伯德图另一种表现形式。</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/87.png" class=""><p>惯性环节的幅相特性是未半圆。把ωT约去后可以证明：</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/88.png" class=""><p>其他环节的图：</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/89.png" class=""><p><strong>振荡环节</strong>（可同时参考二阶系统的频率响应小节）</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/90.png" class=""><p>可以看出，振荡环节相当于一个实数除以两个由极点指向虚轴大于0的某一点的向量，当频率增大是，这一点向正无穷移动，两个向量幅值趋向无穷，相角趋向90度，造成整个振荡环节的幅值趋向0，相角趋向-180度。在$\omega_n$确定的情况下，ζ越小圈越大，越靠近共振频率幅值越大，ζ=0时是无穷大的圈沿着横坐标轴走。图上于虚轴相交的点刚好处于$\omega_n$的频率，幅值为$\frac{1}{2\zeta}$。</p><p>谐振频率<br>$$<br>\omega = \omega_n\sqrt{1-2\zeta^2}<br>$$<br>谐振峰值<br>$$<br>|G(j\omega)|_{\omega = \omega_n\sqrt{1-2\zeta^2}}= \frac 1 {2\zeta\sqrt{1-\zeta^2}}<br>$$</p><p>可以看出当$ζ&lt;\frac{\sqrt{2}}{2}$时，才有谐振峰值，即存在$|G(j\omega)|&gt;1$。ζ越小，谐振峰值越大。</p><p>根据Nyquist图解出参数：</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/91.png" class=""><p><strong>不稳定的振荡环节</strong></p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/92.png" class=""><p>可以看出，不稳定振荡环节的曲线与稳定环节曲线x轴对称，相角从-360变成-180。</p><p><strong>二阶复合微分</strong></p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/93.png" class=""><p>阻尼比越小，曲线越瘦。当$ζ&lt;\frac{\sqrt{2}}{2}$时，$|G(jω)|$先减小再增大，存在比1小的极小值。</p><p><strong>延时环节</strong></p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/94.png" class=""><h5 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h5><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/95.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/96.png" class=""><h5 id="例题"><a href="#例题" class="headerlink" title="例题"></a>例题</h5><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/97.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/98.png" class=""><hr><h2 id="Nyquist稳定判据"><a href="#Nyquist稳定判据" class="headerlink" title="Nyquist稳定判据"></a>Nyquist稳定判据</h2><p>Routh判据（代数稳定判据）不能用于研究如何调整系统结构来改善系统稳定性的问题。</p><p>Nyquist稳定判据（频域稳定判据）可以由开环频率特性直接判定闭环系统的稳定性，可以研究包含纯延时环节的系统的稳定性问题，并且可以研究如何调整系统的结构参数改善系统稳定性问题。<br>$$<br>Z=P-2N<br>$$<br>其中Z是在右半s平面闭环极点的个数，P是在右边s平面中开环极点的个数，N是开环幅相特性曲线包围$(-1,0)$这个点的圈数，顺时针方向为正，逆时针为负。</p><h3 id="证明"><a href="#证明" class="headerlink" title="证明"></a>证明</h3><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/110.png" class=""><p>可以看出$1+G(s)H(s)$的极点和开环极点一致，零点和闭环极点一致。</p><p><strong>柯西辐角原理</strong></p><p>把一个复数q=a+bj，通过$F(s)$变成$F(q)= a’+b’j$的过程叫<strong>映射</strong>。</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/111.png" class=""><p>可以看出映射之前的点同零点的连线和映射之后的点和原点的连线是一样的，即模值一样，角度一样。</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/112.png" class=""><p>因此如果原来的图如果有一条闭合曲线不包围$F(s)$零点，那么，映射之后的曲线一定不包围原点。</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/113.png" class=""><p>同理，容易如果$F(s)$存在极点，映射之前的点与映射之后的点模值互为倒数，角度互为相反数。</p><p>因此，如果有顺时针包围极点的一条曲线，映射一定有逆时针包围原点的曲线。</p><p>曲线同时包含一个零点和一个极点的情况下：</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/114.png" class=""><p>容易推出映射后的点角度为$φ = φ_1-φ_2$，模值为$v = \frac{v_1}{v_2}$。映射后的角度永远无法满足360°都存在，曲线映射后一定不包围原点。</p><p><strong>结论：A曲线顺时针包含一个$F(s)$的零点，映射后打的B曲线就绕$(0,0)$顺时针一圈。顺时针包含一个$F(s)$的极点，则B曲线绕$(0,0)$逆时针一圈。A曲线顺时针环绕的零点比极点多几个，那么B曲线就顺时针环绕几圈，少几个则逆时针围绕几圈，A逆时针同理。</strong></p><p>理论准备完成，现在正式证明：</p><p>首先可以定义一个顺时针包围整个右边平面的曲线A，只要曲线内没有闭环极点则为稳定：</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/115.png" class=""><p>可以看出这里列出的公式P是右半平面包含的$1+G(s)H(s)$的极点也即是开环极点个数，Z是$1+G(s)H(s)$的零点也即是闭环极点的个数，N为映射到$1+G(s)H(s)$之后逆时针包围零点的圈数。这个等式显然是成立的。而把$F(s)$由$1+G(s)H(s)$变为$G(s)H(s)$相当于向左移动一个单位，映射后的曲线变为包围$(-1,0)$点。因此有了公式：<br>$$<br>Z = P-N<br>$$<br>Z是在右边平面闭环极点的个数，一定大于或等于0，用来判断稳定性，P是右半平面开环极点个数，N是逆时针绕$(-1,0)$的圈数，由于平时画的Nyquist图只有一半（与另一半x轴对称），所以N又可以表示为2N：<br>$$<br>Z = P-2N<br>$$<br>当系统稳定时Z=0，P=N，这个称为<strong>Nyquist稳定性判据</strong>。</p><h3 id="题目"><a href="#题目" class="headerlink" title="题目"></a>题目</h3><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/116.png" class=""><p>当Nyquist路径碰到虚轴上的开环极点时，要从右边画一个无限小的圆弧绕过去。</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/117.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/118.png" class=""><p>我们把Nyquist图逆时针穿过(-1,0)左边实轴称为正穿越，N为正数，顺时针称为负穿越，N为负数。当只给出开环传递函数的伯德图时，看对数幅频曲线在上半平面的曲线部分的频率，在这部分频率中对数相频曲线往下穿过-180°称为负穿越，反之正穿越。如果在这个区域没有穿过而是贴着-180°而起，算半次穿越（注意）。</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/119.png" class=""><hr><h2 id="稳定裕度"><a href="#稳定裕度" class="headerlink" title="稳定裕度"></a>稳定裕度</h2><p>稳定裕度是系统动态性能指标，指的是系统的稳定程度（注意这是对<strong>最小相角系统</strong>而言）</p><p>对于<strong>最小相角系统</strong>来说，只要越过(-1,0)的左边就是不稳定，因此稳定程度可以确定为曲线与(-1,0)的距离，这就是稳定裕度，这是开环频率指标。</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/120.png" class=""><p><strong>相角裕度</strong>确定了Nyquist曲线上$|G(j\omega)|=1$的点，到-180°的角度差。物理意义是系统在相角上距离临界稳定还具有的储备量，意思是最多可以加多少角度的纯延时环节。</p><p><strong>幅值裕度</strong>确定了Nyquist曲线上与负实轴交界的点到(-1,0)点的距离的倒数，这个数越大，距离(-1,0)越远，系统越稳定。物理意义是系统在增益上距离临界稳定还具有的储备量。意思是最多还可以再乘上多少的增益。</p><h3 id="题目-1"><a href="#题目-1" class="headerlink" title="题目"></a>题目</h3><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/121.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/122.png" class=""><p>求相角裕度要先求出$|G(j\omega_c)| = 1$对应的$\omega_c$的值（要试根），再代入相角式子中计算裕度。求幅值裕度解相角等于-180°的方程（或者令G(j\omega）虚部为0)，解方程时可能要使用$\arctan a +\arctan b = arctan\frac{a+b}{1-ab}$，然后把这个频率代入模值方程的倒数中，就可以得到幅值裕度h。</p><p><strong>画伯德图算</strong></p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/123.png" class=""><p>伯德图算出来的相角裕度和幅值裕度比实际小一些，这在工程上时有好处的，也免去试根的麻烦，做题时画图后再做计算较方便。<strong>当求-180°对应的频率时，如果对数幅频特性是按照-20，-40，-60的斜率依次下降的，那么-180°就处于两个转折频率的几何中点处，即两个转折频率相乘后开方（容易证明所有惯性环节在相频特性曲线图上的几何形状都是一样的，区别只是转折频率而已，就连幅频特性曲线后面都是一样的，区别只是转折频率较高的惯性环节前面多出一节近似0分贝的图像）。</strong>如果函数没有这个规律，就老实用相角方程算。    </p><hr><h2 id="利用开环频率特性分析系统性能"><a href="#利用开环频率特性分析系统性能" class="headerlink" title="利用开环频率特性分析系统性能"></a>利用开环频率特性分析系统性能</h2><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/124.png" class=""><p>在截止频率附近的叫做<strong>中频段</strong>，左边的特别是第一个转折频率前叫做<strong>低频段</strong>，最后在0分贝线下较多的地方叫做<strong>高频段</strong>。注意：这只适用于单位反馈的最小相角系统，因为这样才能通过对数幅频曲线唯一确定对数相频曲线和闭环传递函数。</p><p>低频段和系统的稳态精度息息相关，确定了开环增益和系统型别，只要系统稳定，K和v越大越好。中频段可以直接把相角裕度读出来，和系统的动态性能$t_s和\delta%$息息相关，如果要求相角裕度大于40°，截止频率就要尽量满足以-20斜率穿越0分贝线。高频段决定闭环系统的抗高频干扰能力（$\phi(s) = \frac{G(s)}{1+G(s)}&lt;&lt;1$）,越低越陡越好。</p><p><strong>在最小相角系统中，要学会通过对数幅频曲线去推算相频特性曲线。</strong></p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/125.png" class=""><p>可以发现，斜率越小，相角归宿越小，每个转折频率后都有不同的相角归宿，在转折频率处，可以大概估计为之前的相角归宿和之后的相角归宿的中间值。</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/126.png" class=""><p>可以看出，中间的频带拉的越宽，相角往中间的归宿靠的越近，这也是要用-20斜率穿过0分贝线并且要拉的比较宽的原因，这样相角就尽可能接近-90°，延缓向-180°靠的频率，相角裕度较大。（要注意型别大于等于2的系统可能存在的刚开始的穿越）</p><p>并且可以同时调整K值，调整K值只会上下平移对数幅频曲线，不会改变对数相频曲线，把曲线的截止频率调整到相角最大的地方，也可以增大相角裕度。</p><p><strong>对于典型二阶欠阻尼系统</strong>：</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/127.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/128.png" class=""><p>可以看出系统的相角裕度只与阻尼比有关，和超调量有异曲同工之处。知道二阶系统的相角裕度后查图可以知其超调量。并且调节时间也同截止频率和相角裕度有关：$t_s\omega_c = \frac{7}{\tan\gamma}$。所以通过查图可以由相角裕度和截止频率推出其调节时间。</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/129.png" class=""><p>二阶系统用时域方法计算更具优越性，但频域方法能扩展到更高级的系统中。</p><p>估计高阶系统的动态性能是用以下两个公式或查图可以保守估计超调量和调节时间：</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/130.png" class=""><h3 id="题目-2"><a href="#题目-2" class="headerlink" title="题目"></a>题目</h3><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/131.png" class=""><p>可以看出右移倍频<strong>不会改变相角裕度</strong>，因为每个惯性环节在伯德图的相角曲线的几何形状是不变的，转折频率改变的只是相角所处的位置（右移），截止频率同样也整体右移同样幅度，因此相角裕度不变。</p><hr><h2 id="利用闭环频率特性曲线分析系统性能"><a href="#利用闭环频率特性曲线分析系统性能" class="headerlink" title="利用闭环频率特性曲线分析系统性能"></a>利用闭环频率特性曲线分析系统性能</h2><h3 id="闭环频率特性曲线绘制"><a href="#闭环频率特性曲线绘制" class="headerlink" title="闭环频率特性曲线绘制"></a>闭环频率特性曲线绘制</h3><p>开环曲线和闭环曲线的关系：</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/132.png" class=""><p>可以看出，闭环曲线的模值和相角与OA和AB的夹角有关。</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/133.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/134.png" class=""><p>这里可以利用两个工具：</p><p>等M圆，在图中开环的Nyquist曲线上的点对应交于等M圆上的一个圆，可以直接读出这一点频率的闭环幅值。越靠近(-1,0)的点幅值越大，越靠近(0,0)的点幅值越小。</p><p>等N圆，在图中开环的Nyquist曲线上的点对应交于等N圆上的一个圆，可以直接读出这一点频率的闭环相角。越往上相角越大，原理是圆内同弦所对的圆周角是相等的。</p><p>移植到伯德图中：</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/135.png" class=""><p>这样当约定一点的开环幅值相角后，可以在图中找到对应的点，看其与哪一个闭环的幅值相角曲线相交，可直接读数。</p><p>这就是<strong>对数幅相特性曲线</strong>，是继频率特性，Nytuist图，伯德图之后分析系统的第四种绘图方式，现在基本不用了，用计算机可以直接完成闭环伯德图绘制。</p><h3 id="闭环频率特性分析系统性能"><a href="#闭环频率特性分析系统性能" class="headerlink" title="闭环频率特性分析系统性能"></a>闭环频率特性分析系统性能</h3><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/136.png" class=""><ol><li>零频值 $M_0 = M(0)$。</li><li>谐振频率$\omega_r$，谐振峰值$M_r$。</li><li>带宽频率$\omega_b$，表示$M(\omega)$下降到零频值的0.707倍时对应的频率。</li></ol><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/137.png" class=""><p>二阶系统知道带宽和谐振峰值后，可以直接通过查表来确定闭环系统的超调量、阻尼比和调节时间。</p><p>对于高阶系统：</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/138.png" class=""><p>注意$\omega_c$是开环的截止频率，但是实际工程直接把闭环的带宽频率代进去计算也差不太多。同样也可以直接读图。</p><hr><h2 id="线性系统的时域校正"><a href="#线性系统的时域校正" class="headerlink" title="线性系统的时域校正"></a>线性系统的时域校正</h2><h4 id="反馈校正"><a href="#反馈校正" class="headerlink" title="反馈校正"></a>反馈校正</h4><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/73.png" class=""><p>可以看出，反馈校正较小被包围环节的时间常数的同时，也减小了增益。相反，改成正反馈可以增加增益，增大时间常数。</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/74.png" class=""><hr><h2 id="根轨迹"><a href="#根轨迹" class="headerlink" title="根轨迹"></a>根轨迹</h2><p>作用：研究系统中的某一参数发生变化时，系统性能的变化趋势。</p><p>根的位置对系统表现有着至关重要的影响，掌握了根的变化规律，就可以利用补偿器来改变根的位置，从而达到影响系统表现的作用。</p><p>开环传递函数化成首一标准形式后的系数叫根轨迹增益，仅对开环而言。</p><p>例：其中研究对象是开环传递函数$G(s)H(s)$：</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/45.png" class=""><p>其中根随着K从0增大到无穷的轨迹就是根轨迹。</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/75.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/76.png" class=""><p><strong>因此根轨迹要满足模值条件和相角条件。</strong><br>$$<br>|G(s)H(s)| = K^*\frac{\prod_{i=1}^{m}|s-z_i|}{\prod_{j=1}^{n}|s-p_j|} = 1<br>$$</p><p>$$<br>∠G(s)H(s)= \sum_{i=1}^{m}∠(s-z_i)-\sum_{j=1}^{n}∠(s-p_j) = (2k+1)\pi<br>$$</p><p><strong>对于s平面上的任意的点，总存在一个K*，使其满足模值条件，但该点不一定是根轨迹上的点。但是满足相角条件的点一定在根轨迹上，而根轨迹上对应的K*值，应由模值条件确定。</strong></p><p><strong>根轨迹规则：</strong></p><ol><li><p>根轨迹起始于开环极点，终止于开环零点。如果开环极点的个数n大于开环零点个数m，则有n-m条根轨迹终止于无穷远处。<br>$$<br>原因：K^* =\frac{\prod_{j=1}^{n}|s-p_j|}{\prod_{i=1}^{m}|s-z_i|}<br>$$</p></li><li><p>根轨迹的分支数=开环极点数，根轨迹连续且对称于实轴。通常开环传递函数的分母比分子阶数高，因此闭环极点数等于开环极点数等于根轨迹分支数。</p></li><li><p>从实轴上最右端的开环零、极点算起，奇数开环零、极点到偶数开环零、极点之间的区域必是根轨迹。</p></li><li><p>当$n-m\geq 2$时闭环根之和保持一个常值。</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/46.png" class=""><p><strong>定理：两个开环极点一个开环零点，复平面出现根轨迹，一定是以开环零点为圆心的圆弧。</strong></p></li></ol><p>​        <img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/77.png" class=""></p><p>​        <img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/78.png" class=""></p><ol start="5"><li><p>渐近线（σ为渐近线和实轴的交点，φ为渐近线与实轴的夹角）：<br>$$<br>\sigma_a = \frac{\sum_{i=1}^{n}p_i - \sum_{j=1}^{m}z_j}{n-m}<br>$$</p><p>$$<br>\phi_a = \frac{(2k+1)\pi}{n-m}<br>$$</p></li><li><p>实轴上两个根的分离点d：<br>$$<br>\sum_{i=1}^{n} \frac{1}{d-p_i} =\sum_{j=1}^{m} \frac{1}{d-z_j}<br>$$<br>解方程的时候要试根，没有更好办法。然后把分离点带入模值条件中可以得到K*的值。</p></li><li><p>与虚轴的交点（系统临界稳定的点）：</p><p>可以把s=jω代入特征方程中，并令特征方程为0，解实部和虚部两条方程可以得出与虚轴交点以及K*的值。</p></li><li><p>出射角/入射角（即满足相角条件）：<br>$$<br>\sum_{i=1}^{m}∠(s-z_i)-\sum_{j=1}^{n}∠(s-p_j) = (2k+1)\pi<br>$$</p></li></ol><h4 id="参数根轨迹（除K之外其他参数变化时系统的根轨迹）"><a href="#参数根轨迹（除K之外其他参数变化时系统的根轨迹）" class="headerlink" title="参数根轨迹（除K之外其他参数变化时系统的根轨迹）"></a>参数根轨迹（除K之外其他参数变化时系统的根轨迹）</h4><p>需要根据特征方程构建等效开环传递函数，含参数的放分子，不含参数放分母。</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/79.png" class=""><p>画出根轨迹后，等效开环传递函数的任务结束，分析系统要回到原来的函数并利用根轨迹。</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/80.png" class=""><p>注意：如果参数在次数最大的项上，直接整体同除系数，把系数转移到次数低的项，然后再构造等效开环传递函数。</p><h4 id="零度根轨迹（系统实质上处于正反馈时的根轨迹）"><a href="#零度根轨迹（系统实质上处于正反馈时的根轨迹）" class="headerlink" title="零度根轨迹（系统实质上处于正反馈时的根轨迹）"></a>零度根轨迹（系统实质上处于正反馈时的根轨迹）</h4><p>模值条件不变，相角条件变成2kπ。</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/81.png" class=""><p>变动三条，实轴上的根轨迹变成偶数点左边，渐近线的夹角公式分子变为2kπ，出、入射角公式的右边变为2kπ。</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/82.png" class=""><p>可以看出正反馈和负反馈不是对立的，而是一个事情的两个方面。可以看成K从零往负无穷大变化的根轨迹。相当于K的范围扩大到了整个实数域，构成完整的根轨迹图。</p><h4 id="定理"><a href="#定理" class="headerlink" title="定理"></a>定理</h4><p>若开环零极点均为偶数个，且关于一条平行于虚轴的直线左右对称分布，则根轨迹一定关于该直线左右分布。</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/83.png" class=""><h4 id="例题（重要）"><a href="#例题（重要）" class="headerlink" title="例题（重要）"></a>例题（重要）</h4><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/84.png" class=""><ul><li><p>可以看出出现零极点对消情况后得到的开环传递函数得到的闭环传递函数不包含所有的根，还有的根不根据K变化，要用原来的函数求闭环传递函数才可得。</p></li><li><p>附加闭环极点会使超调量减小，峰值时间后移，附加闭环零点反之。 原因是附加开环极点后等于给原来的信号设置了延时环节，附加开环零点后等于在原来的信号基础上又添加一个微分信号。越靠近虚轴，点起到的作用越大。</p></li><li><p>附加开环零点使跟轨迹左移，系统更稳定。附加开环极点使跟轨迹右移，系统更不稳定。</p></li></ul><p><strong>PID控制</strong></p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/85.png" class=""><p>比例+积分PI把稳态精度提高了，把动态性能指标变差了，相当于附加开环零极点，但极点位置为原点，影响程度高。比例+微分PD稳态精度不影响，动态性能有所改善，相当于附加 开环零点根轨迹向左扳。而PID控制即提高了稳态精度，也提高了稳态精度，增加一个开环极点（原点）和两个开环零点，导致附加的开环零点的影响大。</p><hr><h2 id="频率法串联校正"><a href="#频率法串联校正" class="headerlink" title="频率法串联校正"></a>频率法串联校正</h2><p>频率法串联校正仅使用于单位负反馈的最小相角系统，如果是非相角系统，需要画出伯德图的两幅图，在考虑稳定性的基础上进行校正。如果是非单位反馈，可以进行一下处理：</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/185.png" class=""><h3 id="串联超前校正"><a href="#串联超前校正" class="headerlink" title="串联超前校正"></a>串联超前校正</h3><p>$$<br>关键公式 G_c(s) = \frac{aTs+1}{Ts + 1}(a&gt;1)<br>$$</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/139.png" class=""><p>用电路搭建的模型如上图所示，这样的一个电路可以给开环传递函数增加一个极点一个零点，改变增益。</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/140.png" class=""><p>可以看出这个网络的相角都是大于0的，所以叫超前网络。好处是可以增加相角裕度。且最大相角恰好在两个转折频率的几何中点处，且其最大值只与a有关，此时拉起来的增益是$10lg a (dB)$。</p><p>注意：一级超前网络最大超前角为60°，不能把a拉的太大，因为会导致高频抗干扰能力受影响，最有效的a在4到10之间。</p><p>超前校正步骤（给定指标$e_{ss}^* ,\omega_c^* ,\gamma^* $）</p><p>当截止频率和相角裕度都不够的情况下使用（因为超前校正同时增加了截止频率和相角裕度）。</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/141.png" class=""><p>简单来说，是通过相角裕度的差值计算超前网络的a值，这个差值通常加5°~10°。</p><h4 id="题目-3"><a href="#题目-3" class="headerlink" title="题目"></a>题目</h4><p>注意：设计系统的时候指标先紧着牙设计，给后面的设计留下充足的可调整空间。</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/142.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/143.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/144.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/145.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/146.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/147.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/148.png" class=""><p>可以看出，加5°-10°的原因是超前网络提高了系统中频段的幅值，使得系统的截止频率延后，因此原本的相角裕度会减小，5°-10°就是用来补偿这部分减小的裕度的。并且通过后面的斜率变换可以自己控制具体补偿多少，后面的斜率越小越陡，要补偿的角度越多。当补偿之后的角度还差一点时，不用重新设计，可以把超前网络后面的转折频率往后移一下，可以保持第一次调整的截止频率不变的基础上，把补偿的相角往上提一提。可以发现超前网络的a负责提高相角和幅值的大小，补偿后截止频率往后提了$\sqrt{a}$倍频。而T则是负责提高的具体频率位置，把提高的最大相角刚好补偿到截止频率上。总之，设计的时候就围绕相角裕度的补偿设计，由要补偿的相角加5°~10°确定a，a确定了补偿的幅值以及补偿后的截止频率，通过补偿后的截止频率和a又可以反推两个转折频率，由此得出超前网络传递函数。</p><p>如果按照相角补偿好了，计算截止频率的指标还达不到的情况下，直接按照截止频率的指标设计超前网络，把调整后截止频率直接设置成目标截止频率，并以这点直接算出两个转折频率（学会利用几何学）。</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/149.png" class=""><hr><p>当给定的参数是时域指标时，要通过查图或公式转换成频域指标（给定超调量唯一确定相角裕度，给定调节时间和已知相角裕度确定截止频率）：</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/150.png" class=""><p>当其它指标都达标后，最后需要验算h指标：</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/151.png" class=""><p>这里反正切函数过多，并且性质和-20，-40，-60的三段规律差不多，可以试根。</p><h4 id="总结-2"><a href="#总结-2" class="headerlink" title="总结"></a>总结</h4><p>超前校正保持了低频段性质不变，满足稳态精度；改善了中频段，提高了相角裕度和截止频率，动态性能提高；但是抬高了高频段，使得抗高频干扰能力降低。</p><hr><h3 id="串联滞后校正"><a href="#串联滞后校正" class="headerlink" title="串联滞后校正"></a>串联滞后校正</h3><p>$$<br>关键公式 G_c(s) = \frac{bTs+1}{Ts + 1}(0&lt;b&lt;1)<br>$$</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/152.png" class=""><p>对滞后网络来说，其增益就是1，不需要另外增加比例环节调节。这个网络不利因素是相角衰减会影响相角裕度，但是可以把截止频率点尽量往后挪可以减小相角裕度的损失，但是幅值的衰减可以利用起来。因此我们可以把截止频率放在滞后网络<strong>第二个转折频率往后的十倍频程</strong>。</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/153.png" class=""><p>可以看到b取得越小，相角裕度的损失越大，但不会超过-6°。</p><p>滞后校正步骤（给定指标$ e_{ss}* ,\omega_c* ,\gamma* $）：</p><p><strong>实质：利用滞后网络幅值衰减的属性挖掘系统自身的相角储备。</strong></p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/154.png" class=""><p>总结：当原有的截止频率有余而相角裕度严重不足的情况下优先考虑用滞后校正。考虑到相角裕度6°的损失，要找到原来曲线中有($\gamma*+6°$)的相角储备的点作为调整后截止频率的点。总之，设计时围绕相角裕度的挖掘展开。</p><h4 id="题目-4"><a href="#题目-4" class="headerlink" title="题目"></a>题目</h4><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/155.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/156.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/157.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/158.png" class=""><p>这里用了一招试探法，根据-20，-40曲线的经验相角储备45°的点在第一个转折频率处，这里多了一个-60斜率，46°相角储备可以往前挪一挪。只有在题目要求的截止频率之后且相角储备大于$\gamma*+6°$即可，没有标准位置，这里的截止频率在2.3到2.6皆可，但尽量截止频率靠大的设计。</p><p>找到了截止频率后，往前减小十倍频就是滞后环节第二个转折频率，第一个转折频率可以通过几何特性来计算。</p><p>结果：</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/159.png" class=""><p>然后进行验算：</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/160.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/161.png" class=""><hr><p>在设计好系统之后，题目如果需要验算h*的值，就需要求-180°相角的频率$\omega_g$，如果环节过多的话这个方程是很难解的，只能试根。但考试允许带计算器，这时候神器来了，一定要学会用计算器的<a href="http://www.360doc.com/content/16/0622/06/7863900_569691363.shtml">牛顿法求解方程</a>，否则试根过程将非常痛苦。</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/162.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/163.png" class=""><p>第二种方法不用试根也不用计算器的牛顿法，只要计算h=10dB的点不小于-180°，就能证明在-180°的点h&gt;10dB，缺点是无法切确知道h的值。</p><hr><p><strong>迟后校正的另一种用法：保持中频段基本不变，抬高低频段</strong></p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/164.png" class=""><p>这种情况的做法先求出低频段需要增加的增益$K_c$，然后将原来的转折频率降低十倍频作为第二个转折频率$\omega_2$，再通过$20lgK_c=20lg\frac{\omega_2}{\omega_1}$计算出第一个转折频率$\omega_1$。这样滞后环节的传递函数为$Kc \frac{\frac{s}{\omega_2}+1}{\frac{s}{\omega_1}+1}$。校正之后相角裕度会损失不到6°，牺牲少量动态性能大大提高稳态精度。</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/165.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/166.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/167.png" class=""><h4 id="总结-3"><a href="#总结-3" class="headerlink" title="总结"></a>总结</h4><p>减小系统增益K可以增大相角裕度，但是稳态误差会增大。滞后网络既保存了低频段的稳态特性，又通过幅值衰减的特性充分挖掘了相角裕度。调节后截止频率再满足相角裕度的条件下要尽量往后设计，这是因为往前设计会导致第一个转折频率过小，使得惯性环节调节时间过长，并且不容易物理实现。同理原系统的增益K也是尽量往小的设计，K增大不改变校正后的截止频率，但会更加增大滞后校正的幅值衰减，导致第一个转折频率拉得更加靠前，物理实现不容易。另外校正完成之后要验证幅值裕度h的值要学会用计算器的牛顿法。滞后校正的另一种功能是保持中频段，抬高低频段。滞后网络压低了高频段，因此抗高频干扰能力提高。</p><hr><h3 id="串联滞后-超前校正"><a href="#串联滞后-超前校正" class="headerlink" title="串联滞后-超前校正"></a>串联滞后-超前校正</h3><p>$$<br>关键公式 G_c(s) = \frac{T_as+1}{aT_as + 1} * \frac{T_bs+1}{\frac{T_b}{a}s + 1}(aT_a&gt;T_a&gt;T_b&gt;\frac{T_b}{a})<br>$$</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/168.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/169.png" class=""><p>在滞后-超前校正的后半部分，相角超前，可以补充相角裕度；并且幅值衰减，可以挖掘自身的相角储备，因此应当把截止频率设定在最后两个转折频率的几何中点处，这是超前角最大的地方。在选择第二个转折频率的时候，应当与校正后的转折频率拉开十倍频，这样滞后部分对相角的损失不会超过-6°。</p><p>滞后-超前校正步骤（给定指标$ e_{ss}* ,\omega_c* ,\gamma* $）：</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/170.png" class=""><p>这里的角度补偿要好好理解一下，<strong>超前部分需要补偿的角度=目标角度-原有角度+6°</strong>，这里截止频率取的是目标的最小值，挖掘出最大的相角储备，但仍然达不到目标值，这时候要通过超前部分补偿起来，同时超前部分也要补偿滞后部分损失的6°，最多能补偿60°。算好补偿的角度后，就可以把超前部分a的值算出来：<br>$$<br>a = \frac{1+\sin\phi_m}{1-\sin\phi_m}<br>$$<br>第四个转折频率往后$\sqrt{a}$倍频，第三个转折频率往前$\sqrt{a}$倍频，注意第四个转折频率之后的线不一定在0dB。第二个转折频率往前10倍频，第一个转折频率直接以-20斜率拉到0dB线保证低频段不变，这个频率的计算要讲解，关系到后面超前环节的上下位置，能否把截止频率精准放在目标处。同样可以利用几何分析方便求解。</p><h4 id="题目-5"><a href="#题目-5" class="headerlink" title="题目"></a>题目</h4><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/171.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/172.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/173.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/174.png" class=""><p>这里求解第一个转折点时需要用到一定的几何技巧，要熟记。</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/175.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/176.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/177.png" class=""><h4 id="总结-4"><a href="#总结-4" class="headerlink" title="总结"></a>总结</h4><p>滞后-超前校正最主要的工作是算准最后两个转折频率相差的频程a值。通过需要补偿的超前角的角度算出a值以后，在截止频率处和原曲线实轴对称的地方，左右拉$\sqrt{a}$倍频就是第三和第四个转折频率，而不是直接拉到0dB线。只有最后两个转折频率决定的超前环节决定最后补偿的相角，滞后环节对相角的损失不超过6°，可以拉任意长度，但第一个转折频率要拉到0dB防止改变低频段的稳态指标。第一个转折频率决定后面超前环节的上下位置，能不能在预定截止频率处把幅值衰减到0dB。</p><hr><h3 id="串联PID校正"><a href="#串联PID校正" class="headerlink" title="串联PID校正"></a>串联PID校正</h3><p>$$<br>关键公式 G_c(s) = K_Ds + K_P + \frac{K_I}{s} = \frac{K_I(T_1s + 1)(T_2s+1)}{s}<br>$$</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/178.png" class=""><p>串联PID校正可以看成滞后-超前校正的特例，相当于第一个转折频率在左边无穷远处，第二个转折频率在右边无穷远处。它的好处是可以把系统的型别提高一个档次，并且后面最大能够把角度拉起90°。</p><h4 id="题目-6"><a href="#题目-6" class="headerlink" title="题目"></a>题目</h4><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/179.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/180.png" class=""><p>这里决定用什么校正尤为重要，首先用超前的话计算频率为13.6的地方的相角裕度为4.789°目标是65°，需要拉起来超过65°-4.789&gt;60°，不能完成任务，用滞后只能在频率有余的时候做，超前-滞后是滞后的进化版，亦是如此。只能用PID校正。</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/181.png" class=""><p>这里干脆把校正频率定到15，算出需要拉起的角度，然后计算第二个转折频率。</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/182.png" class=""><p>第二个转折频率可以直接<strong>根据一阶复合微分的相频曲线</strong>进行设计（前面两个环节相当于滞后环节，损失不会超过-6°），第一个转折频率的计算方法是让刚开始的-20斜率线的延长线过频率为1的点，保证系统增益为1，同样要巧用几何特性。</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/183.png" class=""><p>计算好转折频率后，传递函数就确定了，把分子可全部乘开就可以得到$K_P、K_I、K_D$的数值。</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/184.png" class=""><hr><h3 id="希望特性设计法"><a href="#希望特性设计法" class="headerlink" title="希望特性设计法"></a>希望特性设计法</h3><p>前面规范的方法要掌握透，但不要当成教条，实际情况可以灵活处理。“希望特性”设计方法通过预定指标直接设计校正后的传递函数，把这个函数减去原来的传递函数可以找到校正的函数。</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/186.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/187.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/188.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/189.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/190.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/191.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/192.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/193.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/194.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/195.png" class=""><h2 id="综合题目"><a href="#综合题目" class="headerlink" title="综合题目"></a>综合题目</h2><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/196.png" class=""><h2 id="线性离散系统的分析与校正"><a href="#线性离散系统的分析与校正" class="headerlink" title="线性离散系统的分析与校正"></a>线性离散系统的分析与校正</h2><p>离散系统：系统中有一处或几处信号是脉冲或数码的系统。有采样系统 — 时间离散，数值连续；数字系统 — 时间离散，数值量化。</p><p>计算机控制系统优点控制计算由程序实现，便于修改，容易实现复杂的控制律；抗干扰性强；一机多用，利用率高；便于联网，实现生产过程的自动化和宏观管理。缺点是采样点间信息丢失，与相同条件下的连续系统相比，性能会有所下降；需附加A/D, D/A转换装置。</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/197.png" class=""><p>由于采样是时间上离散，数值上也是离散的，采用还有时间的延迟，为了简化计算，我们把采样过程理想化，认为采样瞬间完成，并且字节足够（忽略量化误差）。</p><p>在采样以后，输入数码量，计算机进行计算以后的数值也是连续的，连续的量再采样成数码量。然后进行D\A的过程，广泛应用的是零阶保持器，把一个个脉冲转换成一个个阶梯信号。</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/198.png" class=""><p>对于信号采样，相当于在每个采样时刻都乘上一个冲激函数，采用后的信号为：<br>$$<br>e^*(t) = e(t) * \sum_{n=0}^{\infty}\delta(t-nT) = \sum_{n=0}^{\infty}e(nT)\delta(t-nT)<br>$$<br>拉式变换后为：<br>$$<br>E^*(s) = \sum_{n=0}^{\infty}e(nT) * e^{-nTs}<br>$$<br>作用：</p><p>① 给出$E^*(s)$与$e(t)$在采样点上取值之间的关系；</p><p>② 一般可写成封闭形式；</p><p>③ 用于求$e^*(t)$的<strong>z变换</strong>或系统的时间响应。</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/199.png" class=""><p>拉式变换后是一个超越函数，不能用有限的多项式进行表示，不好分析，所以离散系统一般用Z变换。</p><p>用傅里叶级数展开$\delta_T(t)$，代入原方程后进行拉式变换：</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/200.png" class=""><p>结论：采样后的拉式变换为：<br>$$<br>E^*(s) = \frac{1}{T} \sum_{n=-\infty}^{\infty}E(s+jn\omega_s)<br>$$<br>作用：</p><p>① 给出$E^*{(s)}$与$E(s)$之间的联系；</p><p>② 一般写不成封闭形式；</p><p>③ 用于$e^*(t)$的<strong>频谱分析</strong>。</p><h3 id="香农采样定理-——信号复现的必要条件"><a href="#香农采样定理-——信号复现的必要条件" class="headerlink" title="香农采样定理 ——信号复现的必要条件"></a>香农采样定理 ——信号复现的必要条件</h3><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/201.png" class=""><p>结论：对一个连续的非周期信号，经过傅里叶变换后频谱是一个连续的非周期的值，并且在$\omega_h$处衰减到0。但对这个信号进行采样以后频谱变成了连续的周期的值，其频谱函数周期为$\omega_s$，原函数采样周期为$T = \frac{2\pi}{\omega_s}$，频谱幅值缩小T倍。但是这是有条件的，如果图上的采样角频率$\omega_s&lt; 2\omega_h$频谱就会混叠在一起无法分开。因此，信号复现的条件是$\omega_s$足够大，采样周期T足够短。<br>$$<br>\omega_s = \frac{2\pi}{T} &gt; 2\omega_h<br>$$<br> 然后通过一个理想低通滤波器把高频信号全部滤除，就可以得到原来连续信号的频谱，但如果频率混叠在一起，滤出来的信号将会失真。</p><p>在实际工程中，把输入端的信号减去输出端的信号，对这个偏差信号进行采样变成数码量，在计算机上进行计算，然后再把<strong>计算机计算结果的控制量从离散信号转换为连续信号</strong>，这才是信号复现的用途。</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/202.png" class=""><h3 id="零阶保持器"><a href="#零阶保持器" class="headerlink" title="零阶保持器"></a>零阶保持器</h3><p>要过滤高频信号，尽可能还原原频谱，需要找一个频率特性和理想滤波器接近的东西。</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/203.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/204.png" class=""><p>可以看出，零阶保存器的幅频相频特性都和理想滤波器有一定差距。但是通过把零阶保持器之后的阶梯信号光滑地链接起来，可以近似看成原信号延迟二分之一的采样周期后的信号。零阶保持器看成二分之一拍纯延时环节。这样的坏处是导致了相角向后延，使得相角裕度变小，系统动态性能变差。但是换来的是计算机控制的诸多便利，在计算机输出端口读取寄存器的过程就是零阶保持器，工程实现不费事。因此在工程上广泛应用。</p><p>总结：以上分析的采样过程在忽略了采样时间和量化误差的基础上。采样周期的选择要符合香农采样定理，然后采用零阶保持器来过滤信号，可以看成大致过滤出比原信号相角延迟二分之一个采样周期的信号。</p><h3 id="Z变换"><a href="#Z变换" class="headerlink" title="Z变换"></a>Z变换</h3><p>$$<br>离散信号 e^*(t) = e(t) * \sum_{n=0}^{\infty}\delta(t-nT) = \sum_{n=0}^{\infty}e(nT)\delta(t-nT)<br>$$</p><p>$$<br>离散信号的拉氏变换E^*(s) = \sum_{n=0}^{\infty}e(nT) * e^{-nTs}<br>$$</p><p>由于超越函数不好分享，现在令：<br>$$<br>z = e^{Ts}<br>$$<br>则有<br>$$<br>E^*(z) = \sum_{n=0}^{\infty}e(nT) * z^{-n}<br>$$<br>z变换仅对离散信号而言，$z^{-1}$相当于一拍延迟算子，由$e(nT)$决定作用的幅值，由$z^{-n}$决定作用的时间，这就是z变换。<strong>注意是连续函数采样之后的拉式变换才能进行z变换</strong>。z变换有级数求和法（定义法）、查表法（部分分式展开法）、留数法（反演积分法）。</p><h4 id="级数求和法"><a href="#级数求和法" class="headerlink" title="级数求和法"></a>级数求和法</h4><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/205.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/206.png" class=""><h4 id="查表法"><a href="#查表法" class="headerlink" title="查表法"></a>查表法</h4><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/207.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/208.png" class=""><h4 id="留数法"><a href="#留数法" class="headerlink" title="留数法"></a>留数法</h4><p>$$<br>E(z) = \sum_{i=1}^{l}[ResE(s)\frac{z}{z-e^{Ts}}]_{s=s_i}<br>$$</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/217.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/209.png" class=""><h4 id="z变换基本定理"><a href="#z变换基本定理" class="headerlink" title="z变换基本定理"></a>z变换基本定理</h4><ol><li>线性性质    </li></ol><p>$$<br>Z[(a * e_1^*(t) \pm b * e_2^*(t))] = a * E_1(z) \pm b * E_2(z)<br>$$</p><ol start="2"><li><p>实位移定理</p><p>延迟定理<br>$$<br>Z(e(t-nT)) = z^{-n}E(z)<br>$$</p></li></ol><p>​       超前定理<br>$$<br>Z[e(t+nT)] = z^n[E(z) - \sum_{k=0}^{n-1}e(kT)*z^{-k}]<br>$$<br>​       题目</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/210.png" class=""><ol start="3"><li>复位移定理</li></ol><p>$$<br>Z[e(t) * e^{\mp at}] = E(z * e^{\pm aT})<br>$$</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/211.png" class=""><ol start="4"><li>初值定理<br>$$<br>\lim_{n \to 0}e(nT) = \lim_{z \to \infty}E(z)<br>$$</li></ol><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/212.png" class=""><ol start="5"><li>终值定理<br>$$<br>\lim_{n \to \infty}e(nT) = \lim_{z \to 1}(z-1)E(z)<br>$$</li></ol><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/213.png" class=""><ol start="6"><li>卷积定理</li></ol><p>$$<br>设： c^*(t) = e^*(t) \otimes g^*(t) = \sum_{k=0}^{\infty} e(kT)*g[(n-k)T]<br>$$</p><p>$$<br>则：C(z) = E(z) * G(z)<br>$$</p><h4 id="z反变换"><a href="#z反变换" class="headerlink" title="z反变换"></a>z反变换</h4><p>有幂级数法（长除法）、查表法（部分分式展开法，以$\frac{E(z)}{z}$形式展开）、留数法（反演积分法）。</p><p>长除法</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/214.png" class=""><p>查表法</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/215.png" class=""><p>留数法<br>$$<br>e(nT) = \sum Res[E(z) * z^{n-1}]<br>$$</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/216.png" class=""><h3 id="离散系统的数学模型"><a href="#离散系统的数学模型" class="headerlink" title="离散系统的数学模型"></a>离散系统的数学模型</h3><h4 id="线性常系数差分方程及其解法——离散系统的时域数学模型"><a href="#线性常系数差分方程及其解法——离散系统的时域数学模型" class="headerlink" title="线性常系数差分方程及其解法——离散系统的时域数学模型"></a>线性常系数差分方程及其解法——离散系统的时域数学模型</h4><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/218.png" class=""><p>结论：前项差分是从末尾往前看n拍的数据，共n+1拍数据。后项差分是从开头往后看n拍的数据，共n+1拍数据。n阶差分就有n+1个拍的加权和，相同阶数的前项差分和后项差分每一项的权重一致。连续函数中的微分（一阶导）可以看出一阶前项差分除以采样周期T。每一拍中都不出现一次以外的高次项，这就是线性的定义；所有前面的系数是常数，这就是定常的定义，这就是线性常系数差分方程。可以用迭代法或Z变换法求解。</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/219.png" class=""><p>题目</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/220.png" class=""><p><strong>迭代法</strong></p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/221.png" class=""><p><strong>Z变换法</strong></p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/222.png" class=""><h4 id="脉冲传递函数——离散系统的复域数学模型"><a href="#脉冲传递函数——离散系统的复域数学模型" class="headerlink" title="脉冲传递函数——离散系统的复域数学模型"></a>脉冲传递函数——离散系统的复域数学模型</h4><p>定义：零初始条件下离散系统输出z变换对输入z变换之比。<br>$$<br>G(z) = \frac{C(z)}{R(z)}<br>$$<br><strong>定理</strong>：输出序列等于输入序列的单位脉冲响应序列的卷积。</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/223.png" class=""><p><strong>性质</strong>：z同样是一个复数，$G(z)$只和系统的结构参数有关。有了G(z)可唯一确定一个系统的差分方程，是一一对应的。$G(z)$是系统单位脉冲响应的z变换。</p><p>局限性：原则上不反映非零初始条件下系统响应的全部信息，一般只适合描述单输入单输出系统，只适合用于描述线性定常系统。</p><p><strong>题目</strong></p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/224.png" class=""><h4 id="开环系统的脉冲传递函数"><a href="#开环系统的脉冲传递函数" class="headerlink" title="开环系统的脉冲传递函数"></a>开环系统的脉冲传递函数</h4><p>环节直接有开关时：<br>$$<br>G(z) = G_1(z)G_2(z)<br>$$<br>环节之间无开关时：<br>$$<br>G(z) = Z[G_1(s) * G_2(s)] = G_1G_2(z)<br>$$<br>有ZOH时：</p><p>由于离散信号经过$1-e^{-Ts}$环节时还是一个离散信号，所以等价于在后面加采样开关，两边分别进行z变换。</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/225.png" class=""><p><strong>零阶保持器不改变系统阶数，不改变开环极点，只改变开环零点。</strong></p><h4 id="闭环系统的脉冲传递函数"><a href="#闭环系统的脉冲传递函数" class="headerlink" title="闭环系统的脉冲传递函数"></a>闭环系统的脉冲传递函数</h4><p>注意有采样开关的离散系统不能使用Mason公式。</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/226.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/227.png" class=""><p>当采样开关不是对误差的采样，采样开关无法前移，这种情况下一般求不出$G(z)$，只能求出$C(z)$，可以把输入信号当成一个环节，输入单位脉冲进行激励。</p><p>每一个对两个信号求差或求和的东西后面有开关都能等效到之前的几条线路。</p><hr><h3 id="离散系统的稳定性分析"><a href="#离散系统的稳定性分析" class="headerlink" title="离散系统的稳定性分析"></a>离散系统的稳定性分析</h3><p>z变换其实就是拉普拉斯变换把$e^{(Ts)}$换成z的结果，而$s= \sigma +j\omega$，有：<br>$$<br>z = e^{\sigma T}e^{j\omega T}<br>$$<br>所以z的幅值和s的实部有关，z的相角和s的虚部有关，s的虚轴相当于z域中半径为1的圆。同理s=-1的轴相当于z域中半径为$e^{-T}$的圆，s越往左，在z域中圆的半径越小。因此<strong>s的稳定域映射到z域中代表的是单位圆</strong>。当s域中的一点在实轴上从0到负无穷相当于在z域上从1到0，从0到正无穷相当于z域从1到正无穷。当频率达到二分之一的采样角频率时，映射到z域是180°角的线上。也就是说<strong>s域中每一个宽度为$\omega_s$的带都代表了一个z域</strong>。在实轴附近的那个带称为主带。在<strong>香农采样定理满足的条件（$\frac{\omega_n}{2}&gt;\omega_h$）下，我们系统的开环零极点在s域上都落在主带上</strong>。</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/228.png" class=""><p>因为z域单位圆越往内数据密度越大，所以为了不造成太大失真，与离散系统有关的数字要用双字节长度。</p><h3 id="离散系统的稳定性判据"><a href="#离散系统的稳定性判据" class="headerlink" title="离散系统的稳定性判据"></a>离散系统的稳定性判据</h3><h4 id="通过w变换使用劳斯判据"><a href="#通过w变换使用劳斯判据" class="headerlink" title="通过w变换使用劳斯判据"></a>通过w变换使用劳斯判据</h4><p>z域上不好进行稳定性判断（如列劳斯表），要把其进行w变换把单位圆的内外转换成虚轴左右。至少有三种方案可供变换：</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/229.png" class=""><p>进行完w变换之后就可以用劳斯判据了。</p><p><strong>题目</strong></p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/230.png" class=""><h4 id="z域中的Jurry稳定判据（重要）"><a href="#z域中的Jurry稳定判据（重要）" class="headerlink" title="z域中的Jurry稳定判据（重要）"></a>z域中的Jurry稳定判据（重要）</h4><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/231.png" class=""><p>$D(z)$是离散系统特征方程，$D(1)$一定要大于0，如果$D(z)$最高次项的次数是偶数，则$D(-1)&gt;0$，是奇数则$D(-1)&lt;0$。这两个条件成立后要列Jurry表。规则如上图，把从<strong>0次到最后一次的系数列第一行</strong>，倒序列第二行，然后第三行把第一列和最后一列往回列行列式计算，第四列把第三列倒序。看第一列元素，都取绝对值，第二行大于第一行，第三行大于第四行，第六行大于第五行以此类推，推到一行三个元素，全部满足系统稳定，否则不稳定。</p><h4 id="题目-7"><a href="#题目-7" class="headerlink" title="题目"></a>题目</h4><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/232.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/233.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/234.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/235.png" class=""><h3 id="离散系统的稳态误差"><a href="#离散系统的稳态误差" class="headerlink" title="离散系统的稳态误差"></a>离散系统的稳态误差</h3><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/236.png" class=""><p>由于当s=0时，z=1，所以可以把z-1在分母中的次数称为系统的型别，把其他部分在z=1时的值称为系统的增益。<br>$$<br>GH(z) = Z[G(s)H(s)] = \frac{1}{(z-1)^v }GH_0(z)<br>$$</p><p>$$<br>\lim_{z \to 1}GH_0(z) = K<br>$$</p><p>用终值定理求$e(\infty)$：<br>$$<br>e(\infty) = \lim_{z \to 1}(z-1)\phi_e(z)R(z) = \lim_{z \to 1}(z-1)R(z) * \frac{1}{1+GH(z)}<br>$$<br><strong>题目</strong></p><p>先判稳</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/237.png" class=""><p>求误差传递函数</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/238.png" class=""><hr><p>由此看来，离散系统同样可以用<strong>静态误差系数法</strong>：</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/239.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/240.png" class=""><hr><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/241.png" class=""><p>可以看到，加了零阶保持器之后不改变系统型别，系统的稳态误差只和原系统增益有关，去除了采样周期对稳态误差的影响。</p><p><strong>动态误差系数法</strong></p><p>可以参考连续系统的动态误差系数法。</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/242.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/243.png" class=""><h3 id="闭环极点分布与动态响应"><a href="#闭环极点分布与动态响应" class="headerlink" title="闭环极点分布与动态响应"></a>闭环极点分布与动态响应</h3><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/244.png" class=""><p>结论：输入单位阶跃的稳态响应值为$\phi (1)$，相当于闭环增益。其他的极点都处于单位圆的内部，结果都衰减到0。对于极点位置对系统的影响，z域内极点位于单位圆内系统稳定，只有落在正实轴上才不产生振荡，越靠近180°振荡频率越高。当极点的模值相同时，信号衰减的速度一致。在进行z反变换时，解出来的是逐渐衰减的离散信号。<br>$$<br>Z^{-1}[\frac{z}{z-p}] = \sum_{n=1}^{\infty} p^n<br>$$<br>对于共轭复数极点，其解出来的系数也一定是共轭复数。有：</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/245.png" class=""><p>因此，对于共轭极点有：<br>$$<br>Z^{-1}[C_1\frac{z}{z-p_1}+C_2\frac{z}{z-p_2}] = 2|C||p|^kcos(k\theta + \phi)<br>$$<br>其中θ是极点对于实轴正方向的夹角，φ是C对于实轴正方向的夹角，k是正整数变量。当极点的角度越小，即θ越小，三角函数中的离散信号越密集，比如$θ=\frac{\pi}{8}$时，一个三角函数周期内有8个离散信号。取90°时会发生一正一负的振铃现象。</p><p><strong>计算动态性能的一般步骤</strong></p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/246.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/247.png" class=""><p>原理是直接用长除法来计算每一个采样点的值，只要值足够多就能定义采样点上的超调量和调节时间。</p><p><strong>根轨迹分析与连续系统类似</strong></p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/248.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/249.png" class=""><h3 id="离散系统的校正"><a href="#离散系统的校正" class="headerlink" title="离散系统的校正"></a>离散系统的校正</h3><h2 id="非线性控制系统分析"><a href="#非线性控制系统分析" class="headerlink" title="非线性控制系统分析"></a>非线性控制系统分析</h2><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/250.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/251.png" class=""><h3 id="相平面法（了解）"><a href="#相平面法（了解）" class="headerlink" title="相平面法（了解）"></a>相平面法（了解）</h3><p><strong>相平面：由系统某变量及其导数构成的用以描述系统状态的平面。</strong></p><p><strong>相轨迹：系统变量及其导数随时间变化在相平面上描绘出来的轨迹。</strong></p><p>相平面法一般用于描述二阶非线性，二阶系统知道x和x的导数就能将运动规律描述清楚，三阶需要三维图像，不好在平面中表述。</p><p>设二阶非线性系统方程为：</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/253.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/252.png" class=""><p>结论：曲线总是顺时针旋转运动，且垂直过横轴，否则就是平衡点。</p><p><strong>解析法绘制相轨迹</strong></p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/254.png" class=""><p>绘制一个二阶的非线性方程的相轨迹要点是把x的二阶导数化为只有x的一阶导数和x的项，然后两边积分可以得到相轨迹，其中的C和初始位置有关。这里运用到了高数中微分方程求解的技巧。</p><p><strong>等倾斜线法绘制相轨迹</strong></p><p>解析法有时由于微分方程难解行不通，而等倾斜线法是通用的方法。</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/255.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/256.png" class=""><p>每条过原点的直线上轨迹通过的斜率都是一致的，通过绘制每条过原点的直线上轨迹的斜率可以大致刻画出轨迹。</p><p>其他曲线也可以用等倾斜线法：</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/261.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/262.png" class=""><p><strong>由相轨迹求时间解</strong></p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/257.png" class=""><p>这里一般求解每一小段的时间然后求和，可以近似得到时间。</p><p><strong>二阶系统的相轨迹</strong></p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/258.png" class=""><h4 id="非线性系统的相平面分析"><a href="#非线性系统的相平面分析" class="headerlink" title="非线性系统的相平面分析"></a>非线性系统的相平面分析</h4><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/259.png" class=""><p>结论：可以采用线性化方法来分析非线性系统在平衡点附近的运动规律。可以看出这个图在0和-1的点都不稳定，一个震荡发散，一个直接发散。</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/260.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/263.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/264.png" class=""><p><strong>存在死区的非线性</strong>：</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/265.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/266.png" class=""><p><strong>继电特性1</strong>：</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/267.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/268.png" class=""><p><strong>继电特性2</strong>：</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/269.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/270.png" class=""><p>不论初始点在什么地方都能回到中间的环中，这叫做<strong>极限环</strong>，这是稳定的周期运动——自振，对应二阶非线性系统的周期运动。</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/271.png" class=""><p><strong>存在饱和区的非线性</strong>：</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/272.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/273.png" class=""><h3 id="描述函数法（重点）"><a href="#描述函数法（重点）" class="headerlink" title="描述函数法（重点）"></a>描述函数法（重点）</h3><p>这部分涉及傅里叶级数展开的知识点，请回看另一篇文章《傅里叶级数与傅里叶变换公式推导》。</p><p><strong>描述函数定义：输出函数的基波分量（与输入函数频率相同）与输入函数的幅值比和相角差。</strong></p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/275.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/274.png" class=""><p>这里需要熟练掌握傅里叶级数展开中$sin\omega t$和$cos\omega t$前面系数$A_1$和$B_1$的求法。对输出函数求傅里叶展开和输入频率相同的那一项。</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/276.png" class=""><p>也就是说，具有滞环特性（在某处同样输入的输出有两个值，取决于速度方向），那么描述函数一般是复数，否则为实数。</p><p><strong>描述函数法分析非线性系统</strong></p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/277.png" class=""><p>这里使用线性的分析方法分析非线性系统，把系统分解为描述函数和线性系统的串联，并采用的是广义的$(-1,0)$点，在系统运行的过程中，这个点是移动的。</p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/278.png" class=""><p>当x存在比较小的波动即A较小时，广义点在曲线外，系统稳定，A值就会逐渐衰减并保存在曲线外。如果给的是比较大的波动，广义点在曲线内，A值会越来越大，因此第一次穿越曲线的点不是稳定点，而是一个临界点。当A足够大时使广义点在曲线外时，又会回退，最终稳定在曲线边缘，因此第二个曲线的穿越点是一个稳定点，这点的幅值由对应的A值确定，频率由Nyquist曲线决定。规律：从外穿里的不是自振点，从里穿到外的是自振点。</p><p><strong>自振分析</strong></p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/279.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/280.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/281.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/282.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/283.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/284.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/285.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/286.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/287.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/288.png" class=""><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/289.png" class=""><p><strong>改善非线性系统性能的措施</strong></p><img src="/2021/02/19/zi-dong-kong-zhi-yuan-li-jing-jiang/290.png" class=""><p>有时可以在线性系统中人为引入非线性从而达到线性系统达不到的控制效果。如：波动小时死区，波动大时有输出的非线性引入到测速反馈前端。</p><h2 id="遗留问题"><a href="#遗留问题" class="headerlink" title="遗留问题"></a>遗留问题</h2><ol><li><p>留数法求z变换和逆变换怎么来的？</p></li><li><p>卷积的定义，为什么输出序列等于输入序列的单位脉冲响应序列的卷积？</p></li><li><p>完善离散系统校正的部分。</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> 自控 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 自控 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>拉普拉斯变换</title>
      <link href="2021/02/15/la-pu-la-si-bian-huan/"/>
      <url>2021/02/15/la-pu-la-si-bian-huan/</url>
      
        <content type="html"><![CDATA[<p> 阅读本文之前，建议先阅读我的另一篇文章《傅里叶级数与傅里叶变换公式推导》，这是本文的基础。</p><p>另外可参考视频<a href="https://www.bilibili.com/video/BV1MJ41147PH?from=search&amp;seid=794247831929693494">【中文翻译配音】3D动画详细解释傅里叶与拉普拉斯变换！</a>   以及    <a href="https://www.bilibili.com/video/BV16x411M7HR?from=search&amp;seid=794247831929693494">珂学原理」No. 26「拉普拉斯变换了什么</a>   以及  <a href="https://www.bilibili.com/video/BV1qi4y1t7JY">傅里叶变换的直观解释</a></p><h2 id="拉普拉斯变换和傅里叶变换的联系"><a href="#拉普拉斯变换和傅里叶变换的联系" class="headerlink" title="拉普拉斯变换和傅里叶变换的联系"></a>拉普拉斯变换和傅里叶变换的联系</h2><p>首先，列出傅里叶变换的公式：<br>$$<br>F(ω) = \int_{-\infty}^{\infty} f(t) e^{-i\omega t}dt<br>$$<br>变换条件：狄利克雷条件，通俗来说，没办法表示一些持续递增的函数，因此会导致$\int_{-\infty}^{\infty} f(t) e^{-i\omega t}dt$的结果趋于无穷。</p><p>这时，我们对$f(t)$先进行处理，乘上一个衰减因子$e^{-\sigma t}(\sigma&gt;0)$，使其在无穷远处衰减为0。式子变为：<br>$$<br>F(ω) = \int_{-\infty}^{\infty} f(t) e^{-(i\omega+\sigma) t}dt<br>$$</p><p>$$<br>L(s) = \int_{0}^{\infty} f(t) e^{-st}dt<br>$$</p><p>这里我们在工程上只考虑t=0之后的信号变换，因此积分下限为0。并且可以理解为把原函数分解为了$e^{\sigma t}\sin\omega x$和$e^{\sigma t}\sin\omega x$的形式，这样就能解决函数无穷远处无穷大的问题。即傅里叶变换是一个正弦扫描器，而拉普拉斯变换是一个正弦和指数扫描器。</p><p>因此，拉普拉斯的函数是一个复平面函数，是三维的：</p><img src="/2021/02/15/la-pu-la-si-bian-huan/1.jpg" class><p>其中截取其中的$\sigma = 0$的平面就是傅里叶变换的函数。</p><hr><h2 id="拉普拉斯变换的收敛域"><a href="#拉普拉斯变换的收敛域" class="headerlink" title="拉普拉斯变换的收敛域"></a>拉普拉斯变换的收敛域</h2><p><strong>收敛域的定义</strong>：在收敛域中，存在$\sigma$，使得$f(t)e^{-\sigma t}$为收敛函数，从使得$\int_{-\infty}^{\infty} f(t) e^{-(i\omega+\sigma) t}$收敛。</p><p>也就是说，当$\sigma $足够大使得$f(t)e^{-\sigma t}$在无穷远处收敛为0时，此处为收敛域，当$\sigma$小于某一个阈值时为发散域。</p><img src="/2021/02/15/la-pu-la-si-bian-huan/2.png" class><p>通常我们非常关注拉普拉斯变换的极点，这时拉普拉斯变换的作用就体现出来了。很多系统，例如RLC电路，弹簧上的质量，以及普遍的控制系统会产生正弦和指数输出，因此需要比傅里叶变换更强大的工具去分析它们。极点的实部就代表了函数包含的指数项，虚部代表函数包含的三角函数项的频率。在自动控制系统中，出现了虚轴往右的极点，即代表有不衰减甚至增大的信号，系统不稳定。</p><h2 id="拉普拉斯变换的应用"><a href="#拉普拉斯变换的应用" class="headerlink" title="拉普拉斯变换的应用"></a>拉普拉斯变换的应用</h2><h3 id="常用拉普拉斯变换公式"><a href="#常用拉普拉斯变换公式" class="headerlink" title="常用拉普拉斯变换公式"></a>常用拉普拉斯变换公式</h3><p>$$<br>\mathscr{L}(e^{-at}) = \int_{0}^{\infty} e^{-at} e^{-st}dt = -\frac 1 {a+s}e^{-(a+s)t}|_0^{\infty} = \frac 1 {a+s}<br>$$</p><p>$$<br>\mathscr{L}(u(t)) = \frac 1 s<br>$$</p><p>$$<br>\mathscr{L}(\delta(t)) =  \int_0^{+\infty} \delta(t)e^{-st}dt = 1<br>$$</p><p>$$<br>\mathscr{L}(t) = \frac 1 {s^2}<br>$$</p><p>$$<br>\mathscr{L}(\frac {t^2} 2) = \frac 1 {s^2}<br>$$</p><p>$$<br>\mathscr{L}(\frac {t^n} {n!}) = \frac 1 {s^{n+1}}<br>$$</p><p>$$<br>\mathscr{L}(te^{-at}) = \frac 1 {(s+a)^2}<br>$$</p><p>$$<br>\mathscr{L}(sinωt) = \frac ω {s^2+ω^2}<br>$$</p><p>$$<br>\mathscr{L}(cosωt) = \frac s {s^2+ω^2}<br>$$</p><p>$$<br>\mathscr{L}(e^{-at}sinωt) = \frac ω {(s+a)^2+ω^2}<br>$$</p><p>$$<br>\mathscr{L}(e^{-at}cosωt) = \frac {s+a} {(s+a)^2+ω^2}<br>$$</p><h3 id="性质"><a href="#性质" class="headerlink" title="性质"></a>性质</h3><p>拉普拉斯变换是线性变换，也就是说符合叠加原理：<br>$$<br>\mathscr{L}(af(t) + bg(t)) = aF(s)+bG(s)<br>$$<br>求导：<br>$$<br>\mathscr{L}(f’(t))= \int_0^{+\infty}f’(t)e^{-st}dt = f(t)e^{-st}|_0^{+\infty} -\int_0^{+\infty}f(t)(-se^{-st})dt = sF(s)-f(0)=sF(s)<br>$$<br>同理，积分:<br>$$<br>\mathscr{L}(\int_0^t f(t)dt) = \frac {F(s)} s<br>$$<br>卷积：<br>$$<br>\mathscr{L}(f(t)\otimes g(t)) = F(s)G(s)<br>$$<br>这些在解微分方程（描述动态世界的数学手段）等方面大大简化了运算，因此拉普拉斯变换是方便快捷的分析工具。</p><h2 id="拉普拉斯逆变换"><a href="#拉普拉斯逆变换" class="headerlink" title="拉普拉斯逆变换"></a>拉普拉斯逆变换</h2><p>公式：<br>$$<br>L^{-1}(F(s)) = \frac 1 {2\pi i}\int_{c-j\infty}^{c+j\infty}F(s)e^{st}ds<br>$$<br>但这个公式在我们的学习过程中并不常用，通常可以用我们上面的常用拉普拉斯变换公式来推导出逆变换结果。</p>]]></content>
      
      
      <categories>
          
          <category> 数学 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数学 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>傅里叶级数与傅里叶变换公式推导</title>
      <link href="2021/02/02/fu-li-xie-ji-shu-yu-fu-li-xie-bian-huan-gong-shi-tui-dao/"/>
      <url>2021/02/02/fu-li-xie-ji-shu-yu-fu-li-xie-bian-huan-gong-shi-tui-dao/</url>
      
        <content type="html"><![CDATA[<p> 首先，傅里叶分析是指把一个周期或非周期函数展开成一个个三角函数的叠加，如果是对其还没有基本概念的，可以看看<a href="https://zhuanlan.zhihu.com/p/19763358">傅里叶分析之掐死教程</a>，这篇文章不依赖数学公式却又十分透彻地讲述了傅里叶分析的基本概念，十分值得一读。但如果先深入探讨其中的数学由来，接下来会讲述详细的数学推导。</p><p>参考视频：<a href="https://www.bilibili.com/video/BV1qi4y1t7JY">傅里叶变换的直观解释</a></p><p>傅里叶变换的基为三角函数，为什么要选三角函数作为傅里叶变换的基，因为三角函数的一大特点是，经过线性时不变系统的操作（加减，倍乘，倍除，积分，求导）后，不改变波形，仅改变相角和幅值。这就给我们提供了一个巨大的好处，那就是在分析线性时不变系统时，仅通过信号的相角和幅值指标就能还原信号，可以忽略基函数波形本身。</p><h2 id="傅里叶级数"><a href="#傅里叶级数" class="headerlink" title="傅里叶级数"></a>傅里叶级数</h2><h4 id="三角函数系的正交性"><a href="#三角函数系的正交性" class="headerlink" title="三角函数系的正交性"></a>三角函数系的正交性</h4><p>三角函数系：{1,sinx,cosx,sin2x,cos2x,…,sinnx,cosnx,…}，它由无数个sinnx和cosnx组成，其中n=0,1,2,…….。</p><p>正交性：<br>$$<br>\int^\pi_{-\pi}\sin nx \cos mx dx = 0<br>$$</p><p>$$<br>\int^\pi_{-\pi}\cos nx \cos mx dx = 0，n\neq m<br>$$</p><p>$$<br>\int^\pi_{-\pi}\sin nx \sin mx dx = 0，n\neq m<br>$$</p><p>当向量点乘等于0：<br>$$<br>\vec a \cdot \vec b = 0<br>$$<br>则两个<strong>向量正交</strong>。</p><p>拓展到函数中，两个函数相乘，原本点乘的加和变成取积分，则：<br>$$<br>\int^{x_1}_{x_2}f(x) g(x) dx = 0<br>$$<br>称为两个<strong>函数正交</strong>。</p><p>证明其正交性，可以用积化和差公式：<br>$$<br>\int^\pi_{-\pi}\cos nx \cos mx dx<br>= \frac{1}{2}\int^\pi_{-\pi}[cos(n-m)x+cos(n+m)x]dx =0<br>$$<br>其中n,m为大于0的整数，只有n=m时，积分结果才不等于0，其他情况同理。<br>$$<br>\int^\pi_{-\pi}\sin nx \sin mx dx<br>= \frac{1}{2}\int^\pi_{-\pi}[cos(n-m)x-cos(n+m)x]dx<br>$$</p><h4 id="周期为2π的函数展开"><a href="#周期为2π的函数展开" class="headerlink" title="周期为2π的函数展开"></a>周期为2π的函数展开</h4><p>因此当一个函数f(x)周期为2π时，可以展开成<br>$$<br>f(x) = \sum^\infty_{n=0}a_ncosnx + \sum^\infty_{n=0}b_nsinnx<br>= \frac 1 2 a_0 + \sum^\infty_{n=1}({a_ncosnx + b_nsinnx})<br>$$<br>对两边取积分，由于三角函数的正交性<br>$$<br>\int_{-\pi}^\pi f(x)dx = \frac1 2\int_{-\pi}^\pi a_0dx = \pi a_0<br>$$</p><p>$$<br>a_0 = \frac 1 {\pi}\int_{-\pi}^\pi f(x)dx<br>$$</p><p>原式乘以cos mx 再对两边取积分可得：<br>$$<br>\int^\pi_{-\pi}f(x) \cos mx dx  = \sum^\infty_{n=1}\int^\pi_{-\pi} a_ncosnx cosmx dx<br>= \int^\pi_{-\pi} a_ncos^2 nx  dx = a_n\pi<br>$$</p><p>$$<br>a_n = \frac 1 \pi \int^\pi_{-\pi}f(x) \cos nx dx<br>$$</p><p>同理，两边同乘sinmx再取积分可得：<br>$$<br>b_n = \frac 1 \pi \int^\pi_{-\pi}f(x) \sin nx dx<br>$$</p><h4 id="周期为2L的函数展开"><a href="#周期为2L的函数展开" class="headerlink" title="周期为2L的函数展开"></a>周期为2L的函数展开</h4><p>利用换元的方法，令：$x = \frac \pi L t$ ，即$t = \frac L \pi x$，可得：<br>$$<br>f(t) = \frac {a_0} 2 + \sum^\infty_{n=1}({a_ncos \frac{n\pi}{L}t + b_nsin\frac{n\pi}{L}t})<br>$$</p><p>$$<br>a_0 = \frac 1 {L}\int_{-L}^L f(t)dt<br>$$</p><p>$$<br>a_n = \frac 1 L \int^L_{-L}f(x) \cos nx dx<br>$$</p><p>$$<br>b_n = \frac 1 L \int^L_{-L}f(x) \sin nx dx<br>$$</p><p>在工程中t总是从0开始，周期T=2L，ω = $\frac \pi L = \frac 2\pi T$，此时：<br>$$<br>f(t) = \frac {a_0} 2 + \sum^\infty_{n=1}({a_ncosωt + b_nsinωt})<br>$$</p><p>$$<br>a_0 = \frac 2 {T}\int_{0}^T f(t)dt<br>$$</p><p>$$<br>a_n = \frac 2 T \int^T_{0}f(x) \cos nx dx<br>$$</p><p>$$<br>b_n = \frac 2 T \int^T_{0}f(x) \sin nx dx<br>$$</p><h4 id="傅里叶级数的复数表达形式"><a href="#傅里叶级数的复数表达形式" class="headerlink" title="傅里叶级数的复数表达形式"></a>傅里叶级数的复数表达形式</h4><p>欧拉公式：$ e^{iθ} = cosθ + isinθ$ </p><p>可得：<br>$$<br>cosθ = \frac 1 2 (e^{iθ}+e^{-iθ})<br>$$</p><p>$$<br>sinθ = \frac 1 2 i(e^{iθ}-e^{-iθ})<br>$$</p><p>把这两条式子代入f(t)的式子中可得：<br>$$<br>f(t) = \frac {a_0} 2 + \sum_{n=1}^\infty \frac {a_n-ib_n} 2 e^{in\omega t}+ \sum_{n=1}^\infty \frac {a_n+ib_n} 2 e^{-in\omega t}<br>= \sum_{n=0}^0 \frac {a_0} 2 e^{in\omega t} + \sum_{n=1}^\infty \frac {a_n-ib_n} 2 e^{in\omega t}+ \sum_{n=-1}^{-\infty} \frac {a_{-n}+ib_{-n}} 2 e^{in\omega t} = \sum_{-\infty}^\infty C_n e^{in\omega t}<br>$$<br>当n = 0时，<br>$$<br>C_n = \frac {a_0} 2 = \frac 1 {T}\int_{0}^T f(t)dt<br>$$<br>当n &gt; 0时，<br>$$<br>C_n = \frac {a_n-ib_n} 2 = \frac 1 2 (\frac 2 T \int_0^T f(t)cos{n\omega t} - i\frac 2 T \int_0^Tf(t)sin{n\omega t})<br>= \frac 1 T \int_0^T f(t)(cos{n\omega t} - isin{n\omega t}) dt = \frac 1 T \int_0^T f(t) e^{-in\omega t}dt<br>$$<br>当n &lt; 0时，<br>$$<br>C_n = \frac {a_{-n}+ib_{-n}} 2 = \frac 1 T \int_0^T f(t)(cos{n\omega t} - isin{n\omega t}) dt = \frac 1 T \int_0^T f(t) e^{-in\omega t}dt<br>$$</p><p>因此得出结论，一个周期函数f(t)有f(t)=f(t+T)时：<br>$$<br>f(t) = \sum_{-\infty}^\infty C_n e^{in\omega t}<br>$$</p><p>$$<br>C_n = \frac 1 T \int_0^T f(t) e^{-in\omega t}dt<br>$$</p><p>可以得出，互为相反数的n都可以表示同一个频率，它们幅值相等，相角互为相反数，即共轭，可表示为a+bi和a-bi。它们进行叠加后表示实际的频谱，其幅值为单个的2倍，相角与负频率时计算的频谱的相角相等。</p><h2 id="傅里叶变换"><a href="#傅里叶变换" class="headerlink" title="傅里叶变换"></a>傅里叶变换</h2><p>对于$C_n$来说，它的值是一个复数，而nω是一个离散的值，那么可以在代表nω的轴上一个个特定的点上设一个平面，这个平面是一个复平面，它的长度和方向代表$C_n$：</p><img src="/2021/02/02/fu-li-xie-ji-shu-yu-fu-li-xie-bian-huan-gong-shi-tui-dao/1.png" class=""><p>在工程上，横坐标为时间的波形图称为时域表达，而这幅图显示的是在各种不同频率下的值，称为频域表达，也是波形图的频谱，这就是从不同的角度看时间，每一种波形都对应一种频谱。不过很多时候的频谱都不是这种复平面三维的，我们会把$C_n$的幅度即模单独拿出来，就可以表示这个函数在不同频率下的强度了。</p><img src="/2021/02/02/fu-li-xie-ji-shu-yu-fu-li-xie-bian-huan-gong-shi-tui-dao/2.png" class=""><p>当T增大时，ω数值减小，nω之间就挨得越近。T趋于无穷时会形成一条连续的曲线：</p><img src="/2021/02/02/fu-li-xie-ji-shu-yu-fu-li-xie-bian-huan-gong-shi-tui-dao/3.png" class=""><p>由：<br>$$<br>f(t) = \sum_{-\infty}^\infty C_n e^{in\omega t}<br>$$</p><p>$$<br>C_n = \frac 1 T \int_0^T f(t) e^{-in\omega t}dt<br>$$</p><p>得到：<br>$$<br>f_T(t) = \sum_{n=-\infty}^{\infty}\frac 1 T \int_{-\frac T 2}^{\frac T 2} f_T(t) e^{-in\omega_0 t}dt e^{inω_0t}<br>$$</p><p>$$<br>f_T(t) = \sum_{n=-\infty}^{\infty}\frac {\Deltaω} {2\pi} \int_{-\frac T 2}^{\frac T 2} f_T(t) e^{-in\omega_0 t}dt e^{inω_0t}<br>$$</p><p>当$T \rightarrow \infty$：<br>$$<br>f(t) = \frac {1} {2\pi}  \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} f(t) e^{-i\omega t}dt e^{inωt}d\omega<br>$$<br>因此我们把中间的公式称为**傅里叶变换(FT)**：<br>$$<br>F(ω) = \int_{-\infty}^{\infty} f(t) e^{-i\omega t}dt<br>$$<br>$$<br>F(ω) = \int_{-\infty}^{\infty}f(t)cos(ωt)dt-i\int_{-\infty}^{\infty}f(t)sin(ωt)dt<br>$$</p><p>通过这个函数可以表示在任何频率的情况下的三角函数的波形的振幅，这通常是一个复数a+bi，实际上用$\sqrt{a^2+b^2}$表示其振幅（实际振幅为2倍），即幅值图，同理还有相角图。其中实数部分代表cos，虚数部分代表-sin。而负频率没有现实意义，其振幅为正频率的共轭a-bi，只是为了在数学上的计算便利。</p><img src="/2021/02/02/fu-li-xie-ji-shu-yu-fu-li-xie-bian-huan-gong-shi-tui-dao/4.png" class=""><img src="/2021/02/02/fu-li-xie-ji-shu-yu-fu-li-xie-bian-huan-gong-shi-tui-dao/5.png" class=""><p>外面套的公式称为**傅里叶变换的逆变换(IFT)**：<br>$$<br>f(t) = \frac {1} {2\pi}  \int_{-\infty}^{\infty} F(ω) e^{iωt}d\omega<br>$$<br>傅里叶变换的所有内容讲解完毕了，傅里叶变换其实是一种特殊的拉普拉斯变换(s=iω)，遵循拉普拉斯变换的所有性质。</p><h2 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h2><p>1、<strong>傅里叶变换得到的是频率密度函数，它的纵坐标是幅值密度。而傅里叶级数的纵坐标是真实的幅值。</strong></p><p>2、连续周期函数的<strong>傅立叶变换</strong>是冲激函数组成的，可以用三角函数正交性证明。</p><p>3、在一个以2T为周期内f(X)连续或只有有限个第一类间断点，附f（x）单调或可划分成有限个单调区间，则F（x）以2T为周期的傅里叶级数收敛，和函数S（x）也是以2T为周期的周期函数，且在这些间断点上，函数是有限值；在一个周期内具有有限个极值点；绝对可积。</p>]]></content>
      
      
      <categories>
          
          <category> 数学 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数学 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>关于pycharm中第三方库安装失败的解决方法</title>
      <link href="2021/01/30/guan-yu-pycharm-zhong-di-san-fang-ku-an-zhuang-shi-bai-de-jie-jue-fang-fa/"/>
      <url>2021/01/30/guan-yu-pycharm-zhong-di-san-fang-ku-an-zhuang-shi-bai-de-jie-jue-fang-fa/</url>
      
        <content type="html"><![CDATA[<p> 使用pycharm图形界面安装第三方库失败，遇到下面的错误：</p><p>pip._vendor.urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host=’files.pythonhosted.org’, port=443): Read timed out.</p><p>解决方法：在评议charm终端中使用命令安装，并直接更换国内安装源进行安装。</p><ul><li>pip国内的一些镜像</li></ul><p>  阿里云 <a href="http://mirrors.aliyun.com/pypi/simple/">http://mirrors.aliyun.com/pypi/simple/</a><br>  中国科技大学 <a href="https://pypi.mirrors.ustc.edu.cn/simple/">https://pypi.mirrors.ustc.edu.cn/simple/</a><br>  豆瓣(douban) <a href="http://pypi.douban.com/simple/">http://pypi.douban.com/simple/</a><br>  清华大学 <a href="https://pypi.tuna.tsinghua.edu.cn/simple/">https://pypi.tuna.tsinghua.edu.cn/simple/</a><br>  中国科学技术大学 <a href="http://pypi.mirrors.ustc.edu.cn/simple/">http://pypi.mirrors.ustc.edu.cn/simple/</a></p><ul><li>使用时pip的时候在后面加上-i参数，指定pip源<br>eg: pip install scrapy -i <a href="https://pypi.tuna.tsinghua.edu.cn/simple">https://pypi.tuna.tsinghua.edu.cn/simple</a></li></ul><p><strong>永久修改</strong>：</p><p>windows:</p><p>win+R 打开用户目录%HOMEPATH%，在此目录下创建 pip 文件夹，在 pip 目录下创建 pip.ini 文件, 内容如下</p><pre class=" language-a"><code class="language-a">[global]timeout = 6000index-url = https://pypi.tuna.tsinghua.edu.cn/simpletrusted-host = pypi.tuna.tsinghua.edu.cn</code></pre>]]></content>
      
      
      <categories>
          
          <category> Pycharm </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Pycharm </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>机器学习之k近邻算法</title>
      <link href="2021/01/24/ji-qi-xue-xi-zhi-k-jin-lin-suan-fa/"/>
      <url>2021/01/24/ji-qi-xue-xi-zhi-k-jin-lin-suan-fa/</url>
      
        <content type="html"><![CDATA[<p> 本文的代码基于书本《机器学习实战》</p><h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><p>k-近邻算法采用测量不同特征值之间距离的方法进行分类。工作原理是：存在一个样本数据集合，称作训练样本集，样本中每个数据都存在标签。输入没有标签的新数据后，将新数据的每个特征与样本集中数据对应的特征进行比较，算法提取样本集中特征最相似数据（最近邻）的分类标签，我们只选择样本数据集中前k个最相似的数据，使用的是欧式距离的计算公式，通常k是不大于20的整数，选择k个最相似数据中出现次数最多的分类作为新数据的分类，这就是k-近邻算法。</p><h2 id="算法简单示例"><a href="#算法简单示例" class="headerlink" title="算法简单示例"></a>算法简单示例</h2><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np                        <span class="token comment" spellcheck="true">#科学计算包</span><span class="token keyword">import</span> operator                           <span class="token comment" spellcheck="true">#运算符模块</span><span class="token keyword">def</span> <span class="token function">createDataSet</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                       <span class="token comment" spellcheck="true">#创建四组数据</span>    <span class="token comment" spellcheck="true">#四组二维特征</span>    group <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">101</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">89</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">108</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">115</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#四组特征的标签</span>    labels <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'爱情片'</span><span class="token punctuation">,</span><span class="token string">'爱情片'</span><span class="token punctuation">,</span><span class="token string">'动作片'</span><span class="token punctuation">,</span><span class="token string">'动作片'</span><span class="token punctuation">]</span>    <span class="token keyword">return</span> group<span class="token punctuation">,</span> labels<span class="token keyword">def</span> <span class="token function">classify0</span><span class="token punctuation">(</span>inX<span class="token punctuation">,</span> dataSet<span class="token punctuation">,</span> labels<span class="token punctuation">,</span> k<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true">#numpy函数shape[0]返回dataSet的行数</span>    dataSetSize <span class="token operator">=</span> dataSet<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>    <span class="token comment" spellcheck="true">#在列向量方向上重复inX共1次(横向)，行向量方向上重复inX共dataSetSize次(纵向)</span>    diffMat <span class="token operator">=</span> np<span class="token punctuation">.</span>tile<span class="token punctuation">(</span>inX<span class="token punctuation">,</span> <span class="token punctuation">(</span>dataSetSize<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">-</span> dataSet    <span class="token comment" spellcheck="true">#二维特征相减后平方</span>    sqDiffMat <span class="token operator">=</span> diffMat<span class="token operator">**</span><span class="token number">2</span>    <span class="token comment" spellcheck="true">#sum()所有元素相加，sum(0)列相加，sum(1)行相加</span>    sqDistances <span class="token operator">=</span> sqDiffMat<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#开方，计算出距离</span>    distances <span class="token operator">=</span> sqDistances<span class="token operator">**</span><span class="token number">0.5</span>    <span class="token comment" spellcheck="true">#返回distances中元素从小到大排序后的索引值</span>    sortedDistIndices <span class="token operator">=</span> distances<span class="token punctuation">.</span>argsort<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#定一个记录类别次数的字典</span>    classCount <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>    <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>k<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true">#取出前k个元素的类别</span>        voteIlabel <span class="token operator">=</span> labels<span class="token punctuation">[</span>sortedDistIndices<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">]</span>        <span class="token comment" spellcheck="true">#dict.get(key,default=None),字典的get()方法,返回指定键的值,如果值不在字典中返回默认值。</span>        <span class="token comment" spellcheck="true">#计算类别次数</span>        classCount<span class="token punctuation">[</span>voteIlabel<span class="token punctuation">]</span> <span class="token operator">=</span> classCount<span class="token punctuation">.</span>get<span class="token punctuation">(</span>voteIlabel<span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span>    <span class="token comment" spellcheck="true">#python3中用items()替换python2中的iteritems()</span>    <span class="token comment" spellcheck="true">#key=operator.itemgetter(1)根据字典的值进行排序</span>    <span class="token comment" spellcheck="true">#key=operator.itemgetter(0)根据字典的键进行排序</span>    <span class="token comment" spellcheck="true">#reverse降序排序字典，这是一个列表，包含元组</span>    sortedClassCount <span class="token operator">=</span> sorted<span class="token punctuation">(</span>classCount<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>key<span class="token operator">=</span>operator<span class="token punctuation">.</span>itemgetter<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>reverse<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#返回次数最多的类别,即所要分类的类别</span>    <span class="token keyword">return</span> sortedClassCount<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true">#创建数据集</span>    group<span class="token punctuation">,</span> labels <span class="token operator">=</span> createDataSet<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#测试集</span>    test <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">101</span><span class="token punctuation">,</span><span class="token number">20</span><span class="token punctuation">]</span>    <span class="token comment" spellcheck="true">#kNN分类</span>    test_class <span class="token operator">=</span> classify0<span class="token punctuation">(</span>test<span class="token punctuation">,</span> group<span class="token punctuation">,</span> labels<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#打印分类结果</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>test_class<span class="token punctuation">)</span></code></pre><h2 id="基于文件处理的算法（改进约会网站的配对效果）"><a href="#基于文件处理的算法（改进约会网站的配对效果）" class="headerlink" title="基于文件处理的算法（改进约会网站的配对效果）"></a>基于文件处理的算法（改进约会网站的配对效果）</h2><p>文件前几行：</p><pre class=" language-txt"><code class="language-txt">40920    8.326976    0.953952    largeDoses14488    7.153469    1.673904    smallDoses26052    1.441871    0.805124    didntLike75136    13.147394    0.428964    didntLike38344    1.669788    0.134296    didntLike72993    10.141740    1.032955    didntLike35948    6.830792    1.213192    largeDoses42666    13.276369    0.543880    largeDoses67497    8.631577    0.749278    didntLike35483    12.273169    1.508053    largeDoses50242    3.723498    0.831917    didntLike63275    8.385879    1.669485    didntLike5569    4.875435    0.728658    smallDoses51052    4.680098    0.625224    didntLike77372    15.299570    0.331351    didntLike43673    1.889461    0.191283    didntLike61364    7.516754    1.269164    didntLike69673    14.239195    0.261333    didntLike15669    0.000000    1.250185    smallDoses</code></pre><p>导入的包：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> matplotlib<span class="token punctuation">.</span>font_manager <span class="token keyword">import</span> FontProperties<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>lines <span class="token keyword">as</span> mlines<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> operator</code></pre><p>文件处理：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">file2matrix</span><span class="token punctuation">(</span>filename<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true">#打开文件,此次应指定编码</span>    fr <span class="token operator">=</span> open<span class="token punctuation">(</span>filename<span class="token punctuation">,</span><span class="token string">'r'</span><span class="token punctuation">,</span>encoding <span class="token operator">=</span> <span class="token string">'utf-8'</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#读取文件所有内容</span>    arrayOLines <span class="token operator">=</span> fr<span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#针对有BOM的UTF-8文本，应该去掉BOM，否则后面会引发错误。</span>    arrayOLines<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">=</span>arrayOLines<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>lstrip<span class="token punctuation">(</span><span class="token string">'\ufeff'</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#得到文件行数</span>    numberOfLines <span class="token operator">=</span> len<span class="token punctuation">(</span>arrayOLines<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#返回的NumPy矩阵,解析完成的数据:numberOfLines行,3列</span>    returnMat <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>numberOfLines<span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#返回的分类标签向量</span>    classLabelVector <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token comment" spellcheck="true">#行的索引值</span>    index <span class="token operator">=</span> <span class="token number">0</span>    <span class="token keyword">for</span> line <span class="token keyword">in</span> arrayOLines<span class="token punctuation">:</span>        <span class="token comment" spellcheck="true">#s.strip(rm)，当rm空时,默认删除空白符(包括'\n','\r','\t',' ')</span>        line <span class="token operator">=</span> line<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">#使用s.split(str="",num=string,cout(str))将字符串根据'\t'分隔符进行切片。</span>        listFromLine <span class="token operator">=</span> line<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'\t'</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">#将数据前三列提取出来,存放到returnMat的NumPy矩阵中,也就是特征矩阵</span>        returnMat<span class="token punctuation">[</span>index<span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">=</span> listFromLine<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">:</span><span class="token number">3</span><span class="token punctuation">]</span>        <span class="token comment" spellcheck="true">#根据文本中标记的喜欢的程度进行分类,1代表不喜欢,2代表魅力一般,3代表极具魅力   </span>        <span class="token comment" spellcheck="true"># 对于datingTestSet2.txt  最后的标签是已经经过处理的 标签已经改为了1, 2, 3</span>        <span class="token keyword">if</span> listFromLine<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">'didntLike'</span><span class="token punctuation">:</span>            classLabelVector<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>        <span class="token keyword">elif</span> listFromLine<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">'smallDoses'</span><span class="token punctuation">:</span>            classLabelVector<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>        <span class="token keyword">elif</span> listFromLine<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">'largeDoses'</span><span class="token punctuation">:</span>            classLabelVector<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span>        index <span class="token operator">+=</span> <span class="token number">1</span>    <span class="token keyword">return</span> returnMat<span class="token punctuation">,</span> classLabelVector</code></pre><p>分类函数：</p><pre class=" language-python"><code class="language-python"><span class="token triple-quoted-string string">"""    inX - 用于分类的数据(测试集)    dataSet - 用于训练的数据(训练集)    labes - 分类标签    k - kNN算法参数,选择距离最小的k个点    sortedClassCount[0][0] - 分类结果"""</span><span class="token keyword">def</span> <span class="token function">classify0</span><span class="token punctuation">(</span>inX<span class="token punctuation">,</span> dataSet<span class="token punctuation">,</span> labels<span class="token punctuation">,</span> k<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true">#numpy函数shape[0]返回dataSet的行数</span>    dataSetSize <span class="token operator">=</span> dataSet<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>    <span class="token comment" spellcheck="true">#在列向量方向上重复inX共1次(横向)，行向量方向上重复inX共dataSetSize次(纵向)</span>    diffMat <span class="token operator">=</span> np<span class="token punctuation">.</span>tile<span class="token punctuation">(</span>inX<span class="token punctuation">,</span> <span class="token punctuation">(</span>dataSetSize<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">-</span> dataSet    <span class="token comment" spellcheck="true">#二维特征相减后平方</span>    sqDiffMat <span class="token operator">=</span> diffMat<span class="token operator">**</span><span class="token number">2</span>    <span class="token comment" spellcheck="true">#sum()所有元素相加，sum(0)列相加，sum(1)行相加</span>    sqDistances <span class="token operator">=</span> sqDiffMat<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#开方，计算出距离</span>    distances <span class="token operator">=</span> sqDistances<span class="token operator">**</span><span class="token number">0.5</span>    <span class="token comment" spellcheck="true">#返回distances中元素从小到大排序后的索引值</span>    sortedDistIndices <span class="token operator">=</span> distances<span class="token punctuation">.</span>argsort<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#定一个记录类别次数的字典</span>    classCount <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>    <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>k<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true">#取出前k个元素的类别</span>        voteIlabel <span class="token operator">=</span> labels<span class="token punctuation">[</span>sortedDistIndices<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">]</span>        <span class="token comment" spellcheck="true">#dict.get(key,default=None),字典的get()方法,返回指定键的值,如果值不在字典中返回默认值。</span>        <span class="token comment" spellcheck="true">#计算类别次数</span>        classCount<span class="token punctuation">[</span>voteIlabel<span class="token punctuation">]</span> <span class="token operator">=</span> classCount<span class="token punctuation">.</span>get<span class="token punctuation">(</span>voteIlabel<span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span>    <span class="token comment" spellcheck="true">#python3中用items()替换python2中的iteritems()</span>    <span class="token comment" spellcheck="true">#key=operator.itemgetter(1)根据字典的值进行排序</span>    <span class="token comment" spellcheck="true">#key=operator.itemgetter(0)根据字典的键进行排序</span>    <span class="token comment" spellcheck="true">#reverse降序排序字典，这是一个列表，包含元组</span>    sortedClassCount <span class="token operator">=</span> sorted<span class="token punctuation">(</span>classCount<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>key<span class="token operator">=</span>operator<span class="token punctuation">.</span>itemgetter<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>reverse<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#返回次数最多的类别,即所要分类的类别</span>    <span class="token keyword">return</span> sortedClassCount<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span></code></pre><p>归一化函数，把数值限制在0到1的范围内，防止数值较大的属性对计算结果的影响大：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">autoNorm</span><span class="token punctuation">(</span>dataSet<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true">#获得数据的最小值</span>    minVals <span class="token operator">=</span> dataSet<span class="token punctuation">.</span>min<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>    maxVals <span class="token operator">=</span> dataSet<span class="token punctuation">.</span>max<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#最大值和最小值的范围</span>    ranges <span class="token operator">=</span> maxVals <span class="token operator">-</span> minVals    <span class="token comment" spellcheck="true">#shape(dataSet)返回dataSet的矩阵行列数</span>    normDataSet <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>np<span class="token punctuation">.</span>shape<span class="token punctuation">(</span>dataSet<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#返回dataSet的行数</span>    m <span class="token operator">=</span> dataSet<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>    <span class="token comment" spellcheck="true">#原始值减去最小值</span>    normDataSet <span class="token operator">=</span> dataSet <span class="token operator">-</span> np<span class="token punctuation">.</span>tile<span class="token punctuation">(</span>minVals<span class="token punctuation">,</span> <span class="token punctuation">(</span>m<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#除以最大和最小值的差,得到归一化数据</span>    normDataSet <span class="token operator">=</span> normDataSet <span class="token operator">/</span> np<span class="token punctuation">.</span>tile<span class="token punctuation">(</span>ranges<span class="token punctuation">,</span> <span class="token punctuation">(</span>m<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#返回归一化数据结果,数据范围,最小值</span>    <span class="token keyword">return</span> normDataSet<span class="token punctuation">,</span> ranges<span class="token punctuation">,</span> minVals</code></pre><p>分类器测试函数，取百分之十的数据作为测试数据，检测分类器的正确性</p><pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">datingClassTest</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true">#打开的文件名</span>    filename <span class="token operator">=</span> <span class="token string">"datingTestSet.txt"</span>    <span class="token comment" spellcheck="true">#将返回的特征矩阵和分类向量分别存储到datingDataMat和datingLabels中</span>    datingDataMat<span class="token punctuation">,</span> datingLabels <span class="token operator">=</span> file2matrix<span class="token punctuation">(</span>filename<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#取所有数据的百分之十</span>    hoRatio <span class="token operator">=</span> <span class="token number">0.10</span>    <span class="token comment" spellcheck="true">#数据归一化,返回归一化后的矩阵,数据范围,数据最小值</span>    normMat<span class="token punctuation">,</span> ranges<span class="token punctuation">,</span> minVals <span class="token operator">=</span> autoNorm<span class="token punctuation">(</span>datingDataMat<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#获得normMat的行数</span>    m <span class="token operator">=</span> normMat<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>    <span class="token comment" spellcheck="true">#百分之十的测试数据的个数</span>    numTestVecs <span class="token operator">=</span> int<span class="token punctuation">(</span>m <span class="token operator">*</span> hoRatio<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#分类错误计数</span>    errorCount <span class="token operator">=</span> <span class="token number">0.0</span>    <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>numTestVecs<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true">#前numTestVecs个数据作为测试集,后m-numTestVecs个数据作为训练集</span>        classifierResult <span class="token operator">=</span> classify0<span class="token punctuation">(</span>normMat<span class="token punctuation">[</span>i<span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span> normMat<span class="token punctuation">[</span>numTestVecs<span class="token punctuation">:</span>m<span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span>             datingLabels<span class="token punctuation">[</span>numTestVecs<span class="token punctuation">:</span>m<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"分类结果:%s\t真实类别:%d"</span> <span class="token operator">%</span> <span class="token punctuation">(</span>classifierResult<span class="token punctuation">,</span> datingLabels<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> classifierResult <span class="token operator">!=</span> datingLabels<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">:</span>            errorCount <span class="token operator">+=</span> <span class="token number">1.0</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"错误率:%f%%"</span> <span class="token operator">%</span><span class="token punctuation">(</span>errorCount<span class="token operator">/</span>float<span class="token punctuation">(</span>numTestVecs<span class="token punctuation">)</span><span class="token operator">*</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><p>分类结果：</p><pre class=" language-a"><code class="language-a">--snip--分类结果:3    真实类别:3[(3, 4)]分类结果:3    真实类别:3[(2, 2), (3, 1), (1, 1)]分类结果:2    真实类别:2[(2, 2), (1, 2)]分类结果:2    真实类别:1[(1, 2), (3, 2)]分类结果:1    真实类别:1错误率:4.000000%</code></pre><p>绘图函数，可视化数据：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">showdatas</span><span class="token punctuation">(</span>datingDataMat<span class="token punctuation">,</span> datingLabels<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true">#设置汉字格式</span>    font <span class="token operator">=</span> FontProperties<span class="token punctuation">(</span>fname<span class="token operator">=</span>r<span class="token string">"c:\windows\fonts\simhei.ttf"</span><span class="token punctuation">,</span> size<span class="token operator">=</span><span class="token number">14</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true">##需要查看自己的电脑是否会包含该字体</span>    <span class="token comment" spellcheck="true">#将fig画布分隔成1行1列,不共享x轴和y轴,fig画布的大小为(13,8)</span>    <span class="token comment" spellcheck="true">#当nrow=2,nclos=2时,代表fig画布被分为四个区域,axs[0][0]表示第一行第一个区域</span>    fig<span class="token punctuation">,</span> axs <span class="token operator">=</span> plt<span class="token punctuation">.</span>subplots<span class="token punctuation">(</span>nrows<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> ncols<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>sharex<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> sharey<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">13</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    numberOfLabels <span class="token operator">=</span> len<span class="token punctuation">(</span>datingLabels<span class="token punctuation">)</span>    LabelsColors <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token keyword">for</span> i <span class="token keyword">in</span> datingLabels<span class="token punctuation">:</span>        <span class="token keyword">if</span> i <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">:</span>            LabelsColors<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token string">'black'</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> i <span class="token operator">==</span> <span class="token number">2</span><span class="token punctuation">:</span>            LabelsColors<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token string">'orange'</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> i <span class="token operator">==</span> <span class="token number">3</span><span class="token punctuation">:</span>            LabelsColors<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token string">'red'</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#画出散点图,以datingDataMat矩阵的第一(飞行常客例程)、第二列(玩游戏)数据画散点数据,散点大小为15,透明度为0.5</span>    axs<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>x<span class="token operator">=</span>datingDataMat<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> y<span class="token operator">=</span>datingDataMat<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> color<span class="token operator">=</span>LabelsColors<span class="token punctuation">,</span>s<span class="token operator">=</span><span class="token number">15</span><span class="token punctuation">,</span> alpha<span class="token operator">=</span><span class="token punctuation">.</span><span class="token number">5</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#设置标题,x轴label,y轴label</span>    axs0_title_text <span class="token operator">=</span> axs<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>set_title<span class="token punctuation">(</span>u<span class="token string">'每年获得的飞行常客里程数与玩视频游戏所消耗时间占比'</span><span class="token punctuation">,</span>FontProperties<span class="token operator">=</span>font<span class="token punctuation">)</span>    axs0_xlabel_text <span class="token operator">=</span> axs<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>set_xlabel<span class="token punctuation">(</span>u<span class="token string">'每年获得的飞行常客里程数'</span><span class="token punctuation">,</span>FontProperties<span class="token operator">=</span>font<span class="token punctuation">)</span>    axs0_ylabel_text <span class="token operator">=</span> axs<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>set_ylabel<span class="token punctuation">(</span>u<span class="token string">'玩视频游戏所消耗时间占比'</span><span class="token punctuation">,</span>FontProperties<span class="token operator">=</span>font<span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>setp<span class="token punctuation">(</span>axs0_title_text<span class="token punctuation">,</span> size<span class="token operator">=</span><span class="token number">9</span><span class="token punctuation">,</span> weight<span class="token operator">=</span><span class="token string">'bold'</span><span class="token punctuation">,</span> color<span class="token operator">=</span><span class="token string">'red'</span><span class="token punctuation">)</span>      plt<span class="token punctuation">.</span>setp<span class="token punctuation">(</span>axs0_xlabel_text<span class="token punctuation">,</span> size<span class="token operator">=</span><span class="token number">7</span><span class="token punctuation">,</span> weight<span class="token operator">=</span><span class="token string">'bold'</span><span class="token punctuation">,</span> color<span class="token operator">=</span><span class="token string">'black'</span><span class="token punctuation">)</span>      plt<span class="token punctuation">.</span>setp<span class="token punctuation">(</span>axs0_ylabel_text<span class="token punctuation">,</span> size<span class="token operator">=</span><span class="token number">7</span><span class="token punctuation">,</span> weight<span class="token operator">=</span><span class="token string">'bold'</span><span class="token punctuation">,</span> color<span class="token operator">=</span><span class="token string">'black'</span><span class="token punctuation">)</span>     <span class="token comment" spellcheck="true">#画出散点图,以datingDataMat矩阵的第一(飞行常客例程)、第三列(冰激凌)数据画散点数据,散点大小为15,透明度为0.5</span>    axs<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>x<span class="token operator">=</span>datingDataMat<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> y<span class="token operator">=</span>datingDataMat<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> color<span class="token operator">=</span>LabelsColors<span class="token punctuation">,</span>s<span class="token operator">=</span><span class="token number">15</span><span class="token punctuation">,</span> alpha<span class="token operator">=</span><span class="token punctuation">.</span><span class="token number">5</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#设置标题,x轴label,y轴label</span>    axs1_title_text <span class="token operator">=</span> axs<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>set_title<span class="token punctuation">(</span>u<span class="token string">'每年获得的飞行常客里程数与每周消费的冰激淋公升数'</span><span class="token punctuation">,</span>FontProperties<span class="token operator">=</span>font<span class="token punctuation">)</span>    axs1_xlabel_text <span class="token operator">=</span> axs<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>set_xlabel<span class="token punctuation">(</span>u<span class="token string">'每年获得的飞行常客里程数'</span><span class="token punctuation">,</span>FontProperties<span class="token operator">=</span>font<span class="token punctuation">)</span>    axs1_ylabel_text <span class="token operator">=</span> axs<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>set_ylabel<span class="token punctuation">(</span>u<span class="token string">'每周消费的冰激淋公升数'</span><span class="token punctuation">,</span>FontProperties<span class="token operator">=</span>font<span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>setp<span class="token punctuation">(</span>axs1_title_text<span class="token punctuation">,</span> size<span class="token operator">=</span><span class="token number">9</span><span class="token punctuation">,</span> weight<span class="token operator">=</span><span class="token string">'bold'</span><span class="token punctuation">,</span> color<span class="token operator">=</span><span class="token string">'red'</span><span class="token punctuation">)</span>      plt<span class="token punctuation">.</span>setp<span class="token punctuation">(</span>axs1_xlabel_text<span class="token punctuation">,</span> size<span class="token operator">=</span><span class="token number">7</span><span class="token punctuation">,</span> weight<span class="token operator">=</span><span class="token string">'bold'</span><span class="token punctuation">,</span> color<span class="token operator">=</span><span class="token string">'black'</span><span class="token punctuation">)</span>      plt<span class="token punctuation">.</span>setp<span class="token punctuation">(</span>axs1_ylabel_text<span class="token punctuation">,</span> size<span class="token operator">=</span><span class="token number">7</span><span class="token punctuation">,</span> weight<span class="token operator">=</span><span class="token string">'bold'</span><span class="token punctuation">,</span> color<span class="token operator">=</span><span class="token string">'black'</span><span class="token punctuation">)</span>     <span class="token comment" spellcheck="true">#画出散点图,以datingDataMat矩阵的第二(玩游戏)、第三列(冰激凌)数据画散点数据,散点大小为15,透明度为0.5</span>    axs<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>x<span class="token operator">=</span>datingDataMat<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> y<span class="token operator">=</span>datingDataMat<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> color<span class="token operator">=</span>LabelsColors<span class="token punctuation">,</span>s<span class="token operator">=</span><span class="token number">15</span><span class="token punctuation">,</span> alpha<span class="token operator">=</span><span class="token punctuation">.</span><span class="token number">5</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#设置标题,x轴label,y轴label</span>    axs2_title_text <span class="token operator">=</span> axs<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>set_title<span class="token punctuation">(</span>u<span class="token string">'玩视频游戏所消耗时间占比与每周消费的冰激淋公升数'</span><span class="token punctuation">,</span>FontProperties<span class="token operator">=</span>font<span class="token punctuation">)</span>    axs2_xlabel_text <span class="token operator">=</span> axs<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>set_xlabel<span class="token punctuation">(</span>u<span class="token string">'玩视频游戏所消耗时间占比'</span><span class="token punctuation">,</span>FontProperties<span class="token operator">=</span>font<span class="token punctuation">)</span>    axs2_ylabel_text <span class="token operator">=</span> axs<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>set_ylabel<span class="token punctuation">(</span>u<span class="token string">'每周消费的冰激淋公升数'</span><span class="token punctuation">,</span>FontProperties<span class="token operator">=</span>font<span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>setp<span class="token punctuation">(</span>axs2_title_text<span class="token punctuation">,</span> size<span class="token operator">=</span><span class="token number">9</span><span class="token punctuation">,</span> weight<span class="token operator">=</span><span class="token string">'bold'</span><span class="token punctuation">,</span> color<span class="token operator">=</span><span class="token string">'red'</span><span class="token punctuation">)</span>      plt<span class="token punctuation">.</span>setp<span class="token punctuation">(</span>axs2_xlabel_text<span class="token punctuation">,</span> size<span class="token operator">=</span><span class="token number">7</span><span class="token punctuation">,</span> weight<span class="token operator">=</span><span class="token string">'bold'</span><span class="token punctuation">,</span> color<span class="token operator">=</span><span class="token string">'black'</span><span class="token punctuation">)</span>      plt<span class="token punctuation">.</span>setp<span class="token punctuation">(</span>axs2_ylabel_text<span class="token punctuation">,</span> size<span class="token operator">=</span><span class="token number">7</span><span class="token punctuation">,</span> weight<span class="token operator">=</span><span class="token string">'bold'</span><span class="token punctuation">,</span> color<span class="token operator">=</span><span class="token string">'black'</span><span class="token punctuation">)</span>     <span class="token comment" spellcheck="true">#设置图例</span>    didntLike <span class="token operator">=</span> mlines<span class="token punctuation">.</span>Line2D<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> color<span class="token operator">=</span><span class="token string">'black'</span><span class="token punctuation">,</span> marker<span class="token operator">=</span><span class="token string">'.'</span><span class="token punctuation">,</span>                      markersize<span class="token operator">=</span><span class="token number">6</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'didntLike'</span><span class="token punctuation">)</span>    smallDoses <span class="token operator">=</span> mlines<span class="token punctuation">.</span>Line2D<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> color<span class="token operator">=</span><span class="token string">'orange'</span><span class="token punctuation">,</span> marker<span class="token operator">=</span><span class="token string">'.'</span><span class="token punctuation">,</span>                      markersize<span class="token operator">=</span><span class="token number">6</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'smallDoses'</span><span class="token punctuation">)</span>    largeDoses <span class="token operator">=</span> mlines<span class="token punctuation">.</span>Line2D<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> color<span class="token operator">=</span><span class="token string">'red'</span><span class="token punctuation">,</span> marker<span class="token operator">=</span><span class="token string">'.'</span><span class="token punctuation">,</span>                      markersize<span class="token operator">=</span><span class="token number">6</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'largeDoses'</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#添加图例</span>    axs<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>legend<span class="token punctuation">(</span>handles<span class="token operator">=</span><span class="token punctuation">[</span>didntLike<span class="token punctuation">,</span>smallDoses<span class="token punctuation">,</span>largeDoses<span class="token punctuation">]</span><span class="token punctuation">)</span>    axs<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>legend<span class="token punctuation">(</span>handles<span class="token operator">=</span><span class="token punctuation">[</span>didntLike<span class="token punctuation">,</span>smallDoses<span class="token punctuation">,</span>largeDoses<span class="token punctuation">]</span><span class="token punctuation">)</span>    axs<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>legend<span class="token punctuation">(</span>handles<span class="token operator">=</span><span class="token punctuation">[</span>didntLike<span class="token punctuation">,</span>smallDoses<span class="token punctuation">,</span>largeDoses<span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#显示图片</span>    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><p>图片效果：</p><img src="/2021/01/24/ji-qi-xue-xi-zhi-k-jin-lin-suan-fa/1.png" class=""><p>结果预测程序：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">classifyPerson</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true">#输出结果</span>    resultList <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'讨厌'</span><span class="token punctuation">,</span><span class="token string">'有些喜欢'</span><span class="token punctuation">,</span><span class="token string">'非常喜欢'</span><span class="token punctuation">]</span>    <span class="token comment" spellcheck="true">#三维特征用户输入</span>    precentTats <span class="token operator">=</span> float<span class="token punctuation">(</span>input<span class="token punctuation">(</span><span class="token string">"玩视频游戏所耗时间百分比:"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    ffMiles <span class="token operator">=</span> float<span class="token punctuation">(</span>input<span class="token punctuation">(</span><span class="token string">"每年获得的飞行常客里程数:"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    iceCream <span class="token operator">=</span> float<span class="token punctuation">(</span>input<span class="token punctuation">(</span><span class="token string">"每周消费的冰激淋公升数:"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#打开的文件名</span>    filename <span class="token operator">=</span> <span class="token string">"datingTestSet.txt"</span>    <span class="token comment" spellcheck="true">#打开并处理数据</span>    datingDataMat<span class="token punctuation">,</span> datingLabels <span class="token operator">=</span> file2matrix<span class="token punctuation">(</span>filename<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#训练集归一化</span>    normMat<span class="token punctuation">,</span> ranges<span class="token punctuation">,</span> minVals <span class="token operator">=</span> autoNorm<span class="token punctuation">(</span>datingDataMat<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#生成NumPy数组,测试集</span>    inArr <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span>ffMiles<span class="token punctuation">,</span> precentTats<span class="token punctuation">,</span> iceCream<span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#测试集归一化</span>    norminArr <span class="token operator">=</span> <span class="token punctuation">(</span>inArr <span class="token operator">-</span> minVals<span class="token punctuation">)</span> <span class="token operator">/</span> ranges    <span class="token comment" spellcheck="true">#返回分类结果</span>    classifierResult <span class="token operator">=</span> classify0<span class="token punctuation">(</span>norminArr<span class="token punctuation">,</span> normMat<span class="token punctuation">,</span> datingLabels<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#打印结果</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"你可能%s这个人"</span> <span class="token operator">%</span> <span class="token punctuation">(</span>resultList<span class="token punctuation">[</span>classifierResult<span class="token number">-1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><p>输出：</p><pre class=" language-a"><code class="language-a">玩视频游戏所耗时间百分比:11.11每年获得的飞行常客里程数:10000每周消费的冰激淋公升数:1[(3, 2), (2, 1)]你可能非常喜欢这个人</code></pre><h2 id="示例：手写识别系统"><a href="#示例：手写识别系统" class="headerlink" title="示例：手写识别系统"></a>示例：手写识别系统</h2><p>实际图像储存在两个文件夹中，trainingDigits文件夹有约2000个数据文件，testDigits约200个。简单起见，数字已经处理成文本格式。数据文件示例：</p><pre class=" language-a"><code class="language-a">0000000000000111100000000000000000000000000011111110000000000000000000000011111111110000000000000000000111111111111110000000000000000001111111011111100000000000000000111111100000111100000000000000001111111000000011100000000000000011111110000000111100000000000000111111100000000111000000000000001111111000000001110000000000000011111100000000011110000000000000111111000000000011100000000000001111110000000000111000000000000001111110000000000111000000000000011111100000000001110000000000000111111000000000011100000000000001111110000000000111000000000000111111100000000011110000000000001111011000000000111100000000000011110000000000011110000000000000011110000000000011110000000000000111100000000001111100000000000001111000000000111110000000000000011110000000011111000000000000000011100000011111100000000000000000111100011111110000000000000000001111111111111100000000000000000001111111111111000000000000000000011111111111100000000000000000000011111111100000000000000000000000011111000000000000000000000000000011000000000000000000</code></pre><p>导入包：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> operator<span class="token keyword">from</span> os <span class="token keyword">import</span> listdir</code></pre><p>为了使用前面的分类器，需要将这个32*32数据处理为一个1*1024向量：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">img2vector</span><span class="token punctuation">(</span>filename<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true">#创建1x1024零向量</span>    returnVect <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1024</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#打开文件</span>    fr <span class="token operator">=</span> open<span class="token punctuation">(</span>filename<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#按行读取</span>    <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true">#读一行数据</span>        lineStr <span class="token operator">=</span> fr<span class="token punctuation">.</span>readline<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">#每一行的前32个元素依次添加到returnVect中</span>        <span class="token keyword">for</span> j <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            returnVect<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token operator">*</span>i<span class="token operator">+</span>j<span class="token punctuation">]</span> <span class="token operator">=</span> int<span class="token punctuation">(</span>lineStr<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#返回转换后的1x1024向量</span>    <span class="token keyword">return</span> returnVect</code></pre><p>同样把前面的分类函数拿过来后编写测试函数：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">handwritingClassTest</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true">#测试集的Labels</span>    hwLabels <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token comment" spellcheck="true">#返回trainingDigits目录下的文件名</span>    trainingFileList <span class="token operator">=</span> listdir<span class="token punctuation">(</span><span class="token string">'trainingDigits'</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#返回文件夹下文件的个数</span>    m <span class="token operator">=</span> len<span class="token punctuation">(</span>trainingFileList<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#初始化训练的Mat矩阵,测试集</span>    trainingMat <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>m<span class="token punctuation">,</span> <span class="token number">1024</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#从文件名中解析出训练集的类别</span>    <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>m<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true">#获得文件的名字</span>        fileNameStr <span class="token operator">=</span> trainingFileList<span class="token punctuation">[</span>i<span class="token punctuation">]</span>        <span class="token comment" spellcheck="true">#获得分类的数字</span>        classNumber <span class="token operator">=</span> int<span class="token punctuation">(</span>fileName87Str<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'_'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">#将获得的类别添加到hwLabels中</span>        hwLabels<span class="token punctuation">.</span>append<span class="token punctuation">(</span>classNumber<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">#将每一个文件的1x1024数据存储到trainingMat矩阵中</span>        trainingMat<span class="token punctuation">[</span>i<span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">=</span> img2vector<span class="token punctuation">(</span><span class="token string">'trainingDigits/%s'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>fileNameStr<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#返回testDigits目录下的文件名</span>    testFileList <span class="token operator">=</span> listdir<span class="token punctuation">(</span><span class="token string">'testDigits'</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#错误检测计数</span>    errorCount <span class="token operator">=</span> <span class="token number">0.0</span>    <span class="token comment" spellcheck="true">#测试数据的数量</span>    mTest <span class="token operator">=</span> len<span class="token punctuation">(</span>testFileList<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#从文件中解析出测试集的类别并进行分类测试</span>    <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>mTest<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true">#获得文件的名字</span>        fileNameStr <span class="token operator">=</span> testFileList<span class="token punctuation">[</span>i<span class="token punctuation">]</span>        <span class="token comment" spellcheck="true">#获得分类的数字</span>        classNumber <span class="token operator">=</span> int<span class="token punctuation">(</span>fileNameStr<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'_'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">#获得测试集的1x1024向量,用于训练</span>        vectorUnderTest <span class="token operator">=</span> img2vector<span class="token punctuation">(</span><span class="token string">'testDigits/%s'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>fileNameStr<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">#获得预测结果</span>        classifierResult <span class="token operator">=</span> classify0<span class="token punctuation">(</span>vectorUnderTest<span class="token punctuation">,</span> trainingMat<span class="token punctuation">,</span> hwLabels<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"分类返回结果为%d\t真实结果为%d"</span> <span class="token operator">%</span> <span class="token punctuation">(</span>classifierResult<span class="token punctuation">,</span> classNumber<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">if</span><span class="token punctuation">(</span>classifierResult <span class="token operator">!=</span> classNumber<span class="token punctuation">)</span><span class="token punctuation">:</span>            errorCount <span class="token operator">+=</span> <span class="token number">1.0</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"总共错了%d个数据\n错误率为%f%%"</span> <span class="token operator">%</span> <span class="token punctuation">(</span>errorCount<span class="token punctuation">,</span> errorCount<span class="token operator">/</span>mTest<span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><p>输出：</p><pre class=" language-a"><code class="language-a">--snip--分类返回结果为9    真实结果为9分类返回结果为9    真实结果为9分类返回结果为9    真实结果为9分类返回结果为9    真实结果为9分类返回结果为9    真实结果为9分类返回结果为9    真实结果为9分类返回结果为9    真实结果为9分类返回结果为9    真实结果为9分类返回结果为9    真实结果为9总共错了10个数据错误率为1.0571%</code></pre><h2 id="使用第三方库sklearn的代码"><a href="#使用第三方库sklearn的代码" class="headerlink" title="使用第三方库sklearn的代码"></a>使用第三方库sklearn的代码</h2><p>新导入的包：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>neighbors <span class="token keyword">import</span> KNeighborsClassifier <span class="token keyword">as</span> kNN</code></pre><p>测试函数代码修改：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">handwritingClassTest</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true">#测试集的Labels</span>    hwLabels <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token comment" spellcheck="true">#返回trainingDigits目录下的文件名</span>    trainingFileList <span class="token operator">=</span> listdir<span class="token punctuation">(</span><span class="token string">'trainingDigits'</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#返回文件夹下文件的个数</span>    m <span class="token operator">=</span> len<span class="token punctuation">(</span>trainingFileList<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#初始化训练的Mat矩阵,测试集</span>    trainingMat <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>m<span class="token punctuation">,</span> <span class="token number">1024</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#从文件名中解析出训练集的类别</span>    <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>m<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true">#获得文件的名字</span>        fileNameStr <span class="token operator">=</span> trainingFileList<span class="token punctuation">[</span>i<span class="token punctuation">]</span>        <span class="token comment" spellcheck="true">#获得分类的数字</span>        classNumber <span class="token operator">=</span> int<span class="token punctuation">(</span>fileNameStr<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'_'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">#将获得的类别添加到hwLabels中</span>        hwLabels<span class="token punctuation">.</span>append<span class="token punctuation">(</span>classNumber<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">#将每一个文件的1x1024数据存储到trainingMat矩阵中</span>        trainingMat<span class="token punctuation">[</span>i<span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">=</span> img2vector<span class="token punctuation">(</span><span class="token string">'trainingDigits/%s'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>fileNameStr<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#构建kNN分类器</span>    neigh <span class="token operator">=</span> kNN<span class="token punctuation">(</span>n_neighbors <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">,</span> algorithm <span class="token operator">=</span> <span class="token string">'auto'</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#拟合模型, trainingMat为训练矩阵,hwLabels为对应的标签</span>    neigh<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>trainingMat<span class="token punctuation">,</span> hwLabels<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#返回testDigits目录下的文件列表</span>    testFileList <span class="token operator">=</span> listdir<span class="token punctuation">(</span><span class="token string">'testDigits'</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#错误检测计数</span>    errorCount <span class="token operator">=</span> <span class="token number">0.0</span>    <span class="token comment" spellcheck="true">#测试数据的数量</span>    mTest <span class="token operator">=</span> len<span class="token punctuation">(</span>testFileList<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#从文件中解析出测试集的类别并进行分类测试</span>    <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>mTest<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true">#获得文件的名字</span>        fileNameStr <span class="token operator">=</span> testFileList<span class="token punctuation">[</span>i<span class="token punctuation">]</span>        <span class="token comment" spellcheck="true">#获得分类的数字</span>        classNumber <span class="token operator">=</span> int<span class="token punctuation">(</span>fileNameStr<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'_'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">#获得测试集的1x1024向量,用于训练</span>        vectorUnderTest <span class="token operator">=</span> img2vector<span class="token punctuation">(</span><span class="token string">'testDigits/%s'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>fileNameStr<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">#获得预测结果</span>        <span class="token comment" spellcheck="true"># classifierResult = classify0(vectorUnderTest, trainingMat, hwLabels, 3)</span>        classifierResult <span class="token operator">=</span> neigh<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>vectorUnderTest<span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"分类返回结果为%d\t真实结果为%d"</span> <span class="token operator">%</span> <span class="token punctuation">(</span>classifierResult<span class="token punctuation">,</span> classNumber<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">if</span><span class="token punctuation">(</span>classifierResult <span class="token operator">!=</span> classNumber<span class="token punctuation">)</span><span class="token punctuation">:</span>            errorCount <span class="token operator">+=</span> <span class="token number">1.0</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"总共错了%d个数据\n错误率为%f%%"</span> <span class="token operator">%</span> <span class="token punctuation">(</span>errorCount<span class="token punctuation">,</span> errorCount<span class="token operator">/</span>mTest <span class="token operator">*</span> <span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><p>函数说明：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">sklearn</span><span class="token punctuation">.</span>neighbors<span class="token punctuation">.</span>KNeighborsClassifier<span class="token punctuation">(</span>n_neighbors<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token operator">*</span><span class="token punctuation">,</span> weights<span class="token operator">=</span><span class="token string">'uniform'</span><span class="token punctuation">,</span> algorithm<span class="token operator">=</span><span class="token string">'auto'</span><span class="token punctuation">,</span> leaf_size<span class="token operator">=</span><span class="token number">30</span><span class="token punctuation">,</span> p<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> metric<span class="token operator">=</span><span class="token string">'minkowski'</span><span class="token punctuation">,</span> metric_params<span class="token operator">=</span>None<span class="token punctuation">,</span> n_jobs<span class="token operator">=</span>None<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span></code></pre><ul><li><strong>n_neighbors</strong>：默认为5，就是k-NN的k的值，选取最近的k个点。</li><li><strong>weights</strong>：默认是uniform，参数可以是uniform、distance，也可以是用户自己定义的函数。uniform是均等的权重，就说所有的邻近点的权重都是相等的。distance是不均等的权重，距离近的点比距离远的点的影响大。用户自定义的函数，接收距离的数组，返回一组维数相同的权重。</li><li><strong>algorithm</strong>：快速k近邻搜索算法，默认参数为auto，可以理解为算法自己决定合适的搜索算法。除此之外，用户也可以自己指定搜索算法ball_tree、kd_tree、brute方法进行搜索，brute是蛮力搜索，也就是线性扫描，当训练集很大时，计算非常耗时。kd_tree，构造kd树存储数据以便对其进行快速检索的树形数据结构，kd树也就是数据结构中的二叉树。以中值切分构造的树，每个结点是一个超矩形，在维数小于20时效率高。ball tree是为了克服kd树高纬失效而发明的，其构造过程是以质心C和半径r分割样本空间，每个节点是一个超球体。</li><li><strong>leaf_size</strong>：默认是30，这个是构造的kd树和ball树的大小。这个值的设置会影响树构建的速度和搜索速度，同样也影响着存储树所需的内存大小。需要根据问题的性质选择最优的大小。</li><li><strong>metric</strong>：用于距离度量，默认度量是minkowski，也就是p=2的欧氏距离(欧几里德度量)。</li><li><strong>p</strong>：距离度量公式。在上小结，我们使用欧氏距离公式进行距离度量。除此之外，还有其他的度量方法，例如曼哈顿距离。这个参数默认为2，也就是默认使用欧式距离公式进行距离度量。也可以设置为1，使用曼哈顿距离公式进行距离度量。</li><li><strong>metric_params</strong>：距离公式的其他关键参数，这个可以不管，使用默认的None即可。</li><li><strong>n_jobs</strong>：并行处理设置。默认为1，临近点搜索并行工作数。如果为-1，那么CPU的所有cores都用于并行工作。</li></ul><table><thead><tr><th><a href="https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier.fit"><code>fit</code></a>（X，y）</th><th>从训练数据集中拟合k最近邻分类器。</th></tr></thead><tbody><tr><td><a href="https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier.get_params"><code>get_params</code></a>（[deep]）</td><td>获取此估计量的参数。</td></tr><tr><td><a href="https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier.kneighbors"><code>kneighbors</code></a>（[X，n_neighbors，return_distance]）</td><td>查找点的K邻居。</td></tr><tr><td><a href="https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier.kneighbors_graph"><code>kneighbors_graph</code></a>（[X，n_neighbors，mode]）</td><td>计算X中点的k邻居的（加权）图</td></tr><tr><td><a href="https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier.predict"><code>predict</code></a>（X）</td><td>预测提供的数据的类标签。</td></tr><tr><td><a href="https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier.predict_proba"><code>predict_proba</code></a>（X）</td><td>测试数据X的返回概率估计。</td></tr><tr><td><a href="https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier.score"><code>score</code></a>（X，y [，sample_weight]）</td><td>返回给定测试数据和标签上的平均准确度。</td></tr><tr><td><a href="https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier.set_params"><code>set_params</code></a>（**params）</td><td>设置此估算器的参数。</td></tr></tbody></table><p>具体用法可查看<a href="https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html">https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html</a></p><p>运行结果与我们之前自己写的算法差不多，但运行速度明显快了不少。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p> kNN算法的优缺点</p><p><strong>优点</strong></p><ul><li>简单好用，容易理解，精度高，理论成熟，既可以用来做分类也可以用来做回归；</li><li>可用于数值型数据和离散型数据；</li><li>训练时间复杂度为O(n)；无数据输入假定；</li><li>对异常值不敏感。</li></ul><p><strong>缺点：</strong></p><ul><li>计算复杂性高；空间复杂性高；</li><li>样本不平衡问题（即有些类别的样本数量很多，而其它样本的数量很少）；</li><li>一般数值很大的时候不用这个，计算量太大。但是单个样本又不能太少，否则容易发生误分。</li><li>最大的缺点是无法给出数据的内在含义。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Markdown数学公式表示法</title>
      <link href="2021/01/23/markdown-shu-xue-gong-shi-biao-shi-fa/"/>
      <url>2021/01/23/markdown-shu-xue-gong-shi-biao-shi-fa/</url>
      
        <content type="html"><![CDATA[<p> 查看更多请前往<a href="https://katex.org/docs/supported.html">https://katex.org/docs/supported.html</a></p><h3 id="希腊字母"><a href="#希腊字母" class="headerlink" title="希腊字母"></a>希腊字母</h3><table><thead><tr><th align="center">显示</th><th align="center">命令</th><th align="center">显示</th><th align="center">命令</th></tr></thead><tbody><tr><td align="center">α</td><td align="center">\alpha</td><td align="center">β</td><td align="center">\beta</td></tr><tr><td align="center">γ</td><td align="center">\gamma</td><td align="center">δ</td><td align="center">\delta</td></tr><tr><td align="center">ε</td><td align="center">\epsilon</td><td align="center">ζ</td><td align="center">\zeta</td></tr><tr><td align="center">η</td><td align="center">\eta</td><td align="center">θ</td><td align="center">\theta</td></tr><tr><td align="center">ι</td><td align="center">\iota</td><td align="center">κ</td><td align="center">\kappa</td></tr><tr><td align="center">λ</td><td align="center">\lambda</td><td align="center">μ</td><td align="center">\mu</td></tr><tr><td align="center">ν</td><td align="center">\nu</td><td align="center">ξ</td><td align="center">\xi</td></tr><tr><td align="center">π</td><td align="center">\pi</td><td align="center">ρ</td><td align="center">\rho</td></tr><tr><td align="center">σ</td><td align="center">\sigma</td><td align="center">τ</td><td align="center">\tau</td></tr><tr><td align="center">υ</td><td align="center">\upsilon</td><td align="center">φ</td><td align="center">\phi</td></tr><tr><td align="center">χ</td><td align="center">\chi</td><td align="center">ψ</td><td align="center">\psi</td></tr><tr><td align="center">ω</td><td align="center">\omega</td><td align="center">Δ</td><td align="center">\Delta</td></tr></tbody></table><h3 id="特殊符号："><a href="#特殊符号：" class="headerlink" title="特殊符号："></a>特殊符号：</h3><table><thead><tr><th align="center">显示</th><th align="center">命令</th><th align="center">显示</th><th align="center">命令</th></tr></thead><tbody><tr><td align="center">∞</td><td align="center">\infty</td><td align="center">∑</td><td align="center">\sum</td></tr><tr><td align="center">∪</td><td align="center">\cup</td><td align="center">∏</td><td align="center">\prod</td></tr><tr><td align="center">∩</td><td align="center">\cap</td><td align="center">±</td><td align="center">\pm</td></tr><tr><td align="center">⊂</td><td align="center">\subset</td><td align="center">×</td><td align="center">\times</td></tr><tr><td align="center">⊃</td><td align="center">\supset</td><td align="center">÷</td><td align="center">\div</td></tr><tr><td align="center">⊆</td><td align="center">\subseteq</td><td align="center">∣</td><td align="center">\mid</td></tr><tr><td align="center">∈</td><td align="center">\in</td><td align="center">≠</td><td align="center">\neq</td></tr><tr><td align="center">∠</td><td align="center">\angle</td><td align="center">≤</td><td align="center">\leq</td></tr><tr><td align="center">∵</td><td align="center">\because</td><td align="center">≥</td><td align="center">\geq</td></tr><tr><td align="center">∴</td><td align="center">\therefore</td><td align="center">∅</td><td align="center">\emptyset</td></tr><tr><td align="center">∇</td><td align="center">\nabla</td><td align="center">⋁</td><td align="center">\bigvee</td></tr><tr><td align="center">⊥</td><td align="center">\bot</td><td align="center">⋀</td><td align="center">\bigwedge</td></tr><tr><td align="center">⊇</td><td align="center">\supseteq</td><td align="center">⨄</td><td align="center">\biguplus</td></tr><tr><td align="center">∀</td><td align="center">\forall</td><td align="center">⨆</td><td align="center">\bigsqcup</td></tr><tr><td align="center">∃</td><td align="center">\exists</td><td align="center">∫</td><td align="center">\int</td></tr><tr><td align="center">≠</td><td align="center">\not=</td><td align="center">∬</td><td align="center">\iint</td></tr><tr><td align="center">⊄</td><td align="center">\not\subset</td><td align="center">∭</td><td align="center">\iiint</td></tr><tr><td align="center">↑</td><td align="center">\uparrow</td><td align="center">∮</td><td align="center">\oint</td></tr><tr><td align="center">↓</td><td align="center">\downarrow</td><td align="center">y^</td><td align="center">\hat{y}</td></tr><tr><td align="center">→</td><td align="center">\rightarrow</td><td align="center">⨀</td><td align="center">\bigodot</td></tr><tr><td align="center">←</td><td align="center">\leftarrow</td><td align="center">⨂</td><td align="center">\bigotimes</td></tr><tr><td align="center">≈</td><td align="center">\approx</td><td align="center">⨁</td><td align="center">\bigoplus</td></tr><tr><td align="center">≡</td><td align="center">\equiv</td><td align="center">⇒</td><td align="center">\leftarrow</td></tr><tr><td align="center">∐</td><td align="center">\coprod</td><td align="center">⇐</td><td align="center">\Leftarrow</td></tr><tr><td align="center"><img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BL%7D"></td><td align="center">\mathcal{L}</td><td align="center"><img src="https://www.zhihu.com/equation?tex=%5Cmathscr%7BL%7D"></td><td align="center">\mathscr{L}</td></tr></tbody></table><ul><li>上标：^   下标： _             例子：C_n^2</li><li>矢量：\vec a ，\overrightarrow{xy}</li><li>分式：\frac{公式1}{公式2}</li><li>根式：\sqrt{x}{y}</li><li>特殊函数：\sin x，\ln x，\max(A,B,C)，\log</li><li>极限：\lim_{x \to 0}</li><li>平均数：\bar{y}</li><li>微分表示：\dot{}，\ddot{}，\dddot{}，\ddddot{}</li><li>x上面加~： \tilde x</li><li>x上面加帽子：\hat{x}</li><li>x上面加一横：\bar{x}</li><li>注意：数学公式用$内容$表示的话不会换行，用$$内容$$表示会换行。</li></ul><h3 id="占位符"><a href="#占位符" class="headerlink" title="占位符"></a>占位符</h3><ol><li>两个quad空格，符号：<code>\qquad</code>，如：$x \qquad y$</li><li>quad空格，符号：<code>\quad</code>，如：$x \quad y$</li><li>大空格，符号<code>\</code>，如：$x \  y$</li><li>中空格，符号<code>\:</code>，如：$x : y$</li><li>小空格，符号<code>\,</code>，如：$x , y$</li><li>没有空格，符号``，如：$xy$</li><li>紧贴，符号<code>\!</code>，如：$x ! y$</li></ol><h2 id="矩阵与块"><a href="#矩阵与块" class="headerlink" title="矩阵与块"></a>矩阵与块</h2><img src="/2021/01/23/markdown-shu-xue-gong-shi-biao-shi-fa/1.png" class><p>$$<br>\left[ \begin{matrix} a &amp; b &amp; c &amp; d &amp; e\ f &amp; g &amp; h &amp; i &amp; j \ k &amp; l &amp; m &amp; n &amp; o \ p &amp; q &amp; r &amp; s &amp; t \end{matrix} \right]<br>$$</p><h2 id="分支公式"><a href="#分支公式" class="headerlink" title="分支公式"></a>分支公式</h2><p>markdown公式如下：</p><p>$$<br>y=<br>\begin{cases}<br>-x,\quad x\leq 0\<br>x, \quad x&gt;0<br>\end{cases}<br>\tag{1}<br>$$</p>]]></content>
      
      
      <categories>
          
          <category> Markdown </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Markdown </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>机器学习笔记（一）</title>
      <link href="2021/01/21/ji-qi-xue-xi-bi-ji-yi/"/>
      <url>2021/01/21/ji-qi-xue-xi-bi-ji-yi/</url>
      
        <content type="html"><![CDATA[<h1 id="绪论"><a href="#绪论" class="headerlink" title="绪论"></a>绪论</h1><h2 id="什么是机器学习"><a href="#什么是机器学习" class="headerlink" title="什么是机器学习"></a>什么是机器学习</h2><p>机器学习，就是让计算机拥有想人一样的学习能力的技术，从堆积如山的数据中寻找有用知识的数据挖掘技术，如从视频库中寻找自己喜欢的视频资料，根据用户的购买记录向用户推荐其他相关商品。</p><p>根据处理数据种类的不同，可以分为监督学习，无监督学习，强化学习几种类型。监督学习是指既给数据，又给答案，对这种规律进行概括，从而对没学习过的数据也能做出正确解答，让计算机获得这种泛化能力是监督学习的目标。非监督学习是指没有明确答案，只有数据，学习目标不必十分明确，计算机自己提取其中规律的过程。这一类机器学习的典型任务有聚类、异常检测等。强化学习与监督学习类似，不设置答案，自己对预测的结果进行评估，往往认为是人类主要的学习方式之一，在机器人自动控制，游戏中的人工智能，市场战略的最优化等方面有广泛运用，强化学习中经常用到回归，分类，聚类，降维等机器学习算法。</p><h2 id="机器学习任务的例子"><a href="#机器学习任务的例子" class="headerlink" title="机器学习任务的例子"></a>机器学习任务的例子</h2><p><strong>回归</strong>是指把实函数在样本点附近加以近似的有监督的函数近似问题，作为训练集的输入输出样本是已知的，需要获得一个函数y = f（x）使得无论什么问题输出的答案于真实的函数f对应，获得这个函数是监督学习的最终目标。<strong>分类</strong>是指对于特定模式进行识别的有监督的模式识别问题，对d维实向量x为输入样本，所有的输出样本，可以划分为c个类别的问题进行说明。<strong>异常检测</strong>是指寻找输入样本中包含的异常数据的问题。<strong>聚类</strong>属于无监督学习的一种，只给出输入样本，判断各个样本分别属于哪个簇，相同簇之间具有相同性质，如何判断样品直接相似度是很重要的课题。降维是指从高纬度的数据中提取关键信息，转换为易于计算的低纬度问题进而求解的方法。</p><p>在已知模式<strong>x</strong>的时候如果能求得使分类类别y的条件概率p（y|x）达到最大值的类别y的话，就可以进行模式识别了。</p><hr><h1 id="学习模型"><a href="#学习模型" class="headerlink" title="学习模型"></a>学习模型</h1><h2 id="线性模型"><a href="#线性模型" class="headerlink" title="线性模型"></a>线性模型</h2><p>在对函数f进行近似时，最简单的模型就是线性模型θ×x。θ表示模型的参数，通过对这个参数进行学习完成函数的近似计算，这个模型只能表现线性的输入输出函数，没有太多实用价值，对上述的线性模型进行相应的扩展，可以使线性模型用于表示非线性的输入输出。<br>$$<br>f_θ(x) = \sum_{j=1}^b\theta_j\phi_j(x)=\theta^T\phi(x)<br>$$</p><p>其中θ<sub>j</sub> (x)基函数向量的第j个因子，b是基函数的个数。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>超级好用的网站和手机app</title>
      <link href="2021/01/13/chao-ji-hao-yong-de-wang-zhan-he-shou-ji-app/"/>
      <url>2021/01/13/chao-ji-hao-yong-de-wang-zhan-he-shou-ji-app/</url>
      
        <content type="html"><![CDATA[<h2 id="网站"><a href="#网站" class="headerlink" title="网站"></a>网站</h2><ol><li><a href="https://www.xuetangx.com/">学堂在线</a>，自学网站。</li><li><a href="https://www.coursera.org/">Coursera</a>,大型公开在线课程项目，由美国斯坦福大学两名计算机科学教授创办。旨在同世界顶尖大学合作，在线提供网络公开课程。</li><li><a href="http://scholar.hedasudi.com/">谷歌学术镜像</a>，研究必备。</li><li><a href="https://banber.docer.wps.cn/library">数据简报</a>，工作汇报神器，大量制作模板，强推。</li><li><a href="https://slidesgo.com/">slidesgo</a>，大量免费PPT模板下线。</li><li><a href="https://www.logosc.cn/so/">搜图神器</a>，大量免版权图片下载，再也不用担心侵权啦，强烈推荐UP主使用。</li><li><a href="https://crashcourse.club/">Crash Course 中文字幕组</a>，汉化大量的优秀的外国学习视频，是视频中的精品。</li><li><a href="https://www.liuchengtu.com/">迅捷画图</a>，在线画流程图，思维导图，现成模板可以套用，十分方便。</li><li><a href="http://coursegraph.com/navigation/">公开课导航</a>，大量优秀课程的中转平台，在上面找到想要学的课程之后会转到Coursera，网易公开课，学堂在线等平台进行学习。</li><li><a href="https://www.w3school.com.cn/h.asp">W3school</a>，编程语言自学网站，大量浅显易懂文字教程，适合初学者。</li><li><a href="https://www.dotcpp.com/">C语言网</a>，不止有C语言，还有C++，数据结构，单片机，Python，编译器的教程，以及各种编程练习和比赛。</li><li><a href="https://www.runoob.com/">菜鸟教程</a>，各种编程语言的教程，大量文字教程，适合新手。</li><li><a href="https://www.lookae.com/">LookAE</a>，各种视频制作后期资源。</li><li><a href="https://wallhaven.cc/">wallhaven</a>，高清壁纸网站</li><li><a href="https://wallhaven.cc/">耳聆网</a>，非营利性网站，各种免费声音供你使用，强推UP主使用。</li><li><a href="http://www.ypppt.com/">优品PPT</a>，免费PPT模板下载网站，强推。</li><li><a href="https://docsmall.com/">docsmall</a>，在线免费图片压缩，GIF压缩，PDF压缩，合并，分割。</li><li><a href="https://airportal.cn/">AirPortal|空投</a>，方便快捷的文件传输方法，上传之后对方输入取件码即可接收，普通账号有文件大小限制。</li><li><a href="http://www.gddyu.com/">够低调解析</a>，VIP视频白嫖网站，可播放腾讯，爱奇艺等多个视频网站的VIP视频。</li><li><a href="https://www.uupoop.com/">稿定设计|在线PS</a>，方便快捷的在线PS网站，可以智能抠图，证件照换底色，海报素材等。</li><li><a href="https://www.zitijia.com/">字体家</a>，大量免费商业字体，UP主必备。</li><li><a href="https://www.kt1.com/">大数据词云</a>，用大数据生成真正值得分享的词云图。</li><li><a href="https://greasyfork.org/zh-CN">Greasy Fork</a>，谁用谁知道，白嫖神器，具体看我另一篇博文《关于超神插件油猴脚本-Tampermonkey的安装和使用》，首推。</li><li><a href="https://github.com/">Github</a>，一个面向<a href="https://baike.baidu.com/item/%E5%BC%80%E6%BA%90/20720669">开源</a>及私有软件项目的托管平台，因为只支持 Git 作为唯一的版本库格式进行托管，故名 GitHub，程序员神器，提升项目经验神器。</li><li><a href="https://gitee.com/">Gitee</a>，中文版Github，访问速度比Github快得多，将Github仓库转到Gitee可以大大增加下载速度。</li><li><a href="https://www.csdn.net/?spm=1011.2124.3001.5359">CSDN</a>，专业开发者社区，程序员神器，大量视频教程，大量干货博客，大量项目代码，同时也能发表自己的博客和工程，提出疑问等等，强推。</li><li><a href="https://www.51zxw.net/">我要自学网</a>，各式各样超多学习课程，自学必备。</li><li><a href="https://sci-hub.tf/">SCI-HUB</a>，文献白嫖网站，输入DOI码即可免费获得文献全文，学术研究必备，网站会受到多方攻击，不太稳定。</li><li><a href="http://www.4243.net/">大木虫学术导航</a>，集合了各种各样的学术网站和广大的搜索领域，学术研究必备。</li></ol><hr><h2 id="手机app"><a href="#手机app" class="headerlink" title="手机app"></a>手机app</h2><ol><li>轻启动，秒杀打开app出现的几秒钟广告，帮你节省无数个几秒钟。</li><li>实用工具箱，内含上百种实用工具，一个app顶10个。</li><li>网易云课堂，户外充电必备，课程质量很高，零基础入门无障碍。</li><li>慕课网，大量IT行业教程等你学习。</li><li>录音转文字助手，会议必备，帮你快速记录会议内容。</li><li>计划大师，帮你记录你的计划行程，杜绝遗忘。</li></ol><hr>]]></content>
      
      
      <categories>
          
          <category> 工具推荐 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> app </tag>
            
            <tag> 网站 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>关于超神插件油猴脚本(Tampermonkey)的安装和使用</title>
      <link href="2021/01/13/guan-yu-chao-shen-cha-jian-you-hou-jiao-ben-tampermonkey-de-an-zhuang-he-shi-yong/"/>
      <url>2021/01/13/guan-yu-chao-shen-cha-jian-you-hou-jiao-ben-tampermonkey-de-an-zhuang-he-shi-yong/</url>
      
        <content type="html"><![CDATA[<p>Tampermonkey 是一款浏览器脚本管理插件，常见浏览器都支持，结合脚本网站 Greasyfork，能够方便的实现脚本旳一键安装、自动更新、快速启用等便捷功能。可以让浏览器实现各种各样的扩展功能。比如获取网盘下载地址、微博页面精简等，去视频广告，去百度广告等等等等，给浏览器开挂，而且资源占用也极小，浏览器的辅助神器。</p><h2 id="Tampermonkey的安装"><a href="#Tampermonkey的安装" class="headerlink" title="Tampermonkey的安装"></a>Tampermonkey的安装</h2><p>首先，在360浏览器的右上角找这个四个小方块图标，点击它，再点添加：</p><img src="/2021/01/13/guan-yu-chao-shen-cha-jian-you-hou-jiao-ben-tampermonkey-de-an-zhuang-he-shi-yong/1.png" class=""><p>搜索Tempermonkey进行安装：</p><img src="/2021/01/13/guan-yu-chao-shen-cha-jian-you-hou-jiao-ben-tampermonkey-de-an-zhuang-he-shi-yong/2.png" class=""><hr><h2 id="Tampermonkey的使用"><a href="#Tampermonkey的使用" class="headerlink" title="Tampermonkey的使用"></a>Tampermonkey的使用</h2><p>进入Greasy Fork网站（提供脚本的超强网站），搜索你需要的脚本：</p><img src="/2021/01/13/guan-yu-chao-shen-cha-jian-you-hou-jiao-ben-tampermonkey-de-an-zhuang-he-shi-yong/3.png" class=""><img src="/2021/01/13/guan-yu-chao-shen-cha-jian-you-hou-jiao-ben-tampermonkey-de-an-zhuang-he-shi-yong/4.png" class=""><p>搜索完成后进行安装：</p><p>安装完成后打开对应网页可以看到脚本自动运行了：</p><img src="/2021/01/13/guan-yu-chao-shen-cha-jian-you-hou-jiao-ben-tampermonkey-de-an-zhuang-he-shi-yong/6.png" class=""><p>可以在网站内的一个位置找到隐藏按钮打开控制台：</p><img src="/2021/01/13/guan-yu-chao-shen-cha-jian-you-hou-jiao-ben-tampermonkey-de-an-zhuang-he-shi-yong/5.png" class=""><p>注意，如果没看到控制台那么要注意关闭浏览器的广告拦截插件。</p><hr><h1 id="好用的脚本"><a href="#好用的脚本" class="headerlink" title="好用的脚本"></a>好用的脚本</h1><ul><li><strong>淘宝党自动比价工具</strong></li></ul><p>在你浏览商品页面时，自动比较同款商品在淘宝/京东/亚马逊/当当/苏宁/等百家商城的最低价，提供价格历史、口碑评分等查询，还有降价提醒等功能，为你的选择提供参考，数据由购物党网站提供。</p><ul><li><strong>哔哩哔哩番剧解锁大会员,B站视频下载、解析，A站视频下载、解析，集合了优酷、爱奇艺、腾讯、芒果、乐视、等全网VIP视频免费破解去广告,高清普清电视观看，增加对手机支持，持续更新</strong></li><li><strong>视频站启用html5播放器</strong></li><li><strong>懒人专用，全网VIP视频免费破解去广告、全网音乐直接下载、百度网盘直接下载、知乎视频下载等多合一版。长期更新，放心使用</strong></li><li><strong>网页解除限制</strong></li></ul><p>详情查看Greasy Fork网站会发现更多惊喜。</p>]]></content>
      
      
      <categories>
          
          <category> 浏览器脚本 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 油猴脚本 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Python编程从入门到实践笔记</title>
      <link href="2021/01/13/python-bian-cheng-cong-ru-men-dao-shi-jian-bi-ji/"/>
      <url>2021/01/13/python-bian-cheng-cong-ru-men-dao-shi-jian-bi-ji/</url>
      
        <content type="html"><![CDATA[<p>编程环境的安装请见我另两篇文章《Pycharm安装及破解方法》及《Pycharm配置和使用教程》，下面以你能正常使用pycharm为前提。</p><h1 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h1><h2 id="变量及简单数据类型"><a href="#变量及简单数据类型" class="headerlink" title="变量及简单数据类型"></a>变量及简单数据类型</h2><h3 id="变量名的使用"><a href="#变量名的使用" class="headerlink" title="变量名的使用"></a>变量名的使用</h3><ol><li>变量名只能包含字母，数字和下划线。可以以字母和下划线开头，但不能以数字开头。</li><li>变量名不能包含空格，可用下划线来分割单词，如：greeting_message。</li><li>不要将Python关键字和函数名用作变量名。</li><li>变量名应既简短又具有描述性。</li><li>慎用小写字母l和大写字母O，容易被看成1和0。</li></ol><h3 id="字符串"><a href="#字符串" class="headerlink" title="字符串"></a>字符串</h3><p>字符串是一串字符，引号括起的都是字符串，可以是单引号或双引号，如：</p><pre class=" language-python"><code class="language-python">str <span class="token operator">=</span> <span class="token string">"ada lovelace"</span></code></pre><pre class=" language-python"><code class="language-python">str<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token punctuation">)</span>                 <span class="token comment" spellcheck="true">#单词首字母大写</span>str<span class="token punctuation">.</span>upper<span class="token punctuation">(</span><span class="token punctuation">)</span>                 <span class="token comment" spellcheck="true">#单词所有字母大写</span>str<span class="token punctuation">.</span>lower<span class="token punctuation">(</span><span class="token punctuation">)</span>                 <span class="token comment" spellcheck="true">#单词所有字母小写</span>str <span class="token operator">=</span> str1 <span class="token operator">+</span> str2          <span class="token comment" spellcheck="true">#字符串相加</span><span class="token comment" spellcheck="true">#字符串中出现\t是制表符，\n是换行符</span>str<span class="token punctuation">.</span>rstrip<span class="token punctuation">(</span><span class="token punctuation">)</span>                <span class="token comment" spellcheck="true">#删除空格，不改变原变量</span></code></pre><h3 id="整型（浮点型同理）"><a href="#整型（浮点型同理）" class="headerlink" title="整型（浮点型同理）"></a>整型（浮点型同理）</h3><p>加减乘除不必多说</p><pre class=" language-python"><code class="language-python"><span class="token number">3</span> <span class="token operator">**</span> <span class="token number">2</span>     <span class="token comment" spellcheck="true">#乘方，结果是9</span><span class="token number">3</span> <span class="token operator">%</span> <span class="token number">2</span>      <span class="token comment" spellcheck="true">#求模，返回余数</span></code></pre><p>注意，整型相除也是整型，会自行砍掉小数。</p><h3 id="强制类型转换"><a href="#强制类型转换" class="headerlink" title="强制类型转换"></a>强制类型转换</h3><pre class=" language-python"><code class="language-python">str<span class="token punctuation">(</span>age<span class="token punctuation">)</span>         <span class="token comment" spellcheck="true"># 转变为字符串</span>int<span class="token punctuation">(</span>age<span class="token punctuation">)</span>         <span class="token comment" spellcheck="true"># 转变为整型</span></code></pre><hr><h2 id="列表"><a href="#列表" class="headerlink" title="列表"></a>列表</h2><p>列表由一系列特定元素排列而成，如：</p><pre class=" language-python"><code class="language-python">bicycles <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'trek'</span><span class="token punctuation">,</span><span class="token string">'cannondale'</span><span class="token punctuation">,</span><span class="token string">'redline'</span><span class="token punctuation">,</span><span class="token string">'specialized'</span><span class="token punctuation">]</span></code></pre><pre class=" language-python"><code class="language-python">list<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>                  <span class="token comment" spellcheck="true">#表示第一个元素</span>list<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>                 <span class="token comment" spellcheck="true">#表示最后一个元素</span><span class="token comment" spellcheck="true">#列表的增删改</span>list<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token string">'honda'</span><span class="token punctuation">)</span>     <span class="token comment" spellcheck="true">#在列表末尾添加字符串'honda'</span>list<span class="token punctuation">.</span>insert<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token string">'ducati'</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true">#在第一位插入字符串'ducati',后面的元素后移一位</span><span class="token keyword">del</span> list<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>              <span class="token comment" spellcheck="true">#删除第一个元素</span>str <span class="token operator">=</span> list<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token punctuation">)</span>         <span class="token comment" spellcheck="true">#删除列表末尾的元素，同时可以把这个元素赋值给另一个变量</span>str <span class="token operator">=</span> list<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">#删除第一个元素，同时可以把这个元素赋值给另一个变量</span>list<span class="token punctuation">.</span>remove<span class="token punctuation">(</span><span class="token string">'ducati'</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#不清楚元素位置，知道元素值的删除方法</span><span class="token comment" spellcheck="true">#列表的排列（排列时列表数据类型要保持一致）</span>list<span class="token punctuation">.</span>sort<span class="token punctuation">(</span><span class="token punctuation">)</span>              <span class="token comment" spellcheck="true">#按字母顺序排列列表</span>list<span class="token punctuation">.</span>sort<span class="token punctuation">(</span>reverse <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#按与字母顺序相反的顺序排列列表</span>sorted<span class="token punctuation">(</span>list<span class="token punctuation">)</span>             <span class="token comment" spellcheck="true">#不影响原有列表的排列顺序，直接返回一个排列好的列表</span>sorted<span class="token punctuation">(</span>list<span class="token punctuation">,</span>reverse <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span>   <span class="token comment" spellcheck="true">#反向排列，不改变原有列表</span>list<span class="token punctuation">.</span>reverse<span class="token punctuation">(</span><span class="token punctuation">)</span>           <span class="token comment" spellcheck="true">#将列表元素反转排列</span><span class="token comment" spellcheck="true">#使用列表一部分</span>list<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">:</span><span class="token number">3</span><span class="token punctuation">]</span>                <span class="token comment" spellcheck="true">#输出一个包含列表第1到3个元素的列表，没有list[3]</span>list<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">4</span><span class="token punctuation">]</span>                 <span class="token comment" spellcheck="true">#输出一个包含列表前四个元素的列表</span>list<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">:</span><span class="token punctuation">]</span>                 <span class="token comment" spellcheck="true">#输出一个包含列表第三个元素开始往后的元素的列表</span>list<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">3</span><span class="token punctuation">:</span><span class="token punctuation">]</span>                <span class="token comment" spellcheck="true">#输出一个包含列表最后三个元素的列表</span><span class="token comment" spellcheck="true">#复制一个列表</span>list2 <span class="token operator">=</span> list1<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">]</span>         <span class="token comment" spellcheck="true">#不能使用list2 = list1，因为这样它们的地址是一样的</span>len<span class="token punctuation">(</span>list<span class="token punctuation">)</span>                <span class="token comment" spellcheck="true">#确定列表长度</span><span class="token keyword">for</span> i <span class="token keyword">in</span> list<span class="token punctuation">:</span>           <span class="token comment" spellcheck="true">#打印整个列表</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span>range<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span>               <span class="token comment" spellcheck="true">#1到4的整数，是可迭代对象</span>range<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">11</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span>            <span class="token comment" spellcheck="true">#2到10的整数，步长为2（2，4，6，8，10）</span>list<span class="token punctuation">(</span>range<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>         <span class="token comment" spellcheck="true">#转换为列表</span>min<span class="token punctuation">(</span>list_digits<span class="token punctuation">)</span>         <span class="token comment" spellcheck="true">#找出数字列表的最小值</span>max<span class="token punctuation">(</span>list_digits<span class="token punctuation">)</span>         <span class="token comment" spellcheck="true">#找出数字列表的最大值</span>list <span class="token operator">=</span> <span class="token punctuation">[</span>value<span class="token operator">**</span><span class="token number">2</span> <span class="token keyword">for</span> value <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">11</span><span class="token punctuation">)</span><span class="token punctuation">]</span>    <span class="token comment" spellcheck="true">#一行代码生成列表</span></code></pre><hr><h2 id="元组"><a href="#元组" class="headerlink" title="元组"></a>元组</h2><p>不可修改的列表称为元组。</p><pre class=" language-python"><code class="language-python">tuple <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">200</span><span class="token punctuation">,</span><span class="token number">50</span><span class="token punctuation">)</span>             <span class="token comment" spellcheck="true">#两个元素的元组</span>tuple<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">10</span>                <span class="token comment" spellcheck="true">#不合法 </span>tuple <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span>             <span class="token comment" spellcheck="true">#可以给储存元组的变量重新赋值，合法</span></code></pre><hr><h2 id="if语句"><a href="#if语句" class="headerlink" title="if语句"></a>if语句</h2><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#检查单个条件</span><span class="token keyword">if</span> car <span class="token operator">==</span> <span class="token string">'bmw'</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>car<span class="token punctuation">.</span>upper<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">elif</span> car <span class="token operator">==</span> <span class="token string">'saf'</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>car<span class="token punctuation">.</span>lower<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">else</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>car<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#检查多个条件</span><span class="token keyword">if</span> age_0 <span class="token operator">>=</span> <span class="token number">21</span> <span class="token operator">and</span> age_1 <span class="token operator">>=</span> <span class="token number">21</span><span class="token keyword">if</span> age_0 <span class="token operator">>=</span> <span class="token number">21</span> <span class="token operator">or</span> age_1 <span class="token operator">>=</span> <span class="token number">21</span><span class="token comment" spellcheck="true">#检查特定值是否在列表中，特定值是否在字符串中同理</span><span class="token keyword">if</span> <span class="token string">'value'</span> <span class="token keyword">in</span> list<span class="token keyword">if</span> <span class="token string">'value'</span> <span class="token operator">not</span> <span class="token keyword">in</span> list<span class="token comment" spellcheck="true">#确定列表不是空的</span><span class="token keyword">if</span> list</code></pre><hr><h2 id="字典"><a href="#字典" class="headerlink" title="字典"></a>字典</h2><p>字典是一系列的键值对：</p><pre class=" language-python"><code class="language-python">dict <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">'color'</span><span class="token punctuation">:</span><span class="token string">'green'</span><span class="token punctuation">,</span><span class="token string">'points'</span><span class="token punctuation">:</span><span class="token number">5</span><span class="token punctuation">}</span>dict<span class="token punctuation">[</span><span class="token string">'color'</span><span class="token punctuation">]</span>         <span class="token comment" spellcheck="true">#访问字典中'color'所对应的值</span></code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#字典是动态结构，可随时在其中添加键值对,键值对的排列顺序和添加顺序不同，Python不关心键值对顺序，只关心键与值的联系</span>dict<span class="token punctuation">[</span><span class="token string">'x_position'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span><span class="token comment" spellcheck="true">#修改字典中的值</span>dict<span class="token punctuation">[</span><span class="token string">'x_position'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">10</span><span class="token comment" spellcheck="true">#删除键值对</span><span class="token keyword">del</span> dict<span class="token punctuation">[</span><span class="token string">'points'</span><span class="token punctuation">]</span><span class="token comment" spellcheck="true">#遍历字典</span><span class="token keyword">for</span> key<span class="token punctuation">,</span>value <span class="token keyword">in</span> dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>       <span class="token comment" spellcheck="true">#item方法返回一个键值对列表，依次是键，值，键，值。。。</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>key<span class="token operator">/</span>n<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>value<span class="token punctuation">)</span><span class="token keyword">for</span> key <span class="token keyword">in</span> dict<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>              <span class="token comment" spellcheck="true">#遍历字典所有键</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>key<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">for</span> key <span class="token keyword">in</span> sorted<span class="token punctuation">(</span>dict<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>      <span class="token comment" spellcheck="true">#按顺序遍历字典所有键</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>key<span class="token punctuation">)</span><span class="token punctuation">;</span>   <span class="token keyword">for</span> value <span class="token keyword">in</span> dict<span class="token punctuation">.</span>values<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>value<span class="token punctuation">)</span><span class="token comment" spellcheck="true">#嵌套，字典储存于列表或列表储存于字典</span><span class="token comment" spellcheck="true">#字典储存于列表中可运用于游戏中产生的一群敌人（列表），每个敌人的数据都不相同（字典）</span><span class="token comment" spellcheck="true">#列表储存于字典运用于一个特征由多个元素组成，如披萨的原料，顾客点的披萨：外壳：硬，原料：蘑菇，奶酪。</span><span class="token comment" spellcheck="true">#字典中储存字典，运用于网站用户，用户名作为键，用户信息储存于一个字典中，字典作为值。</span></code></pre><hr><h2 id="用户输入和while循环"><a href="#用户输入和while循环" class="headerlink" title="用户输入和while循环"></a>用户输入和while循环</h2><ul><li>函数input()让程序暂停运行，等待用户输入文本，获取用户输入后，Python将其储存在一个变量中，供你使用：</li></ul><pre class=" language-python"><code class="language-python">message <span class="token operator">=</span> input<span class="token punctuation">(</span><span class="token string">"Tell me something,and I will repeat it back to you:"</span><span class="token punctuation">)</span>         <span class="token comment" spellcheck="true">#获取输入，input中是提示信息</span><span class="token keyword">print</span><span class="token punctuation">(</span>message<span class="token punctuation">)</span></code></pre><ul><li>while循环不断执行，知道指定的条件不满足为止：</li></ul><pre class=" language-python"><code class="language-python">num <span class="token operator">=</span> <span class="token number">1</span><span class="token keyword">while</span> num <span class="token operator">&lt;=</span> <span class="token number">5</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>num<span class="token punctuation">)</span>    num<span class="token operator">+</span><span class="token operator">+</span>    <span class="token keyword">if</span> city <span class="token operator">==</span> <span class="token string">'quit'</span><span class="token punctuation">:</span>      <span class="token comment" spellcheck="true">#可以设定条件主动退出循环</span>        <span class="token keyword">break</span>               <span class="token comment" spellcheck="true">#continue为退出本次循</span></code></pre><ul><li>在for循环中不应修改列表，否则将导致Python难以跟踪其中的元素，可使用while进行修改：</li></ul><pre class=" language-python"><code class="language-python">unconfirmed_users <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'alice'</span><span class="token punctuation">,</span><span class="token string">'brian'</span><span class="token punctuation">,</span><span class="token string">'candace'</span><span class="token punctuation">]</span>confirmed_users <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token keyword">while</span> unconfirmed_users<span class="token punctuation">:</span>                       <span class="token comment" spellcheck="true">#验证所有未验证用户，并从旧列表中删除，将已验证用户加入新列表中</span>    current_user <span class="token operator">=</span> unconfirmed_users<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>current_user<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    confirmed_users<span class="token punctuation">.</span>append<span class="token punctuation">(</span>current_users<span class="token punctuation">)</span></code></pre><ul><li>删除包含特定值的所有列表元素</li></ul><pre class=" language-python"><code class="language-python"><span class="token keyword">while</span> <span class="token string">'cat'</span> <span class="token keyword">in</span> pets<span class="token punctuation">:</span>    pets<span class="token punctuation">.</span>remove<span class="token punctuation">(</span><span class="token string">'cat'</span><span class="token punctuation">)</span></code></pre><hr><h2 id="函数"><a href="#函数" class="headerlink" title="函数"></a>函数</h2><p>函数是带名字的代码块，用于完成具体的工作。需要程序多次执行同一项任务是，无需反复编写代码，只需反复调用执行改任务的函数即可。</p><pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">greet_user</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Hello!'</span><span class="token punctuation">)</span></code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#向函数传递信息</span><span class="token keyword">def</span> <span class="token function">greet_user</span><span class="token punctuation">(</span>username<span class="token punctuation">)</span><span class="token punctuation">:</span>                                          <span class="token comment" spellcheck="true">#一个参数</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Hello"</span> <span class="token operator">+</span> username<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">describe_pet</span><span class="token punctuation">(</span>animal_type <span class="token operator">=</span> ‘rabbit’<span class="token punctuation">,</span>pet_name <span class="token operator">=</span> <span class="token string">'snoby'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>       <span class="token comment" spellcheck="true">#两个参数，可以给形参设定默认值，这样就可以不用传入实参</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"I have a"</span> <span class="token operator">+</span> animal_type <span class="token operator">+</span> <span class="token string">'.The name is'</span> <span class="token operator">+</span> pet_name<span class="token punctuation">)</span>    describe_pet<span class="token punctuation">(</span><span class="token string">'hamster'</span><span class="token punctuation">,</span><span class="token string">'harry'</span><span class="token punctuation">)</span>                                    <span class="token comment" spellcheck="true">#实际调用</span>describe_pet<span class="token punctuation">(</span>animal_type <span class="token operator">=</span> <span class="token string">'hamster'</span><span class="token punctuation">,</span>pet_name <span class="token operator">=</span> <span class="token string">'harry'</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#有返回值的函数</span><span class="token keyword">def</span> <span class="token function">git_fromatted_name</span><span class="token punctuation">(</span>first_name<span class="token punctuation">,</span>last_name<span class="token punctuation">)</span><span class="token punctuation">:</span>    full_name <span class="token operator">=</span> first_name <span class="token operator">+</span> last_name    <span class="token keyword">return</span> full_name<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token punctuation">)</span>                                  <span class="token comment" spellcheck="true">#return {'first':first_name,'last':last_name}    可返回字典</span><span class="token comment" spellcheck="true">#把列表传给函数后，函数可以直接对其进行修改,注意这在简单数据类型行不通。如果不想修改列表本身可以用list[:]副本传入</span><span class="token keyword">def</span> <span class="token function">print_models</span><span class="token punctuation">(</span>unprinted_designs<span class="token punctuation">,</span>completed_models<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">while</span> unprinted_designs<span class="token punctuation">:</span>        current_designs <span class="token operator">=</span> unprinted_designs<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Printing model:'</span> <span class="token operator">+</span> current_design<span class="token punctuation">)</span>        completed_models<span class="token punctuation">.</span>append<span class="token punctuation">(</span>current_design<span class="token punctuation">)</span><span class="token comment" spellcheck="true">#传递任意数量的实参</span><span class="token keyword">def</span> <span class="token function">make_pizza</span><span class="token punctuation">(</span><span class="token operator">*</span>toppings<span class="token punctuation">)</span><span class="token punctuation">:</span>                                        <span class="token comment" spellcheck="true">#这里toppings是一个元组，可以传入任意数量的元素</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>toppings<span class="token punctuation">)</span>make_pizza<span class="token punctuation">(</span><span class="token string">'mushrooms'</span><span class="token punctuation">,</span><span class="token string">'green peppers'</span><span class="token punctuation">,</span><span class="token string">'extra cheese'</span><span class="token punctuation">)</span>            <span class="token comment" spellcheck="true">#调用函数，传入的参数自行组成元组</span><span class="token keyword">def</span> <span class="token function">make_pizza</span><span class="token punctuation">(</span>size<span class="token punctuation">,</span><span class="token operator">*</span>toppings<span class="token punctuation">)</span><span class="token punctuation">:</span>                                   <span class="token comment" spellcheck="true">#结合使用    </span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"make a "</span> <span class="token operator">+</span> size <span class="token operator">+</span> <span class="token string">"pizza with the following toppings:"</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> topping <span class="token keyword">in</span> toppings<span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"- "</span> <span class="token operator">+</span> topping<span class="token punctuation">)</span><span class="token comment" spellcheck="true">#使用任意数量的关键字实参（传入任意数量元素的字典）</span><span class="token keyword">def</span> <span class="token function">build_profile</span><span class="token punctuation">(</span>first<span class="token punctuation">,</span>last<span class="token punctuation">,</span><span class="token operator">**</span>user_info<span class="token punctuation">)</span><span class="token punctuation">:</span>                         <span class="token comment" spellcheck="true">#传入信息和键值对，合并成一个字典</span>    profile <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>    profile<span class="token punctuation">[</span><span class="token string">'first_name'</span><span class="token punctuation">]</span> <span class="token operator">=</span> first    profile<span class="token punctuation">[</span><span class="token string">'last_name'</span><span class="token punctuation">]</span> <span class="token operator">=</span> last    <span class="token keyword">for</span> key<span class="token punctuation">,</span>value <span class="token keyword">in</span> user_info<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span>：        profile<span class="token punctuation">[</span>key<span class="token punctuation">]</span> <span class="token operator">=</span> value    <span class="token keyword">return</span> profilebild_profile<span class="token punctuation">(</span><span class="token string">'albert'</span><span class="token punctuation">,</span><span class="token string">'einstein'</span><span class="token punctuation">,</span>location <span class="token operator">=</span> <span class="token string">'princeton'</span><span class="token punctuation">,</span>field <span class="token operator">=</span> <span class="token string">'physics'</span><span class="token punctuation">)</span>      <span class="token comment" spellcheck="true">#调用</span></code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#将函数储存在模块中</span><span class="token comment" spellcheck="true">#创建一个存储函数的独立文件，在其所在目录中的其他py文件都可以通过import+文件名导入模块</span><span class="token comment" spellcheck="true">#pizza.py</span><span class="token keyword">def</span> <span class="token function">make_pizza</span><span class="token punctuation">(</span><span class="token operator">*</span>toppings<span class="token punctuation">)</span><span class="token punctuation">:</span>                                            <span class="token keyword">print</span><span class="token punctuation">(</span>toppings<span class="token punctuation">)</span><span class="token comment" spellcheck="true">#making_pizzas.py</span><span class="token keyword">import</span> pizza                          <span class="token comment" spellcheck="true">#import pizza as p 可以给模块指定别名</span>pizza<span class="token punctuation">.</span>make_pizza<span class="token punctuation">(</span><span class="token string">'mushroom'</span><span class="token punctuation">,</span><span class="token string">'green peppers'</span><span class="token punctuation">,</span><span class="token string">'extra cheese'</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#导入特定函数</span><span class="token keyword">from</span> pizza <span class="token keyword">import</span> make_pizza <span class="token keyword">as</span> mp           <span class="token comment" spellcheck="true">#可以给函数指定别名</span><span class="token comment" spellcheck="true">#导入模块中所有函数</span><span class="token keyword">from</span> pizza <span class="token keyword">import</span> <span class="token operator">*</span></code></pre><hr><h2 id="类"><a href="#类" class="headerlink" title="类"></a>类</h2><p>面向对象编程是最有效的软件编写方法之一。在面向对象编程是，你编写表示现实世界中的事物和场景的类，基于这些类来创造对象，每个对象都具备类的通用行为，也可根据需要赋予每个对象独特的个性。</p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#创建一个类</span><span class="token comment" spellcheck="true">#self是一个指向实类本身的引用，让实例能访问类中的属性和方法。</span><span class="token comment" spellcheck="true">#Python调用_init_()方法来创建实例时会自动传入实参self，我们自己不需要传递它。</span><span class="token keyword">class</span> <span class="token class-name">Dog</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>name<span class="token punctuation">,</span>age<span class="token punctuation">)</span><span class="token punctuation">:</span>   <span class="token comment" spellcheck="true">#注意init两边的横线的两条杠            </span>        self<span class="token punctuation">.</span>name <span class="token operator">=</span> name        self<span class="token punctuation">.</span>age <span class="token operator">=</span> age        self<span class="token punctuation">.</span>model <span class="token operator">=</span> <span class="token number">0</span>             <span class="token comment" spellcheck="true">#可以在此处定义另外没传入的变量</span>    <span class="token keyword">def</span> <span class="token function">sit</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>name<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> ‘<span class="token keyword">is</span> now sitting<span class="token punctuation">.</span>’<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">roll_over</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>name<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">'rolled over!'</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">update_model</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>model<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>model <span class="token operator">=</span> model<span class="token comment" spellcheck="true">#创建实例</span>my_dog <span class="token operator">=</span> Dog<span class="token punctuation">(</span><span class="token string">'willie'</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">)</span>my_dog<span class="token punctuation">.</span>name                        <span class="token comment" spellcheck="true">#访问实例中的变量</span>my_dog<span class="token punctuation">.</span>age                         <span class="token comment" spellcheck="true">#访问实例中的变量</span>my_dog<span class="token punctuation">.</span>sit<span class="token punctuation">(</span><span class="token punctuation">)</span>                       <span class="token comment" spellcheck="true">#调用类中的方法</span><span class="token comment" spellcheck="true">#修改属性的值</span>my_dog<span class="token punctuation">.</span>model <span class="token operator">=</span> <span class="token number">10</span>                  <span class="token comment" spellcheck="true">#大多数情况为了封装完整，应该使用方法对属性进行修改</span>my_dog<span class="token punctuation">.</span>update_model<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span>            <span class="token comment" spellcheck="true">#这样修改</span></code></pre><h3 id="类的继承"><a href="#类的继承" class="headerlink" title="类的继承"></a>类的继承</h3><p>编写类是，并非总是从空白开始。一个类继承另一个类时，自动获得另一个类所有的属性和方法，原有的类称为父类，新类称为子类，子类也可定义属于自己的属性和方法。</p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#假设前面已有一个Car类</span><span class="token keyword">class</span> <span class="token class-name">ElectricCar</span><span class="token punctuation">(</span>Car<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>make<span class="token punctuation">,</span>model<span class="token punctuation">,</span>year<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>_init_<span class="token punctuation">(</span>make<span class="token punctuation">,</span>model<span class="token punctuation">,</span>year<span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#super是一个特殊函数，将父类和子类联系起来，代表了父类，此处父类和子类的_init_函数保持一致</span>        <span class="token comment" spellcheck="true">#此处编写ElecticCar类的独特属性</span><span class="token comment" spellcheck="true">#子类可以重写父类的方法</span><span class="token comment" spellcheck="true">#可以将实例用作属性</span><span class="token keyword">class</span> <span class="token class-name">Battery</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token operator">-</span><span class="token operator">-</span>skip<span class="token keyword">class</span> <span class="token class-name">ElectricCar</span><span class="token punctuation">(</span>car<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">_init_</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>make<span class="token punctuation">,</span>model<span class="token punctuation">,</span>year<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>_init_<span class="token punctuation">(</span>make<span class="token punctuation">,</span>model<span class="token punctuation">,</span>year<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>battery <span class="token operator">=</span> Battery<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>              <span class="token comment" spellcheck="true">#实例作属性</span></code></pre><h3 id="导入类"><a href="#导入类" class="headerlink" title="导入类"></a>导入类</h3><p>Python允许你将类储存在模块中，然后在主程序中导入所需的模块：</p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#car.py</span>Class <span class="token class-name">Car</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token operator">-</span><span class="token operator">-</span>skipClass <span class="token class-name">Smartphone</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token operator">-</span><span class="token operator">-</span>skip<span class="token comment" spellcheck="true">#my_car.py</span><span class="token keyword">from</span> car <span class="token keyword">import</span> Car          <span class="token comment" spellcheck="true">#导入整个模块用import car，运用是要在类前加mudule_name.。导入模块中所有类用from car import *</span>my_new_car <span class="token operator">=</span> Car<span class="token punctuation">(</span><span class="token string">'audi'</span><span class="token punctuation">,</span><span class="token string">'a4'</span><span class="token punctuation">,</span><span class="token number">2016</span><span class="token punctuation">)</span></code></pre><hr><h2 id="文件和异常"><a href="#文件和异常" class="headerlink" title="文件和异常"></a>文件和异常</h2><p>自此，你已掌握了编写组织有序易于使用的程序所需的基本技巧，为了让程序用途更广，本章将学习处理文件，让程序快速分析大量数据；处理异常，用于管理程序运行时出现的错误，还将学习模块json，保存用户数据，以免程序停止运行后丢失。本章的学习可提高程序的实用性，可用性，稳定性。</p><h3 id="从文件中读取数据"><a href="#从文件中读取数据" class="headerlink" title="从文件中读取数据"></a>从文件中读取数据</h3><p>假设已创建了一个文件pi_digits.txt</p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#读取文件，显示内容，不需要主动调用close</span><span class="token keyword">with</span> open<span class="token punctuation">(</span><span class="token string">'pi_digits.txt'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> file_object<span class="token punctuation">:</span>   <span class="token comment" spellcheck="true">#文件命名为file_object。相对路径行不通可以用绝对路径</span>    contents <span class="token operator">=</span> file_object<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token comment" spellcheck="true">#读取文件内容，传入字符串中 </span>    <span class="token keyword">print</span><span class="token punctuation">(</span>contents<span class="token punctuation">.</span>rstrip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>                 <span class="token comment" spellcheck="true">#rstrip()方法删除字符串末尾的空白</span><span class="token comment" spellcheck="true">#逐行读取</span><span class="token keyword">with</span> open<span class="token punctuation">(</span>filename<span class="token punctuation">)</span> <span class="token keyword">as</span> file_object<span class="token punctuation">:</span>    lines <span class="token operator">=</span> file_object<span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span>         <span class="token comment" spellcheck="true">#readlines()方法从文件中读取每一行，储存在一个列表中</span>    <span class="token keyword">for</span> line <span class="token keyword">in</span> file_object<span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span>line<span class="token punctuation">)</span>        </code></pre><h3 id="写入文件"><a href="#写入文件" class="headerlink" title="写入文件"></a>写入文件</h3><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#整体写入</span><span class="token keyword">with</span> open<span class="token punctuation">(</span>filename<span class="token punctuation">,</span><span class="token string">'w'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> file_object<span class="token punctuation">:</span>             <span class="token comment" spellcheck="true">#以写入模式打开文件，如果文件不存在会自动创建，已经存在会清空文件</span>    file_object<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"I love programming."</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">#注意只能写入字符串，写入多行时可以加换行符</span><span class="token comment" spellcheck="true">#附加内容</span><span class="token keyword">with</span> open<span class="token punctuation">(</span>filename<span class="token punctuation">,</span><span class="token string">'a'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> file_object<span class="token punctuation">:</span>             <span class="token comment" spellcheck="true">#以附加模式打开文件，不会清空原有文件，写入的行添加到文件末尾</span>    file_object<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"I love programming."</span><span class="token punctuation">)</span>        </code></pre><h3 id="异常"><a href="#异常" class="headerlink" title="异常"></a>异常</h3><p>发生程序异常时未对异常进行处理，程序会停止。使用try-except代码块时，即使出现异常，也会继续运行，显示你编写的友好的错误信息而不是traceback。</p><pre class=" language-python"><code class="language-python"><span class="token keyword">try</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token operator">/</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token keyword">except</span> ZeroDivisionError<span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'You can\'t divide by zero!'</span><span class="token punctuation">)</span><span class="token keyword">else</span><span class="token punctuation">:</span>                                                              <span class="token comment" spellcheck="true">#正常运行</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"answer"</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#处理文件找不到的异常</span><span class="token keyword">try</span><span class="token punctuation">:</span>    <span class="token keyword">with</span> open<span class="token punctuation">(</span>filename<span class="token punctuation">)</span> <span class="token keyword">as</span> f_obj<span class="token punctuation">:</span>        contents <span class="token operator">=</span> f_obj<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">except</span> FileNotFoundError<span class="token punctuation">:</span>    msg <span class="token operator">=</span> <span class="token string">"Sorry,the file"</span> <span class="token operator">+</span> filename <span class="token operator">+</span> <span class="token string">"does not exist."</span>          <span class="token comment" spellcheck="true">#如果这里写pass，错误时可以不输出信息</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>msg<span class="token punctuation">)</span></code></pre><h3 id="分析文本"><a href="#分析文本" class="headerlink" title="分析文本"></a>分析文本</h3><pre class=" language-python"><code class="language-python">str<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token comment" spellcheck="true">#以空格为分隔符将字符串拆分为多个部分，并储存到一个列表中</span><span class="token comment" spellcheck="true">#计算文本单词数</span><span class="token keyword">def</span> <span class="token function">count_words</span><span class="token punctuation">(</span>filename<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">try</span><span class="token punctuation">:</span>        <span class="token keyword">with</span> open<span class="token punctuation">(</span>filename<span class="token punctuation">)</span> <span class="token keyword">as</span> f_obj<span class="token punctuation">:</span>            contents <span class="token operator">=</span> f_obj<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">except</span> FileNotFoundError<span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Sorry,the file does not exist'</span><span class="token punctuation">)</span>    <span class="token keyword">else</span><span class="token punctuation">:</span>        word <span class="token operator">=</span> contents<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span>        num_words <span class="token operator">=</span> len<span class="token punctuation">(</span>words<span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"The file "</span> <span class="token operator">+</span> filename <span class="token operator">+</span> <span class="token string">"has about "</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>num_words<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">" words."</span><span class="token punctuation">)</span></code></pre><h3 id="存储数据"><a href="#存储数据" class="headerlink" title="存储数据"></a>存储数据</h3><p>程序需要把用户提供的数据存储在列表和字典等数据结构中，用户关闭程序时，需要保存他们提供的信息，一种简单的办法是用模块json来储存信息</p><p><strong>json.dump()和json.load()</strong></p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> jsonnumbers <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">7</span><span class="token punctuation">,</span><span class="token number">11</span><span class="token punctuation">,</span><span class="token number">13</span><span class="token punctuation">]</span>filename <span class="token operator">=</span> <span class="token string">'numbers.json'</span><span class="token keyword">with</span> open<span class="token punctuation">(</span>filename<span class="token punctuation">,</span><span class="token string">'w'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f_obj<span class="token punctuation">:</span>    json<span class="token punctuation">.</span>dump<span class="token punctuation">(</span>numbers<span class="token punctuation">,</span>f_obj<span class="token punctuation">)</span>         <span class="token comment" spellcheck="true">#传入要储存的数据和储存数据的文件对象</span><span class="token comment" spellcheck="true">#文件中数据存储格式和Python中一样[2,3,5,7,11,13]</span><span class="token comment" spellcheck="true">#再将列表读取到内存中</span><span class="token keyword">with</span> open<span class="token punctuation">(</span>filename<span class="token punctuation">)</span> <span class="token keyword">as</span> f_obj<span class="token punctuation">:</span>    numbers <span class="token operator">=</span> json<span class="token punctuation">.</span>load<span class="token punctuation">(</span>f_obj<span class="token punctuation">)</span>       <span class="token comment" spellcheck="true">#列表被读取出来</span></code></pre><hr><h2 id="测试代码"><a href="#测试代码" class="headerlink" title="测试代码"></a>测试代码</h2><p>每个程序员都需要经常测试其代码，在用户发现问题前找到它，因此需要编写测试代码改进代码。</p><p>Python标准库中的模块unittest提供了测试工具，单元测试用于核实函数的某个方面没有问题。</p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> unittest<span class="token keyword">from</span> name_function <span class="token keyword">import</span> get_formatted_name<span class="token comment" spellcheck="true">#测试类,所有以test_开头的方法自动运行</span><span class="token keyword">class</span> <span class="token class-name">NamesTestCase</span><span class="token punctuation">(</span>unittest<span class="token punctuation">.</span>TestCase<span class="token punctuation">)</span><span class="token punctuation">:</span>                     <span class="token comment" spellcheck="true">#必须继承unittest.TestCase</span>    <span class="token keyword">def</span> <span class="token function">test_first_last_name</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>                         <span class="token comment" spellcheck="true">#核实名和姓能否被正确格式化</span>        formatted_name <span class="token operator">=</span> get_formatted_name<span class="token punctuation">(</span><span class="token string">'janis'</span><span class="token punctuation">,</span><span class="token string">'joplin'</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>assertEqual<span class="token punctuation">(</span>formatted_name<span class="token punctuation">,</span><span class="token string">'Janis Joplin'</span><span class="token punctuation">)</span>     <span class="token comment" spellcheck="true">#断言方法，核实得到的结果与期望是否一致</span>unittest<span class="token punctuation">.</span>main<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#如果全部测试通过会输出OK,第一行的句点表明几个测试通过</span><span class="token comment" spellcheck="true">#不通过第一行会有E,最后显示FALLED</span><span class="token comment" spellcheck="true">#测试不通过时，意味新代码有错。不要修改测试，而应修改导致测试不通过的代码。</span></code></pre><table><thead><tr><th align="center">方法</th><th align="center">用途</th></tr></thead><tbody><tr><td align="center">assertEqual(a,b)</td><td align="center">核实a == b</td></tr><tr><td align="center">assertNotEqual(a,b)</td><td align="center">核实a != b</td></tr><tr><td align="center">assertTrue(x)</td><td align="center">核实x为True</td></tr><tr><td align="center">assertFalse(x)</td><td align="center">核实x为False</td></tr><tr><td align="center">assertIn(item,list)</td><td align="center">核实item在list中</td></tr><tr><td align="center">assertNotIn(item,list)</td><td align="center">核实item不在list中</td></tr></tbody></table><p>类的测试和函数的测试类似：</p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#假设已经创建了一个匿名调查类AnonymousSurvey</span><span class="token keyword">from</span> survey <span class="token keyword">import</span> AnonymousSurvey<span class="token keyword">import</span> unittest<span class="token keyword">class</span> <span class="token class-name">TestAnonmyousSurvey</span><span class="token punctuation">(</span>unittest<span class="token punctuation">.</span>TestCase<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">test_store_single_response</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        question <span class="token operator">=</span> <span class="token string">'what language did you first learn to speak?'</span>        my_survey <span class="token operator">=</span> AnonymousSurvey<span class="token punctuation">(</span>question<span class="token punctuation">)</span>                <span class="token comment" spellcheck="true">#问题</span>        my_survey<span class="token punctuation">.</span>store_response<span class="token punctuation">(</span><span class="token string">'English'</span><span class="token punctuation">)</span>                  <span class="token comment" spellcheck="true">#答案，会添加到答案列表中  </span>        my_survey<span class="token punctuation">.</span>store_response<span class="token punctuation">(</span><span class="token string">'Chinese'</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>assertIn<span class="token punctuation">(</span><span class="token string">'English'</span><span class="token punctuation">,</span>my_survey<span class="token punctuation">.</span>responses<span class="token punctuation">)</span>unittest<span class="token punctuation">.</span>main<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><p><strong>方法setUp()，TestCase类包含方法，对测试函数初始化</strong></p><pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> survey <span class="token keyword">import</span> AnonymousSurvey<span class="token keyword">import</span> unittest<span class="token keyword">class</span> <span class="token class-name">TestAnonmyousSurvey</span><span class="token punctuation">(</span>unittest<span class="token punctuation">.</span>TestCase<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">setUp</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        question <span class="token operator">=</span> <span class="token string">'what language did you first learn to speak?'</span>        my_survey <span class="token operator">=</span> AnonymousSurvey<span class="token punctuation">(</span>question<span class="token punctuation">)</span>                        <span class="token comment" spellcheck="true">#输入问题</span>        self<span class="token punctuation">.</span>responses <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'English'</span><span class="token punctuation">,</span><span class="token string">'Spanish'</span><span class="token punctuation">,</span><span class="token string">'Mandarin'</span><span class="token punctuation">]</span>    <span class="token keyword">def</span> <span class="token function">test_store_single_response</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>                            <span class="token comment" spellcheck="true">#测试一个答案 </span>        my_survey<span class="token punctuation">.</span>store_response<span class="token punctuation">(</span>self<span class="token punctuation">.</span>responses<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>                         self<span class="token punctuation">.</span>assertIn<span class="token punctuation">(</span>self<span class="token punctuation">.</span>responses<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>my_survey<span class="token punctuation">.</span>responses<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">test_store_three_responses</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>                            <span class="token comment" spellcheck="true">#测试三个答案</span>        <span class="token keyword">for</span> response <span class="token keyword">in</span> self<span class="token punctuation">.</span>responses<span class="token punctuation">:</span>            self<span class="token punctuation">.</span>my_survey<span class="token punctuation">.</span>store_reponse<span class="token punctuation">(</span>response<span class="token punctuation">)</span>        <span class="token keyword">for</span> response <span class="token keyword">in</span> self<span class="token punctuation">.</span>responses<span class="token punctuation">:</span>            self<span class="token punctuation">.</span>assertIn<span class="token punctuation">(</span>response<span class="token punctuation">,</span>self<span class="token punctuation">.</span>my_survey<span class="token punctuation">.</span>responses<span class="token punctuation">)</span>unittest<span class="token punctuation">.</span>main<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><hr><h1 id="项目"><a href="#项目" class="headerlink" title="项目"></a>项目</h1><h2 id="数据可视化"><a href="#数据可视化" class="headerlink" title="数据可视化"></a>数据可视化</h2><p>数据可视化是通过可视化来表示探索数据，与数据挖掘紧密相关，在基因研究，天气研究，政治经济分析等众多领域，大家都使用Python完成数据密集型工作，数据科学家编写了一系列令人印象深刻的可视化和分析工具，最流行的是matplotlib，它是一个数学绘图库，可以制作简单的图表。我们还将使用Pygal包，它专注于生成适合在数字设备上显示的图表。</p><p>pycharm安装matplotlib十分方便快捷，直接在File→setting→Project interpreter中一键导入即可，不再赘述。</p><h3 id="绘制简单曲线图"><a href="#绘制简单曲线图" class="headerlink" title="绘制简单曲线图"></a>绘制简单曲线图</h3><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#最简版</span><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> pltsquares <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">9</span><span class="token punctuation">,</span><span class="token number">16</span><span class="token punctuation">,</span><span class="token number">25</span><span class="token punctuation">]</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>squres<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><img src="/2021/01/13/python-bian-cheng-cong-ru-men-dao-shi-jian-bi-ji/1.png" class=""><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#改善可读性</span><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> pltinput_values <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">]</span>                           <span class="token comment" spellcheck="true">#x轴的值</span>squares <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">9</span><span class="token punctuation">,</span><span class="token number">16</span><span class="token punctuation">,</span><span class="token number">25</span><span class="token punctuation">]</span>                              <span class="token comment" spellcheck="true">#y轴的值</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>input_values，squares<span class="token punctuation">,</span>linewidth <span class="token operator">=</span>  <span class="token number">5</span><span class="token punctuation">)</span>       <span class="token comment" spellcheck="true">#线段宽度</span>plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">"Square Numbers"</span><span class="token punctuation">,</span>fontsize <span class="token operator">=</span> <span class="token number">24</span><span class="token punctuation">)</span>            <span class="token comment" spellcheck="true">#标题及其大小</span>plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">"Value"</span><span class="token punctuation">,</span>fontsize <span class="token operator">=</span> <span class="token number">14</span><span class="token punctuation">)</span>                    <span class="token comment" spellcheck="true">#x轴标签及其大小</span>plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">"Square of Value"</span><span class="token punctuation">,</span>fontsize <span class="token operator">=</span> <span class="token number">14</span><span class="token punctuation">)</span>          <span class="token comment" spellcheck="true">#y轴标签及其大小</span>plt<span class="token punctuation">.</span>tick_params<span class="token punctuation">(</span>axis <span class="token operator">=</span> <span class="token string">'both'</span><span class="token punctuation">,</span>labelsize <span class="token operator">=</span> <span class="token number">14</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">#设置刻度标记的大小</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><img src="/2021/01/13/python-bian-cheng-cong-ru-men-dao-shi-jian-bi-ji/2.png" class=""><h3 id="绘制散点图"><a href="#绘制散点图" class="headerlink" title="绘制散点图"></a>绘制散点图</h3><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> pltx_values <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">]</span>y_values <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">9</span><span class="token punctuation">,</span><span class="token number">16</span><span class="token punctuation">,</span><span class="token number">25</span><span class="token punctuation">]</span><span class="token comment" spellcheck="true">#scatter方法绘制散点图，可删除数据点黑色轮廓，可设置颜色，默认为蓝色。cmap = plt.cm.Blues为设置渐变蓝色</span>plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>x_values<span class="token punctuation">,</span>y_values<span class="token punctuation">,</span>s <span class="token operator">=</span> <span class="token number">100</span><span class="token punctuation">,</span>edgecolor <span class="token operator">=</span> <span class="token string">'none'</span><span class="token punctuation">,</span>c <span class="token operator">=</span> <span class="token string">'red'</span><span class="token punctuation">)</span>   plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">"Square Numbers"</span><span class="token punctuation">,</span>fontsize <span class="token operator">=</span> <span class="token number">24</span><span class="token punctuation">)</span>                   <span class="token comment" spellcheck="true">#配置四连，不再赘述</span>plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">"Value"</span><span class="token punctuation">,</span>fontsize <span class="token operator">=</span> <span class="token number">14</span><span class="token punctuation">)</span>                   plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">"Square of Value"</span><span class="token punctuation">,</span>fontsize <span class="token operator">=</span> <span class="token number">14</span><span class="token punctuation">)</span>         plt<span class="token punctuation">.</span>tick_params<span class="token punctuation">(</span>axis <span class="token operator">=</span> <span class="token string">'both'</span><span class="token punctuation">,</span>labelsize <span class="token operator">=</span> <span class="token number">14</span><span class="token punctuation">)</span>        plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><img src="/2021/01/13/python-bian-cheng-cong-ru-men-dao-shi-jian-bi-ji/3.png" class=""><h3 id="保存图表"><a href="#保存图表" class="headerlink" title="保存图表"></a>保存图表</h3><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#第一个实参是文件名，第二个指定将图表多余的空白裁剪掉</span>plt<span class="token punctuation">.</span>savefig<span class="token punctuation">(</span><span class="token string">'squares_plot.png'</span><span class="token punctuation">,</span>bbox_inches <span class="token operator">=</span> <span class="token string">'tight'</span><span class="token punctuation">)</span></code></pre><h3 id="随机漫步"><a href="#随机漫步" class="headerlink" title="随机漫步"></a>随机漫步</h3><pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> random <span class="token keyword">import</span> choice<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt<span class="token keyword">class</span> <span class="token class-name">RandomWalk</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>num_points <span class="token operator">=</span> <span class="token number">5000</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>num_points <span class="token operator">=</span> num_points        self<span class="token punctuation">.</span>x_values <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>        self<span class="token punctuation">.</span>y_values <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>    <span class="token keyword">def</span> <span class="token function">fill_walk</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">while</span> len<span class="token punctuation">(</span>self<span class="token punctuation">.</span>x_values<span class="token punctuation">)</span> <span class="token operator">&lt;</span> self<span class="token punctuation">.</span>num_points<span class="token punctuation">:</span>            x_direction <span class="token operator">=</span> choice<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>                        <span class="token comment" spellcheck="true">#这里采用choice方法选取随机数</span>            x_distance <span class="token operator">=</span> choice<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span>            x_step <span class="token operator">=</span> x_direction <span class="token operator">*</span> x_distance            y_direction <span class="token operator">=</span> choice<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>            y_distance <span class="token operator">=</span> choice<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span>            y_step <span class="token operator">=</span> y_direction <span class="token operator">*</span> y_distance            <span class="token keyword">if</span> x_step <span class="token operator">==</span> <span class="token number">0</span> <span class="token operator">and</span> y_step <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>                <span class="token keyword">continue</span>            next_x <span class="token operator">=</span> self<span class="token punctuation">.</span>x_values<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">+</span> x_step            next_y <span class="token operator">=</span> self<span class="token punctuation">.</span>y_values<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">+</span> y_step            self<span class="token punctuation">.</span>x_values<span class="token punctuation">.</span>append<span class="token punctuation">(</span>next_x<span class="token punctuation">)</span>            self<span class="token punctuation">.</span>y_values<span class="token punctuation">.</span>append<span class="token punctuation">(</span>next_y<span class="token punctuation">)</span>rw <span class="token operator">=</span> RandomWalk<span class="token punctuation">(</span><span class="token punctuation">)</span>rw<span class="token punctuation">.</span>fill_walk<span class="token punctuation">(</span><span class="token punctuation">)</span>point_numbers <span class="token operator">=</span> list<span class="token punctuation">(</span>range<span class="token punctuation">(</span>rw<span class="token punctuation">.</span>num_points<span class="token punctuation">)</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span>s <span class="token operator">=</span> <span class="token number">100</span><span class="token punctuation">,</span>c <span class="token operator">=</span> <span class="token string">'green'</span><span class="token punctuation">,</span>edgecolor <span class="token operator">=</span> <span class="token string">'none'</span><span class="token punctuation">)</span>                             <span class="token comment" spellcheck="true">#绘制起点            </span>plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>rw<span class="token punctuation">.</span>x_values<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>rw<span class="token punctuation">.</span>y_values<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>s <span class="token operator">=</span> <span class="token number">100</span><span class="token punctuation">,</span>c <span class="token operator">=</span> <span class="token string">'red'</span><span class="token punctuation">,</span>edgecolor <span class="token operator">=</span> <span class="token string">'none'</span><span class="token punctuation">)</span>   <span class="token comment" spellcheck="true">#绘制终点</span>plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>rw<span class="token punctuation">.</span>x_values<span class="token punctuation">,</span>rw<span class="token punctuation">.</span>y_values<span class="token punctuation">,</span>s <span class="token operator">=</span> <span class="token number">15</span><span class="token punctuation">,</span>c <span class="token operator">=</span> point_numbers<span class="token punctuation">,</span>                       <span class="token comment" spellcheck="true">#根据绘制的先后决定点颜色的深浅   </span>            cmap<span class="token operator">=</span>plt<span class="token punctuation">.</span>cm<span class="token punctuation">.</span>Blues<span class="token punctuation">,</span>edgecolor <span class="token operator">=</span> <span class="token string">'none'</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#plt.figure(dpi=128,figsize=(10,6))      调整绘图窗口尺寸</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><img src="/2021/01/13/python-bian-cheng-cong-ru-men-dao-shi-jian-bi-ji/4.png" class=""><h3 id="使用Pygal模拟掷骰子（柱状图）"><a href="#使用Pygal模拟掷骰子（柱状图）" class="headerlink" title="使用Pygal模拟掷骰子（柱状图）"></a>使用Pygal模拟掷骰子（柱状图）</h3><pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> random <span class="token keyword">import</span> randint<span class="token keyword">import</span> pygal<span class="token keyword">class</span> <span class="token class-name">Die</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>numsides <span class="token operator">=</span> <span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>num_sides <span class="token operator">=</span> numsides    <span class="token keyword">def</span> <span class="token function">roll</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span>  randint<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>self<span class="token punctuation">.</span>num_sides<span class="token punctuation">)</span><span class="token comment" spellcheck="true">#投掷1000次，结果储存在列表中</span>die <span class="token operator">=</span> Die<span class="token punctuation">(</span><span class="token punctuation">)</span>results <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token keyword">for</span> roll_num <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">10000</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    result <span class="token operator">=</span> die<span class="token punctuation">.</span>roll<span class="token punctuation">(</span><span class="token punctuation">)</span>    results<span class="token punctuation">.</span>append<span class="token punctuation">(</span>result<span class="token punctuation">)</span><span class="token comment" spellcheck="true">#处理数据</span>frequencies <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token keyword">for</span> value <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>die<span class="token punctuation">.</span>num_sides<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    frequency <span class="token operator">=</span> results<span class="token punctuation">.</span>count<span class="token punctuation">(</span>value<span class="token punctuation">)</span>             <span class="token comment" spellcheck="true">#count函数，计算列表中一个值出现的次数</span>    frequencies<span class="token punctuation">.</span>append<span class="token punctuation">(</span>frequency<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>frequencies<span class="token punctuation">)</span><span class="token comment" spellcheck="true">#构建柱状图</span>hist <span class="token operator">=</span> pygal<span class="token punctuation">.</span>Bar<span class="token punctuation">(</span><span class="token punctuation">)</span>hist<span class="token punctuation">.</span>title <span class="token operator">=</span> <span class="token string">'Results of rolling one D6 1000 times.'</span>hist<span class="token punctuation">.</span>x_labels <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'1'</span><span class="token punctuation">,</span><span class="token string">'2'</span><span class="token punctuation">,</span><span class="token string">'3'</span><span class="token punctuation">,</span><span class="token string">'4'</span><span class="token punctuation">,</span><span class="token string">'5'</span><span class="token punctuation">,</span><span class="token string">'6'</span><span class="token punctuation">]</span>hist<span class="token punctuation">.</span>x_title <span class="token operator">=</span> <span class="token string">"Result"</span>hist<span class="token punctuation">.</span>y_title <span class="token operator">=</span> <span class="token string">"Frequency of Result"</span>hist<span class="token punctuation">.</span>add<span class="token punctuation">(</span><span class="token string">'D6'</span><span class="token punctuation">,</span>frequencies<span class="token punctuation">)</span>hist<span class="token punctuation">.</span>render_to_file<span class="token punctuation">(</span><span class="token string">'die_visual.svg'</span><span class="token punctuation">)</span>             <span class="token comment" spellcheck="true">#保存文件</span></code></pre><img src="/2021/01/13/python-bian-cheng-cong-ru-men-dao-shi-jian-bi-ji/5.png" class=""><hr><h2 id="从网上下载数据并处理和绘图"><a href="#从网上下载数据并处理和绘图" class="headerlink" title="从网上下载数据并处理和绘图"></a>从网上下载数据并处理和绘图</h2><p>本章中，你将从网上下载数据，并对数据进行可视化。我们将使用Python模块csv来处理以CSV（逗号分隔的值）格式存储的天气数据，使用模块json来访问以JSON存储的人口数据。</p><h3 id="绘制天气情况图表"><a href="#绘制天气情况图表" class="headerlink" title="绘制天气情况图表"></a>绘制天气情况图表</h3><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> csv<span class="token keyword">from</span> matplotlib <span class="token keyword">import</span> pyplot <span class="token keyword">as</span> plt<span class="token keyword">from</span> datetime <span class="token keyword">import</span> datetimefilename <span class="token operator">=</span> <span class="token string">'death_valley_2014.csv'</span><span class="token keyword">with</span> open<span class="token punctuation">(</span>filename<span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>    reader <span class="token operator">=</span> csv<span class="token punctuation">.</span>reader<span class="token punctuation">(</span>f<span class="token punctuation">)</span>              <span class="token comment" spellcheck="true">#创建一个与该文件向关联的阅读器</span>    header_row <span class="token operator">=</span> next<span class="token punctuation">(</span>reader<span class="token punctuation">)</span>           <span class="token comment" spellcheck="true">#返回文件中的下一行，这里是第一行，返回一个列表，以逗号分隔开的内容为一个元素</span><span class="token comment" spellcheck="true">#    for index,conlumn_header in enumerate(header_row):  #enumerate()方法获取列表每个元素的索引和值</span><span class="token comment" spellcheck="true">#        print(index,conlumn_header)</span>    dates<span class="token punctuation">,</span>highs<span class="token punctuation">,</span>lows <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token comment" spellcheck="true"># 遍历文件余下的各行，阅读器对象从其停留的地方继续往下读取csv文件，每次返回下一行，第一行已经读取，这里从第二行开始</span>    <span class="token comment" spellcheck="true"># 返回的都是第二列每一天最高温度的值</span>    <span class="token keyword">for</span> row <span class="token keyword">in</span> reader<span class="token punctuation">:</span>        <span class="token keyword">try</span><span class="token punctuation">:</span>                                                    <span class="token comment" spellcheck="true">#对缺失的数据进行检查</span>            current_date <span class="token operator">=</span> datetime<span class="token punctuation">.</span>strptime<span class="token punctuation">(</span>row<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token string">"%Y-%m-%d"</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#这里获取日期，第二个参数指定如何解读日期</span>            high <span class="token operator">=</span> int<span class="token punctuation">(</span>row<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>                                  <span class="token comment" spellcheck="true">#转化为整形，matplotlib才能读取它们</span>            low <span class="token operator">=</span> int<span class="token punctuation">(</span>row<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token keyword">except</span> ValueError<span class="token punctuation">:</span>            <span class="token keyword">print</span><span class="token punctuation">(</span>current_date<span class="token punctuation">,</span><span class="token string">'missing data'</span><span class="token punctuation">)</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            dates<span class="token punctuation">.</span>append<span class="token punctuation">(</span>current_date<span class="token punctuation">)</span>            highs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>high<span class="token punctuation">)</span>            lows<span class="token punctuation">.</span>append<span class="token punctuation">(</span>low<span class="token punctuation">)</span><span class="token comment" spellcheck="true">#绘图代码</span>fig <span class="token operator">=</span> plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>dpi <span class="token operator">=</span> <span class="token number">128</span><span class="token punctuation">,</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">)</span>                      <span class="token comment" spellcheck="true">#调节图的大小，第一个参数是窗口分辨率，第二个是长和宽</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>dates<span class="token punctuation">,</span>highs<span class="token punctuation">,</span>c<span class="token operator">=</span><span class="token string">'red'</span><span class="token punctuation">,</span>alpha<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span>                         <span class="token comment" spellcheck="true">#画折线图，alpha为透明度</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>dates<span class="token punctuation">,</span>lows<span class="token punctuation">,</span>c<span class="token operator">=</span><span class="token string">'blue'</span><span class="token punctuation">,</span>alpha<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>fill_between<span class="token punctuation">(</span>dates<span class="token punctuation">,</span>highs<span class="token punctuation">,</span>lows<span class="token punctuation">,</span>facecolor <span class="token operator">=</span> <span class="token string">'blue'</span><span class="token punctuation">,</span>alpha<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#中间填充颜色</span>fig<span class="token punctuation">.</span>autofmt_xdate<span class="token punctuation">(</span><span class="token punctuation">)</span>                                             <span class="token comment" spellcheck="true">#绘制倾斜的x轴标签</span>plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'Daily high and low temperatures - 2014'</span><span class="token punctuation">,</span>fontsize<span class="token operator">=</span><span class="token number">24</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">''</span><span class="token punctuation">,</span>fontsize<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'Temperature(F)'</span><span class="token punctuation">,</span>fontsize<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>tick_params<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token string">'both'</span><span class="token punctuation">,</span>which <span class="token operator">=</span> <span class="token string">'major'</span><span class="token punctuation">,</span>labelsize <span class="token operator">=</span> <span class="token number">16</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><p>datetime.strptime方法第一个参数是传入的字符串，第二个参数规定字符串的格式，下表列出了一些这样的实参：</p><table><thead><tr><th align="center">实参</th><th align="center">含义</th></tr></thead><tbody><tr><td align="center">%A</td><td align="center">星期的名称，如Monday</td></tr><tr><td align="center">%B</td><td align="center">月份名称，如January</td></tr><tr><td align="center">%m</td><td align="center">用数字表示的月份（01-12）</td></tr><tr><td align="center">%d</td><td align="center">用数字表示的月份中的一天（01-31）</td></tr><tr><td align="center">%Y</td><td align="center">四位的年份，如2021</td></tr><tr><td align="center">%y</td><td align="center">两位的年份，如21</td></tr><tr><td align="center">%H</td><td align="center">24小时的小时数（00-23）</td></tr><tr><td align="center">%I</td><td align="center">12小时的小时数（01-12）</td></tr><tr><td align="center">%p</td><td align="center">am或pm</td></tr><tr><td align="center">%M</td><td align="center">分钟数（00-59）</td></tr><tr><td align="center">%S</td><td align="center">秒数（00-61）</td></tr></tbody></table><h3 id="制作世界人口地图"><a href="#制作世界人口地图" class="headerlink" title="制作世界人口地图"></a>制作世界人口地图</h3><p>JSON文件其实是一个很长的列表，每个元素都是字典。</p><p>书本提供的链接已经不能下载数据，但感谢CSDN的兄弟，让我下载到了这份数据，链接附上：</p><p><a href="https://pan.baidu.com/s/1FlwB2SQzn_z06SR3eM9mJg%EF%BC%8C%E6%8F%90%E5%8F%96%E7%A0%81%EF%BC%9Aq6vy">https://pan.baidu.com/s/1FlwB2SQzn_z06SR3eM9mJg，提取码：q6vy</a></p><p>注意：原来的pygal.i18n的包已经弃用，改为pygal.maps.world，请自行下载pygal_maps_world模块。</p><p>代码如下：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> json<span class="token keyword">from</span> pygal<span class="token punctuation">.</span>maps<span class="token punctuation">.</span>world <span class="token keyword">import</span> COUNTRIES      <span class="token comment" spellcheck="true">#注意原来的包已经弃用，COUNTIES是一个字典，两位国别码是键，国家名是值</span><span class="token keyword">import</span> pygal<span class="token keyword">from</span> pygal<span class="token punctuation">.</span>style <span class="token keyword">import</span> RotateStyle <span class="token keyword">as</span> RS<span class="token punctuation">,</span>LightColorizedStyle <span class="token keyword">as</span> LCS<span class="token keyword">def</span> <span class="token function">get_country_code</span><span class="token punctuation">(</span>country_name<span class="token punctuation">)</span><span class="token punctuation">:</span>         <span class="token comment" spellcheck="true">#获取两位国别码的函数</span>    <span class="token keyword">for</span> code<span class="token punctuation">,</span>name <span class="token keyword">in</span> COUNTRIES<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> name <span class="token operator">==</span> country_name<span class="token punctuation">:</span>            <span class="token keyword">return</span> code    <span class="token keyword">return</span> Nonefilename <span class="token operator">=</span> <span class="token string">"population_data.json"</span><span class="token keyword">with</span> open<span class="token punctuation">(</span>filename<span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>    pop_data <span class="token operator">=</span> json<span class="token punctuation">.</span>load<span class="token punctuation">(</span>f<span class="token punctuation">)</span>           <span class="token comment" spellcheck="true">#生成一个列表，每个元素是字典</span>cc_populations <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token keyword">for</span> pop_dict <span class="token keyword">in</span> pop_data<span class="token punctuation">:</span>    <span class="token keyword">if</span> pop_dict<span class="token punctuation">[</span><span class="token string">'Year'</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">'2010'</span><span class="token punctuation">:</span>                <span class="token comment" spellcheck="true">#只用2010年的信息</span>        country_name <span class="token operator">=</span> pop_dict<span class="token punctuation">[</span><span class="token string">'Country Name'</span><span class="token punctuation">]</span>        population <span class="token operator">=</span> int<span class="token punctuation">(</span>float<span class="token punctuation">(</span>pop_dict<span class="token punctuation">[</span><span class="token string">'Value'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        code <span class="token operator">=</span> get_country_code<span class="token punctuation">(</span>country_name<span class="token punctuation">)</span>     <span class="token comment" spellcheck="true">#获取两位国别码</span>        <span class="token keyword">if</span> code<span class="token punctuation">:</span>                                  <span class="token comment" spellcheck="true">#过滤掉不是国家的信息</span>            cc_populations<span class="token punctuation">[</span>code<span class="token punctuation">]</span> <span class="token operator">=</span> populationcc_pops_1<span class="token punctuation">,</span>cc_pops_2<span class="token punctuation">,</span>cc_pops_3 <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token punctuation">,</span><span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token punctuation">,</span><span class="token punctuation">{</span><span class="token punctuation">}</span>          <span class="token comment" spellcheck="true">#分成三类可以用不同颜色的深浅表示，区分度更明显</span><span class="token keyword">for</span> cc<span class="token punctuation">,</span>pop <span class="token keyword">in</span> cc_populations<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">if</span> pop <span class="token operator">&lt;</span> <span class="token number">10000000</span><span class="token punctuation">:</span>        cc_pops_1<span class="token punctuation">[</span>cc<span class="token punctuation">]</span> <span class="token operator">=</span> pop    <span class="token keyword">elif</span> pop <span class="token operator">&lt;</span> <span class="token number">1000000000</span><span class="token punctuation">:</span>        cc_pops_2<span class="token punctuation">[</span>cc<span class="token punctuation">]</span> <span class="token operator">=</span> pop    <span class="token keyword">else</span><span class="token punctuation">:</span>        cc_pops_3<span class="token punctuation">[</span>cc<span class="token punctuation">]</span> <span class="token operator">=</span> popwm_style <span class="token operator">=</span> RS<span class="token punctuation">(</span><span class="token string">'#336699'</span><span class="token punctuation">,</span>base_style<span class="token operator">=</span>LCS<span class="token punctuation">)</span>           #让地图颜色更一致，更明亮，更容易区分不同的编组wm <span class="token operator">=</span> pygal<span class="token punctuation">.</span>maps<span class="token punctuation">.</span>world<span class="token punctuation">.</span>World<span class="token punctuation">(</span>style <span class="token operator">=</span> wm_style<span class="token punctuation">)</span>wm<span class="token punctuation">.</span>title <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token string">'World Population in 2010, by Country'</span><span class="token punctuation">)</span>wm<span class="token punctuation">.</span>add<span class="token punctuation">(</span><span class="token string">'0-10m'</span><span class="token punctuation">,</span>cc_pops_1<span class="token punctuation">)</span>wm<span class="token punctuation">.</span>add<span class="token punctuation">(</span><span class="token string">'10m-1bn'</span><span class="token punctuation">,</span>cc_pops_2<span class="token punctuation">)</span>wm<span class="token punctuation">.</span>add<span class="token punctuation">(</span><span class="token string">'>1bn'</span><span class="token punctuation">,</span>cc_pops_3<span class="token punctuation">)</span>wm<span class="token punctuation">.</span>render_to_file<span class="token punctuation">(</span><span class="token string">'americas.svg'</span><span class="token punctuation">)</span></code></pre><p>｛% asset_img 7.png %｝</p><hr><h2 id="使用API"><a href="#使用API" class="headerlink" title="使用API"></a>使用API</h2><p>在本章，程序将使用Web应用编程接口（API）自动请求网站的特定信息而不是整个网站，再对信息进行可视化，这样信息是最新的。</p><p>使用API调用请求数据，在浏览器地址栏输入：</p><pre><code>https://api.github.com/search/repositories?q=language:python&amp;sort=stars</code></pre><p>这个调用返回GitHub当前托管了多少个项目，还有最受欢迎的Python仓库的信息。</p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> requestsurl <span class="token operator">=</span> <span class="token string">'https://api.github.com/search/repositories?q=language:python&amp;sort=stars'</span>r <span class="token operator">=</span> requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span>url<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Status code:'</span><span class="token punctuation">,</span>r<span class="token punctuation">.</span>status_code<span class="token punctuation">)</span>       <span class="token comment" spellcheck="true">#状态码为200则响应成功</span>response_dict <span class="token operator">=</span> r<span class="token punctuation">.</span>json<span class="token punctuation">(</span><span class="token punctuation">)</span>                 <span class="token comment" spellcheck="true">#这个API返回的是JSON格式信息，因此转换为字典</span><span class="token keyword">print</span><span class="token punctuation">(</span>response_dict<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Total repositories:"</span><span class="token punctuation">,</span>response_dict<span class="token punctuation">[</span><span class="token string">'total_count'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>   <span class="token comment" spellcheck="true">#看仓库总数</span><span class="token comment" spellcheck="true">#看获取了多少仓库的信息</span>repo_dicts <span class="token operator">=</span> response_dict<span class="token punctuation">[</span><span class="token string">'items'</span><span class="token punctuation">]</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Repositories returned:"</span><span class="token punctuation">,</span>len<span class="token punctuation">(</span>repo_dicts<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#查看获取到的每个仓库的信息</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"\nSelected information about each repository:"</span><span class="token punctuation">)</span><span class="token keyword">for</span> repo_dict <span class="token keyword">in</span> repo_dicts<span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"\nName:"</span><span class="token punctuation">,</span>repo_dict<span class="token punctuation">[</span><span class="token string">'name'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Owner:"</span><span class="token punctuation">,</span> repo_dict<span class="token punctuation">[</span><span class="token string">'owner'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'login'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Stars:'</span><span class="token punctuation">,</span>repo_dict<span class="token punctuation">[</span><span class="token string">'stargazers_count'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Repository:'</span><span class="token punctuation">,</span>repo_dict<span class="token punctuation">[</span><span class="token string">'html_url'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Description:'</span><span class="token punctuation">,</span>repo_dict<span class="token punctuation">[</span><span class="token string">'description'</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><p>监视API速率限制，在浏览器输入：<a href="https://api.github.com/rate_limit%EF%BC%8C%E5%86%85%E5%AE%B9%E5%A6%82%E4%B8%8B%EF%BC%9A">https://api.github.com/rate_limit，内容如下：</a></p><pre><code>{"resources":    {"core":        {"limit":60,"remaining":60,"reset":1610899050,"used":0},        "graphql":{"limit":0,"remaining":0,"reset":1610899050,"used":0},        "integration_manifest":{"limit":5000,"remaining":5000,"reset":1610899050,"used":0},        "search":{"limit":10,"remaining":10,"reset":1610895510,"used":0}    },    "rate":{"limit":60,"remaining":60,"reset":1610899050,"used":0}}</code></pre><p>我们关心的是搜索API的速率限制，可知极限为每分钟10个请求，用完配额后会受到一条简单的响应，必须等待配额重置。很多API都要求你注册获得API秘钥后才能执行API调用。</p><p><strong>使用API可视化仓库：</strong></p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> requests<span class="token keyword">import</span> pygal<span class="token keyword">from</span> pygal<span class="token punctuation">.</span>style <span class="token keyword">import</span> LightColorizedStyle <span class="token keyword">as</span> LCS<span class="token punctuation">,</span>LightenStyle <span class="token keyword">as</span> LSurl <span class="token operator">=</span> <span class="token string">'https://api.github.com/search/repositories?q=language:python&amp;sort=stars'</span>r <span class="token operator">=</span> requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span>url<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Status code:'</span><span class="token punctuation">,</span>r<span class="token punctuation">.</span>status_code<span class="token punctuation">)</span>       <span class="token comment" spellcheck="true">#状态码为200则响应成功</span>response_dict <span class="token operator">=</span> r<span class="token punctuation">.</span>json<span class="token punctuation">(</span><span class="token punctuation">)</span>                 <span class="token comment" spellcheck="true">#这个API返回的是JSON格式信息，因此转换为字典</span><span class="token keyword">print</span><span class="token punctuation">(</span>response_dict<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Total repositories:"</span><span class="token punctuation">,</span>response_dict<span class="token punctuation">[</span><span class="token string">'total_count'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>   <span class="token comment" spellcheck="true">#看仓库总数</span>repo_dicts <span class="token operator">=</span> response_dict<span class="token punctuation">[</span><span class="token string">'items'</span><span class="token punctuation">]</span><span class="token comment" spellcheck="true">#收集每个仓库的名字和星数信息</span>names<span class="token punctuation">,</span>plot_dicts<span class="token punctuation">,</span>stars <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token keyword">for</span> repo_dict <span class="token keyword">in</span> repo_dicts<span class="token punctuation">:</span>    names<span class="token punctuation">.</span>append<span class="token punctuation">(</span>repo_dict<span class="token punctuation">[</span><span class="token string">'name'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    plot_dict <span class="token operator">=</span> <span class="token punctuation">{</span>        <span class="token string">'value'</span><span class="token punctuation">:</span> repo_dict<span class="token punctuation">[</span><span class="token string">'stargazers_count'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>          <span class="token comment" spellcheck="true">#数据</span>        <span class="token string">'label'</span><span class="token punctuation">:</span> str<span class="token punctuation">(</span>repo_dict<span class="token punctuation">[</span><span class="token string">'description'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>          <span class="token comment" spellcheck="true">#描述</span>        <span class="token string">'xlink'</span><span class="token punctuation">:</span> repo_dict<span class="token punctuation">[</span><span class="token string">'html_url'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                  <span class="token comment" spellcheck="true">#链接</span>        <span class="token punctuation">}</span>    plot_dicts<span class="token punctuation">.</span>append<span class="token punctuation">(</span>plot_dict<span class="token punctuation">)</span>    stars<span class="token punctuation">.</span>append<span class="token punctuation">(</span>repo_dict<span class="token punctuation">[</span><span class="token string">'stargazers_count'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>my_style <span class="token operator">=</span> LS<span class="token punctuation">(</span><span class="token string">'#333366'</span><span class="token punctuation">,</span>base_style<span class="token operator">=</span>LCS<span class="token punctuation">)</span>   #定义样式，基色为深蓝色my_config <span class="token operator">=</span> pygal<span class="token punctuation">.</span>Config<span class="token punctuation">(</span><span class="token punctuation">)</span>                <span class="token comment" spellcheck="true">#创建设定，下面是一系列设定</span>my_config<span class="token punctuation">.</span>x_label_rotation <span class="token operator">=</span> <span class="token number">45</span>my_config<span class="token punctuation">.</span>show_legend <span class="token operator">=</span> <span class="token boolean">False</span>my_config<span class="token punctuation">.</span>title_font_size <span class="token operator">=</span> <span class="token number">24</span>my_config<span class="token punctuation">.</span>label_font_size <span class="token operator">=</span> <span class="token number">14</span>my_config<span class="token punctuation">.</span>major_label_font_size <span class="token operator">=</span> <span class="token number">18</span>      <span class="token comment" spellcheck="true">#主要标签大小</span>my_config<span class="token punctuation">.</span>truncate_label <span class="token operator">=</span> <span class="token number">15</span>             <span class="token comment" spellcheck="true">#较长的项目名缩短为15个字符</span>my_config<span class="token punctuation">.</span>show_y_guides <span class="token operator">=</span> <span class="token boolean">False</span>           <span class="token comment" spellcheck="true">#隐藏图表中的水平线</span>my_config<span class="token punctuation">.</span>width <span class="token operator">=</span> <span class="token number">1000</span>                    <span class="token comment" spellcheck="true">#图表宽度</span>chart <span class="token operator">=</span> pygal<span class="token punctuation">.</span>Bar<span class="token punctuation">(</span>my_config<span class="token punctuation">,</span>style <span class="token operator">=</span> my_style<span class="token punctuation">)</span>chart<span class="token punctuation">.</span>title <span class="token operator">=</span> <span class="token string">"Most_Starred Python Projects on Github"</span>chart<span class="token punctuation">.</span>x_labels <span class="token operator">=</span> names                    <span class="token comment" spellcheck="true">#x轴标签</span>chart<span class="token punctuation">.</span>add<span class="token punctuation">(</span><span class="token string">''</span><span class="token punctuation">,</span>plot_dicts<span class="token punctuation">)</span>                  <span class="token comment" spellcheck="true">#导入数据</span>chart<span class="token punctuation">.</span>render_to_file<span class="token punctuation">(</span><span class="token string">'python_repos.svg'</span><span class="token punctuation">)</span></code></pre><img src="/2021/01/13/python-bian-cheng-cong-ru-men-dao-shi-jian-bi-ji/6.png" class=""><p>探索如何使用其他网站的API调用，可以自己去查API接口，这部分内容我会在以后更新放在其他博文里。</p><hr><h2 id="Django入门"><a href="#Django入门" class="headerlink" title="Django入门"></a>Django入门</h2><h3 id="建立项目"><a href="#建立项目" class="headerlink" title="建立项目"></a>建立项目</h3><p>Python提供了一组开发Web开发的卓越工具，这时一个Web框架，一套用于帮助开发交互式网站的工具。</p><p><strong>建立虚拟环境</strong>，新建一个目录，将终端切换到这个目录，使用如下命令建立虚拟环境:</p><pre><code>python -m venv 11_env</code></pre><p>建立虚拟环境后，需要使用如下命令<strong>激活</strong>它：</p><pre><code>source 11_env/Scripts/activate</code></pre><p>环境处于激活状态时环境名包含在括号里，这时可以在环境中安装包，使用已安装的包，在11_env中安装的包在环境处于活动状态时才能使用。</p><p>如果要<strong>停止</strong>虚拟环境，执行命令：</p><pre><code>deactivate</code></pre><p><strong>安装Django</strong>:</p><pre><code>pip3 install Django</code></pre><p><strong>在Django中创建项目：</strong></p><pre><code>django-admin.py startproject learning_log</code></pre><p>这时在根目录下就会出现learning_log文件夹，内含几个.py文件。manage.py接受命令交给Django的相关部分执行，管理诸如使用数据库和运行服务器等任务。文件settings.py指定Django如何与你的系统交互，如何管理项目。urls.py告诉Django应该创建哪些网页来响应浏览器的请求。文件wsgi.py帮助Django提供它创建的文件。</p><p><strong>创建数据库：</strong></p><p>Django将大部分与项目相关的信息都储存在数据库中，因此我们需要创建一个供Django使用的数据库，活跃状态下进入manage.py的目录执行如下命令：</p><pre><code>python manage.py migrate</code></pre><p>我们将修改数据库成为迁移数据库，在使用SQLite的新项目中首次执行这个命令时，Django将新建一个数据库。在这里Django创建必要的数据库表，用于储存我们将在这个项目中使用的信息，确保数据库结构与当前代码匹配。</p><p>核实Django是否正确创建了项目：</p><pre><code>python manage.py runserver</code></pre><p>Django启动服务器，让你能够查看系统中的项目，当你在浏览器中输入URL请求网页时，Django服务器将进行响应。打开浏览器输入：<a href="http://localhost:8000/%E5%8D%B3%E5%8F%AF%E6%9F%A5%E7%9C%8B%E7%BD%91%E9%A1%B5%EF%BC%8C%E6%8E%A7%E5%88%B6%E5%8F%B0%E6%8C%89Ctrl+C%E5%8F%AF%E4%BB%A5%E5%85%B3%E9%97%AD%E6%9C%8D%E5%8A%A1%E5%99%A8%E3%80%82">http://localhost:8000/即可查看网页，控制台按Ctrl+C可以关闭服务器。</a></p><img src="/2021/01/13/python-bian-cheng-cong-ru-men-dao-shi-jian-bi-ji/8.png" class=""><h3 id="创建应用程序"><a href="#创建应用程序" class="headerlink" title="创建应用程序"></a><strong>创建应用程序</strong></h3><p>在激活状态下，切换到manage.py的目录下执行命令：</p><pre><code>python manage.py startapp learning_logs</code></pre><p>Django创建程序应用learning_logs，项目文件新增一个文件夹learning_logs，里面有一些.py文件，其中models.py定义我们要在应用程序中管理的数据。</p><p>models.py:</p><pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> django<span class="token punctuation">.</span>db <span class="token keyword">import</span> models<span class="token keyword">class</span> <span class="token class-name">Topic</span><span class="token punctuation">(</span>models<span class="token punctuation">.</span>Model<span class="token punctuation">)</span><span class="token punctuation">:</span>          <span class="token comment" spellcheck="true">#Model是Django中定义了模型基本功能的类，只有text和date_added两个属性</span>    text <span class="token operator">=</span> models<span class="token punctuation">.</span>CharField<span class="token punctuation">(</span>max_length<span class="token operator">=</span><span class="token number">200</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true">#CharField储存少量文本，在数据库中预留200个字符的位置</span>    date_added <span class="token operator">=</span> models<span class="token punctuation">.</span>DateTimeField<span class="token punctuation">(</span>auto_now_add<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true">#记录日期和时间，当用户创建新主题，自动设置成当前日期和时间</span>    <span class="token keyword">def</span> <span class="token function">__str__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>             <span class="token comment" spellcheck="true">#显示模型的简单表示</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>text</code></pre><p>然后打开learning_log目录下的setting.py，把修改一段代码：</p><pre class=" language-python"><code class="language-python">INSTALLED_APPS <span class="token operator">=</span> <span class="token punctuation">[</span>                              <span class="token comment" spellcheck="true">#安装在项目中的应用程序</span>    <span class="token string">'django.contrib.admin'</span><span class="token punctuation">,</span>    <span class="token string">'django.contrib.auth'</span><span class="token punctuation">,</span>    <span class="token string">'django.contrib.contenttypes'</span><span class="token punctuation">,</span>    <span class="token string">'django.contrib.sessions'</span><span class="token punctuation">,</span>    <span class="token string">'django.contrib.messages'</span><span class="token punctuation">,</span>    <span class="token string">'django.contrib.staticfiles'</span><span class="token punctuation">,</span>    <span class="token comment" spellcheck="true">#我的应用程序</span>    <span class="token string">'learning_logs'</span><span class="token punctuation">,</span><span class="token punctuation">]</span></code></pre><p>接下来需要Django修改数据库，使其能够储存于模型Topic相关的信息，在终端执行：</p><pre><code>python manage.py makemigrations learning_logs</code></pre><p>命令makemigrations让Django确定如何修改数据库，使其储存与我们定义的新模型相关的数据，Django创建了一个名为0001——initial.py的迁移文件，这个文件在数据库中为模型Topic创建一个表。</p><p>应用这种迁移：</p><pre><code>python manage.py migrate</code></pre><p><strong>当需要修改数据时，都需要采取如下三个步骤：修改models.py，对learning_logs调用makemigrations，让Django迁移项目。</strong></p><p><strong>Django管理网站：</strong></p><p>为应用程序定义模型时，Django提供的管理网站（admin site）让你能轻松处理模型。</p><p>Django允许创建具备所有权限的用户——超级用户，命令如下（要在cmd执行否则不成功）：</p><pre><code>python manage.py createsuperuser</code></pre><p><strong>向管理网站注册模型：</strong></p><p>Django自动在网站中添加了一些模型，如User和Group，但对于我们自己创建的模型，必须进行手工注册。</p><p>models.py所在的目录中有admin.py文件，为向管理网站注册Topic，输入下面代码：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> django<span class="token punctuation">.</span>contrib <span class="token keyword">import</span> admin<span class="token keyword">from</span> learning_logs<span class="token punctuation">.</span>models <span class="token keyword">import</span> Topic            <span class="token comment" spellcheck="true">#导入要注册的模型</span>admin<span class="token punctuation">.</span>site<span class="token punctuation">.</span>register<span class="token punctuation">(</span>Topic<span class="token punctuation">)</span>                       <span class="token comment" spellcheck="true">#可以通过管理网站管理模型了</span></code></pre><p>访问<a href="http://localhost:8000/admin/%EF%BC%8C%E8%BE%93%E5%85%A5%E7%94%A8%E6%88%B7%E5%90%8D%E5%92%8C%E5%AF%86%E7%A0%81%EF%BC%8C%E5%8F%AF%E4%BB%A5%E8%BF%9B%E5%85%A5%E8%B6%85%E7%BA%A7%E7%94%A8%E6%88%B7%E8%B4%A6%E6%88%B7%E8%AE%BF%E9%97%AE%E7%AE%A1%E7%90%86%E7%BD%91%E7%AB%99%EF%BC%8C%E5%8F%AF%E4%BB%A5%E8%AE%A9%E4%BD%A0%E6%B7%BB%E5%8A%A0%E4%BF%AE%E6%94%B9%E7%94%A8%E6%88%B7%E5%92%8C%E7%94%A8%E6%88%B7%E7%BB%84%EF%BC%8C%E7%AE%A1%E7%90%86%E5%88%9A%E6%89%8D%E5%AE%9A%E4%B9%89%E7%9A%84%E6%A8%A1%E5%9E%8BTopic%E7%9B%B8%E5%85%B3%E7%9A%84%E6%95%B0%E6%8D%AE%E3%80%82">http://localhost:8000/admin/，输入用户名和密码，可以进入超级用户账户访问管理网站，可以让你添加修改用户和用户组，管理刚才定义的模型Topic相关的数据。</a></p><img src="/2021/01/13/python-bian-cheng-cong-ru-men-dao-shi-jian-bi-ji/9.png" class=""><p><strong>添加主题</strong></p><p>单击Topics进入主题网页，单击Add，看到一个用于添加新主题的菜单，输入Chess单击Save。在Add一个Rock Climbing。这样就有两个主题了。</p><p><strong>定义模型Entry：</strong></p><p>要记录学到的国际象棋和攀岩知识，需要为用户可在学习笔记中添加的条目定义模型，每个条目都与特定主题相关联，这种关系被称为多对一关系，即多个条目可关联到同一个主题：</p><p>models.py</p><pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> django<span class="token punctuation">.</span>db <span class="token keyword">import</span> models<span class="token keyword">class</span> <span class="token class-name">Topic</span><span class="token punctuation">(</span>models<span class="token punctuation">.</span>Model<span class="token punctuation">)</span><span class="token punctuation">:</span>          <span class="token comment" spellcheck="true">#Model是Django中定义了模型基本功能的类，只有text和date_added两个属性</span>    text <span class="token operator">=</span> models<span class="token punctuation">.</span>CharField<span class="token punctuation">(</span>max_length<span class="token operator">=</span><span class="token number">200</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true">#CharField储存少量文本，在数据库中预留200个字符的位置</span>    date_added <span class="token operator">=</span> models<span class="token punctuation">.</span>DateTimeField<span class="token punctuation">(</span>auto_now_add<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true">#记录日期和时间，当用户创建新主题，自动设置成当前日期和时间</span>    <span class="token keyword">def</span> <span class="token function">__str__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>             <span class="token comment" spellcheck="true">#显示模型的简单表示</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>text<span class="token keyword">class</span> <span class="token class-name">Entry</span><span class="token punctuation">(</span>models<span class="token punctuation">.</span>Model<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true">#外键是数据库术语，引用数据库中另一条记录将条目关联到特定的主题</span>    <span class="token comment" spellcheck="true">#在django2.0后，定义外键和一对一关系的时候需要加on_delete选项，此参数为了避免两个表里的数据不一致问题，不然会报错</span>    topic <span class="token operator">=</span> models<span class="token punctuation">.</span>ForeignKey<span class="token punctuation">(</span>Topic<span class="token punctuation">,</span>on_delete<span class="token operator">=</span>models<span class="token punctuation">.</span>CASCADE<span class="token punctuation">)</span>     text <span class="token operator">=</span> models<span class="token punctuation">.</span>TextField<span class="token punctuation">(</span><span class="token punctuation">)</span>                             <span class="token comment" spellcheck="true">#不需要长度限制的字段</span>    date_added <span class="token operator">=</span> models<span class="token punctuation">.</span>DateTimeField<span class="token punctuation">(</span>auto_now_add<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true">#按创建顺序呈现条目，条目旁边放置时间戳</span>    <span class="token keyword">class</span> <span class="token class-name">Meta</span><span class="token punctuation">:</span>                                           <span class="token comment" spellcheck="true">#储存用于管理模型的额外信息，可以使用entries表示多个条目</span>        verbose_name_plural <span class="token operator">=</span> <span class="token string">'entries'</span>    <span class="token keyword">def</span> <span class="token function">__str__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>text<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">50</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token string">"..."</span>                     <span class="token comment" spellcheck="true">#呈现条目时只显示前50个字符</span></code></pre><p>修改完models.py后记得迁移模型：</p><pre><code>python manage.py makemigrations learning_logspython manage.py migrate</code></pre><p>这时会生成一个新的迁移文件0002——entry.py，使数据库能储存于模型Entry相关的信息。</p><p>然后向管理网站注册Entry：</p><p>admin.py:</p><pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> django<span class="token punctuation">.</span>contrib <span class="token keyword">import</span> admin<span class="token keyword">from</span> <span class="token punctuation">.</span>models <span class="token keyword">import</span> Topic<span class="token punctuation">,</span>Entryadmin<span class="token punctuation">.</span>site<span class="token punctuation">.</span>register<span class="token punctuation">(</span>Topic<span class="token punctuation">)</span>admin<span class="token punctuation">.</span>site<span class="token punctuation">.</span>register<span class="token punctuation">(</span>Entry<span class="token punctuation">)</span></code></pre><p>这时登录超级用户管理网站，就可以在主题下添加条目了：</p><img src="/2021/01/13/python-bian-cheng-cong-ru-men-dao-shi-jian-bi-ji/10.png" class=""><p>输入一些数据后，就可以通过交互式终端会话以编程方式查看这些数据了，这种交互式环境被称为Django Shell，是测试项目和排除故障的理想之地。下面是交互式Shell示例:</p><pre><code>$ python manage.py shell&gt;&gt;&gt; from learning_logs.models import Topic&gt;&gt;&gt; Topic.objects.all()&lt;QuerySet [&lt;Topic: Chess&gt;, &lt;Topic: Rock Climbing&gt;]&gt;&gt;&gt;&gt; topics = Topic.objects.all()&gt;&gt;&gt; for topic in topics:...     print(topic.id,topic)...1 Chess2 Rock Climbing</code></pre><p>知道对象的ID后，就可获取该对象并查看其任何属性，其中内容展示由于中文原因造成乱码：</p><pre><code>&gt;&gt;&gt; t = Topic.objects.get(id=1)&gt;&gt;&gt; t.text'Chess'&gt;&gt;&gt; t.date_addeddatetime.datetime(2021, 1, 18, 15, 29, 47, 62586, tzinfo=&lt;UTC&gt;)&gt;&gt;&gt; t.entry_set.all()&lt;QuerySet [&lt;Entry: ▒й▒▒▒▒▒▒▒▒▒▒▒▒˫▒▒▒▒ִ16▒ӣ▒˫▒▒▒▒˫▒▒˫▒ڣ▒˫▒▒˫ʿ▒▒▒▒▒䣬һ▒▒▒▒▒▒▒▒▒▒▒▒90▒▒λ▒ÿɹ▒▒▒▒▒...&gt;]&gt;</code></pre><p>退出shell会话输入exit()按回车即可。</p><h3 id="创建网页：学习笔记主页"><a href="#创建网页：学习笔记主页" class="headerlink" title="创建网页：学习笔记主页"></a>创建网页：学习笔记主页</h3><p>使用Django创建网页的过程分为三个阶段：定义URL、编写视图、编写模板。</p><p>首先必须定义URL模式，URL模式描述了URL是如何设计的，让Django知道如何将浏览器请求与网站URL匹配，以确定返回哪个网页。</p><p>每个URL都被映射到特定的视图——视图函数获取并处理网页所需的信息。视图函数通常调用一个模板，后者生成浏览器能够理解的网页。</p><p><strong>映射URL：</strong></p><p>用户通过在浏览器中点击链接或输入URL来请求网页，因此我们需要确定项目需要哪些URL。主页的URL最重要，是用户访问项目的基础URL<a href="http://localhost:8000/%E3%80%82%E6%88%91%E4%BB%AC%E5%B0%86%E8%BF%99%E4%B8%AA%E5%9F%BA%E7%A1%80URL%E6%98%A0%E5%B0%84%E5%88%B0%E2%80%9C%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E2%80%9D%E7%9A%84%E4%B8%BB%E9%A1%B5%E3%80%82">http://localhost:8000/。我们将这个基础URL映射到“学习笔记”的主页。</a></p><p><strong>在这里书本上的代码是Django1.0时期的，而后来新出的Django2.0使代码有了很大变化，此处是书本的大坑。</strong>此处请参照下面代码：</p><p>urls.py:</p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#注意2.0的代码的变化</span><span class="token keyword">from</span> django<span class="token punctuation">.</span>contrib <span class="token keyword">import</span> admin<span class="token keyword">from</span> django<span class="token punctuation">.</span>urls <span class="token keyword">import</span> path<span class="token punctuation">,</span> includeurlpatterns <span class="token operator">=</span> <span class="token punctuation">[</span>    path<span class="token punctuation">(</span><span class="token string">'admin/'</span><span class="token punctuation">,</span> admin<span class="token punctuation">.</span>site<span class="token punctuation">.</span>urls<span class="token punctuation">)</span><span class="token punctuation">,</span>    path<span class="token punctuation">(</span><span class="token string">''</span><span class="token punctuation">,</span> include<span class="token punctuation">(</span><span class="token string">'learning_logs.urls'</span><span class="token punctuation">,</span> namespace<span class="token operator">=</span><span class="token string">'learning_logs'</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">]</span></code></pre><p>此时我们需要在文件夹learning_logs中创建另一个urls.py文件，代码修改如下：</p><p>urls.py:</p><pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> django<span class="token punctuation">.</span>urls <span class="token keyword">import</span> path<span class="token keyword">from</span> <span class="token punctuation">.</span> <span class="token keyword">import</span> views                <span class="token comment" spellcheck="true">#从此文件所在的目录中导入wiews</span>app_name<span class="token operator">=</span><span class="token string">'learning_logs'</span>           <span class="token comment" spellcheck="true">#巨坑，书中没有，不写runserver时会报错</span><span class="token comment" spellcheck="true">#URL模式是一个对函数path的调用，第一个参数是正则表达式，第二个参数指定了调用的视图函数第三个参数指定名称</span><span class="token comment" spellcheck="true">#当需要提供到这个主页的链接时，都将使用这个名称而不是编写URL</span>urlpatterns <span class="token operator">=</span> <span class="token punctuation">[</span>                    <span class="token comment" spellcheck="true">#包含可在learning_logs中请求的网页</span>    path<span class="token punctuation">(</span><span class="token string">''</span><span class="token punctuation">,</span> views<span class="token punctuation">.</span>index<span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'index'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                             <span class="token comment" spellcheck="true"># 主页</span>   <span class="token punctuation">]</span></code></pre><p>视图函数接受请求中的信息，准备好生成网页所需要的数据，再将这些数据发送给浏览器，这通常定义了网页是什么样的模板实现的。</p><p>views.py:</p><pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> django<span class="token punctuation">.</span>shortcuts <span class="token keyword">import</span> render<span class="token keyword">def</span> <span class="token function">index</span><span class="token punctuation">(</span>request<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">return</span> render<span class="token punctuation">(</span>request<span class="token punctuation">,</span><span class="token string">'learning_logs/index.html'</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#参数是原始请求对象以及一个可用于创建网页的模板</span></code></pre><p>URL请求与我们刚才定义的模式匹配时，Django将在views.py文件中查找函数，再将请求对象传递给这个视图函数，在这里我们不需要处理任何数据。</p><p><strong>编写模板：</strong></p><p>模板定义了网页的结构，指定了网页是什么样的，每当网页被请求时，Django将填入相关的数据，模板能让你访问视图提供的任何数据，我们的主页视图没有提供任何的数据，因此相应的模板非常简单。</p><p>在文件夹learning_logs中新建一个文件夹，命名templates，在里面新建一个文件夹名为learning_logs，在learning_logs中新建文件命名index.html。</p><p>index.html:</p><pre class=" language-html"><code class="language-html"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>p</span><span class="token punctuation">></span></span>learning Log<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>p</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>p</span><span class="token punctuation">></span></span>Learning Log helps you keep track of your learning.for any topic you're learning about.<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>p</span><span class="token punctuation">></span></span></code></pre><p> &lt;p&gt;&lt;/p&gt; 标识段落。这里定义两个段落，第一个充当标题，第二个阐述内容。</p><p>此时运行服务器，进入首页，看到的不是默认的Django网页，而是调用函数view.index()后使用index.html模板来渲染的网页。</p><img src="/2021/01/13/python-bian-cheng-cong-ru-men-dao-shi-jian-bi-ji/11.png" class=""><p>创建网页的过程看起来很复杂，但将URL、视图、模板分离的效果实际上很好，这让我们能够分别考虑到项目的不同方面，在项目很大时，每个参与者可专注于其擅长的方面。数据库专家专注于模型，程序员专注于视图代码，Web设计人员专注于模板。</p><h3 id="创建其他网页"><a href="#创建其他网页" class="headerlink" title="创建其他网页"></a>创建其他网页</h3><p>我们将创建两个显示数据的网页，一个列出所有主题，一个显示特定主题下的所有条目，每个网页都将指定URL模式，编写一个视图函数，并编写一个模板，但这样做之前，要先创建一个父模板，项目中的其他模板都继承它。</p><p><strong>模板继承：</strong></p><p>在创建网站时，有一些所有网页都包含的元素，可编写一个包含通用元素的模板，让所有网页继承这个模板。</p><p>首先创建一个名为base.html的模板，储存在index.html所在的目录中，所有页面都包含顶端的标题，这个标题设置为到主页的链接：</p><p>base.html:</p><pre class=" language-html"><code class="language-html"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>p</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>a</span> <span class="token attr-name">href</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>{% url <span class="token punctuation">'</span>learning_logs:index<span class="token punctuation">'</span> %}<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>learning Log<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>a</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>p</span><span class="token punctuation">></span></span>{% block content %}{% endblock content %}</code></pre><p>第一部分创建了包含项目名的段落，该段落也是一个到主页的链接。为创建链接，我们使用了一个模板标签，它生成了一个URL，该URL与learning_logs/urls.py中定义的名为index的URL模式匹配。此时，learning_logs是一个命名空间，index是该命名空间中一个名称独特的URL模式，在简单的HTML页面中，链接是使用锚标签定义的：</p><pre class=" language-html"><code class="language-html"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>a</span> <span class="token attr-name">href</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>link_url<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>link text<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>a</span><span class="token punctuation">></span></span></code></pre><p>使用模板标签生成URL可让链接保持最新容易得多，修改项目中的URL只需修改urls.py的URL模式。</p><p>第二部分插入了一对块标签，名为content，是一个占位符，其中的内容由子模板指定。在父模板中，可使用任意多的块来预留空间，而子模板可根据需要定义相应数量的块。</p><p>重新编写index.html:</p><pre class=" language-html"><code class="language-html">{% extends "learning_logs/base.html" %}{% block content %}    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>p</span><span class="token punctuation">></span></span>Learning Log helps you keep track of your learning.for any topic you're learning about.<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>p</span><span class="token punctuation">></span></span>{% endblock content %}</code></pre><p>与原来的代码相比，我们将标题替换为了从父模板继承的代码。在子模板中只需包含当前网页特有的内容，简化了模板，让网站修改容易得多。</p><h4 id="显示所有主题的页面："><a href="#显示所有主题的页面：" class="headerlink" title="显示所有主题的页面："></a>显示所有主题的页面：</h4><p>首先定义显示所有主题页面的URL，我们将使用单词topics，因此<a href="http://localhost:8000/topics/">http://localhost:8000/topics/</a>  将返回这个页面，<strong>learning_logs/urls.py</strong>修改如下：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> django<span class="token punctuation">.</span>urls <span class="token keyword">import</span> path<span class="token keyword">from</span> <span class="token punctuation">.</span> <span class="token keyword">import</span> views                <span class="token comment" spellcheck="true">#从此文件所在的目录中导入wiews</span>app_name<span class="token operator">=</span><span class="token string">'learning_logs'</span>           <span class="token comment" spellcheck="true">#巨坑，书中没有，不写runserver时会报错</span><span class="token comment" spellcheck="true">#URL模式是一个对函数path的调用，第一个参数是正则表达式，第二个参数指定了调用的视图函数第三个参数指定名称</span><span class="token comment" spellcheck="true">#当需要提供到这个主页的链接时，都将使用这个名称而不是编写URL</span>urlpatterns <span class="token operator">=</span> <span class="token punctuation">[</span>                    <span class="token comment" spellcheck="true">#包含可在learning_logs中请求的网页</span>    path<span class="token punctuation">(</span><span class="token string">''</span><span class="token punctuation">,</span> views<span class="token punctuation">.</span>index<span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'index'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                             <span class="token comment" spellcheck="true"># 主页</span>    path<span class="token punctuation">(</span><span class="token string">'topics/'</span><span class="token punctuation">,</span> views<span class="token punctuation">.</span>topics<span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'topics'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                    <span class="token comment" spellcheck="true"># 显示所有的主题</span>   <span class="token punctuation">]</span></code></pre><p>views.py:</p><pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> django<span class="token punctuation">.</span>shortcuts <span class="token keyword">import</span> render<span class="token keyword">from</span> <span class="token punctuation">.</span>models <span class="token keyword">import</span> Topic                  <span class="token comment" spellcheck="true">#导入所需数据相关的模型</span><span class="token keyword">def</span> <span class="token function">index</span><span class="token punctuation">(</span>request<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">return</span> render<span class="token punctuation">(</span>request<span class="token punctuation">,</span><span class="token string">'learning_logs/index.html'</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">topics</span><span class="token punctuation">(</span>request<span class="token punctuation">)</span><span class="token punctuation">:</span>                       <span class="token comment" spellcheck="true">#形参是Django从服务器收到的request对象          </span>    <span class="token comment" spellcheck="true">#显示所有主题</span>    topics <span class="token operator">=</span> Topic<span class="token punctuation">.</span>objects<span class="token punctuation">.</span>order_by<span class="token punctuation">(</span><span class="token string">'date_added'</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true">#查询数据库，请求提供Topic对象，按属性date_added进行排序</span>    context <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">'topics'</span><span class="token punctuation">:</span>topics<span class="token punctuation">}</span>                    <span class="token comment" spellcheck="true">#定义一个要发送给模板的上下文字典，键是模板中访问数据的名称，值是我们发送给模板的数据</span>    <span class="token keyword">return</span> render<span class="token punctuation">(</span>request<span class="token punctuation">,</span><span class="token string">'learning_logs/topics.html'</span><span class="token punctuation">,</span>context<span class="token punctuation">)</span><span class="token comment" spellcheck="true">#这里多传递一个数据</span></code></pre><p>同样在index.html所在目录中，创建topics.html：</p><pre class=" language-html"><code class="language-html">{% extends "learning_logs/base.html" %}{% block content %}    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>p</span><span class="token punctuation">></span></span>Topics<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>p</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>ul</span><span class="token punctuation">></span></span>        {% for topic in topics %}        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>li</span><span class="token punctuation">></span></span>{{ topic }}<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>li</span><span class="token punctuation">></span></span>        {% empty %}        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>li</span><span class="token punctuation">></span></span>No topics have been added yet.<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>li</span><span class="token punctuation">></span></span>        {% endfor %}    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>ul</span><span class="token punctuation">></span></span>{% endblock content %}</code></pre><p>在content块中，首先显示一个主题名称的文本。然后使用了一个for循环的模板标签，遍历字典context中的列表topics，这里for循环必须使用 endfor 标签来显式指出其结束位置。在循环中，需要将变量名用双花括号括起来，告诉Django使用了一个模板变量，这样每次循环都会被替换成topic当前值。在标签对&lt;ul&gt;&lt;/ul&gt;的内部，&lt;li&gt;与&lt;/li&gt;之间的内容都是一个项目列表项。 empty 标签告诉Django列表topics为空怎么办。</p><p>此时修改父模板，将其包含到显示所有主题的页面的链接：</p><p>base.html:</p><pre class=" language-html"><code class="language-html"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>p</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>a</span> <span class="token attr-name">href</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>{% url <span class="token punctuation">'</span>learning_logs:index<span class="token punctuation">'</span> %}<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>learning Log<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>a</span><span class="token punctuation">></span></span> -    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>a</span> <span class="token attr-name">href</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>{% url <span class="token punctuation">'</span>learning_logs:topics<span class="token punctuation">'</span> %}<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>Topics<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>a</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>p</span><span class="token punctuation">></span></span>{% block content %}{% endblock content %}</code></pre><p>主页链接后面添加了一个连字符。后面新加一行让Django生成一个链接，与learning_logs/urls.py中名为topics的URL模式匹配。</p><p>现在可以在浏览器看到效果了：</p><img src="/2021/01/13/python-bian-cheng-cong-ru-men-dao-shi-jian-bi-ji/12.png" class=""><h4 id="显示特定主题的页面"><a href="#显示特定主题的页面" class="headerlink" title="显示特定主题的页面"></a>显示特定主题的页面</h4><p>显示特定主题的URL模式与前面所有的URL模式有所不同，它将使用主题的id属性来指出请求的是哪个主题，例如用户查看主题Chess（id为1）的详细页面，URL将为<a href="http://localhost:8000/topics/1/%E3%80%82">http://localhost:8000/topics/1/。</a></p><p>urls.py：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> django<span class="token punctuation">.</span>urls <span class="token keyword">import</span> path<span class="token punctuation">,</span>re_path<span class="token keyword">from</span> <span class="token punctuation">.</span> <span class="token keyword">import</span> views                <span class="token comment" spellcheck="true">#从此文件所在的目录中导入wiews</span>app_name<span class="token operator">=</span><span class="token string">'learning_logs'</span>           <span class="token comment" spellcheck="true">#巨坑，书中没有，不写runserver时会报错</span><span class="token comment" spellcheck="true">#URL模式是一个对函数path的调用，第一个参数是正则表达式，第二个参数指定了调用的视图函数第三个参数指定名称</span><span class="token comment" spellcheck="true">#当需要提供到这个主页的链接时，都将使用这个名称而不是编写URL</span>urlpatterns <span class="token operator">=</span> <span class="token punctuation">[</span>                    <span class="token comment" spellcheck="true">#包含可在learning_logs中请求的网页</span>    path<span class="token punctuation">(</span><span class="token string">''</span><span class="token punctuation">,</span> views<span class="token punctuation">.</span>index<span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'index'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                             <span class="token comment" spellcheck="true"># 主页</span>    path<span class="token punctuation">(</span><span class="token string">'topics/'</span><span class="token punctuation">,</span> views<span class="token punctuation">.</span>topics<span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'topics'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                    <span class="token comment" spellcheck="true"># 显示所有的主题</span>    re_path<span class="token punctuation">(</span><span class="token string">'topics/(?P&lt;topic_id>\d+)/'</span><span class="token punctuation">,</span> views<span class="token punctuation">.</span>topic<span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'topic'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    <span class="token comment" spellcheck="true"># 特定主题的详细页面</span>    <span class="token comment" spellcheck="true">#使用正则表达式要用re_path否则控制台报警告</span>   <span class="token punctuation">]</span></code></pre><p>这里采用了正则表达式。这里捕获URL中的值?P和topic_id意思是将捕获到的值储存到topic_id中，\d+指与任何整数匹配，不管多少位。</p><p>views.py:</p><pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> django<span class="token punctuation">.</span>shortcuts <span class="token keyword">import</span> render<span class="token keyword">from</span> <span class="token punctuation">.</span>models <span class="token keyword">import</span> Topic                  <span class="token comment" spellcheck="true">#导入所需数据相关的模型</span><span class="token keyword">def</span> <span class="token function">index</span><span class="token punctuation">(</span>request<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">return</span> render<span class="token punctuation">(</span>request<span class="token punctuation">,</span><span class="token string">'learning_logs/index.html'</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">topics</span><span class="token punctuation">(</span>request<span class="token punctuation">)</span><span class="token punctuation">:</span>                       <span class="token comment" spellcheck="true">#形参是Django从服务器收到的request对象</span>    <span class="token comment" spellcheck="true">#显示所有主题</span>    topics <span class="token operator">=</span> Topic<span class="token punctuation">.</span>objects<span class="token punctuation">.</span>order_by<span class="token punctuation">(</span><span class="token string">'date_added'</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true">#查询数据库，请求提供Topic对象，按属性date_added进行排序</span>    <span class="token comment" spellcheck="true"># 定义一个要发送给模板的上下文字典，键是模板中访问数据的名称，值是我们发送给模板的数据</span>    context <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">'topics'</span><span class="token punctuation">:</span>topics<span class="token punctuation">}</span>    <span class="token keyword">return</span> render<span class="token punctuation">(</span>request<span class="token punctuation">,</span><span class="token string">'learning_logs/topics.html'</span><span class="token punctuation">,</span>context<span class="token punctuation">)</span><span class="token comment" spellcheck="true">#这里多传递一个数据</span><span class="token keyword">def</span> <span class="token function">topic</span><span class="token punctuation">(</span>request<span class="token punctuation">,</span>topic_id<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true">#显示单个主题及其所有条目</span>    topic <span class="token operator">=</span> Topic<span class="token punctuation">.</span>objects<span class="token punctuation">.</span>get<span class="token punctuation">(</span>id<span class="token operator">=</span>topic_id<span class="token punctuation">)</span>                 <span class="token comment" spellcheck="true">#获取指定的主题</span>    entries <span class="token operator">=</span> topic<span class="token punctuation">.</span>entry_set<span class="token punctuation">.</span>order_by<span class="token punctuation">(</span><span class="token string">'-date_added'</span><span class="token punctuation">)</span>      <span class="token comment" spellcheck="true">#获取与该主题相关联的条目，按date_added降序排序</span>    context <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">"topic"</span><span class="token punctuation">:</span>topic<span class="token punctuation">,</span><span class="token string">'entries'</span><span class="token punctuation">:</span>entries<span class="token punctuation">}</span>            <span class="token comment" spellcheck="true">#数据储存在字典中发送给模板topic.html</span>    <span class="token keyword">return</span> render<span class="token punctuation">(</span>request<span class="token punctuation">,</span><span class="token string">'learning_logs/topic.html'</span><span class="token punctuation">,</span>context<span class="token punctuation">)</span></code></pre><p>topic.html:</p><pre class=" language-html"><code class="language-html">{% extends "learning_logs/base.html" %}{% block content %}<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>p</span><span class="token punctuation">></span></span>Topic:{{ topic }}<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>p</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>ul</span><span class="token punctuation">></span></span>    {% for entry in entries %}        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>li</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>p</span><span class="token punctuation">></span></span>{{ entry.date_added|date:'M d, Y H:i }}<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>p</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>p</span><span class="token punctuation">></span></span>{{ entry.text|linebreaks }}<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>p</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>li</span><span class="token punctuation">></span></span>    {% empty %}        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>li</span><span class="token punctuation">></span></span>         There are no entries for this topic yet.        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>li</span><span class="token punctuation">></span></span>    {% endfor %}<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>ul</span><span class="token punctuation">></span></span>{% endblock content %}</code></pre><p>首先使用了包含在字典context里的topic作为主题。然后遍历entries条目，显示出属性date_added的值，竖线|表示模板过滤器，对模板变量的值修改的函数，过滤器date:’M d, Y H:i以这样的格式显示时间戳：January 1,2021 23:00。接下来的一行享受text的完整值，过滤器linebreaks将包含换行符的长条目转换为浏览器能够理解的格式，以免显示一个不间断的文本块。</p><p>将所有主题页面中的每个主题都设置为链接：</p><p>topics.html:</p><pre class=" language-html"><code class="language-html">{% extends "learning_logs/base.html" %}{% block content %}<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>p</span><span class="token punctuation">></span></span>Topics<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>p</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>ul</span><span class="token punctuation">></span></span>    {% for topic in topics %}    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>li</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>a</span> <span class="token attr-name">href</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>{% url <span class="token punctuation">'</span>learning_logs:topic<span class="token punctuation">'</span> topic.id %}<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>{{ topic }}<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>a</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>li</span><span class="token punctuation">></span></span>    {% empty %}    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>li</span><span class="token punctuation">></span></span>No topics have been added yet.<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>li</span><span class="token punctuation">></span></span>    {% endfor %}<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>ul</span><span class="token punctuation">></span></span>{% endblock content %}</code></pre><p>再次访问网页发现功能已经实现：</p><img src="/2021/01/13/python-bian-cheng-cong-ru-men-dao-shi-jian-bi-ji/13.png" class=""><hr><h2 id="用户账户"><a href="#用户账户" class="headerlink" title="用户账户"></a>用户账户</h2><p>Web应用程序的核心是让任何用户都能够注册账户并能够使用它。本章中，你将创建一些表单让用户能够添加主题和条目，以及编辑现有条目。你还将学习Django如何防范对基于表单的网页发起的常见攻击。然后，我们将实现一个用户身份验证系统，创建一个注册页面，供用户注册，并让有些页面只让已登录的用户访问。接下来，修改一些视图参数，使用户只能看到自己的数据。</p><h3 id="让用户能输入数据"><a href="#让用户能输入数据" class="headerlink" title="让用户能输入数据"></a>让用户能输入数据</h3><p>首先让用户能添加新主题，与前面的方法几乎一样，主要差别是需要导入包含表单的模块form.py。</p><p>用户输入并提交的信息都是表单，我们需要验证提供的信息是正确的数据类型且不是恶意信息，再对有效的信息进行处理。创建表单最简单的方式是使用ModelForm，它根据我们之前定义的模型中的信息自动创建表单。接下来在models.py的目录下创建forms.py文件：</p><p>form.py:</p><pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> django <span class="token keyword">import</span> forms<span class="token keyword">from</span> <span class="token punctuation">.</span>models <span class="token keyword">import</span> Topic<span class="token keyword">class</span> <span class="token class-name">TopicForm</span><span class="token punctuation">(</span>forms<span class="token punctuation">.</span>ModelForm<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">class</span> <span class="token class-name">Meta</span><span class="token punctuation">:</span>        model <span class="token operator">=</span> Topic               <span class="token comment" spellcheck="true">#根据模型Topic创建一个表单</span>        fields <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'text'</span><span class="token punctuation">]</span>           <span class="token comment" spellcheck="true">#该表单只包含字段text</span>        labels <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">'text'</span><span class="token punctuation">:</span><span class="token string">''</span><span class="token punctuation">}</span>        <span class="token comment" spellcheck="true">#不用为text生成标签</span></code></pre><p><strong>URL模式new_topic:</strong></p><p>当用户要添加新主题时，我们将切换到<a href="http://localhost:8000/new_topic/%E3%80%82">http://localhost:8000/new_topic/。</a></p><p>learning_logs/urls.py:</p><pre class=" language-python"><code class="language-python"><span class="token operator">-</span><span class="token operator">-</span>snip<span class="token operator">-</span><span class="token operator">-</span>urlpatterns <span class="token operator">=</span> <span class="token punctuation">[</span>                    <span class="token comment" spellcheck="true">#包含可在learning_logs中请求的网页</span>    <span class="token operator">-</span><span class="token operator">-</span>snip<span class="token operator">-</span><span class="token operator">-</span>    path<span class="token punctuation">(</span><span class="token string">'new_topic/'</span><span class="token punctuation">,</span> views<span class="token punctuation">.</span>new_topic<span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'new_topic'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>           <span class="token comment" spellcheck="true"># 同于添加新主题的网页</span>   <span class="token punctuation">]</span></code></pre><p>views.py:</p><pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> django<span class="token punctuation">.</span>shortcuts <span class="token keyword">import</span> render<span class="token keyword">from</span> <span class="token punctuation">.</span>models <span class="token keyword">import</span> Topic                  <span class="token comment" spellcheck="true">#导入所需数据相关的模型</span><span class="token keyword">from</span> django<span class="token punctuation">.</span>http <span class="token keyword">import</span> HttpResponseRedirect<span class="token keyword">from</span> django<span class="token punctuation">.</span>urls <span class="token keyword">import</span> reverse            <span class="token comment" spellcheck="true">#注意这里在django2.0的包名有所变化</span><span class="token keyword">from</span> <span class="token punctuation">.</span>forms <span class="token keyword">import</span> TopicForm<span class="token operator">-</span><span class="token operator">-</span>snip<span class="token operator">-</span><span class="token operator">-</span><span class="token keyword">def</span> <span class="token function">new_topic</span><span class="token punctuation">(</span>request<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">if</span> request<span class="token punctuation">.</span>method <span class="token operator">!=</span> <span class="token string">'POST'</span><span class="token punctuation">:</span>           <span class="token comment" spellcheck="true">#判断请求是GET还是POST,如未提交数据（点击进入页面链接），创建一个新表单</span>        form <span class="token operator">=</span> TopicForm<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">else</span><span class="token punctuation">:</span>                                  <span class="token comment" spellcheck="true">#POST请求，对提交的表单数据进行处理（点击了提交按钮）</span>        form <span class="token operator">=</span> TopicForm<span class="token punctuation">(</span>request<span class="token punctuation">.</span>POST<span class="token punctuation">)</span>     <span class="token comment" spellcheck="true">#使用用户输入的数据创建一个TopicForm实例，储存在form中</span>        <span class="token keyword">if</span> form<span class="token punctuation">.</span>is_valid<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                <span class="token comment" spellcheck="true">#检查填写了所有必不可少的字段（默认所有），且输入的数据与要求的类型一致</span>            form<span class="token punctuation">.</span>save<span class="token punctuation">(</span><span class="token punctuation">)</span>                    <span class="token comment" spellcheck="true">#表单中的数据写入数据库</span>            <span class="token keyword">return</span> HttpResponseRedirect<span class="token punctuation">(</span>reverse<span class="token punctuation">(</span><span class="token string">'learning_logs:topics'</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#获取topics的URL，重新定位到页面topics</span>    context <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">'form'</span><span class="token punctuation">:</span> form<span class="token punctuation">}</span>    <span class="token keyword">return</span> render<span class="token punctuation">(</span>request<span class="token punctuation">,</span><span class="token string">'learning_logs/new_topic.html'</span><span class="token punctuation">,</span>context<span class="token punctuation">)</span></code></pre><p>创建Web应用程序时，用到的两种主要请求类型是GET请求和POST请求。只是从服务器读取数据的页面使用GET请求，用户需要通过表单提交信息使用POST请求，处理所有表单时，我们都将使用POST方法。</p><p>新建new_topic.html:</p><pre class=" language-html"><code class="language-html">{% extends "learning_logs/base.html" %}{% block content %}<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>p</span><span class="token punctuation">></span></span>Add a new topic:<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>p</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>form</span> <span class="token attr-name">action</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>{% url <span class="token punctuation">'</span>learning_logs:new_topic<span class="token punctuation">'</span> %}<span class="token punctuation">"</span></span> <span class="token attr-name">method</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>post<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>    {% csrf_token %}    {{ form.as_p }}    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>button</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>submit<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>add topic<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>button</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>form</span><span class="token punctuation">></span></span>{% endblock content %}</code></pre><p>从form标签哪一行开始，定义了一个HTML表单，实参action告诉服务器提交的表单数据发送到视图函数new_topic()，以POST请求的方式。  csrf_token 标签防止攻击者利用表单获得对服务器未经授权的访问。显示表单，自动创建表单需要的全部字段，修饰符as_p以段落格式渲染所有表单元素。下边设置一个提交按钮。</p><p>topics.html添加一个到new_topic的链接:</p><pre class=" language-html"><code class="language-html">{% extends "learning_logs/base.html" %}{% block content %}<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>p</span><span class="token punctuation">></span></span>Topics<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>p</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>ul</span><span class="token punctuation">></span></span>   --snip--<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>ul</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>a</span> <span class="token attr-name">href</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>{% url <span class="token punctuation">'</span>learning_logs:new_topic<span class="token punctuation">'</span> %}<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>Add a new topic:<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>a</span><span class="token punctuation">></span></span>{% endblock content %}</code></pre><p>现在打开服务器，打开网页，可以看到效果了：</p><img src="/2021/01/13/python-bian-cheng-cong-ru-men-dao-shi-jian-bi-ji/14.png" class=""><img src="/2021/01/13/python-bian-cheng-cong-ru-men-dao-shi-jian-bi-ji/15.png" class=""><p><strong>添加新条目：</strong></p><p>forms.py:</p><pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> django <span class="token keyword">import</span> forms<span class="token keyword">from</span> <span class="token punctuation">.</span>models <span class="token keyword">import</span> Topic<span class="token punctuation">,</span>Entry<span class="token operator">-</span><span class="token operator">-</span>snip<span class="token operator">-</span><span class="token operator">-</span><span class="token keyword">class</span> <span class="token class-name">EntryForm</span><span class="token punctuation">(</span>forms<span class="token punctuation">.</span>ModelForm<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">class</span> <span class="token class-name">Meta</span><span class="token punctuation">:</span>        model <span class="token operator">=</span> Entry        field <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">'text'</span><span class="token punctuation">}</span>        labels <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">'text'</span><span class="token punctuation">:</span><span class="token string">''</span><span class="token punctuation">}</span>        <span class="token comment" spellcheck="true">#设置widgets可覆盖Django选择的默认小部件。forms.Textarea定制字段'text'的输入小部件，并设置文本宽度80列</span>        widgets <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">'text'</span><span class="token punctuation">:</span> forms<span class="token punctuation">.</span>Textarea<span class="token punctuation">(</span>attrs<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">'cols'</span><span class="token punctuation">:</span><span class="token number">80</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">}</span></code></pre><p>learning_logs/urls.py:</p><pre class=" language-python"><code class="language-python">urlpatterns <span class="token operator">=</span> <span class="token punctuation">[</span>                    <span class="token comment" spellcheck="true">#包含可在learning_logs中请求的网页</span>    <span class="token operator">-</span><span class="token operator">-</span>snip<span class="token operator">-</span><span class="token operator">-</span>    re_path<span class="token punctuation">(</span><span class="token string">'new_entry/(?P&lt;topic_id>\d+)/'</span><span class="token punctuation">,</span> views<span class="token punctuation">.</span>new_entry<span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'new_entry'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token comment" spellcheck="true"># 添加新条目的网页</span>   <span class="token punctuation">]</span></code></pre><p>views.py:</p><pre class=" language-python"><code class="language-python"><span class="token operator">-</span><span class="token operator">-</span>snip<span class="token operator">-</span><span class="token operator">-</span><span class="token keyword">from</span> <span class="token punctuation">.</span>forms <span class="token keyword">import</span> TopicForm<span class="token punctuation">,</span>EntryForm<span class="token operator">-</span><span class="token operator">-</span>snip<span class="token operator">-</span><span class="token operator">-</span><span class="token keyword">def</span> <span class="token function">new_entry</span><span class="token punctuation">(</span>request<span class="token punctuation">,</span>topic_id<span class="token punctuation">)</span><span class="token punctuation">:</span>    topic <span class="token operator">=</span> Topic<span class="token punctuation">.</span>objects<span class="token punctuation">.</span>get<span class="token punctuation">(</span>id<span class="token operator">=</span>topic_id<span class="token punctuation">)</span>    <span class="token keyword">if</span> request<span class="token punctuation">.</span>method <span class="token operator">!=</span> <span class="token string">'POST'</span><span class="token punctuation">:</span>        form <span class="token operator">=</span> EntryForm<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">else</span><span class="token punctuation">:</span>        form <span class="token operator">=</span> EntryForm<span class="token punctuation">(</span>data<span class="token operator">=</span>request<span class="token punctuation">.</span>POST<span class="token punctuation">)</span>          <span class="token comment" spellcheck="true">#填充数据</span>        <span class="token keyword">if</span> form<span class="token punctuation">.</span>is_valid<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            new_entry <span class="token operator">=</span> form<span class="token punctuation">.</span>save<span class="token punctuation">(</span>commit<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>      <span class="token comment" spellcheck="true">#保存到new_entry中，但不保存到数据库中</span>            new_entry<span class="token punctuation">.</span>topic <span class="token operator">=</span> topic                  <span class="token comment" spellcheck="true">#获取主题</span>            new_entry<span class="token punctuation">.</span>save<span class="token punctuation">(</span><span class="token punctuation">)</span>                         <span class="token comment" spellcheck="true">#保存到数据库，与主题关联</span>            <span class="token comment" spellcheck="true">#列表args包含在URL中的所有实参，在这里只有一个</span>            <span class="token keyword">return</span> HttpResponseRedirect<span class="token punctuation">(</span>reverse<span class="token punctuation">(</span><span class="token string">'learning_logs:topic'</span><span class="token punctuation">,</span>args<span class="token operator">=</span><span class="token punctuation">[</span>topic_id<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    context <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">'topic'</span><span class="token punctuation">:</span> topic<span class="token punctuation">,</span><span class="token string">'form'</span><span class="token punctuation">:</span> form<span class="token punctuation">}</span>    <span class="token keyword">return</span>  render<span class="token punctuation">(</span>request<span class="token punctuation">,</span><span class="token string">'learning_logs/new_entry.html'</span><span class="token punctuation">,</span>context<span class="token punctuation">)</span></code></pre><p>new_entry.html:</p><pre class=" language-html"><code class="language-html">{% extends "learning_logs/base.html" %}{% block content %}<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>p</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>a</span> <span class="token attr-name">href</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>{% url <span class="token punctuation">'</span>learning_logs:topic<span class="token punctuation">'</span> topic.id %}<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>{{ topic }}<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>a</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>p</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>p</span><span class="token punctuation">></span></span>Add a new entry:<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>p</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>form</span> <span class="token attr-name">action</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>{% url <span class="token punctuation">'</span>learning_logs:new_entry<span class="token punctuation">'</span> topic.id %}<span class="token punctuation">"</span></span> <span class="token attr-name">method</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>post<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>    {% csrf_token %}    {{ form.as_p}}    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>button</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>submit<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>add entry<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>button</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>form</span><span class="token punctuation">></span></span>{% endblock content %}</code></pre><p>页面的顶端是主题名，同时也是一个链接。表单的实参action包含topic_id值，让视图函数能将新条目关联到正确的主题。</p><p>更改topic.html，添加链接：</p><pre class=" language-html"><code class="language-html">{% extends "learning_logs/base.html" %}{% block content %}<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>p</span><span class="token punctuation">></span></span>Topic:{{ topic }}<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>p</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>p</span><span class="token punctuation">></span></span>Entries<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>p</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>p</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>a</span> <span class="token attr-name">href</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>{% url <span class="token punctuation">'</span>learning_logs:new_entry<span class="token punctuation">'</span> topic.id %}<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>add new entry<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>a</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>p</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>ul</span><span class="token punctuation">></span></span>--snip--<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>ul</span><span class="token punctuation">></span></span>{% endblock content %}</code></pre><p>这时网页就可以看到效果了：</p><img src="/2021/01/13/python-bian-cheng-cong-ru-men-dao-shi-jian-bi-ji/16.png" class=""><img src="/2021/01/13/python-bian-cheng-cong-ru-men-dao-shi-jian-bi-ji/17.png" class=""><h3 id="编辑条目"><a href="#编辑条目" class="headerlink" title="编辑条目"></a>编辑条目</h3><p>创建一个页面，让用户能编辑现有的条目。</p><p>urls.py:</p><pre class=" language-python"><code class="language-python"><span class="token operator">-</span><span class="token operator">-</span>snip<span class="token operator">-</span><span class="token operator">-</span>urlpatterns <span class="token operator">=</span> <span class="token punctuation">[</span>                    <span class="token comment" spellcheck="true">#包含可在learning_logs中请求的网页</span>    <span class="token operator">-</span><span class="token operator">-</span>snip<span class="token operator">-</span><span class="token operator">-</span>    re_path<span class="token punctuation">(</span><span class="token string">'edit_entry/(?P&lt;topic_id>\d+)/'</span><span class="token punctuation">,</span> views<span class="token punctuation">.</span>edit_entry<span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'edit_entry'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token comment" spellcheck="true"># 编辑条目页面</span>   <span class="token punctuation">]</span></code></pre><p>views.py:</p><pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> django<span class="token punctuation">.</span>shortcuts <span class="token keyword">import</span> render<span class="token keyword">from</span> <span class="token punctuation">.</span>models <span class="token keyword">import</span> Topic<span class="token punctuation">,</span>Entry             <span class="token comment" spellcheck="true">#导入所需数据相关的模型</span><span class="token keyword">from</span> django<span class="token punctuation">.</span>http <span class="token keyword">import</span> HttpResponseRedirect<span class="token keyword">from</span> django<span class="token punctuation">.</span>urls <span class="token keyword">import</span> reverse            <span class="token comment" spellcheck="true">#注意这里在django2.0的包名有所变化</span><span class="token keyword">from</span> <span class="token punctuation">.</span>forms <span class="token keyword">import</span> TopicForm<span class="token punctuation">,</span>EntryForm<span class="token operator">-</span><span class="token operator">-</span>snip<span class="token operator">-</span><span class="token operator">-</span><span class="token keyword">def</span> <span class="token function">edit_entry</span><span class="token punctuation">(</span>request<span class="token punctuation">,</span>entry_id<span class="token punctuation">)</span><span class="token punctuation">:</span>    entry <span class="token operator">=</span> Entry<span class="token punctuation">.</span>objects<span class="token punctuation">.</span>get<span class="token punctuation">(</span>id<span class="token operator">-</span>entry_id<span class="token punctuation">)</span>    topic <span class="token operator">=</span> entry<span class="token punctuation">.</span>topic    <span class="token keyword">if</span> request<span class="token punctuation">.</span>method <span class="token operator">!=</span> <span class="token string">'POST'</span><span class="token punctuation">:</span>        form <span class="token operator">=</span> EntryForm<span class="token punctuation">(</span>instance<span class="token operator">=</span>entry<span class="token punctuation">)</span>                    <span class="token comment" spellcheck="true">#根据现有条目创建表单</span>    <span class="token keyword">else</span><span class="token punctuation">:</span>        form <span class="token operator">=</span> EntryForm<span class="token punctuation">(</span>instance<span class="token operator">=</span>entry<span class="token punctuation">,</span>data<span class="token operator">=</span>request<span class="token punctuation">.</span>POST<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true">#根据现有条目创建表单，根据POST内容对其进行修改</span>        <span class="token keyword">if</span> form<span class="token punctuation">.</span>is_valid<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            form<span class="token punctuation">.</span>save<span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token keyword">return</span> HttpResponseRedirect<span class="token punctuation">(</span>reverse<span class="token punctuation">(</span><span class="token string">'learning_logs:topic'</span><span class="token punctuation">,</span>args<span class="token operator">=</span><span class="token punctuation">[</span>topic<span class="token punctuation">.</span>id<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    context <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">'entry'</span><span class="token punctuation">:</span>entry<span class="token punctuation">,</span><span class="token string">'topic'</span><span class="token punctuation">:</span>topic<span class="token punctuation">,</span><span class="token string">'form'</span><span class="token punctuation">:</span>form<span class="token punctuation">}</span>    <span class="token keyword">return</span> render<span class="token punctuation">(</span>request<span class="token punctuation">,</span><span class="token string">'learning_logs/edit_entry.html'</span><span class="token punctuation">,</span>context<span class="token punctuation">)</span></code></pre><p>新建edit_entry.html:</p><pre class=" language-html"><code class="language-html">{% extends "learning_logs/base.html" %}{% block content %}<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>p</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>a</span> <span class="token attr-name">href</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>{% url <span class="token punctuation">'</span>learning_logs:topic<span class="token punctuation">'</span> topic.id %}<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>{{ topic }}<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>a</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>p</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>p</span><span class="token punctuation">></span></span>Edit entry:<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>p</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>form</span> <span class="token attr-name">action</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>{% url <span class="token punctuation">'</span>learning_logs:edit_entry<span class="token punctuation">'</span> entry.id %}<span class="token punctuation">"</span></span> <span class="token attr-name">method</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>post<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>    {% csrf_token %}    {{ form.as_p}}    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>button</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>submit<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>save changes<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>button</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>form</span><span class="token punctuation">></span></span>{% endblock content %}</code></pre><p>修改topic.html:</p><pre class=" language-html"><code class="language-html">--snip--        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>li</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>p</span><span class="token punctuation">></span></span>{{ entry.date_added|date:'M d, Y H:i' }}<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>p</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>p</span><span class="token punctuation">></span></span>{{ entry.text|linebreaks }}<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>p</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>a</span> <span class="token attr-name">href</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>{% url <span class="token punctuation">'</span>learning_logs:edit_entry<span class="token punctuation">'</span> entry.id %}<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>edit entry<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>a</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>li</span><span class="token punctuation">></span></span>--snip--</code></pre><p>这时打开网页可以看到效果：</p><img src="/2021/01/13/python-bian-cheng-cong-ru-men-dao-shi-jian-bi-ji/18.png" class=""><img src="/2021/01/13/python-bian-cheng-cong-ru-men-dao-shi-jian-bi-ji/19.png" class=""><h3 id="创建用户账户"><a href="#创建用户账户" class="headerlink" title="创建用户账户"></a>创建用户账户</h3><p>下面将建立用户注册和身份验证系统，我们将创建一个新的应用程序，包含与处理用户账户相关的所有功能。</p><p>首先使用命令创建名为users的应用程序，结构与learning_logs相同：</p><pre class=" language-cmd"><code class="language-cmd">python manage.py startapp users</code></pre><p>settings.py</p><pre class=" language-python"><code class="language-python"><span class="token operator">-</span><span class="token operator">-</span>snip<span class="token operator">-</span><span class="token operator">-</span>INSTALLED_APPS <span class="token operator">=</span> <span class="token punctuation">[</span>                              <span class="token comment" spellcheck="true">#安装在项目中的应用程序</span>    <span class="token operator">-</span><span class="token operator">-</span>snip<span class="token operator">-</span><span class="token operator">-</span>    <span class="token comment" spellcheck="true">#我的应用程序</span>    <span class="token string">'learning_logs'</span><span class="token punctuation">,</span>    <span class="token string">'users'</span><span class="token punctuation">,</span><span class="token punctuation">]</span></code></pre><p>learning_log/urls.py:</p><pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> django<span class="token punctuation">.</span>contrib <span class="token keyword">import</span> admin<span class="token keyword">from</span> django<span class="token punctuation">.</span>urls <span class="token keyword">import</span> path<span class="token punctuation">,</span>includeurlpatterns <span class="token operator">=</span> <span class="token punctuation">[</span>    path<span class="token punctuation">(</span><span class="token string">'admin/'</span><span class="token punctuation">,</span> admin<span class="token punctuation">.</span>site<span class="token punctuation">.</span>urls<span class="token punctuation">)</span><span class="token punctuation">,</span>    path<span class="token punctuation">(</span><span class="token string">''</span><span class="token punctuation">,</span> include<span class="token punctuation">(</span><span class="token string">'learning_logs.urls'</span><span class="token punctuation">,</span> namespace<span class="token operator">=</span><span class="token string">'learning_logs'</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    path<span class="token punctuation">(</span><span class="token string">'users/'</span><span class="token punctuation">,</span> include<span class="token punctuation">(</span><span class="token string">'users.urls'</span><span class="token punctuation">,</span> namespace<span class="token operator">=</span><span class="token string">'users'</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">]</span></code></pre><h4 id="登录页面："><a href="#登录页面：" class="headerlink" title="登录页面："></a><strong>登录页面：</strong></h4><p>在users文件夹中新建urls.py:</p><pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> django<span class="token punctuation">.</span>urls <span class="token keyword">import</span> path<span class="token punctuation">,</span>re_path<span class="token keyword">from</span> <span class="token punctuation">.</span> <span class="token keyword">import</span> views<span class="token keyword">from</span> django<span class="token punctuation">.</span>contrib<span class="token punctuation">.</span>auth<span class="token punctuation">.</span>views <span class="token keyword">import</span> LoginView         <span class="token comment" spellcheck="true">#导入默认视图LoginView</span>app_name<span class="token operator">=</span><span class="token string">'users'</span><span class="token comment" spellcheck="true">#URL模式是一个对函数path的调用，第一个参数是正则表达式，第二个参数指定了调用的视图函数第三个参数指定名称</span><span class="token comment" spellcheck="true">#当需要提供到这个主页的链接时，都将使用这个名称而不是编写URL</span>urlpatterns <span class="token operator">=</span> <span class="token punctuation">[</span>    <span class="token comment" spellcheck="true">#鉴于没有编写视图函数而是使用默认的LoginView，后面的as_view告诉Django去哪里寻找模板</span>    path<span class="token punctuation">(</span><span class="token string">'login/'</span><span class="token punctuation">,</span> LoginView<span class="token punctuation">.</span>as_view<span class="token punctuation">(</span>template_name<span class="token operator">=</span><span class="token string">'users/login.html'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'login'</span><span class="token punctuation">)</span>   <span class="token punctuation">]</span></code></pre><p>接下来在users中创建一个templates目录，在templates中创建一个users目录，又在这个users目录中创建login.html:</p><pre class=" language-html"><code class="language-html">{% extends "learning_logs/base.html" %}{% block content %}  ｛% if form.errors %｝    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>p</span><span class="token punctuation">></span></span>>Your username and password didn't match.Please try again.<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>p</span><span class="token punctuation">></span></span>   {% endif %}   <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>form</span> <span class="token attr-name">method</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>post<span class="token punctuation">"</span></span> <span class="token attr-name">action</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span> {% <span class="token punctuation">'</span>users:login<span class="token punctuation">'</span> %}<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>       {% csrf_token %}       {{ form.as_p }}       <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>button</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>submit<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>log in<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>button</span><span class="token punctuation">></span></span>       <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>input</span> <span class="token attr-name">type</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>hidden<span class="token punctuation">"</span></span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>next<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>{% url <span class="token punctuation">'</span>learning_logs:index<span class="token punctuation">'</span> %}<span class="token punctuation">"</span></span> <span class="token punctuation">/></span></span>   <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>form</span><span class="token punctuation">></span></span>{% endblock content %}</code></pre><p>首先如果表单的errors属性被设置，就显示错误信息，表示用户名密码不匹配。要让登录视图处理表单，因此将action设置为登录页面的URL，登录视图发送一个表单给模板，模板中显示这个表单并添加一个提交按钮。最后包含了一个隐藏表单元素next，其中的参数value告诉Django在用户登录成功后定位到主页。</p><p>下面在base.html添加到登录页面的链接:</p><pre class=" language-html"><code class="language-html"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>p</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>a</span> <span class="token attr-name">href</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>{% url <span class="token punctuation">'</span>learning_logs:index<span class="token punctuation">'</span> %}<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>learning Log<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>a</span><span class="token punctuation">></span></span> -    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>a</span> <span class="token attr-name">href</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>{% url <span class="token punctuation">'</span>learning_logs:topics<span class="token punctuation">'</span> %}<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>Topics<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>a</span><span class="token punctuation">></span></span> -    {% if user.is_authenticated %}      Hello,{{ user.username }}.    {% else %}      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>a</span> <span class="token attr-name">href</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>{% url <span class="token punctuation">'</span>users:login<span class="token punctuation">'</span> %}<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>log in<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>a</span><span class="token punctuation">></span></span>    {% endif %}<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>p</span><span class="token punctuation">></span></span>{% block content %}{% endblock content %}</code></pre><p>在Django身份验证系统中，每个模板都可使用变量user，这个变量的is_authenticated属性在登录时为True，否则为False。</p><p>此时在admin页面退出管理员账户，就可以在网页中看到log in按钮，点击它：</p><img src="/2021/01/13/python-bian-cheng-cong-ru-men-dao-shi-jian-bi-ji/20.png" class=""><h4 id="注销："><a href="#注销：" class="headerlink" title="注销："></a><strong>注销：</strong></h4><p>让用户点击一个按钮就可注销并返回主页：</p><p>users/urls.py:</p><pre class=" language-python"><code class="language-python"><span class="token operator">-</span><span class="token operator">-</span>snip<span class="token operator">-</span><span class="token operator">-</span>urlpatterns <span class="token operator">=</span> <span class="token punctuation">[</span>    path<span class="token punctuation">(</span><span class="token string">'login/'</span><span class="token punctuation">,</span> LoginView<span class="token punctuation">.</span>as_view<span class="token punctuation">(</span>template_name<span class="token operator">=</span><span class="token string">'users/login.html'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'login'</span><span class="token punctuation">)</span>    path<span class="token punctuation">(</span><span class="token string">'logout/'</span><span class="token punctuation">,</span> views<span class="token punctuation">.</span>logout_view<span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'logout'</span><span class="token punctuation">)</span>   <span class="token punctuation">]</span></code></pre><p>users/views.py（注意新版的包名有所变化）:</p><pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> django<span class="token punctuation">.</span>urls <span class="token keyword">import</span> reverse<span class="token keyword">from</span> django<span class="token punctuation">.</span>contrib<span class="token punctuation">.</span>auth <span class="token keyword">import</span> logout<span class="token keyword">from</span> django<span class="token punctuation">.</span>http <span class="token keyword">import</span> HttpResponseRedirect<span class="token keyword">def</span> <span class="token function">logout_view</span><span class="token punctuation">(</span>request<span class="token punctuation">)</span><span class="token punctuation">:</span>    logout<span class="token punctuation">(</span>request<span class="token punctuation">)</span>    <span class="token keyword">return</span> HttpResponseRedirect<span class="token punctuation">(</span>reverse<span class="token punctuation">(</span><span class="token string">'learning_logs:index'</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><p>建立链接，修改base.html，给登录后的用户名旁边加上log out按钮：</p><pre class=" language-html"><code class="language-html"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>p</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>a</span> <span class="token attr-name">href</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>{% url <span class="token punctuation">'</span>learning_logs:index<span class="token punctuation">'</span> %}<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>learning Log<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>a</span><span class="token punctuation">></span></span> -    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>a</span> <span class="token attr-name">href</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>{% url <span class="token punctuation">'</span>learning_logs:topics<span class="token punctuation">'</span> %}<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>Topics<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>a</span><span class="token punctuation">></span></span> -    {% if user.is_authenticated %}      Hello,{{ user.username }}.      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>a</span> <span class="token attr-name">href</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>{% url <span class="token punctuation">'</span>users:logout<span class="token punctuation">'</span> %}<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>log out<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>a</span><span class="token punctuation">></span></span>    {% else %}      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>a</span> <span class="token attr-name">href</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>{% url <span class="token punctuation">'</span>users:login<span class="token punctuation">'</span> %}<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>log in<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>a</span><span class="token punctuation">></span></span>    {% endif %}<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>p</span><span class="token punctuation">></span></span>{% block content %}{% endblock content %}</code></pre><h4 id="注册页面："><a href="#注册页面：" class="headerlink" title="注册页面："></a>注册页面：</h4><p>users/urls.py:</p><pre class=" language-python"><code class="language-python"><span class="token operator">-</span><span class="token operator">-</span>snip<span class="token operator">-</span><span class="token operator">-</span>urlpatterns <span class="token operator">=</span> <span class="token punctuation">[</span>    path<span class="token punctuation">(</span><span class="token string">'login/'</span><span class="token punctuation">,</span> LoginView<span class="token punctuation">.</span>as_view<span class="token punctuation">(</span>template_name<span class="token operator">=</span><span class="token string">'users/login.html'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'login'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    path<span class="token punctuation">(</span><span class="token string">'logout/'</span><span class="token punctuation">,</span> views<span class="token punctuation">.</span>logout_view<span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'logout'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    path<span class="token punctuation">(</span><span class="token string">'register/'</span><span class="token punctuation">,</span> views<span class="token punctuation">.</span>register<span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'register'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>   <span class="token punctuation">]</span></code></pre><p>users/views.py:</p><pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> django<span class="token punctuation">.</span>urls <span class="token keyword">import</span> reverse<span class="token keyword">from</span> django<span class="token punctuation">.</span>contrib<span class="token punctuation">.</span>auth <span class="token keyword">import</span> logout<span class="token punctuation">,</span>login<span class="token punctuation">,</span>authenticate<span class="token keyword">from</span> django<span class="token punctuation">.</span>http <span class="token keyword">import</span> HttpResponseRedirect<span class="token keyword">from</span> django<span class="token punctuation">.</span>shortcuts <span class="token keyword">import</span> render<span class="token keyword">from</span> django<span class="token punctuation">.</span>contrib<span class="token punctuation">.</span>auth<span class="token punctuation">.</span>forms <span class="token keyword">import</span> UserCreationForm<span class="token keyword">def</span> <span class="token function">logout_view</span><span class="token punctuation">(</span>request<span class="token punctuation">)</span><span class="token punctuation">:</span>    logout<span class="token punctuation">(</span>request<span class="token punctuation">)</span>    <span class="token keyword">return</span> HttpResponseRedirect<span class="token punctuation">(</span>reverse<span class="token punctuation">(</span><span class="token string">'learning_logs:index'</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">register</span><span class="token punctuation">(</span>request<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">if</span> request<span class="token punctuation">.</span>method <span class="token operator">!=</span> <span class="token string">'POST'</span><span class="token punctuation">:</span>                 <span class="token comment" spellcheck="true">#点击注册，创建一个表单</span>        form <span class="token operator">=</span> UserCreationForm<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">else</span><span class="token punctuation">:</span>                                        <span class="token comment" spellcheck="true">#点击提交，录入信息，切换登录状态，转到主页</span>        form <span class="token operator">=</span> UserCreationForm<span class="token punctuation">(</span>data<span class="token operator">=</span>request<span class="token punctuation">.</span>POST<span class="token punctuation">)</span>        <span class="token keyword">if</span> form<span class="token punctuation">.</span>is_valid<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            new_user <span class="token operator">=</span> form<span class="token punctuation">.</span>save<span class="token punctuation">(</span><span class="token punctuation">)</span>            authenticated_user <span class="token operator">=</span> authenticate<span class="token punctuation">(</span>username<span class="token operator">=</span>new_user<span class="token punctuation">.</span>username<span class="token punctuation">,</span>password<span class="token operator">=</span>request<span class="token punctuation">.</span>POST<span class="token punctuation">[</span><span class="token string">'password1'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>            login<span class="token punctuation">(</span>request<span class="token punctuation">,</span>authenticated_user<span class="token punctuation">)</span>            <span class="token keyword">return</span> HttpResponseRedirect<span class="token punctuation">(</span>reverse<span class="token punctuation">(</span><span class="token string">'learning_logs:index'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    context <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">'form'</span><span class="token punctuation">:</span>form<span class="token punctuation">}</span>    <span class="token keyword">return</span> render<span class="token punctuation">(</span>request<span class="token punctuation">,</span><span class="token string">'users/register.html'</span><span class="token punctuation">,</span>context<span class="token punctuation">)</span></code></pre><p>保存用户信息后，我们调用authenticate()，将实参用户名和密码传递给它，返回一个通过了 身份验证的用户对象，然后调用login登录。用户注册时被要求输入密码两次，输入两次相同表单才可能有效。</p><p>在login.html目录下新建register.html:</p><pre class=" language-html"><code class="language-html">{% extends "learning_logs/base.html" %}{% block content %}<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>form</span> <span class="token attr-name">action</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>{% url <span class="token punctuation">'</span>users:register<span class="token punctuation">'</span> %}<span class="token punctuation">"</span></span> <span class="token attr-name">method</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>post<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>    {% csrf_token %}    {{ form.as_p}}    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>button</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>submit<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>register<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>button</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>input</span> <span class="token attr-name">type</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>hidden<span class="token punctuation">"</span></span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>next<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>{% url <span class="token punctuation">'</span>learning_logs:index<span class="token punctuation">'</span> %}<span class="token punctuation">"</span></span> <span class="token punctuation">/></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>form</span><span class="token punctuation">></span></span>{% endblock content %}</code></pre><p>在base.html添加用户在没有登录时显示到注册页面的链接：</p><pre class=" language-html"><code class="language-html">--snip--    {% else %}      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>a</span> <span class="token attr-name">href</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>{% url <span class="token punctuation">'</span>users:register<span class="token punctuation">'</span> %}<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>register<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>a</span><span class="token punctuation">></span></span> -      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>a</span> <span class="token attr-name">href</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>{% url <span class="token punctuation">'</span>users:login<span class="token punctuation">'</span> %}<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>log in<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>a</span><span class="token punctuation">></span></span>    {% endif %}--snip--</code></pre><p>现在可以看到效果了：</p><img src="/2021/01/13/python-bian-cheng-cong-ru-men-dao-shi-jian-bi-ji/21.png" class=""><h3 id="让用户拥有自己的数据"><a href="#让用户拥有自己的数据" class="headerlink" title="让用户拥有自己的数据"></a>让用户拥有自己的数据</h3><p>这里将创建一个系统，确定各项数据所属用户，再限制对页面的访问，让用户只能使用自己的数据。</p><p>Django提供了修饰器@login_required，可以实现某些页面只允许已登录的用户访问。</p><p>修改learning_logs/views.py:</p><pre class=" language-python"><code class="language-python"><span class="token operator">-</span><span class="token operator">-</span>snip<span class="token operator">-</span><span class="token operator">-</span><span class="token keyword">from</span> django<span class="token punctuation">.</span>contrib<span class="token punctuation">.</span>auth<span class="token punctuation">.</span>decorators <span class="token keyword">import</span> login_required<span class="token operator">-</span><span class="token operator">-</span>snip<span class="token operator">-</span><span class="token operator">-</span>@login_required<span class="token keyword">def</span> <span class="token function">topics</span><span class="token punctuation">(</span>request<span class="token punctuation">)</span><span class="token punctuation">:</span>                          <span class="token operator">-</span><span class="token operator">-</span>snip<span class="token operator">-</span><span class="token operator">-</span>@login_required<span class="token keyword">def</span> <span class="token function">topic</span><span class="token punctuation">(</span>request<span class="token punctuation">,</span>topic_id<span class="token punctuation">)</span><span class="token punctuation">:</span>@login_required<span class="token keyword">def</span> <span class="token function">new_topic</span><span class="token punctuation">(</span>request<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token operator">-</span><span class="token operator">-</span>snip<span class="token operator">-</span><span class="token operator">-</span>@login_required<span class="token keyword">def</span> <span class="token function">new_entry</span><span class="token punctuation">(</span>request<span class="token punctuation">,</span>topic_id<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token operator">-</span><span class="token operator">-</span>snip<span class="token operator">-</span><span class="token operator">-</span>@login_required<span class="token keyword">def</span> <span class="token function">edit_entry</span><span class="token punctuation">(</span>request<span class="token punctuation">,</span>entry_id<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token operator">-</span><span class="token operator">-</span>snip<span class="token operator">-</span><span class="token operator">-</span></code></pre><p>login_required()检查用户是否已登录，当用户已登录时，才运行topics的代码，否则重定向到登录页面。</p><p>修改settings.py，让Django知道到哪里查找登录页面，在末尾添加：</p><pre class=" language-python"><code class="language-python">LOGIN_URL <span class="token operator">=</span> <span class="token string">'/users/login/'</span></code></pre><p>现在未登录状态下点击topics或输入编辑添加主题条目的链接，就会跳转到登录页面。</p><p><strong>将数据关联到用户：</strong></p><p>我们只需将最高层的数据关联到用户，这样更底层的数据自动管理到用户。下面修改模型Topic，添加一个关联到用户的外键，完成后必须对数据库进行迁移。最后必须对一些视图进行修改，使其只显示与当前登录的用户相关联的数据。</p><p>models.py</p><pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> django<span class="token punctuation">.</span>db <span class="token keyword">import</span> models<span class="token keyword">from</span> django<span class="token punctuation">.</span>contrib<span class="token punctuation">.</span>auth<span class="token punctuation">.</span>models <span class="token keyword">import</span> User<span class="token keyword">class</span> <span class="token class-name">Topic</span><span class="token punctuation">(</span>models<span class="token punctuation">.</span>Model<span class="token punctuation">)</span><span class="token punctuation">:</span>              text <span class="token operator">=</span> models<span class="token punctuation">.</span>CharField<span class="token punctuation">(</span>max_length<span class="token operator">=</span><span class="token number">200</span><span class="token punctuation">)</span>     date_added <span class="token operator">=</span> models<span class="token punctuation">.</span>DateTimeField<span class="token punctuation">(</span>auto_now_add<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>      owner <span class="token operator">=</span> models<span class="token punctuation">.</span>ForeignKey<span class="token punctuation">(</span>User<span class="token punctuation">,</span>on_delete<span class="token operator">=</span>models<span class="token punctuation">.</span>CASCADE<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">__str__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>             <span class="token comment" spellcheck="true">#显示模型的简单表示</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>text<span class="token operator">-</span><span class="token operator">-</span>snip<span class="token operator">-</span><span class="token operator">-</span></code></pre><p>确定当前数据库有哪些用户，输入命令启动Django shell会话：</p><pre class=" language-cmd"><code class="language-cmd">$ python manage.py shellPython 3.9.1 (tags/v3.9.1:1e5d33e, Dec  7 2020, 17:08:21) [MSC v.1927 64 bit (AMD64)] on win32Type "help", "copyright", "credits" or "license" for more information.(InteractiveConsole)>>> from django.contrib.auth.models import User>>> User.objects.all()......................................>>> for user in User.objects.all():...     print(user.username,user.id)...tianjue 1testAccount 2>>></code></pre><p>迁移数据库：</p><pre class=" language-cmd"><code class="language-cmd">$ python manage.py makemigrations learning_logsYou are trying to add a non-nullable field 'owner' to topic without a default; we can't do that (the database needs something to populate existing rows).Please select a fix: 1) Provide a one-off default now (will be set on all existing rows with a null value for this column) 2) Quit, and let me add a default in models.pySelect an option: 1Please enter the default value now, as valid PythonThe datetime and django.utils.timezone modules are available, so you can do e.g. timezone.nowType 'exit' to exit this prompt>>> 1Migrations for 'learning_logs':  learning_logs\migrations\0003_topic_owner.py    - Add field owner to topic</code></pre><p>执行迁移：</p><pre class=" language-cmd"><code class="language-cmd">$ python manage.py migrate</code></pre><p>现在可以在shell中验证是否符合预期：</p><pre class=" language-cmd"><code class="language-cmd">>>> from learning_logs.models import Topic>>> for topic in Topic.objects.all():...     print(topic,topic.owner)...Chess tianjueRock Climbing tianjueLearning tianjue</code></pre><p>可以看到每个主题都属于用户tianjue了。</p><p><strong>只允许访问自己的主题：</strong></p><p>learning_logs/views.py:</p><pre class=" language-python"><code class="language-python"><span class="token operator">-</span><span class="token operator">-</span>snip<span class="token operator">-</span><span class="token operator">-</span><span class="token keyword">from</span> django<span class="token punctuation">.</span>http <span class="token keyword">import</span> HttpResponseRedirect<span class="token punctuation">,</span>Http404<span class="token operator">-</span><span class="token operator">-</span>snip<span class="token operator">-</span><span class="token operator">-</span>@login_required<span class="token keyword">def</span> <span class="token function">topics</span><span class="token punctuation">(</span>request<span class="token punctuation">)</span><span class="token punctuation">:</span>                         <span class="token comment" spellcheck="true"># 查询数据库，请求提供Topic对象，只让所有者访问，按属性date_added进行排序</span>    topics <span class="token operator">=</span> Topic<span class="token punctuation">.</span>objects<span class="token punctuation">.</span>filter<span class="token punctuation">(</span>owner<span class="token operator">=</span>request<span class="token punctuation">.</span>user<span class="token punctuation">)</span><span class="token punctuation">.</span>order_by<span class="token punctuation">(</span><span class="token string">'date_added'</span><span class="token punctuation">)</span>      context <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">'topics'</span><span class="token punctuation">:</span>topics<span class="token punctuation">}</span>    <span class="token keyword">return</span> render<span class="token punctuation">(</span>request<span class="token punctuation">,</span><span class="token string">'learning_logs/topics.html'</span><span class="token punctuation">,</span>context<span class="token punctuation">)</span>@login_required<span class="token keyword">def</span> <span class="token function">topic</span><span class="token punctuation">(</span>request<span class="token punctuation">,</span>topic_id<span class="token punctuation">)</span><span class="token punctuation">:</span>    topic <span class="token operator">=</span> Topic<span class="token punctuation">.</span>objects<span class="token punctuation">.</span>get<span class="token punctuation">(</span>id<span class="token operator">=</span>topic_id<span class="token punctuation">)</span>                    <span class="token keyword">if</span> topic<span class="token punctuation">.</span>owner <span class="token operator">!=</span> request<span class="token punctuation">.</span>user<span class="token punctuation">:</span>                               <span class="token comment" spellcheck="true">#如果主题不归用户所有，返回404响应</span>        <span class="token keyword">raise</span>  Http404    entries <span class="token operator">=</span> topic<span class="token punctuation">.</span>entry_set<span class="token punctuation">.</span>order_by<span class="token punctuation">(</span><span class="token string">'-date_added'</span><span class="token punctuation">)</span>         context <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">'topic'</span><span class="token punctuation">:</span>topic<span class="token punctuation">,</span><span class="token string">'entries'</span><span class="token punctuation">:</span>entries<span class="token punctuation">}</span>              <span class="token keyword">return</span> render<span class="token punctuation">(</span>request<span class="token punctuation">,</span><span class="token string">'learning_logs/topic.html'</span><span class="token punctuation">,</span>context<span class="token punctuation">)</span>@login_required<span class="token keyword">def</span> <span class="token function">new_topic</span><span class="token punctuation">(</span>request<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">if</span> request<span class="token punctuation">.</span>method <span class="token operator">!=</span> <span class="token string">'POST'</span><span class="token punctuation">:</span>                   form <span class="token operator">=</span> TopicForm<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">else</span><span class="token punctuation">:</span>                                          form <span class="token operator">=</span> TopicForm<span class="token punctuation">(</span>request<span class="token punctuation">.</span>POST<span class="token punctuation">)</span>             <span class="token keyword">if</span> form<span class="token punctuation">.</span>is_valid<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                           new_topic <span class="token operator">=</span> form<span class="token punctuation">.</span>save<span class="token punctuation">(</span>commit<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>            new_topic<span class="token punctuation">.</span>owner <span class="token operator">=</span> request<span class="token punctuation">.</span>user                         <span class="token comment" spellcheck="true">#把新建立的主题和用户关联上</span>            new_topic<span class="token punctuation">.</span>save<span class="token punctuation">(</span><span class="token punctuation">)</span>                                <span class="token keyword">return</span> HttpResponseRedirect<span class="token punctuation">(</span>reverse<span class="token punctuation">(</span><span class="token string">'learning_logs:topics'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    context <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">'form'</span><span class="token punctuation">:</span> form<span class="token punctuation">}</span>    <span class="token keyword">return</span> render<span class="token punctuation">(</span>request<span class="token punctuation">,</span><span class="token string">'learning_logs/new_topic.html'</span><span class="token punctuation">,</span>context<span class="token punctuation">)</span>@login_required<span class="token keyword">def</span> <span class="token function">new_entry</span><span class="token punctuation">(</span>request<span class="token punctuation">,</span>topic_id<span class="token punctuation">)</span><span class="token punctuation">:</span>    topic <span class="token operator">=</span> Topic<span class="token punctuation">.</span>objects<span class="token punctuation">.</span>get<span class="token punctuation">(</span>id<span class="token operator">=</span>topic_id<span class="token punctuation">)</span>    <span class="token keyword">if</span> topic<span class="token punctuation">.</span>owner <span class="token operator">!=</span> request<span class="token punctuation">.</span>user<span class="token punctuation">:</span>                              <span class="token comment" spellcheck="true">#如果主题不归用户所有，返回404响应</span>        <span class="token keyword">raise</span> Http404    <span class="token operator">-</span><span class="token operator">-</span>snip<span class="token operator">-</span><span class="token operator">-</span>@login_required<span class="token keyword">def</span> <span class="token function">edit_entry</span><span class="token punctuation">(</span>request<span class="token punctuation">,</span>entry_id<span class="token punctuation">)</span><span class="token punctuation">:</span>    entry <span class="token operator">=</span> Entry<span class="token punctuation">.</span>objects<span class="token punctuation">.</span>get<span class="token punctuation">(</span>id<span class="token operator">=</span>entry_id<span class="token punctuation">)</span>    topic <span class="token operator">=</span> entry<span class="token punctuation">.</span>topic    <span class="token keyword">if</span> topic<span class="token punctuation">.</span>owner <span class="token operator">!=</span> request<span class="token punctuation">.</span>user<span class="token punctuation">:</span>                               <span class="token comment" spellcheck="true">#如果主题不归用户所有，返回404响应</span>        <span class="token keyword">raise</span> Http404    <span class="token operator">-</span><span class="token operator">-</span>snip<span class="token operator">-</span><span class="token operator">-</span></code></pre><img src="/2021/01/13/python-bian-cheng-cong-ru-men-dao-shi-jian-bi-ji/22.png" class=""><img src="/2021/01/13/python-bian-cheng-cong-ru-men-dao-shi-jian-bi-ji/23.png" class=""><p>现在这个项目运行任何用户注册，每个用户可以随意添加主题和条目，并且只能访问自己的数据。</p><hr><h2 id="设置应用程序的样式并对其进行部署"><a href="#设置应用程序的样式并对其进行部署" class="headerlink" title="设置应用程序的样式并对其进行部署"></a>设置应用程序的样式并对其进行部署</h2><h3 id="设置项目的样式"><a href="#设置项目的样式" class="headerlink" title="设置项目的样式"></a>设置项目的样式</h3><p>当前，学习笔记的功能基本完成，但未设置样式。我们将使用Bootstrap库，这是一种工具，用于为Web应用程序设置样式，最后把这个项目部署到服务器端。</p><p>执行命令，安装django-bootstrap3:</p><pre class=" language-cmd"><code class="language-cmd">$ pip3 install django-bootstrap3</code></pre><p>在settings.py中添加代码：</p><pre class=" language-python"><code class="language-python"><span class="token operator">-</span><span class="token operator">-</span>snip<span class="token operator">-</span><span class="token operator">-</span>INSTALLED_APPS <span class="token operator">=</span> <span class="token punctuation">[</span>                                  <span class="token operator">-</span><span class="token operator">-</span>snip<span class="token operator">-</span><span class="token operator">-</span>    <span class="token comment" spellcheck="true">#第三方应用程序</span>    <span class="token string">'bootstrap3'</span><span class="token punctuation">,</span>    <span class="token comment" spellcheck="true">#我的应用程序</span>    <span class="token string">'learning_logs'</span><span class="token punctuation">,</span>    <span class="token string">'users'</span><span class="token punctuation">,</span><span class="token punctuation">]</span><span class="token operator">-</span><span class="token operator">-</span>snip<span class="token operator">-</span><span class="token operator">-</span>BOOTSTRAP3 <span class="token operator">=</span><span class="token punctuation">{</span>    <span class="token string">'include_jquery'</span><span class="token punctuation">:</span> <span class="token boolean">True</span><span class="token punctuation">,</span><span class="token punctuation">}</span></code></pre><p>需要让django-bootstrap3包含jQuery，这是一个JavaScript库，能够让你使用Bootstrap模板的一些交互性元素，这样无需手工下载jQuery。</p><p>Bootstarp是一个大型样式设置工具集，提供了大量的模板，具体可访问<a href="https://getbootstrap.com/%E3%80%82">https://getbootstrap.com/。</a></p><p>首先需要修改base.html,在这个文件定义HTML头部，添加一些在模板中使用Bootstrap所需的信息，删除base.html全部代码，改为：</p><img src="/2021/01/13/python-bian-cheng-cong-ru-men-dao-shi-jian-bi-ji/28.png" class=""><img src="/2021/01/13/python-bian-cheng-cong-ru-men-dao-shi-jian-bi-ji/29.png" class=""><p>首先，HTML分为两个主要部分：头部(head)和主体(body)，头部不包含任何内容，只是将正确显示页面所需的信息告诉浏览器。</p><p>主体包含用户在页面上看到的内容&lt;nav&gt;元素表示页面的导航链接部分，这个元素内的所有内容，都根据(selector)navbar、navbar-default、navbar-static-top定义的Bootstrap样式规则来设置样式，选择器决定了特定的样式规则应用于页面的哪些元素。</p><p>在class=”navbar-header”的地方，定义了一个按钮&lt;button&gt;，将浏览器窗口太窄，无法水平显示的整个导航栏显示出来，如果用户点击这个按钮，会出现一个下拉列表，包含所有的导航元素，在用户缩小浏览器窗口或在屏幕较小的移动设备上显示网页，collapse会使导航栏折叠起来。 在class=”navbar-brand”的地方表示在导航栏的左边显示项目名，设置为主页链接。</p><p>div id=”navbar” class=”navbar-collapse collapse”定义了一组让用户能够在网站中导航的链接，导航栏是一个以ul 开头的列表，其中的每个链接都是列表项 li，要添加更多的链接，可插入下述结构的行：</p><pre class=" language-html"><code class="language-html"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>li</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>a</span> <span class="token attr-name">href</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>{% url <span class="token punctuation">'</span>learning_logs:title<span class="token punctuation">'</span> %}<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>Title<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>a</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>li</span><span class="token punctuation">></span></span></code></pre><p>后面的部分是一个容器，包含一个名为header的块和content块，header块决定页面包含哪些消息以及用户可在页面上执行哪些操作，其属性page-header将一系列的样式应用于这个块。</p><p>现在打开浏览器可以看到网页发生了很大改变：</p><img src="/2021/01/13/python-bian-cheng-cong-ru-men-dao-shi-jian-bi-ji/24.png" class=""><p><strong>设置登录页面的样式：</strong></p><p>login.html:</p><pre class=" language-html"><code class="language-html">{% extends "learning_logs/base.html" %}{% load bootstrap3 %}{% block header %}  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>h2</span><span class="token punctuation">></span></span>Log in to your account.<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>h2</span><span class="token punctuation">></span></span>{% endblock header %}{% block content %}   <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>form</span> <span class="token attr-name">method</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>post<span class="token punctuation">"</span></span> <span class="token attr-name">action</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>{% url <span class="token punctuation">'</span>users:login<span class="token punctuation">'</span> %}<span class="token punctuation">"</span></span> <span class="token attr-name">class</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>form<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>       {% csrf_token %}       {% bootstrap_form form %}       {% buttons %}         <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>button</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>submit<span class="token punctuation">"</span></span> <span class="token attr-name">class</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>btn btn-primary<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>log in<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>button</span><span class="token punctuation">></span></span>       {% endbuttons %}       <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>input</span> <span class="token attr-name">type</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>hidden<span class="token punctuation">"</span></span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>next<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>{% url <span class="token punctuation">'</span>learning_logs:index<span class="token punctuation">'</span> %}<span class="token punctuation">"</span></span> <span class="token punctuation">/></span></span>   <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>form</span><span class="token punctuation">></span></span>{% endblock content %}</code></pre><p>首先是加载bootstrap3模板，然后定义header块，原来的if form.error代码块删除了，因为bootstrap3会自动管理表单错误。</p><p>后面用bootstrap_form form显示表单，替换了原来的form.as_p。后面的按钮用了bootstrap3模板标签。</p><p>现在 访问login页面，样式已经改变：</p><img src="/2021/01/13/python-bian-cheng-cong-ru-men-dao-shi-jian-bi-ji/25.png" class=""><p><strong>设置new_topic页面的样式：</strong></p><p>修改new_topic.html:</p><pre class=" language-html"><code class="language-html">{% extends "learning_logs/base.html" %}{% load bootstrap3 %}{% block header %}  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>h2</span><span class="token punctuation">></span></span>Add a new topic:<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>h2</span><span class="token punctuation">></span></span>{% endblock header %}{% block content %}<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>form</span> <span class="token attr-name">action</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>{% url <span class="token punctuation">'</span>learning_logs:new_topic<span class="token punctuation">'</span> %}<span class="token punctuation">"</span></span> <span class="token attr-name">method</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>post<span class="token punctuation">"</span></span> <span class="token attr-name">class</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>form<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>    {% csrf_token %}    {% bootstrap_form form %}    {% buttons %}    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>button</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>submit<span class="token punctuation">"</span></span> <span class="token attr-name">class</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>btn btn-primary<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>add topic<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>button</span><span class="token punctuation">></span></span>    {% endbuttons %}<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>form</span><span class="token punctuation">></span></span>{% endblock content %}</code></pre><p>可以看到效果：</p><img src="/2021/01/13/python-bian-cheng-cong-ru-men-dao-shi-jian-bi-ji/26.png" class=""><p><strong>设置topics页面的样式：</strong></p><p>topics.html:</p><pre class=" language-html"><code class="language-html">{% extends "learning_logs/base.html" %}{% block header %}<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>h1</span><span class="token punctuation">></span></span>Add a new topic:<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>h1</span><span class="token punctuation">></span></span>{% endblock header %}{% block content %}<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>ul</span><span class="token punctuation">></span></span>    {% for topic in topics %}    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>li</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>h3</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>a</span> <span class="token attr-name">href</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>{% url <span class="token punctuation">'</span>learning_logs:topic<span class="token punctuation">'</span> topic.id %}<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>{{ topic }}<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>a</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>h3</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>li</span><span class="token punctuation">></span></span>    {% empty %}    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>li</span><span class="token punctuation">></span></span>No topics have been added yet.<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>li</span><span class="token punctuation">></span></span>    {% endfor %}<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>ul</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>h3</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>a</span> <span class="token attr-name">href</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>{% url <span class="token punctuation">'</span>learning_logs:new_topic<span class="token punctuation">'</span> %}<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>Add a new topic:<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>a</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>h3</span><span class="token punctuation">></span></span>{% endblock content %}</code></pre><p>这里没有使用bootstrap3自定义标签，只是加了header块，改了字体大小。</p><p><strong>设置topic页面中的条目样式：</strong></p><p>topic.html:</p><pre class=" language-html"><code class="language-html">{% extends "learning_logs/base.html" %}{% block header %}<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>h2</span><span class="token punctuation">></span></span>{{ topic }}<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>h2</span><span class="token punctuation">></span></span>{% endblock header %}{% block content %}<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>p</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>a</span> <span class="token attr-name">href</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>{% url <span class="token punctuation">'</span>learning_logs:new_entry<span class="token punctuation">'</span> topic.id %}<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>add new entry<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>a</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>p</span><span class="token punctuation">></span></span>{% for entry in entries %}  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>div</span> <span class="token attr-name">class</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>panel panel-default<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>div</span> <span class="token attr-name">class</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>panel-heading<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>          <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>h3</span><span class="token punctuation">></span></span>              {{ entry.date_added|date:'M d, Y H:i' }}              <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>small</span><span class="token punctuation">></span></span>                  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>a</span> <span class="token attr-name">href</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>{% url <span class="token punctuation">'</span>learning_logs:edit_entry<span class="token punctuation">'</span> entry.id %}<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>edit entry<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>a</span><span class="token punctuation">></span></span>              <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>small</span><span class="token punctuation">></span></span>          <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>h3</span><span class="token punctuation">></span></span>      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>div</span><span class="token punctuation">></span></span>      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>div</span> <span class="token attr-name">class</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>panel-body<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>          {{ entry.text|linebreaks }}      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>div</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>div</span><span class="token punctuation">></span></span><span class="token comment" spellcheck="true">&lt;!-- panel --></span>{% empty %}    There are no entries for this topic yet.{% endfor %}{% endblock content %}</code></pre><p>删除了以前使用的无序列表结构，创建了面板式div元素，而不是将每一个条目作为一个列表项，其中有两个嵌套div：面板标题(panel-heading)div和面板主体(panel-body)div。面板标题div包含条目的创建日期以及用于编辑条目的链接，还使用了标签small使其比时间戳小一些。面板主体包含实际文本。</p><p>效果如下：</p><img src="/2021/01/13/python-bian-cheng-cong-ru-men-dao-shi-jian-bi-ji/27.png" class=""><p>同样，给其他页面设置：</p><p>new_entry.html:</p><pre class=" language-html"><code class="language-html">{% extends "learning_logs/base.html" %}{% load bootstrap3 %}{% block header %}<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>h2</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>a</span> <span class="token attr-name">href</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>{% url <span class="token punctuation">'</span>learning_logs:topic<span class="token punctuation">'</span> topic.id %}<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>{{ topic }}<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>a</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>h2</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>h3</span><span class="token punctuation">></span></span>Add a new entry:<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>h3</span><span class="token punctuation">></span></span>{% endblock header %}{% block content %}<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>form</span> <span class="token attr-name">action</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>{% url <span class="token punctuation">'</span>learning_logs:new_entry<span class="token punctuation">'</span> topic.id %}<span class="token punctuation">"</span></span> <span class="token attr-name">method</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>post<span class="token punctuation">"</span></span> <span class="token attr-name">class</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>form<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>    {% csrf_token %}    {% bootstrap_form form %}    {% buttons %}    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>button</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>submit<span class="token punctuation">"</span></span> <span class="token attr-name">class</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>btn btn-primary<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>add entry<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>button</span><span class="token punctuation">></span></span>    {% endbuttons %}<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>form</span><span class="token punctuation">></span></span>{% endblock content %}</code></pre><p>edit_entry.html:</p><pre class=" language-html"><code class="language-html">{% extends "learning_logs/base.html" %}{% load bootstrap3 %}{% block header %}<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>h2</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>a</span> <span class="token attr-name">href</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>{% url <span class="token punctuation">'</span>learning_logs:topic<span class="token punctuation">'</span> topic.id %}<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>{{ topic }}<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>a</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>h2</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>h3</span><span class="token punctuation">></span></span>Edit entry:<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>h3</span><span class="token punctuation">></span></span>{% endblock header %}{% block content %}<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>form</span> <span class="token attr-name">action</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>{% url <span class="token punctuation">'</span>learning_logs:edit_entry<span class="token punctuation">'</span> entry.id %}<span class="token punctuation">"</span></span> <span class="token attr-name">method</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>post<span class="token punctuation">"</span></span> <span class="token attr-name">class</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>form<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>    {% csrf_token %}    {% bootstrap_form form %}    {% buttons %}    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>button</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>submit<span class="token punctuation">"</span></span> <span class="token attr-name">class</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>btn btn-primary<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>save changes<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>button</span><span class="token punctuation">></span></span>    {% endbuttons %}<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>form</span><span class="token punctuation">></span></span>{% endblock content %}</code></pre><h3 id="部署学习笔记"><a href="#部署学习笔记" class="headerlink" title="部署学习笔记"></a>部署学习笔记</h3><p>由于在墙内是注册不了书本上要求的网站的，没办法还原书本的操作。我们需要按自己的方法部署。这部分需要话费的精力较多，还需要购买云服务器，需要一定的时间成本和金钱成本，具体可参考视频<a href="https://www.bilibili.com/video/BV18t411Y7of?from=search&amp;seid=15366684656551352770">python3 django项目部署方案</a>和<a href="https://www.bilibili.com/video/BV1rx411272x?from=search&amp;seid=15366684656551352770">Nginx + uWsgi 部署 Django + Mezzanine 生产服务器</a>。等我以后有需求时会写一篇新博文来完善此处内容。</p><hr><h2 id="最后的话"><a href="#最后的话" class="headerlink" title="最后的话"></a>最后的话</h2><p>至此，pyhon的基本知识学习完毕了，我们掌握了python的基本语法，能够自己下载和处理一些数据了，还能用Django搭建自己的网站，现在已经具备了开发各种项目所需的python基本技能。在学习的过程中，肯定会遇到自己不能解决的问题，这时候，查阅资料的能力尤为关键，其中给我最大帮助的是CSDN，遇到的大多数问题都能在其中找到答案，最后郑重提醒：每学完一项技术时，一定要写博客，写博客，写博客，很重要！这对知识的巩固有至关重要的作用，博客的搭建可以参考我的另一篇博文《个人建立hexo博客Matery主题的过程心得》。</p><p>祝贺你在学习Python的道路上走出了坚实的一步，愿你在以后的学习中好运相伴！</p>]]></content>
      
      
      <categories>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pycharm配置和使用教程</title>
      <link href="2021/01/12/pycharm-pei-zhi-he-shi-yong-jiao-cheng/"/>
      <url>2021/01/12/pycharm-pei-zhi-he-shi-yong-jiao-cheng/</url>
      
        <content type="html"><![CDATA[<h2 id="pycharm的配置"><a href="#pycharm的配置" class="headerlink" title="pycharm的配置"></a>pycharm的配置</h2><p>首先在安装pycharm的窗口：</p><img src="/2021/01/12/pycharm-pei-zhi-he-shi-yong-jiao-cheng/1.png" class=""><p>四个√可以全部打上，第一个是在桌面创建64位启动器的快捷方式，第二个是给启动器添加PATH地址，第三个是在鼠标右键的菜单添加“以工程的方式打开文件夹的选项”，第四个是文件添加.py后缀。</p><p>在file→setting可以对pycharm进行设置：</p><img src="/2021/01/12/pycharm-pei-zhi-he-shi-yong-jiao-cheng/4.png" class=""><p>Appearance中，Theme项可以改主题，黑色或白色。</p><p>Editor→General→Font可以调字体大小</p><p>如果想在代码中加上个人信息，可以这样设置：</p><img src="/2021/01/12/pycharm-pei-zhi-he-shi-yong-jiao-cheng/5.png" class=""><p><strong>导入第三方库</strong>：</p><img src="/2021/01/12/pycharm-pei-zhi-he-shi-yong-jiao-cheng/7.png" class=""><p>project→project interpreter</p><hr><h2 id="pycharm的使用"><a href="#pycharm的使用" class="headerlink" title="pycharm的使用"></a>pycharm的使用</h2><p>pycharm最下方三个按钮</p><img src="/2021/01/12/pycharm-pei-zhi-he-shi-yong-jiao-cheng/2.png" class=""><p>Terminal是终端，作用和cmd一样，可以直接输入py文件名***.py直接看运行结果。Run用来呈现运行结果。Python Console是python控制台，可以输入程序进行测试。</p><p>右上角是运行历史，有你最近运行的文件，可以直接进行运行调试操作：</p><img src="/2021/01/12/pycharm-pei-zhi-he-shi-yong-jiao-cheng/3.png" class=""><p>右键点击文件夹可直接在文件夹下创建各种文件：</p><img src="/2021/01/12/pycharm-pei-zhi-he-shi-yong-jiao-cheng/6.png" class=""><hr><p>pycharm的快捷键</p><p>为了提高编写代码的速度，以及方面程度，需要知道一些常用的快捷键。</p><p>最常用的是：</p><ol><li><p>ctrl+c  复制</p></li><li><p>ctrl+d  快速复制上行的内容至下一行</p></li><li><p>Ctrl+shift+n   通过文件名快速查找工程内的文件</p></li><li><p>ctrl +a    全选</p></li><li><p>Ctrl+alt+l  调整代码格式</p></li><li><p>Alt+enter  导入模块</p></li><li><p>Ctrl+z  回退</p></li><li><p>ctrl+x  剪贴</p></li><li><p>ctrl+/   注释，去注释</p></li><li><p>shift +Tab  往移动</p></li><li><p>shift +enter  自动回车，跳入下一行</p></li><li><p>ctrl +enter  自动回车，跳入上一行</p></li></ol><p>更多的快捷键：<a href="https://segmentfault.com/a/1190000005776418">https://segmentfault.com/a/1190000005776418</a></p><hr><p>pycharm的调试</p><p>设置好断点，点击debug：</p><img src="/2021/01/12/pycharm-pei-zhi-he-shi-yong-jiao-cheng/8.png" class=""><p>每一行都会出现运行结果的数据，按下F8可以运行下一行，按下F9运行至下一个断点处。</p><img src="/2021/01/12/pycharm-pei-zhi-he-shi-yong-jiao-cheng/9.png" class=""><p>所有的数据都可以在下方的栏目中找到，随着运行过程的进行，数据也会随之改变。</p>]]></content>
      
      
      <categories>
          
          <category> Pycharm </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Pycharm配置和使用 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pycharm安装及破解方法</title>
      <link href="2021/01/12/pycharm-an-zhuang-ji-po-jie-fang-fa/"/>
      <url>2021/01/12/pycharm-an-zhuang-ji-po-jie-fang-fa/</url>
      
        <content type="html"><![CDATA[<ol><li><p>首先下载好pycharm专业版2018.2.4安装包，文件名为pycharm-professional-2018.2.4.exe，并进行安装。</p></li><li><p>将0.0.0.0 account.jetbrains.com添加到hosts文件最后，注意hosts文件无后缀，如果遇到无法修改或权限问题，可以采用覆盖的方法去替换hosts文件。修改后请检查hosts文件是否修改，激活码无法激活的原因99.99%是因为hosts没有修改正确。Windows系统hosts文件路径：c:\windows\system32\drivers\etc</p></li><li><p>下载破解文件并将 JetbrainsCrack-3.1-release-enc.jar 放置到 pycharm安装目录的\bin目录下（位置可随意，只要配置文件填写相对应的路径）。</p></li><li><p>在 Pycharm安装目录的\bin目录下找到 <code>pycharm.exe.vmoptions</code> 和 <code>pycharm64.exe.vmoptions</code> (如果你是idea激活则是：idea.exe.vmoptions和idea64.exe.vmoptions)，以文本格式打开并同时在两个文件最后追加 -javaagent:D:\JetBrains\PyCharm 2018.2.1\bin\JetbrainsIdesCrack-3.4-release-enc.jar，注意路径修改成你的pycharm安装路径，文件名称是你破解包名，然后保存。</p></li><li><p>打开pycharm64，点击activate code，输入以下激活码</p><p>ThisCrackLicenseId-{<br>“licenseId”:”11011”,<br>“licenseeName”:”微信公众号”,<br>“assigneeName”:”随便输入”,<br>“assigneeEmail”:”邮箱，随便输入”,<br>“licenseRestriction”:””,<br>“checkConcurrentUse”:false,<br>“products”:[<br>{“code”:”II”,”paidUpTo”:”2099-12-31”},<br>{“code”:”DM”,”paidUpTo”:”2099-12-31”},<br>{“code”:”AC”,”paidUpTo”:”2099-12-31”},<br>{“code”:”RS0”,”paidUpTo”:”2099-12-31”},<br>{“code”:”WS”,”paidUpTo”:”2099-12-31”},<br>{“code”:”DPN”,”paidUpTo”:”2099-12-31”},<br>{“code”:”RC”,”paidUpTo”:”2099-12-31”},<br>{“code”:”PS”,”paidUpTo”:”2099-12-31”},<br>{“code”:”DC”,”paidUpTo”:”2099-12-31”},<br>{“code”:”RM”,”paidUpTo”:”2099-12-31”},<br>{“code”:”CL”,”paidUpTo”:”2099-12-31”},<br>{“code”:”PC”,”paidUpTo”:”2099-12-31”}<br>],<br>“hash”:”2911276/0”,<br>“gracePeriodDays”:7,<br>“autoProlongated”:false}</p></li></ol><p>点击OK,激活完成。</p>]]></content>
      
      
      <categories>
          
          <category> Pycharm </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Pycharm安装破解 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>怎么样玩转信息研究方法指南学习笔记</title>
      <link href="2021/01/11/zen-me-yang-wan-zhuan-xin-xi-yan-jiu-fang-fa-zhi-nan-xue-xi-bi-ji/"/>
      <url>2021/01/11/zen-me-yang-wan-zhuan-xin-xi-yan-jiu-fang-fa-zhi-nan-xue-xi-bi-ji/</url>
      
        <content type="html"><![CDATA[<p>本文是基于《怎样玩转信息研究方法指南》所写的个人的阅读总结，该书采用漫画方式进行叙述，十分直观易懂，我在阅读过程中整理笔记，在此基础上进行压缩总结，整理成本文。</p><h3 id="定题"><a href="#定题" class="headerlink" title="定题"></a>定题</h3><p><strong>定一个论题</strong>，开始研究，但题目不能过大（如：美国内战），这不是一个人能完成的工作，可以延伸成“美国内战时期，谁的武器更好”，但这依旧不够具体。谁是指什么？更好是指什么方面？必须更加深入地挖掘才能明确问题。然后再延伸为“武器供给怎样影响了美国内战的结果？”，还是有点宽泛。改为“北方联邦的武器制造和供应系统是否助力于北方联盟在美国内战中打败南部同盟”，这是个好论题。由于是研究小论文，应当把提问改为陈述：“美国联邦的武器制造和分配有助于北方联邦在美国内战中打败南部同盟”。</p><hr><h3 id="找文献"><a href="#找文献" class="headerlink" title="找文献"></a>找文献</h3><p>这就是“论题陈述”，接下来是<strong>收集论据</strong>，可能会发现有一些论据表明你的观点是错误的，请不要无视，可以调整和改进自己的论题。<strong>首先不要用百度，谷歌，维基百科</strong>，把内容拷贝作为你的观点。原因：1. 以用户为主导的开放网站上的信息，有些时候不太靠谱。2. 你或许一直都错误地将谷歌，百度百科用于学术研究行为，它们应该是起点，而不是全部。对搜索背景信息来说，百度是个好地方，但问题在于其中的巨量信息很多没用或完全错误。<strong>实体书和电子书</strong>是不错的信息来源，在搜索背景信息的时候，会看到<strong>参考文献</strong>，这个非常实用。还有就是<strong>图书馆的资料库</strong>，里面有编目系统，包含书架上的实体书目，资料，还有相关的网络资源，包括电子书，期刊论文以及图书馆没有的实体版本的资料。另一个就是<strong>学术期刊论文</strong>，与书籍相比，期刊论文可以聚焦于某一论题下一个相当有针对性的方面，让你的问题豁然开朗。图书馆可能有期刊的影印本。</p><p>为了对抗网络上不相关，不准确，动机险恶的信息，你们应该牢记一些东西：</p><ol><li>谁创造了它？</li><li>它紧跟时代吗？能帮你解答你的研究问题吗？还是离题了？</li><li>支撑作者的结论是什么？</li><li>作者写作它的目的是什么？</li><li>它是写给谁看的？</li><li>它是经过专业认证的吗？</li></ol><p>你是在前人的成果上做进一步的研究调查，引文能表明你知道哪些相关工作已经完成，而你的研究是以之为基础的，因此你需要<strong>引用它们</strong>，这十分有必要，比你先做这些研究的人们希望并需要有人认可他们做出的努力，不希望被人钻空子，声称你这些都是你自己的成果。其次要让读者能<strong>追溯你思维的逻辑</strong>，从而确认你的研究调查的确可以推导出所得结论。最后，记得一直<strong>追踪记录</strong>你的研究过程：数据库、文献、搜索关键字等。</p><hr><h3 id="信息组织和查找原理"><a href="#信息组织和查找原理" class="headerlink" title="信息组织和查找原理"></a>信息组织和查找原理</h3><p><strong>元数据</strong>能用一种便于数据库和编目系统查询的方式描述信息。普通搜索本质上是在经过谷歌排序的网页里搜寻你输入的短语（或关键字）。网页按照短语出现的位置、频率、包含多少链接、该网页存在了多久等因素进行排序，很有可能翻出来一大堆无用的垃圾信息。在图书馆提供的资源里，会看到许多标签，都代表这本资料的一个特征。当我们把一系列类似的概念归入同一个标准标签是，就称这个标签为一个“<strong>受控词汇</strong>（唯一官方指定）”，目的是为了信息更容易被搜索和发现。“<strong>主题标目</strong>（描述性标签）”是数据库和编目系统实用的一类元数据。如果在编目系统搜索“座位”，可能会看到座位——见椅子的信息，让你知道所使用的并不是系统偏好的词汇，明确“椅子”是官方使用的词语。使用主题词的时候，可以表明狭义信息，也可以是广义信息，例如可以搜“椅子”或“家具”。</p><hr><h3 id="信息搜索与图书馆编目系统"><a href="#信息搜索与图书馆编目系统" class="headerlink" title="信息搜索与图书馆编目系统"></a>信息搜索与图书馆编目系统</h3><p><strong>编目系统</strong>是一个巨大的、可检索的在线列表，只要把一份写有元数据的记录添加到系统中，就能搜索并找到那项资料。我们要把一个中心论点拆分开来，分成一些有用的搜索关键词，剔除无用信息，找到<strong>中心论点的核心</strong>。如：社交媒体的使用限制了职场生产力并降低收入，可以拆除：社交媒体、职场生产力、收入三个关键词。然后想出一些同义词或近义词代替关键词，如：社交网络代替社交媒体，效率和生产代替职场生产力，利润代替收入。然后，将这些词语组合起来，输入搜索栏，改变搜索词语的组合方式，可能会给搜索结果的数量、质量带来巨大的影响（可以搜：社交网络和职场，社交媒体和生产力等）。记录下你使用过的搜索词汇，那些有效，哪些无效。可以通过编目系统和数据库提供的一系列选项，切换到<strong>高级搜索</strong>功能（范围有全文，主题，作者，编目号码，系列名，期刊名等）。先试试<strong>主题搜索</strong>，系统会浏览一系列主题词标签登记在这个词汇下的书籍++，主题搜索比关键词搜索更简洁，更有条理，许多东西不止一个主题。如果不知道这种东西被赋予什么标签，不熟悉有关某一论题的正确的主题词，可以通过同义词词典找到可替换的术语从而扩大或缩小搜索范围，或使用图书馆提供的图书编目系统或数据库的主题词指南，查找官方使用的主题词（点击图书档案下的主题词会为你呈现这个主题标目下所有书目的书单）。也可以使用<strong>作者搜索</strong>，注意准确拼写。也可以使用<strong>书名搜索</strong>，但不确定书名的情况下，最好用主题或关键词搜索。总之，要在正确的范围内作调查，研究“美国内战”却 用作者搜索不会带给你想要的结果，弄清楚你想要哪种搜索，应该输入什么词汇。</p><ul><li><p>可以用<strong>布尔运算符</strong>(AND,OR,NOT)进行词汇的组合搜索，改进关键词搜索，同时也可以用括号来组织复杂的搜索语句，例如：（基因改良食品 or 转基因食品）and （安全）。</p></li><li><p>如果记不起一个词的准确拼法，可以使用<strong>截词</strong>（搜theroy可以用thero*），小心不要截掉太多内容，否则会给出海量结果。</p></li><li><p><strong>通配符</strong>可以让你在一个词的中间填空，例如：gr?y，alumin!um。问好代表一个字母，感叹号代表一个字母或没有字母。</p></li><li><p>另一种搜索技巧是使用<strong>引号</strong>搜索档案或电子书全文中的某一具体短语，能保证你的搜索词是一个整体，而不是两个分开的短语。例如：搜“心脏病”数据库不会把它们拆成“心脏”和“病”看待。</p></li><li><p>假设你找到了很好的信息资源，它往往自带一张<strong>参考资料或引用文献</strong>，列举了作者在研究过程中使用过的书、论文、网址等信息。浏览看看是否有你值得一看的东西，在数据库里搜索一下，往往会有惊喜。</p><hr></li></ul><h3 id="期刊和数据库"><a href="#期刊和数据库" class="headerlink" title="期刊和数据库"></a>期刊和数据库</h3><p><strong>期刊</strong>是一些定期出版的资料，可以是杂志，新闻报刊，学术期刊，可以是网上发布的文章或实体书，一般分为三大类：大众、行业/职业、学术/理论/同行评议。<strong>大众类期刊</strong>是你在书店或杂货店看到的杂志和报纸，采用光滑的纸张，明亮的颜色吸引读者，时常包含大量广告，出版非常频繁，每月，每周甚至每天出版，决定大众出版物内容的最重要因素是潮流，一些未经深入调查研究的时兴话题往往占据了这些出版物大部分版面，很少专业术语，没什么技术含量，不包含参考文献，无法让你对某一话题有更加深入的了解，无法为学术研究项目提供可靠的资料。<strong>专业或行业出版物</strong>专门提供与某一行业相关的信息，通常由专业组织来出版。主要面向熟悉该领域特有技术行话的读者。其重点不是独创性的调查研究，挑选文章的标准是以实验为基础，会提供引文和参考文献，但不必须经过实验检验，可能会对你的研究调查有帮助，但需要验证有疑点的推断和结论，同时也会用炫酷的设计和投放广告，广告与行业相关，行业出版物一般每一个月或两个月出版一次，网络版要频繁很多。<strong>学术期刊、理论期刊、同行评议期刊、调查研究期刊</strong>，这些都由专业学者和研究人员撰写，专业组织或学术机构出版的出版物，内容是对专业领域或学术领域非常重要的论题独创性的研究和分析，是最可靠的文章，是学者们相互交流研究进程的基本渠道之一。学术期刊针对的是非常特定的读者群体，使用大量术语和行话，标题明确，充满术语，内容很长，充满图表以及其他佐证文章观点的插图，没有与核心内容无关的广告，印刷简约。世界上很多学术期刊只能在图书馆数据库看到，十分昂贵，通常每月，双月，每季，每年甚至几年才出版一次。一卷指的是一年，期刊两个月出版一次，一年就有六期，六期包含在这一卷中。一卷的页码只有第一其从1算起，之后的几期可能会接着前一期的页码算。学术期刊中的文章要经历一个同行评议的过程，能确保文章的准确性。</p><p>大部分学术期刊里的文章无法被谷歌搜索出来，谷歌只能帮你定位一大堆学术论文或全文的引文，大部分论文的全文是找不到的，之所以能在图书馆找到是因为图书馆付费了，但不意味你获得了资料的所有权，大部分时候，学生和学者都可以得到所需的信息。<strong>数据库</strong>和编目系统搜索方式相似。搜索之后可以看到期刊刊名，卷号，期号和页码，且可以看到获取全文的链接。两个非常重要的搜索结果限制是<strong>同行评议限制</strong>和<strong>全文限制</strong>，同行评议限制排除没有通过同行评议流程的结果，全文限制排除了不提供论文全文的结果，能搜出非常好的文章。</p><ul><li><p><strong>主题标目</strong>是一片金库，如果文章列表的一些主题标目跟你的论题高度一致，那么就要快速记下以便之后使用。</p></li><li><p><strong>摘要</strong>是数据库档案中极有用的部分，用一两段话提供一篇论文的概述，简要说明论文讲了什么，用了什么方法，最终的发现是什么，可以立刻判断出论文对你的研究有没有用，节约时间。</p></li><li><p>搜期刊论文的方法一是在编目系统中搜索期刊名，再去书架上找卷号和期号。另一种是看能否在图书馆数据库找到，可以在综合性数据库和专题类数据库中尝试查找一下期刊名，用卷号、期号、论文题目缩小搜索范围。</p></li><li><p>学术期刊会在官方网站或社交媒体上提供免费博客、播客和新闻，某些期刊与你的研究相关，一定要关注它们的更新。这些信息可以谷歌一些期刊名称，或者数据库专题期刊列表里找找看。</p></li><li><p>有困难时，可以找图书管理员聊聊。</p><hr></li></ul><h3 id="在开放时间中搜索信息"><a href="#在开放时间中搜索信息" class="headerlink" title="在开放时间中搜索信息"></a>在开放时间中搜索信息</h3><ul><li><p>用谷歌、必应、雅虎或其他商业搜索引擎做普通搜索时，想找到我们需要的信息很难，因为信息实在太多了，事实上互联网上的大部分信息你都无法知晓（没有被搜索引擎的爬虫获取到）。如果使用普通网络搜索而不是数据库搜索，会错过一大堆信息，这是写学术论文的一大损失。图书馆资源可以排除混乱的信息，增加你搜索的深度并提高搜索质量。</p></li><li><p>搜索引擎也有<strong>高级搜索</strong>选项，可以沿用布尔运算符，可以限制搜索范围如：使用语种，上一次更新时间，文件类型，域名类型等。使用普通搜索时，在一个词前加减号可以将它从搜索词中剔除，网址前加”site:”可以让你搜索网址里面的内容，短语加引号可以搜索完整的短语。大部分搜索引擎默认你搜索词汇中有and。</p></li><li><p>一些政府官方网站，公众网站，非营利组织官方网站有时也会提供与你课题相关的信息。</p></li><li><p>百度百科可以作为你研究的起点，但不能再研究成果中引用百度百科的内容，因为这些文章不能作为真正意义上的学术信息来源，也不是原创的研究，只是信息稍加整合，告诉你一个基本的概念而已。因此用这些资料打打基础就好，熟悉一下这个论题的各个方面，在百科全书文章中，最有用的是参考文献，引述作品，注释和其他一些页面上呈现的内容，是现成的可以查找的资源。阅读百科文章时要谨慎，防止有人添加劣质信息。</p></li></ul><hr><h3 id="评估信息资源"><a href="#评估信息资源" class="headerlink" title="评估信息资源"></a>评估信息资源</h3><p>无论你使用的信息来自学术期刊，流行杂志，书，网站请核实这些信息的来源，每一点信息都需要进行评估，很多复杂因素决定了信息来源是否可用。哪怕一些很<br>“学术”的信息不一定适合你的研究，也不仅仅因为“大众化”的东西就把它排除在外。评估是持续不断的过程，不要收集一堆资源进行一次性评估，而是找到一个，评估是否保留，再找下一个。评估信息资源的重要性不止体现在学术研究上，高质量的信息能帮你做出很多人生抉择。</p><p>进行信息评估时的几个问题：</p><ul><li>信息来自哪里</li><li>谁制造发布了这些信息</li><li>哪个机构负责出版这些信息</li><li>作者和出版方在论题相关领域足够权威吗</li><li>作者是否有足够教育背景，他们的经历和该学科相关吗</li><li>是什么让一份出版物和网站信息相当可靠，作为可靠信息有一段时间了吗</li><li>是不是经过同行评议审核的作品，并且是学术资源，还是更像通俗读物</li></ul><p>评估网站信息的时候，一定要<strong>确保这个机构可以对内容负责</strong>，如果不是官方发布的学术资料，看看能否在网页上找到“关于我们”的链接，能提供与该机构有关的信息，有时会发现许多机构有明显倾向性，动机是达成某项目的，而不是研究本身，这样的机构可能不会给出你需要的客观而有学术价值的信息。</p><p>对于应该相信谁，相信什么，要<strong>建立自己的认知系统</strong>，这是建立在我们个人经验，偏见以及与现存的其他系统的交互之上的，因此我们要保持辩证的观点看问题，保持健康的怀疑心态，主动接受种类更广的，不同类别的作者创造的内容，问自己为什么这条信息有用，这个作者更值得信赖。</p><p>学术型资源有不同的目标群体，看看信息中的语言是否太过专业难懂，或者太过浅显不足以应当研究需求。看看资源的研究范围，是覆盖了一个论题的多个方面还是仅仅针对十分细枝末节的话题，是把你知道的信息重复了一遍，还是提供了你之前不知道的新视角，新内容？这就要看<strong>你的研究到底需要什么</strong>，早点明确你的研究需求很重要。</p><p>有时有些信息有意说服读者相信一些事情，这种做法不一定值得信任，小心在某一话题立场鲜明的作者，使用一种有说服意图的资源之前，请确保你已经了解过其他对立的观点，并且一些矛盾已经被解决了。</p><p>在评估一个信息资源时，引文和参考文献扮演十分重要的角色。作者有没有提供一份他们在研究过程中参考过的文献清单？有没有解释哪种信息资源提供了哪段引文或论据？你应该能按照他们提供的信息资源顺藤摸瓜，证实作者正确使用了这些信息，回溯他们的研究。</p><p>要检查信息的时效性：它是多久之前被创造的？有时你会希望信息越新越好，在科技、医药和其他更新迅速的研究领域尤为重要，看看新的信息是否颠覆了旧的内容。</p><hr><h3 id="信息使用道德"><a href="#信息使用道德" class="headerlink" title="信息使用道德"></a>信息使用道德</h3><p><strong>抄袭</strong>是指把别人的成果拿走，当做你自己的成果使用，并且不给哪些真正研究和写作的人署名，这就是知识的盗窃。把署名放在该放的地方就叫<strong>引文</strong>。记住，研究是一种群体行为，作为研究者，你的贡献是在他人成果基础上有所建树，每一种新发现都是建立在其他人的研究成果之上的。用自己的话把别人的内容再进行叙述也是抄袭，因为拿走了学术创意当做自己的。你要说明原版是哪里来的，以及原版不是你的作品，这就是<strong>转述</strong>。如果你压缩并精简了一个想法，那就叫做<strong>概述</strong>。</p><p>不是所有内容都需要引文，如果你的论文中有一些论据是常识，不是建立在其他人原创研究的基础上的，这些论据就不需要写引文。</p><p>作为一个研究者，你应该把你遇到的各种知识综合成一个新的产物，创造新知识，你用的是已存在的研究和信息，但最后的产物必须是你自己创造，你自己对零碎信息的理解和整合。不是简单罗列总结其他人的研究成果，而是在创立对研究的新观点，为现有的知识体系做贡献。</p><p>写论文时，一定要细心整理信息资源，否则会很容易忘记自己需要用到的信息出处，是谁写了哪些内容。至少记下使用过的信息来源，让你能回过头参考，可以使用<strong>参考文献管理软件</strong>（bibliographic manager）帮你在网上追踪信息来源。</p><p>写引文不仅能帮你避免被指控抄袭的麻烦，还能帮你找到有益于自己的研究信息资源。</p><p>学术论文有很多种“方式”写作，最常见的有MLA写作指南，APA出版手册，芝加哥写作手册，不同的写作方式一般与不同的学术学科密切相关。这些指南提供了非常多的细节指导，保证你论文的规范性。</p><p>在引用信息资源时，要关注两种主要组成部分，一种是小注释，跟在引文，转述或总结后面，标识信息是怎么样来的，另一种是你放在论文最后一张的清单，详细讲述你在研究过程中使用过的信息的来源。文内引文和脚注/尾注不只是告诉你的读者信息来自另一个地方，也会引导读者去看你论文末尾的完整清单，这张清单里必须包含你在研究里使用过的所有信息资源。</p><p>书和论文不是需要引用的唯一信息资源，根据不同的论题，你可能还要引用电影，纪录片，电视，博客，视频，网站等等。引文不一定是官方的，你提供一个在线链接，就是简单，非正式地引用了一个信息。<strong>zotero那样的免费在线工具</strong>可以帮你生成和组织所有类型的引文。</p><p>版权是法律对知识产权所有者的保护，一般版权所有者有在一定时间内贩卖、发行他们的知识产权的权利。</p><p>一般情况下，正当使用信息要求你的作品不使原作的商业潜能受损，并且你只使用了原作的一小部分，并非所有对受版权法保护资料的使用都必须是非营利和教育目的，只要最终产物和原作品有实质性的不同就行。要小心使用资源，在版权方面宁求稳妥，不要冒险！</p><p>另一方面，一些版权所有者鼓励人们使用他们的作品，一种方法是加入知识共享许可协议的条件下发表作品，该协议是保护自己作为创造者的权益同时允许其他人使用，发布甚至在他们作品上继续加工的协议。</p><hr>]]></content>
      
      
      <categories>
          
          <category> 学习方法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 研究方法 </tag>
            
            <tag> 论文写作 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>个人建立hexo博客Matery主题的过程心得</title>
      <link href="2021/01/10/ge-ren-jian-li-hexo-bo-ke-matery-zhu-ti-de-guo-cheng-xin-de/"/>
      <url>2021/01/10/ge-ren-jian-li-hexo-bo-ke-matery-zhu-ti-de-guo-cheng-xin-de/</url>
      
        <content type="html"><![CDATA[<h1 id="博客搭建"><a href="#博客搭建" class="headerlink" title="博客搭建"></a>博客搭建</h1><hr><h2 id="下载git和node"><a href="#下载git和node" class="headerlink" title="下载git和node"></a>下载git和node</h2><p>首先，搭建博客需要两个环境，一个是node.js，一个是git。</p><p>打开cmd控制台输入</p><pre class=" language-cmd"><code class="language-cmd">node -v               #查看node版本git --version      #查看git版本</code></pre><img src="/2021/01/10/ge-ren-jian-li-hexo-bo-ke-matery-zhu-ti-de-guo-cheng-xin-de/1.jpg" class=""><p>如果没有显示版本号则需要配置环境变量：</p><p>右键点击“我的电脑”→高级系统设置→环境变量</p><p>给在系统变量给node新建变量：</p><p>变量：NODE_PATH            值：node文件夹所在地址（如：F:\node）</p><p>然后点击系统变量中Path的编辑，新建以下几个环境变量：</p><pre class=" language-script"><code class="language-script">F:\node\F:\Git\Git\cmdF:\node\node_global\#具体情况需要看文件位置而定</code></pre><p>然后再验证node和git的版本。</p><hr><h2 id="cnpm安装"><a href="#cnpm安装" class="headerlink" title="cnpm安装"></a>cnpm安装</h2><p>直接用npm速度会比较慢（源在国外），因此要利用npm安装cnpm.</p><p>打开Git Bash输入以下命令：</p><pre class=" language-cmd"><code class="language-cmd">npm install -g cnpm --registry=http://registry.npm.taobao.org#安装淘宝的cnpm 管理器</code></pre><p>安装完成后，以后可以用cnpm直接代替npm.</p><hr><h2 id="hexo框架安装"><a href="#hexo框架安装" class="headerlink" title="hexo框架安装"></a>hexo框架安装</h2><pre class=" language-cmd"><code class="language-cmd">cnpm install -g hexo-cli    #安装hexo框架hexo -v        #查看hexo版本</code></pre><hr><h2 id="利用hexo搭建博客"><a href="#利用hexo搭建博客" class="headerlink" title="利用hexo搭建博客"></a>利用hexo搭建博客</h2><p>在一个地方创建空文件夹（命名blog），所有东西将在里面生成。</p><p>打开文件夹，在此文件夹下运行git bash（右键单击空白处）</p><pre class=" language-git"><code class="language-git">sudo hexo init     #生成博客 初始化博客</code></pre><p>这时候系统会自动克隆文件到blog，并默认landscape主题。再输入命令：</p><pre class=" language-git"><code class="language-git">hexo s    #启动本地博客服务</code></pre><p>浏览器访问 <a href="http://localhost:4000/%EF%BC%8C%E8%BF%99%E6%97%B6%E5%8F%AF%E4%BB%A5%E7%9C%8B%E5%88%B0%E7%B3%BB%E7%BB%9F%E9%BB%98%E8%AE%A4%E7%9A%84%E7%89%88%E6%9C%AC%E3%80%82">http://localhost:4000/，这时可以看到系统默认的版本。</a></p><hr><h2 id="创建文章"><a href="#创建文章" class="headerlink" title="创建文章"></a>创建文章</h2><pre class=" language-git"><code class="language-git">hexo n <span class="token string">"我的第一篇文章"</span> #创建新的文章 </code></pre><p>可以看到在source文件夹下的_posts文件夹下创建了.md文件。</p><p>打开文件就可以编辑内容，里面是基于markdown语法的。</p><p>想了解Markdown语法如何使用，请看b站视频<a href="https://www.bilibili.com/video/BV1hJ411X75X?from=search&amp;seid=9433284770037044167">15分钟快速上手Markdown教程</a></p><hr><h2 id="部署到gitee"><a href="#部署到gitee" class="headerlink" title="部署到gitee"></a>部署到gitee</h2><p>输入命令：</p><pre class=" language-git"><code class="language-git">hexo clean #清理hexo g #生成hexo s  #启动本地服务器</code></pre><p>这时可以再本地 <a href="http://localhost:4000/%E6%9F%A5%E7%9C%8B%E8%87%AA%E5%B7%B1%E6%9C%AA%E5%8F%91%E5%B8%83%E7%9A%84%E7%89%88%E6%9C%AC%E3%80%82">http://localhost:4000/查看自己未发布的版本。</a></p><p>然后我们可以把它部署到网上了，部署的方案有很多种，可以把它部署到github，也可以部署到gitee，由于github访问速度较慢，且有的地区无法访问，因此我个人是部署到了gitee上。</p><p>首先你必须有个gitee账号，创建一个公开仓库，注意命名和路径必须与你的用户名一致（不是昵称）。</p><p>创建完仓库后，点击管理</p><img src="/2021/01/10/ge-ren-jian-li-hexo-bo-ke-matery-zhu-ti-de-guo-cheng-xin-de/2.jpg" class=""><p>此处可以查看仓库的路径，复制这个路径，等下用到。</p><hr><p>打开位于Blog文件夹下的_config.yml文件，这个文件是用来配置你的博客的。滑到底端，改下面的三行代码并保存：</p><pre class=" language-yml"><code class="language-yml">deploy:  type: git  repo: https://gitee.com/用户名/用户名.git    #你的仓库地址+.git  branch: master</code></pre><p>然后安装git部署插件：</p><pre class=" language-git"><code class="language-git">cnpm install --save hexo-deployer-git</code></pre><p>然后在git bash上输入命令：</p><pre class=" language-git"><code class="language-git">hexo d     # 部署到仓库</code></pre><p>然后输入你gitee的用户名和密码，等部署完毕，点开仓库，可以发现里面有你部署进去的文件。</p><img src="/2021/01/10/ge-ren-jian-li-hexo-bo-ke-matery-zhu-ti-de-guo-cheng-xin-de/3.jpg" class=""><p>此时点击服务里面的gitee Pages，对内容进行更新：</p><img src="/2021/01/10/ge-ren-jian-li-hexo-bo-ke-matery-zhu-ti-de-guo-cheng-xin-de/4.jpg" class=""><p>更新完成后就可以登录https://你的用户名.gitee.io/对你的博客进行访问啦！</p><hr><h1 id="Matery主题的搭建和完善"><a href="#Matery主题的搭建和完善" class="headerlink" title="Matery主题的搭建和完善"></a>Matery主题的搭建和完善</h1><h2 id="主题下载和更改"><a href="#主题下载和更改" class="headerlink" title="主题下载和更改"></a>主题下载和更改</h2><pre class=" language-git"><code class="language-git"> git clone https://github.com/blinkfox/hexo-theme-matery   #在themes文件夹下执行命令，下载matery主题到本地</code></pre><p>打开blog文件夹下的_config.yml，对其中的内容进行更改：</p><pre class=" language-yml"><code class="language-yml"># Sitetitle: 微笑紫瞳星subtitle: '感谢各位的来访，请在留言板上留下你的足迹'description: '本站记录本人各种学习的旅途，用于巩固自我并启发后来人'keywords: [博客制作,个人经验分享,Unity,人工智能等]author: 微笑紫瞳星language: zh-CNtimezone: ''</code></pre><pre class=" language-yml"><code class="language-yml"># URL## If your site is put in a subdirectory, set url as 'http://example.com/child' and root as '/child/'url: http://tianjuewudi.gitee.io/root: /permalink: :year/:month/:day/:title/permalink_defaults:pretty_urls:  trailing_index: true # Set to false to remove trailing 'index.html' from permalinks  trailing_html: true # Set to false to remove trailing '.html' from permalinks</code></pre><p>主题修改找到关键词theme把内容替换成自己的主题：</p><pre class=" language-yml"><code class="language-yml">theme: hexo-theme-matery</code></pre><p>其他还有很多内容关于各种插件，我将一一讲述。</p><hr><h2 id="Matery主题配置"><a href="#Matery主题配置" class="headerlink" title="Matery主题配置"></a>Matery主题配置</h2><p>效果预览：</p><p>｛% asset_img 5.jpg %｝</p><p>打开themes文件夹下的Matery主题文件夹。首先打开media文件夹,对里面的文件进行一一说明:</p><ol><li>banner中存放的是在首页展示的图片，一天换一张，共7张，一个星期轮一次，可对其进行替换，图片名称须相同。</li><li>fetureimages中的图片将被展示在相册中，且在没有给文章设置封面时，随机挑选一张作为封面，可替换。</li><li>reward中存放着别人打赏你扫描的二维码，一张微信，一张支付宝，可替换。</li><li>comment_bg.png是评论区上的图片。</li><li>icp.png是备案标志。</li><li>logo.png是你昵称旁的标志，可替换。</li></ol><p>打开matery文件夹下的_config.yml可对主题进行配置</p><p>首页的轮播设置（页首语和文章推送）：</p><pre class=" language-yml"><code class="language-yml">cover:  showPrevNext: true # 是否显示左右切换按钮. Whether to display the left and right toggle buttons.  showIndicators: true # 是否显示指示器. # Whether to display the indicators  autoLoop: true # 是否自动轮播. Whether it is automatically rotated.  duration: 120 # 切换延迟时间. Switching delay time.  intervalTime: 5000 # 自动切换下一张的间隔时间. Automatically switch the interval of the next one.  useConfig: false # 是否使用配置文件, 在 _data/covers.json 下配置推荐文章, false则使用主题在文章中的配置 cover coverImg  # useConfig 使用方式: 将主题 hexo-theme-matery/source/_data/covers.json 移动到 my-blog/source/_data/下修改配置即可</code></pre><p>我的梦想模块：</p><pre class=" language-yml"><code class="language-yml">dream:  enable: true  showTitle: true  title: 关于多巴胺的兴趣驱动  text: 了解自身的兴趣产生和作用机制是控制自我的重要一步，多巴胺是能让自身产生兴奋愉悦感的物质，对于任何事物的任何兴趣都是基于多巴胺驱动的，但奈何人体对于多巴胺具有耐受性，长期沉浸于高多巴胺分泌的环境下会使得人体对于快乐的感觉变得迟钝。因此，让自己沉浸于技术学习的最好办法是平时隔绝高多巴胺分泌的娱乐活动，但又把这种活动作为阶段性成就的奖赏，你便会得到数倍于平时的快乐。</code></pre><img src="/2021/01/10/ge-ren-jian-li-hexo-bo-ke-matery-zhu-ti-de-guo-cheng-xin-de/6.jpg" class=""><p>其他以此类推，代码注释非常友好，可以轻易知道其功能。</p><hr><h2 id="看板娘模块的安装和使用"><a href="#看板娘模块的安装和使用" class="headerlink" title="看板娘模块的安装和使用"></a>看板娘模块的安装和使用</h2><p>模块安装：</p><pre class=" language-git"><code class="language-git">cnpm install --save hexo-helper-live2d</code></pre><p>下载完成后，可以在node_modules文件夹中找到自己安装的插件。</p><p>然后下载你想要的看板娘模块（可以自己到网上找哪个合心意的），执行命令：</p><pre class=" language-git"><code class="language-git">cnpm install &amp;#123;packagename&amp;#125;<span class="token comment" spellcheck="true"># 例如cnpm install live2d-widget-model-haru</span></code></pre><p>下载完成后，回到blog根目录下配置_config.yml，添加以下代码（model要根据自己情况设置）：</p><pre class=" language-yml"><code class="language-yml">live2d:  enable: true  scriptFrom: local  pluginRootPath: live2dw/  pluginJsPath: lib/  pluginModelPath: assets/  tagMode: false  debug: false  model:    use: live2d-widget-model-z16  display:    position: right    width: 200    height: 400  mobile:    show: false</code></pre><p>这样在右下角有看板娘啦！</p><hr><h2 id="音乐播放器的使用"><a href="#音乐播放器的使用" class="headerlink" title="音乐播放器的使用"></a>音乐播放器的使用</h2><p>进入matery主题文件夹下的_config.yml，可以发现matery主题自带一个音乐播放器模块,对其进行修改：</p><pre class=" language-yml"><code class="language-yml"># Whether to display the musics.# 是否在首页显示音乐.music:  enable: true  title: #非吸底模式有效    enable: true    show: 听听音乐  autoHide: true    # hide automaticaly  server: netease   #require    music platform: netease, tencent, kugou, xiami, baidu  type: playlist    #require song, playlist, album, search, artist  id: 5456680252     # require song id / playlist id / album id / search keyword  # 503838841  fixed: true       # 开启吸底模式  autoplay: true   # 是否自动播放  theme: '#42b983'  loop: 'all'       # 音频循环播放, 可选值: 'all', 'one', 'none'  order: 'random'   # 音频循环顺序, 可选值: 'list', 'random'  preload: 'auto'   # 预加载，可选值: 'none', 'metadata', 'auto'  volume: 0.7       # 默认音量，请注意播放器会记忆用户设置，用户手动设置音量后默认音量即失效  listFolded: true  # 列表默认折叠  hideLrc: true     # 隐藏歌词</code></pre><p>这里最重要的是id号，这决定了我们播放的歌单，默认是播放网易云音乐（server: netease），腾讯，酷狗，虾米，百度音乐都可以，这里以网易云为例：</p><p>首先在网易云上创建自己的歌单，然后用浏览器打开网易云音乐，打开你的歌单页面，看网址，网站后面的一串数字就是你歌单的id，把它填到配置中去。</p><hr><h2 id="Valine评论系统的使用"><a href="#Valine评论系统的使用" class="headerlink" title="Valine评论系统的使用"></a>Valine评论系统的使用</h2><p>可以看到在matery主题_config.yml有这么一段代码（enable改为true）：</p><pre class=" language-yml"><code class="language-yml"># The configuration of the Valine comment module is not activated by default.# To use it, activate the configuration item and set appId and appKey.# Valine 评论模块的配置，默认为不激活，如要使用，就请激活该配置项，并设置 appId 和 appKey.valine:  enable: true  appId:   appKey:   notify: true  verify: false  visitor: true  avatar: 'mm' # Gravatar style : mm/identicon/monsterid/wavatar/retro/hide  pageSize: 10  placeholder: '请畅所欲言' # Comment Box placeholder  background: /medias/comment_bg.png</code></pre><p>在这里，我们只需填写的内容只有appId和appKey。具体操作访问<a href="https://valine.js.org/quickstart.html">https://valine.js.org/quickstart.html</a></p><p>然后把你得到的appId和appKey填入其中，那么在留言板和每篇文章的最后都会出现这么一个评论区：</p><img src="/2021/01/10/ge-ren-jian-li-hexo-bo-ke-matery-zhu-ti-de-guo-cheng-xin-de/7.jpg" class=""><p>这样利用leanCloud就可以无后端得开发出一个评论区啦，非常简单便捷。</p><hr><h2 id="文章图片无法显示问题"><a href="#文章图片无法显示问题" class="headerlink" title="文章图片无法显示问题"></a>文章图片无法显示问题</h2><p>hexo根目录下运行</p><pre class=" language-script"><code class="language-script">cnpm install https://github.com/CodeFalling/hexo-asset-image --save</code></pre><p>安装成功后这个插件的内容需要修改（可能有bug）</p><p>打开/node_modules/hexo-asset-image/index.js，将内容更换为下面的代码</p><pre class=" language-js"><code class="language-js"><span class="token string">'use strict'</span><span class="token punctuation">;</span><span class="token keyword">var</span> cheerio <span class="token operator">=</span> <span class="token function">require</span><span class="token punctuation">(</span><span class="token string">'cheerio'</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">// http://stackoverflow.com/questions/14480345/how-to-get-the-nth-occurrence-in-a-string</span><span class="token keyword">function</span> <span class="token function">getPosition</span><span class="token punctuation">(</span>str<span class="token punctuation">,</span> m<span class="token punctuation">,</span> i<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>  <span class="token keyword">return</span> str<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span>m<span class="token punctuation">,</span> i<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">join</span><span class="token punctuation">(</span>m<span class="token punctuation">)</span><span class="token punctuation">.</span>length<span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token keyword">var</span> version <span class="token operator">=</span> <span class="token function">String</span><span class="token punctuation">(</span>hexo<span class="token punctuation">.</span>version<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">'.'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>hexo<span class="token punctuation">.</span>extend<span class="token punctuation">.</span>filter<span class="token punctuation">.</span><span class="token function">register</span><span class="token punctuation">(</span><span class="token string">'after_post_render'</span><span class="token punctuation">,</span> <span class="token keyword">function</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>  <span class="token keyword">var</span> config <span class="token operator">=</span> hexo<span class="token punctuation">.</span>config<span class="token punctuation">;</span>  <span class="token keyword">if</span><span class="token punctuation">(</span>config<span class="token punctuation">.</span>post_asset_folder<span class="token punctuation">)</span><span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token keyword">var</span> link <span class="token operator">=</span> data<span class="token punctuation">.</span>permalink<span class="token punctuation">;</span>    <span class="token keyword">if</span><span class="token punctuation">(</span>version<span class="token punctuation">.</span>length <span class="token operator">&gt;</span> <span class="token number">0</span> <span class="token operator">&amp;&amp;</span> <span class="token function">Number</span><span class="token punctuation">(</span>version<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">3</span><span class="token punctuation">)</span>       <span class="token keyword">var</span> beginPos <span class="token operator">=</span> <span class="token function">getPosition</span><span class="token punctuation">(</span>link<span class="token punctuation">,</span> <span class="token string">'/'</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">;</span>    <span class="token keyword">else</span>       <span class="token keyword">var</span> beginPos <span class="token operator">=</span> <span class="token function">getPosition</span><span class="token punctuation">(</span>link<span class="token punctuation">,</span> <span class="token string">'/'</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// In hexo 3.1.1, the permalink of "about" page is like ".../about/index.html".</span>    <span class="token keyword">var</span> endPos <span class="token operator">=</span> link<span class="token punctuation">.</span><span class="token function">lastIndexOf</span><span class="token punctuation">(</span><span class="token string">'/'</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">;</span>    link <span class="token operator">=</span> link<span class="token punctuation">.</span><span class="token function">substring</span><span class="token punctuation">(</span>beginPos<span class="token punctuation">,</span> endPos<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">var</span> toprocess <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'excerpt'</span><span class="token punctuation">,</span> <span class="token string">'more'</span><span class="token punctuation">,</span> <span class="token string">'content'</span><span class="token punctuation">]</span><span class="token punctuation">;</span>    <span class="token keyword">for</span><span class="token punctuation">(</span><span class="token keyword">var</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> toprocess<span class="token punctuation">.</span>length<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span><span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>      <span class="token keyword">var</span> key <span class="token operator">=</span> toprocess<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">;</span>      <span class="token keyword">var</span> $ <span class="token operator">=</span> cheerio<span class="token punctuation">.</span><span class="token function">load</span><span class="token punctuation">(</span>data<span class="token punctuation">[</span>key<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        ignoreWhitespace<span class="token punctuation">:</span> <span class="token boolean">false</span><span class="token punctuation">,</span>        xmlMode<span class="token punctuation">:</span> <span class="token boolean">false</span><span class="token punctuation">,</span>        lowerCaseTags<span class="token punctuation">:</span> <span class="token boolean">false</span><span class="token punctuation">,</span>        decodeEntities<span class="token punctuation">:</span> <span class="token boolean">false</span>      <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>      <span class="token function">$</span><span class="token punctuation">(</span><span class="token string">'img'</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">each</span><span class="token punctuation">(</span><span class="token keyword">function</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token function">$</span><span class="token punctuation">(</span><span class="token keyword">this</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">attr</span><span class="token punctuation">(</span><span class="token string">'src'</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            <span class="token comment" spellcheck="true">// For windows style path, we replace '\' to '/'.</span>            <span class="token keyword">var</span> src <span class="token operator">=</span> <span class="token function">$</span><span class="token punctuation">(</span><span class="token keyword">this</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">attr</span><span class="token punctuation">(</span><span class="token string">'src'</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">replace</span><span class="token punctuation">(</span><span class="token string">'\\'</span><span class="token punctuation">,</span> <span class="token string">'/'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token keyword">if</span><span class="token punctuation">(</span><span class="token operator">!</span><span class="token regex">/http[s]*.*|\/\/.*/</span><span class="token punctuation">.</span><span class="token function">test</span><span class="token punctuation">(</span>src<span class="token punctuation">)</span> <span class="token operator">&amp;&amp;</span>               <span class="token operator">!</span><span class="token regex">/^\s*\//</span><span class="token punctuation">.</span><span class="token function">test</span><span class="token punctuation">(</span>src<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>              <span class="token comment" spellcheck="true">// For "about" page, the first part of "src" can't be removed.</span>              <span class="token comment" spellcheck="true">// In addition, to support multi-level local directory.</span>              <span class="token keyword">var</span> linkArray <span class="token operator">=</span> link<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">'/'</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">filter</span><span class="token punctuation">(</span><span class="token keyword">function</span><span class="token punctuation">(</span>elem<span class="token punctuation">)</span><span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>                <span class="token keyword">return</span> elem <span class="token operator">!=</span> <span class="token string">''</span><span class="token punctuation">;</span>              <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>              <span class="token keyword">var</span> srcArray <span class="token operator">=</span> src<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">'/'</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">filter</span><span class="token punctuation">(</span><span class="token keyword">function</span><span class="token punctuation">(</span>elem<span class="token punctuation">)</span><span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>                <span class="token keyword">return</span> elem <span class="token operator">!=</span> <span class="token string">''</span> <span class="token operator">&amp;&amp;</span> elem <span class="token operator">!=</span> <span class="token string">'.'</span><span class="token punctuation">;</span>              <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>              <span class="token keyword">if</span><span class="token punctuation">(</span>srcArray<span class="token punctuation">.</span>length <span class="token operator">&gt;</span> <span class="token number">1</span><span class="token punctuation">)</span>                srcArray<span class="token punctuation">.</span><span class="token function">shift</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>              src <span class="token operator">=</span> srcArray<span class="token punctuation">.</span><span class="token function">join</span><span class="token punctuation">(</span><span class="token string">'/'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>              <span class="token function">$</span><span class="token punctuation">(</span><span class="token keyword">this</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">attr</span><span class="token punctuation">(</span><span class="token string">'src'</span><span class="token punctuation">,</span> config<span class="token punctuation">.</span>root <span class="token operator">+</span> link <span class="token operator">+</span> src<span class="token punctuation">)</span><span class="token punctuation">;</span>              console<span class="token punctuation">.</span>info<span class="token operator">&amp;&amp;</span>console<span class="token punctuation">.</span><span class="token function">info</span><span class="token punctuation">(</span><span class="token string">"update link as:--&gt;"</span><span class="token operator">+</span>config<span class="token punctuation">.</span>root <span class="token operator">+</span> link <span class="token operator">+</span> src<span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token keyword">else</span><span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            console<span class="token punctuation">.</span>info<span class="token operator">&amp;&amp;</span>console<span class="token punctuation">.</span><span class="token function">info</span><span class="token punctuation">(</span><span class="token string">"no src attr, skipped..."</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            console<span class="token punctuation">.</span>info<span class="token operator">&amp;&amp;</span>console<span class="token punctuation">.</span><span class="token function">info</span><span class="token punctuation">(</span><span class="token function">$</span><span class="token punctuation">(</span><span class="token keyword">this</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>      <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>      data<span class="token punctuation">[</span>key<span class="token punctuation">]</span> <span class="token operator">=</span> $<span class="token punctuation">.</span><span class="token function">html</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>  <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre><p>然后打开_config.yml文件，修改下述内容</p><pre class=" language-yml"><code class="language-yml">post_asset_folder: true</code></pre><hr><blockquote><p>通过常规的 markdown 语法和相对路径来引用图片和其它资源可能会导致它们在存档页或者主页上显示不正确。在Hexo 2时代，社区创建了很多插件来解决这个问题。但是，随着Hexo 3 的发布，许多新的标签插件被加入到了核心代码中。这使得你可以更简单地在文章中引用你的资源。</p></blockquote><p>​        也就是说在存档页和主页不能使用和文章内容中的常规语法来引用图片。比如说：当你打开文章资源文件夹功能后，你把一个 <code>example.jpg</code> 图片放在了你的资源文件夹中，如果通过使用相对路径的常规 markdown 语法 <code>![](/example.jpg)</code> ，它将 <em>不会</em> 出现在首页上。（但是它会在文章中按你期待的方式工作）</p><p>​        正确的引用图片方式是使用下列的标签插件而不是 markdown ：</p><pre class=" language-script"><code class="language-script">{% asset_img example.jpg This is an example image %}</code></pre><hr><h2 id="如何消除首页的颜色变化蒙版效果"><a href="#如何消除首页的颜色变化蒙版效果" class="headerlink" title="如何消除首页的颜色变化蒙版效果"></a>如何消除首页的颜色变化蒙版效果</h2><p>打开themes文件夹→matery→source→css→matery.css，找到这么一大段代码，注释其中的代码。</p><pre class=" language-yml"><code class="language-yml">@-webkit-keyframes rainbow {    /*注释内容*/}@keyframes rainbow {    /*注释内容*/}</code></pre><p>完成之后，重新部署到网站上，ctrl+F5刷新网页。</p><hr><h2 id="多平台一键部署（未尝试）"><a href="#多平台一键部署（未尝试）" class="headerlink" title="多平台一键部署（未尝试）"></a>多平台一键部署（未尝试）</h2><p>修改 Hexo 根目录下的 <code>_config.yml</code> 文件中的如下内容:</p><pre class=" language-yml"><code class="language-yml">deploy:  - type: git    repo: https://github.com/lxl80/blog.git    branch: gh-pages    ignore_hidden: false  - type: git    repo: https://gitee.com/lxl80/lxl80.git    branch: master    ignore_hidden: false</code></pre><p>安装：</p><pre class=" language-yml"><code class="language-yml">cnpm install hexo-deployer-cos-enhanced --save</code></pre><p>_config.yml配置如下：</p><pre class=" language-yml"><code class="language-yml">deploy:  - type: git    repo: https://github.com/lxl80/blog.git    branch: gh-pages    ignore_hidden: false  - type: cos    bucket: lxl80-130****    region: ap-beijing    secretId: AKIDh9****F8FvL    secretKey: Z3IGiur****QZR3PgjXmlVg    cdnConfig:      enable: true      cdnUrl: https://static.lixl.cn      bucket: static-130****      region: ap-beijing      folder: static      secretId: AKIDh9****F8FvL      secretKey: Z3IGiur****QZR3PgjXmlVg</code></pre><p>用hexo c,hexo g ,hexo d三连可实现一键发布。</p><hr><h2 id="文章-Front-matter-介绍"><a href="#文章-Front-matter-介绍" class="headerlink" title="文章 Front-matter 介绍"></a>文章 Front-matter 介绍</h2><p><code>Front-matter</code> 选项中的所有内容均为<strong>非必填</strong>的。但仍然建议至少填写 <code>title</code> 和 <code>date</code> 的值。</p><table><thead><tr><th>配置选项</th><th>默认值</th><th>描述</th></tr></thead><tbody><tr><td>title</td><td><code>Markdown</code> 的文件标题</td><td>文章标题，强烈建议填写此选项</td></tr><tr><td>date</td><td>文件创建时的日期时间</td><td>发布时间，强烈建议填写此选项，且最好保证全局唯一</td></tr><tr><td>author</td><td>根 <code>_config.yml</code> 中的 <code>author</code></td><td>文章作者</td></tr><tr><td>img</td><td><code>featureImages</code> 中的某个值</td><td>文章特征图</td></tr><tr><td>top</td><td><code>true</code></td><td>推荐文章（文章是否置顶），如果 <code>top</code> 值为 <code>true</code>，则会作为首页推荐文章</td></tr><tr><td>cover</td><td><code>false</code></td><td>表示该文章是否需要加入到首页轮播封面中</td></tr><tr><td>coverImg</td><td>无</td><td>表示该文章在首页轮播封面需要显示的图片路径，如果没有，则默认使用文章的特色图片</td></tr><tr><td>password</td><td>无</td><td>文章阅读密码，如果要对文章设置阅读验证密码的话，就可以设置 <code>password</code> 的值，该值必须是用 <code>SHA256</code> 加密后的密码，防止被他人识破。前提是在主题的 <code>config.yml</code> 中激活了 <code>verifyPassword</code> 选项</td></tr><tr><td>toc</td><td><code>true</code></td><td>是否开启 TOC，可以针对某篇文章单独关闭 TOC 的功能。前提是在主题的 <code>config.yml</code> 中激活了 <code>toc</code> 选项</td></tr><tr><td>mathjax</td><td><code>false</code></td><td>是否开启数学公式支持 ，本文章是否开启 <code>mathjax</code>，且需要在主题的 <code>_config.yml</code> 文件中也需要开启才行</td></tr><tr><td>summary</td><td>无</td><td>文章摘要，自定义的文章摘要内容，如果这个属性有值，文章卡片摘要就显示这段文字，否则程序会自动截取文章的部分内容作为摘要</td></tr><tr><td>categories</td><td>无</td><td>文章分类，本主题的分类表示宏观上大的分类，只建议一篇文章一个分类</td></tr><tr><td>tags</td><td>无</td><td>文章标签，一篇文章可以多个标签</td></tr></tbody></table><p>实例：</p><pre class=" language-markdown"><code class="language-markdown"><span class="token hr punctuation">---</span>title: 基于Hexo的matery主题搭建博客date: 2020-01-09 16:44:00author: 微笑紫瞳星img: /source/images/xxx.jpgtop: truecover: truecoverImg: /images/1.jpgpassword: toc: falsemathjax: falsesummary: 这是你自定义的文章摘要内容，如果这个属性有值，文章卡片摘要就显示这段文字，否则程序会自动截取文章的部分内容作为摘要categories: 工具tags:  <span class="token list punctuation">-</span> blog  - <span class="token title important">hexo<span class="token punctuation">---</span></span></code></pre><hr><h2 id="百度优化（使百度发现我们的网站）"><a href="#百度优化（使百度发现我们的网站）" class="headerlink" title="百度优化（使百度发现我们的网站）"></a>百度优化（使百度发现我们的网站）</h2><p>登录<a href="https://ziyuan.baidu.com/">百度搜索资源平台</a>， 登录成功之后在 用户中心 –&gt; 站点管理 页面中点击<a href="https://ziyuan.baidu.com/site/siteadd">添加网站</a>，按提示操作。</p><img src="/2021/01/10/ge-ren-jian-li-hexo-bo-ke-matery-zhu-ti-de-guo-cheng-xin-de/8.jpg" class=""><p>选择文件验证，下载文件将它上传到gitee仓库中，然后点击服务→gitee Pages进行更新，更新完成后验证文件就可以正常访问啦。</p><p>然后再把站内的各种连接提交上去：</p><img src="/2021/01/10/ge-ren-jian-li-hexo-bo-ke-matery-zhu-ti-de-guo-cheng-xin-de/9.jpg" class=""><p>自动提交分为主动推送、自动推送和sitemap。</p><p>如何选择链接提交方式<br>1、主动推送：最为快速的提交方式，推荐您将站点当天新产出链接立即通过此方式推送给百度，以保证新链接可以及时被百度收录。<br>2、自动推送：最为便捷的提交方式，请将自动推送的JS代码部署在站点的每一个页面源代码中，部署代码的页面在每次被浏览时，链接会被自动推送给百度。可以与主动推送配合使用。<br>3、sitemap：您可以定期将网站链接放到sitemap中，然后将sitemap提交给百度。百度会周期性的抓取检查您提交的sitemap，对其中的链接进行处理，但收录速度慢于主动推送。<br>4、手动提交：一次性提交链接给百度，可以使用此种方式。</p><p>般主动提交比手动提交效果好，这里介绍主动提交的三种方法从效率上来说：<strong>主动推送&gt;自动推送&gt;sitemap</strong>。</p><p><strong>安装sitemap插件</strong></p><pre class=" language-cmd"><code class="language-cmd">npm install hexo-generator-sitemap --save     npm install hexo-generator-baidu-sitemap --save</code></pre><p><strong>修改博客配置文件</strong></p><p>在根目录配置文件中修改url为你的站点地址</p><pre class=" language-yml"><code class="language-yml"># URL## If your site is put in a subdirectory, set url as 'http://yoursite.com/child' and root as '/child/'url: http://cherryblog.siteroot: /permalink: :title.htmlpermalink_defaults:123456</code></pre><p>执行完之后就会在网站根目录生成sitemap.xml文件和baidusitemap.xml文件，可通过<a href="http://www.cherryblog.site/baidusitemap.xml,%E6%9F%A5%E7%9C%8B%E8%AF%A5%E6%96%87%E4%BB%B6%E6%98%AF%E5%90%A6%E7%94%9F%E6%88%90%EF%BC%8C%E5%85%B6%E4%B8%ADsitemap.xml%E6%96%87%E4%BB%B6%E6%98%AF%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E9%80%9A%E7%94%A8%E7%9A%84%E6%96%87%E4%BB%B6%EF%BC%8Cbaidusitemap.xml%E6%98%AF%E7%99%BE%E5%BA%A6%E4%B8%93%E7%94%A8%E7%9A%84sitemap%E6%96%87%E4%BB%B6%E3%80%82">http://www.cherryblog.site/baidusitemap.xml,查看该文件是否生成，其中sitemap.xml文件是搜索引擎通用的文件，baidusitemap.xml是百度专用的sitemap文件。</a></p><h4 id="主动推送"><a href="#主动推送" class="headerlink" title="主动推送"></a>主动推送</h4><p>安装插件<code>npm install hexo-baidu-url-submit --save</code><br>然后再根目录的配置文件中新增字段</p><pre class=" language-yml"><code class="language-yml">baidu_url_submit:  count: 100 # 提交最新的一个链接  host: www.cherryblog.site # 在百度站长平台中注册的域名  token: 8OGYpxowYnhgVsUM # 请注意这是您的秘钥， 所以请不要把博客源代码发布在公众仓库里!  path: baidu_urls.txt # 文本文档的地址， 新链接会保存在此文本文档里12345</code></pre><p>在加入新的deploy</p><pre class=" language-yml"><code class="language-yml">deploy: - type:baidu_url_submitter</code></pre><p>这样执行<code>hexo deploy</code>的时候，新的链接就会被推送了。</p><h4 id="设置自动推送"><a href="#设置自动推送" class="headerlink" title="设置自动推送"></a>设置自动推送</h4><p>在主题配置文件下设置,将baidu_push设置为true：</p><pre class=" language-yml"><code class="language-yml"># Enable baidu push so that the blog will push the url to baidu automatically which is very helpful for SEObaidu_push: true</code></pre><p>然后就会将一下代码自动推送到百度,这样每次访问博客中的页面就会自动向百度提交sitemap</p><pre class=" language-ejs"><code class="language-ejs">{% if theme.baidu_push %}<script>(function()&#123;    var bp = document.createElement('script');    var curProtocol = window.location.protocol.split(':')[0];    if (curProtocol === 'https') &#123;        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';            &#125;    else &#123;        bp.src = 'http://push.zhanzhang.baidu.com/push.js';    &#125;    var s = document.getElementsByTagName("script")[0];    s.parentNode.insertBefore(bp, s);&#125;)();</script>{% endif %}</code></pre><h4 id="sitemap"><a href="#sitemap" class="headerlink" title="sitemap"></a>sitemap</h4><p>将我们上一步生成的sitemap文件提交到百度就可以了。</p><hr>]]></content>
      
      
      <categories>
          
          <category> 博客 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 博客搭建 </tag>
            
            <tag> Markdown </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
